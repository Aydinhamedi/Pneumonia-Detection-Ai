{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras/TF model\n",
    "<pre>\n",
    " Copyright (c) 2024 Aydin Hamedi\n",
    " \n",
    " This software is released under the MIT License.\n",
    " https://opensource.org/licenses/MIT\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:44.939427800Z",
     "start_time": "2023-12-28T02:27:44.923095500Z"
    },
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "outputs": [],
   "source": [
    "CPU_only = False # True to Force TF to use the cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pylibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:47.128539500Z",
     "start_time": "2023-12-28T02:27:44.940432900Z"
    },
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "if CPU_only:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import cv2\n",
    "import glob \n",
    "import keras\n",
    "import pprint\n",
    "import random\n",
    "import shutil\n",
    "import gzip\n",
    "import glob\n",
    "import pickle\n",
    "import datetime\n",
    "import subprocess\n",
    "import gpu_control\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from hyperas import optim\n",
    "# import tensorflow_addons as tfa\n",
    "from keras_adabound import AdaBound\n",
    "from importlib import reload\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.losses import categorical_crossentropy\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "from model_profiler import model_profiler\n",
    "from keras_gradient_noise import add_gradient_noise\n",
    "from keras.optimizers import SGD, Adam, Adagrad, Adadelta, Nadam, RMSprop, Adamax\n",
    "# from tensorflow_addons.optimizers import Yogi\n",
    "from adabelief_tf import AdaBeliefOptimizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from keras import Sequential\n",
    "from random import randint, choice, shuffle\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard, LambdaCallback\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D,\\\n",
    "    MaxPooling2D,\\\n",
    "        Flatten,\\\n",
    "            Dense,\\\n",
    "                Dropout,\\\n",
    "                    BatchNormalization,\\\n",
    "                        SeparableConv2D,\\\n",
    "                            Input, Concatenate,\\\n",
    "                                GlobalAveragePooling2D,\\\n",
    "                                    CuDNNLSTM, concatenate,\\\n",
    "                                        Reshape, Multiply, \\\n",
    "                                            Conv1D, MaxPooling1D\n",
    "# Utils\n",
    "from Utils.one_cycle import OneCycleLr\n",
    "from Utils.lr_find import LrFinder\n",
    "from Utils.Grad_cam import make_gradcam_heatmap\n",
    "from Utils.print_color_V2_NEW import print_Color_V2\n",
    "from Utils.print_color_V1_OLD import print_Color\n",
    "from Utils.Other import *\n",
    "# Other\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu_instance in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:47.139048Z",
     "start_time": "2023-12-28T02:27:47.116546100Z"
    },
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Directory paths# Directory paths for training, test and validation image data\n",
    "train_dir = 'Database\\\\Train\\\\Data\\\\train'\n",
    "test_dir = 'Database\\\\Train\\\\Data\\\\test'\n",
    "validation_dir = 'Database\\\\Train\\\\Data\\\\val'\n",
    "img_res = [224, 224, 3]\n",
    "# img_res = [324, 324, 3]\n",
    "# img_res = [224, 224, 3]\n",
    "# img_res = [384, 384, 3] # Very slow needs >=24Gb Vram for batch size of 1 (NR!)\n",
    "interpolation_order_IFG = 2\n",
    "categorical_IMP = True\n",
    "Make_EV_DATA = False\n",
    "R_fill_mode = True\n",
    "add_img_grain = True\n",
    "Save_TS = True\n",
    "Use_SMOTE = False # (‚ö†Ô∏èBeta‚ö†Ô∏è)\n",
    "ADBD = 0\n",
    "OP_HDC = False\n",
    "SL_EX = '_V1' # _NONOM_V1 | _V1 | _SDNP_V1\n",
    "LNTS = 0\n",
    "Debug_OUT = False\n",
    "adjust_brightness_Mode = True\n",
    "RANGE_NOM = True # False for 0 to 255 True for 0 to 1 >> use False for models like ConvNeXtXLarge (‚ö†Ô∏èdeprecated‚ö†Ô∏è)\n",
    "scale_data_NP_M = False # (‚ö†Ô∏èdeprecated‚ö†Ô∏è)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:48.287855100Z",
     "start_time": "2023-12-28T02:27:48.252944800Z"
    },
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Policy \"float32\">\n"
     ]
    }
   ],
   "source": [
    "SAVE_TYPE = 'H5'\n",
    "Use_mixed_float16 = False\n",
    "#Other\n",
    "if Use_mixed_float16:\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "else:\n",
    "    tf.keras.mixed_precision.set_global_policy('float32')\n",
    "    \n",
    "print(tf.keras.mixed_precision.global_policy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:31:27.059139500Z",
     "start_time": "2023-12-28T02:27:50.219209700Z"
    },
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33mUsing Def IDG...\u001b[0m\n",
      "Found 23681 images belonging to 2 classes.\n",
      "\u001b[0;33mLoading all images and labels into memory...\u001b[0m\n",
      "\u001b[0;33mMaking categorical data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mGenerating augmented data \u001b[0m\u001b[0;36m[\u001b[0m\u001b[0;32mADBD: \u001b[0m\u001b[0;31m0\u001b[0m\u001b[0;36m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mNormalizing image data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mData type: \u001b[0m\u001b[0;32mfloat32\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mRGB Range: \u001b[0m\u001b[0;34mMin = 0.0\u001b[0m\u001b[0m | \u001b[0m\u001b[0;31mMax = 1.0\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mLabel ratio: \u001b[0m\u001b[0;31m49.35% PNEUMONIA \u001b[0m\u001b[0;35m| \u001b[0m\u001b[0;32m50.65% NORMAL\u001b[0m\n",
      "\u001b[0;33mSetting LNTS...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mOriginal num_samples: \u001b[0m\u001b[0;32m23681\u001b[0m\n",
      "\u001b[0;33mshuffling data...\u001b[0m\n",
      "\u001b[0;33mSaving TS...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mSample dir: \u001b[0m\u001b[0;32mSamples/TSR400_y2024_m02_d10-h22_m17_s08\u001b[0m\n",
      "\u001b[0;32mDone.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Z_SCORE_normalize\n",
    "def Z_SCORE_normalize(arr):\n",
    "   arr = arr.astype('float32')\n",
    "   mean = np.mean(arr)\n",
    "   std_dev = np.std(arr)\n",
    "   arr = (arr - mean) / std_dev\n",
    "   return arr\n",
    "#normalize_TO_RANGE\n",
    "def normalize_TO_RANGE(arr, min_val, max_val):\n",
    "  arr = arr.astype('float32')\n",
    "  arr = (arr - arr.min()) / (arr.max() - arr.min())\n",
    "  arr = arr * (max_val - min_val) + min_val\n",
    "  return arr\n",
    "#scale_data\n",
    "def scale_data_NP(data):\n",
    "    if scale_data_NP_M:\n",
    "        data = data.astype('float32')\n",
    "        data = (data - 127.5) / 127.5\n",
    "        return data\n",
    "    else:\n",
    "        return data / 255\n",
    "#add_image_grain\n",
    "def add_image_grain(image, intensity = 0.01):\n",
    "    # Generate random noise array\n",
    "    noise = np.random.randint(0, 255, size=image.shape, dtype=np.uint8)\n",
    "\n",
    "    # Scale the noise array\n",
    "    scaled_noise = (noise * intensity).astype(np.float32)\n",
    "    # Add the noise to the image\n",
    "    noisy_image = cv2.add(image, scaled_noise)\n",
    "\n",
    "    return noisy_image\n",
    "#apply_clahe_rgb_array\n",
    "def apply_clahe_rgb_array(images, clip_limit=1.8, tile_grid_size=(8, 8)):\n",
    "    # Create a CLAHE object\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    \n",
    "    # Iterate over each image in the array\n",
    "    for i in range(len(images)):\n",
    "        # Split the image into color channels\n",
    "        b, g, r = cv2.split(images[i])\n",
    "        \n",
    "        # Convert the channels to the appropriate format\n",
    "        b = cv2.convertScaleAbs(b)\n",
    "        g = cv2.convertScaleAbs(g)\n",
    "        r = cv2.convertScaleAbs(r)\n",
    "        \n",
    "        # Apply adaptive histogram equalization to each channel\n",
    "        equalized_b = clahe.apply(b)\n",
    "        equalized_g = clahe.apply(g)\n",
    "        equalized_r = clahe.apply(r)\n",
    "\n",
    "        # Merge the equalized channels back into an image\n",
    "        equalized_image = cv2.merge((equalized_b, equalized_g, equalized_r))\n",
    "\n",
    "        # Replace the original image with the equalized image in the array\n",
    "        images[i] = equalized_image\n",
    "\n",
    "    return images\n",
    "#noise_func\n",
    "def noise_func(image):\n",
    "    noise_type = np.random.choice(['L1', 'L2', 'L3', 'none'])\n",
    "    new_image = np.copy(image)\n",
    "    \n",
    "    if noise_type == 'L3':\n",
    "        intensityL2 = random.uniform(-0.05, 0.05)\n",
    "        intensityL1 = random.uniform(-0.04, 0.04)\n",
    "    else:\n",
    "        intensityL2 = random.uniform(-0.06, 0.06)\n",
    "        intensityL1 = random.uniform(-0.04, 0.04)\n",
    "    \n",
    "    block_size_L1 = random.randint(16, 32)\n",
    "    block_size_L2 = random.randint(32, 64)\n",
    "    \n",
    "    if noise_type == 'L2' or noise_type == 'L3':\n",
    "        for i in range(0, image.shape[0], block_size_L2):\n",
    "            for j in range(0, image.shape[1], block_size_L2):\n",
    "                block = image[i:i+block_size_L2, j:j+block_size_L2]\n",
    "                block = (np.random.rand() * intensityL2 + 1) * block\n",
    "                new_image[i:i+block_size_L2, j:j+block_size_L2] = block\n",
    "        image = new_image      \n",
    "        \n",
    "    if noise_type == 'L1' or noise_type == 'L3': \n",
    "        for i in range(0, image.shape[0], block_size_L1):\n",
    "            for j in range(0, image.shape[1], block_size_L1):\n",
    "                block = image[i:i+block_size_L1, j:j+block_size_L1]\n",
    "                block = (np.random.rand() * intensityL1 + 1) * block\n",
    "                new_image[i:i+block_size_L1, j:j+block_size_L1] = block\n",
    "    \n",
    "    if add_img_grain:\n",
    "        intensity = random.uniform(0, 0.045)  # Random intensity between 0 and 0.026\n",
    "        new_image = add_image_grain(new_image, intensity=intensity)\n",
    "    return new_image\n",
    "#shuffle_data\n",
    "def shuffle_data(x, y):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    return x, y\n",
    "#save_images_to_dir\n",
    "def save_images_to_dir(images, labels, dir_path):\n",
    "    # create the directory if it doesn't exist\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    # iterate over the images and labels\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        # get the class label\n",
    "        class_label = np.argmax(label)\n",
    "        # create the file path\n",
    "        file_path = os.path.join(dir_path, f'image_{i}_class_{class_label}.png')\n",
    "        # save the image to the file path\n",
    "        plt.imsave(file_path, image.squeeze())\n",
    "    # compress the directory\n",
    "    shutil.make_archive(dir_path, 'gztar', dir_path)\n",
    "    # remove the original directory\n",
    "    shutil.rmtree(dir_path)\n",
    "#Debug_img_Save\n",
    "def Debug_img_Save(img, id = 'DEF'):    \n",
    "    SITD = np.random.choice(img.shape[0], size=400, replace=False)\n",
    "    S_dir = f'Samples\\\\Debug\\\\{id}\\\\TSR_SUB_400_' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')\n",
    "    print_Color(f'~*[Debug] (DPO) Sample dir: ~*{S_dir}', ['red', 'green'], advanced_mode=True)\n",
    "    save_images_to_dir(normalize_TO_RANGE(img[SITD], 0, 1), img[SITD], S_dir)\n",
    "# Create an ImageDataGenerator for the training set\n",
    "if OP_HDC:\n",
    "    print_Color('Using OP_HDC IDG...', ['yellow'])\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=179,\n",
    "        zoom_range=0.24, \n",
    "        shear_range=0.22,\n",
    "        width_shift_range=0.21,\n",
    "        brightness_range=(0.86, 1.1),\n",
    "        height_shift_range=0.21,\n",
    "        channel_shift_range=100,\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        fill_mode='nearest', # constant\n",
    "        preprocessing_function=noise_func\n",
    "    )\n",
    "else:\n",
    "    print_Color('Using Def IDG...', ['yellow'])\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=179,\n",
    "        zoom_range=0.26, \n",
    "        shear_range=0.25,\n",
    "        width_shift_range=0.25,\n",
    "        brightness_range=(0.78, 1.1),\n",
    "        height_shift_range=0.25,\n",
    "        channel_shift_range=100,\n",
    "        featurewise_center=False,\n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        featurewise_std_normalization=False,\n",
    "        fill_mode='nearest', # constant\n",
    "        preprocessing_function=noise_func\n",
    "    )\n",
    "train_datagen_SM = ImageDataGenerator(\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.07, \n",
    "    shear_range=0.07,\n",
    "    width_shift_range=0.07,\n",
    "    brightness_range=(0.99, 1.01),\n",
    "    height_shift_range=0.07,\n",
    "    channel_shift_range=0,\n",
    "    featurewise_center=False,\n",
    "    interpolation_order=interpolation_order_IFG,\n",
    "    featurewise_std_normalization=False\n",
    ")\n",
    "# Create an iterator for the training set\n",
    "train_generator_SM = train_datagen_SM.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_res[0], img_res[1]),\n",
    "    batch_size=sum([len(files) for r, d, files in os.walk(train_dir)]),\n",
    "    class_mode='binary')\n",
    "# Create an ImageDataGenerator for the validation set (OP)\n",
    "if Make_EV_DATA:\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=False,\n",
    "        zoom_range = 0.01, \n",
    "        width_shift_range=0.01, \n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        height_shift_range=0.01)\n",
    "\n",
    "    # Create an iterator for the validation set\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_res[0], img_res[1]),\n",
    "        batch_size=sum([len(files) for r, d, files in os.walk(validation_dir)]),\n",
    "        class_mode='binary',\n",
    "        color_mode='rgb')\n",
    "\n",
    "    # Create an ImageDataGenerator for the test set\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=False,\n",
    "        zoom_range = 0.01, \n",
    "        width_shift_range=0.01, \n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        height_shift_range=0.01)\n",
    "\n",
    "    # Create an iterator for the test set\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_res[0], img_res[1]),\n",
    "        batch_size=sum([len(files) for r, d, files in os.walk(test_dir)]),\n",
    "        class_mode='binary',\n",
    "        color_mode='rgb')\n",
    "# Load all images and labels into memory\n",
    "print_Color('Loading all images and labels into memory...', ['yellow'])\n",
    "x_train, y_train = next(iter(train_generator_SM))\n",
    "if Make_EV_DATA:\n",
    "    x_val, y_val = next(iter(val_generator))\n",
    "    x_test, y_test = next(iter(test_generator))\n",
    "if Debug_OUT: Debug_img_Save(x_train, 'ST1') # DEBUG\n",
    "# fit parameters from data\n",
    "# train_datagen.fit(x_train)\n",
    "#to_categorical (TEMP)\n",
    "if categorical_IMP:\n",
    "    print_Color('Making categorical data...', ['yellow'])\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    if Make_EV_DATA:\n",
    "        y_val = to_categorical(y_val, num_classes=2)\n",
    "        y_test = to_categorical(y_test, num_classes=2)\n",
    "# Use_SMOTE\n",
    "if Use_SMOTE:\n",
    "    print_Color('SMOTE...', ['yellow'])\n",
    "    # Convert y_train from one-hot encoding to label encoding\n",
    "    y_train_label_encoded = np.argmax(y_train, axis=1)\n",
    "\n",
    "    # Print the original label distribution\n",
    "    unique, counts = np.unique(y_train_label_encoded, return_counts=True)\n",
    "    print_Color(f'~*- Original label distribution: ~*{dict(zip(unique, counts))}', ['normal', 'blue'], advanced_mode=True)\n",
    "\n",
    "    # Use SMOTE to oversample the minority class\n",
    "    smote = SMOTE(random_state=42)\n",
    "    x_train_res, y_train_res_label_encoded = smote.fit_resample(x_train.reshape(x_train.shape[0], -1), y_train_label_encoded)\n",
    "\n",
    "    # Print the resampled label distribution\n",
    "    unique_res, counts_res = np.unique(y_train_res_label_encoded, return_counts=True)\n",
    "    print_Color(f'~*- Resampled label distribution: ~*{dict(zip(unique_res, counts_res))}', ['normal', 'blue'], advanced_mode=True)\n",
    "\n",
    "    # Reshape x_train_res back to the original x_train shape\n",
    "    x_train_res = x_train_res.reshape(-1, x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "\n",
    "    # Convert y_train_res from label encoding back to one-hot encoding\n",
    "    y_train_res = to_categorical(y_train_res_label_encoded)\n",
    "\n",
    "    # Calculate the ratio of two labels after resampling\n",
    "    pneumonia_count = np.sum(y_train_res[:, 1])\n",
    "    total_count = y_train_res.shape[0]\n",
    "    label_ratio_res = pneumonia_count / total_count\n",
    "    label_ratio_percentage_res = label_ratio_res * 100\n",
    "\n",
    "    # Replace the original data with the resampled data\n",
    "    x_train = x_train_res\n",
    "    y_train = y_train_res\n",
    "\n",
    "    # Delete the resampled data to free up memory\n",
    "    del x_train_res, y_train_res_label_encoded, y_train_res\n",
    "# Generating augmented data\n",
    "print_Color(f'~*Generating augmented data ~*[~*ADBD: ~*{str(ADBD)}~*]~*...',\n",
    "            ['yellow', 'cyan', 'green', 'red', 'cyan', 'yellow'],\n",
    "            advanced_mode=True)\n",
    "if ADBD > 0:\n",
    "    for i in range(ADBD):\n",
    "        # ADB_clip_limit Scheduler>>>\n",
    "        if i == 0:\n",
    "            ADB_clip_limit = 0.8\n",
    "        else:\n",
    "            #V1>>>\n",
    "            CL_SLM = 2.4\n",
    "            ADB_clip_limit = max(2 / (i + 1)**CL_SLM, 0.05)\n",
    "            # Try it in win graphing calculator copy and paste:\n",
    "            #  ‚îå-------------‚î¨--‚î¨---------------‚îê\n",
    "            #  ‚îÇ ùë¶=2/(ùë•+1)^ùëß ‚îúOR‚î§ ùë¶=2/(ùë•+1)^2.4 ‚îÇ\n",
    "            #  ‚îî-------------‚î¥--‚î¥---------------‚îò\n",
    "            #V2>>>\n",
    "            # CL_SLM_2 = 1.4\n",
    "            # CL_SLM_Start_2 = 2\n",
    "            # ADB_clip_limit = CL_SLM_Start_2/(i+1)**(i+CL_SLM_2) \n",
    "            # Try it in win graphing calculator copy and paste:\n",
    "            #  ‚îå-----------------‚î¨--‚î¨-------------------‚îê\n",
    "            #  ‚îÇ ùë¶=2/(ùë•+1)^(ùë•+ùëâ) ‚îúOR‚î§ ùë¶=2/(ùë•+1)^(ùë•+1.4) ‚îÇ\n",
    "            #  ‚îî-----------------‚î¥--‚î¥-------------------‚îò\n",
    "        print(f'>   Generating ADB[{i+1}/{ADBD}]...')\n",
    "        # prepare an iterators to scale images\n",
    "        train_iterator = train_datagen.flow(x_train, y_train, batch_size=len(x_train))\n",
    "\n",
    "        # get augmented data\n",
    "        x_train_augmented, y_train_augmented = train_iterator.next()\n",
    "        print(f'>   ‚îú‚îÄ‚îÄ‚îÄApplying adaptive histogram equalization...')\n",
    "        print(f'>   ‚îú‚îÄ‚îÄ‚îÄAdaptive histogram equalization clip limit = {round(ADB_clip_limit, 2)}')\n",
    "        x_train_augmented = np.clip(x_train_augmented, 0, 255) \n",
    "        if Debug_OUT: Debug_img_Save(x_train_augmented, 'ST2') # DEBUG\n",
    "        #print_Color(f'~*>   |---Grayscale range: ~*Min = {np.min(x_train_augmented)}~* | ~*Max = {np.max(x_train_augmented)}', ['normal', 'blue', 'normal', 'red'], advanced_mode=True)\n",
    "        x_train_augmented = apply_clahe_rgb_array(x_train_augmented, clip_limit=ADB_clip_limit) # compensating the image info loss\n",
    "        print(f'>   ‚îî‚îÄ‚îÄ‚îÄAdding the Generated ADB...')\n",
    "        if Debug_OUT: Debug_img_Save(x_train_augmented, 'ST3') # DEBUG\n",
    "        # append augmented data to original data\n",
    "        x_train = np.concatenate([x_train, x_train_augmented])\n",
    "        y_train = np.concatenate([y_train, y_train_augmented])\n",
    "        #free up memory\n",
    "        del y_train_augmented\n",
    "        del x_train_augmented\n",
    "# normalizing \n",
    "print_Color('Normalizing image data...', ['yellow'])\n",
    "if Debug_OUT: Debug_img_Save(x_train, 'ST4') # DEBUG\n",
    "x_train = np.clip(x_train, 0, 255)\n",
    "if RANGE_NOM:\n",
    "    x_train = scale_data_NP(x_train)\n",
    "y_train = np.array(y_train) \n",
    "if Make_EV_DATA:\n",
    "    x_test = np.clip(x_test, 0, 255)  \n",
    "    x_val = np.clip(x_val, 0, 255)  \n",
    "    if RANGE_NOM:\n",
    "        x_val = scale_data_NP(x_val)\n",
    "    y_val = np.array(y_val)  \n",
    "    if RANGE_NOM: \n",
    "        x_test = scale_data_NP(x_test)\n",
    "    y_test = np.array(y_test) \n",
    "if Debug_OUT: Debug_img_Save(x_train, 'ST5') # DEBUG\n",
    "# Check the data type of image data\n",
    "print_Color(f'~*Data type: ~*{x_train.dtype}', ['normal', 'green'], advanced_mode=True)\n",
    "# Check the range of image data\n",
    "print_Color(f'~*RGB Range: ~*Min = {np.min(x_train)}~* | ~*Max = {np.max(x_train)}', ['normal', 'blue', 'normal', 'red'], advanced_mode=True)\n",
    "# Calculate the ratio of two labels\n",
    "if categorical_IMP:\n",
    "    label_sums = np.sum(y_train, axis=0)\n",
    "    label_ratio = label_sums / (np.sum(y_train) + 1e-10)\n",
    "    label_ratio_percentage = label_ratio * 100\n",
    "    print_Color(f'~*Label ratio: ~*{100 - label_ratio_percentage[0]:.2f}% PNEUMONIA ~*| ~*{label_ratio_percentage[0]:.2f}% NORMAL',\n",
    "                ['normal', 'red', 'magenta', 'green'], advanced_mode=True)    \n",
    "print_Color('Setting LNTS...', ['yellow'])\n",
    "# Get the total number of samples in the arrays\n",
    "num_samples = x_train.shape[0]\n",
    "print_Color(f'~*Original num_samples: ~*{num_samples}', ['normal', 'green'], advanced_mode=True)\n",
    "if LNTS != 0:\n",
    "    print_Color(f'~*Applying LNTS of: ~*{LNTS}', ['normal', 'green'], advanced_mode=True)\n",
    "    print_Color(f'~*SNC: ~*{num_samples - LNTS}', ['normal', 'green'], advanced_mode=True)\n",
    "    # Generate random indices to select LNTS samples\n",
    "    indices = np.random.choice(num_samples, size=LNTS, replace=False)\n",
    "    # Select the samples using the generated indices\n",
    "    x_selected = x_train[indices]\n",
    "    y_selected = y_train[indices]\n",
    "    x_train = x_selected\n",
    "    y_train = y_selected\n",
    "    #free up memory\n",
    "    del x_selected\n",
    "    del y_selected\n",
    "    del indices\n",
    "    #Debug\n",
    "    num_samples = x_train.shape[0]\n",
    "    print_Color(f'~*New num_samples: ~*{num_samples}', ['normal', 'green'], advanced_mode=True)\n",
    "# Shuffle the training data\n",
    "print_Color('shuffling data...', ['yellow'])\n",
    "x_train, y_train = shuffle_data(x_train, y_train)\n",
    "#save_images_to_dir    \n",
    "if Save_TS:\n",
    "    print_Color('Saving TS...', ['yellow'])\n",
    "    SITD = np.random.choice(num_samples, size=400, replace=False)\n",
    "    S_dir = 'Samples/TSR400_' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')\n",
    "    print_Color(f'~*Sample dir: ~*{S_dir}', ['normal', 'green'], advanced_mode=True)\n",
    "    if RANGE_NOM:\n",
    "        if scale_data_NP_M:\n",
    "            save_images_to_dir((x_train[SITD] + 1) / 2.0, y_train[SITD], S_dir)\n",
    "        else:\n",
    "            save_images_to_dir(x_train[SITD], y_train[SITD], S_dir)\n",
    "    else:\n",
    "        save_images_to_dir(x_train[SITD] / 255, y_train[SITD], S_dir)\n",
    "print_Color('Done.', ['green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save EV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'Database\\\\Test\\\\Data\\\\x_val{SL_EX}.npy', x_val)\n",
    "np.save(f'Database\\\\Test\\\\Data\\\\y_val{SL_EX}.npy', y_val)\n",
    "np.save(f'Database\\\\Test\\\\Data\\\\x_test{SL_EX}.npy', x_test)\n",
    "np.save(f'Database\\\\Test\\\\Data\\\\y_test{SL_EX}.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load EV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:31:27.380088800Z",
     "start_time": "2023-12-28T02:31:27.270860200Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "x_val = np.load(f'Database\\\\Test\\\\Data\\\\x_val{SL_EX}.npy')\n",
    "y_val = np.load(f'Database\\\\Test\\\\Data\\\\y_val{SL_EX}.npy')\n",
    "x_test = np.load(f'Database\\\\Test\\\\Data\\\\x_test{SL_EX}.npy')\n",
    "y_test = np.load(f'Database\\\\Test\\\\Data\\\\y_test{SL_EX}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x2000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Select a subset of your data\n",
    "subset_size_pixels = 40  # Change this to the size of the subset you want for individual pixels\n",
    "subset_size_mean = 800  # Change this to the size of the subset you want for mean RGB values\n",
    "indices_pixels = np.random.choice(x_train.shape[0], subset_size_pixels, replace=False)\n",
    "indices_mean = np.random.choice(x_train.shape[0], subset_size_mean, replace=False)\n",
    "subset_pixels = x_train[indices_pixels]\n",
    "subset_mean = x_train[indices_mean]\n",
    "\n",
    "# Reshape the data for calculating Z-scores\n",
    "reshaped_data_pixels = subset_pixels.reshape(-1, subset_pixels.shape[-1])\n",
    "reshaped_data_mean = subset_mean.reshape(-1, subset_mean.shape[-1])\n",
    "\n",
    "# Calculate the mean intensity\n",
    "mean_intensity_pixels = reshaped_data_pixels.mean(axis=-1)\n",
    "mean_intensity_mean = reshaped_data_mean.mean(axis=-1)\n",
    "\n",
    "# Stack the mean intensity with the reshaped data\n",
    "data_with_mean_pixels = np.hstack([reshaped_data_pixels, mean_intensity_pixels.reshape(-1, 1)])\n",
    "data_with_mean_mean = np.hstack([reshaped_data_mean, mean_intensity_mean.reshape(-1, 1)])\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores_pixels = np.abs(zscore(data_with_mean_pixels, axis=0))\n",
    "z_scores_mean = np.abs(zscore(data_with_mean_mean, axis=0))\n",
    "\n",
    "# Identify outliers\n",
    "outliers_pixels = np.where(z_scores_pixels > 3)\n",
    "outliers_mean = np.where(z_scores_mean > 3)\n",
    "\n",
    "# Create a 3D scatter plot for RGB channels\n",
    "fig = plt.figure(figsize=(10, 20))\n",
    "\n",
    "# Plot for individual pixels\n",
    "ax = fig.add_subplot(211, projection='3d')\n",
    "ax.scatter(z_scores_pixels[:, 0], z_scores_pixels[:, 1], z_scores_pixels[:, 2], alpha=0.1)\n",
    "ax.scatter(z_scores_pixels[outliers_pixels[0], 0], z_scores_pixels[outliers_pixels[0], 1], z_scores_pixels[outliers_pixels[0], 2], color='red')\n",
    "ax.set_title('Z-Score Scatter Plot for Individual Pixels')\n",
    "ax.set_xlabel('Red')\n",
    "ax.set_ylabel('Green')\n",
    "ax.set_zlabel('Blue')\n",
    "\n",
    "# Plot for mean RGB values\n",
    "ax = fig.add_subplot(212, projection='3d')\n",
    "ax.scatter(z_scores_mean[:, 0], z_scores_mean[:, 1], z_scores_mean[:, 2], alpha=0.1)\n",
    "ax.scatter(z_scores_mean[outliers_mean[0], 0], z_scores_mean[outliers_mean[0], 1], z_scores_mean[outliers_mean[0], 2], color='red')\n",
    "ax.set_title('Z-Score Scatter Plot for Mean RGB Values')\n",
    "ax.set_xlabel('Red')\n",
    "ax.set_ylabel('Green')\n",
    "ax.set_zlabel('Blue')\n",
    "\n",
    "# Density plot of the mean intensity\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(data=z_scores_pixels[:, -1], fill=True)\n",
    "plt.title('Density Plot of Z-Scores for Mean Intensity for Individual Pixels')\n",
    "plt.xlabel('Z-Score')\n",
    "\n",
    "sns.kdeplot(data=z_scores_mean[:, -1], fill=True)\n",
    "plt.title('Density Plot of Z-Scores for Mean Intensity for Mean RGB Values')\n",
    "plt.xlabel('Z-Score')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1\n",
    "```\n",
    "recommended: ‚ö†Ô∏è\n",
    "statuses: Ready\n",
    "Working: ‚úÖ\n",
    "Max fine tuned acc: ‚âÖ95.1\n",
    "Max fine tuned acc TLRev2: N/A\n",
    "type: transfer learning>>>(EfficientNetB7)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import EfficientNetB7\n",
    "\n",
    "EfficientNet_M = EfficientNetB7(include_top=True, input_shape=(img_res[0], img_res[1], img_res[2]), weights=None, classes=2, classifier_activation='softmax')\n",
    "# define new model\n",
    "model = Model(inputs=EfficientNet_M.inputs, outputs=EfficientNet_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)\n",
    "# opt = SGD(learning_rate=0.008, momentum=0.85, decay=0.001)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.1\n",
    "```\n",
    "recommended: ‚ùå\n",
    "statuses: S.Ready (can improve)\n",
    "Working: ‚ùå\n",
    "Max fine tuned acc: ‚âÖ93.2\n",
    "Max fine tuned acc TLRev2: N/A\n",
    "type: transfer learning>>>(ConvNeXtLarge)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ConvNeXtLarge\n",
    "\n",
    "ConvNeXtLarge_M = ConvNeXtLarge(include_top=False, input_shape=(img_res[0], img_res[1], img_res[2]), weights='imagenet', classes=2, classifier_activation='softmax', include_preprocessing=False)\n",
    "# define new model\n",
    "model = Model(inputs=ConvNeXtLarge_M.inputs, outputs=ConvNeXtLarge_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)\n",
    "# opt = SGD(learning_rate=0.008, momentum=0.85, decay=0.001)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "### Rev1.2\n",
    "```\n",
    "recommended: ‚úÖ\n",
    "statuses: Ready\n",
    "Working: ‚úÖ\n",
    "Max fine tuned acc: 95.3\n",
    "Max fine tuned acc TLRev2: 97.12\n",
    "type: transfer learning>>>(EfficientNetB7::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T17:34:12.077394600Z",
     "start_time": "2023-12-27T17:34:05.068171500Z"
    },
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Total layers in the base model:  806\n",
      "Freezing 0 layers in the base model...\n",
      "Percentage of the base model that is frozen: 0.00%\n",
      "Total model layers:  814\n",
      "Model: \"model\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     Trainable  \n",
      "=============================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               Y          \n",
      "                                )]                                                                           \n",
      "                                                                                                             \n",
      " stem_conv (Conv2D)             (None, 112, 112, 64  1728        ['input_1[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 64  256         ['stem_conv[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_activation (Activation)   (None, 112, 112, 64  0           ['stem_bn[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 64  576        ['stem_activation[0][0]']        Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 64  256        ['block1a_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_activation (Activation  (None, 112, 112, 64  0          ['block1a_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_se_squeeze (GlobalAver  (None, 64)          0           ['block1a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 64)     0           ['block1a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 16)     1040        ['block1a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 64)     1088        ['block1a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 64  0           ['block1a_activation[0][0]',     Y          \n",
      "                                )                                 'block1a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 32  2048        ['block1a_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1a_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1b_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1a_project_bn[0][0]']     Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1b_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1b_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1b_activation (Activation  (None, 112, 112, 32  0          ['block1b_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1b_se_squeeze (GlobalAver  (None, 32)          0           ['block1b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1b_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1b_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1b_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1b_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1b_activation[0][0]',     Y          \n",
      "                                )                                 'block1b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1b_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1b_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1b_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1b_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1b_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1b_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1b_add (Add)              (None, 112, 112, 32  0           ['block1b_drop[0][0]',           Y          \n",
      "                                )                                 'block1a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block1c_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1b_add[0][0]']            Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1c_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1c_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1c_activation (Activation  (None, 112, 112, 32  0          ['block1c_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1c_se_squeeze (GlobalAver  (None, 32)          0           ['block1c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1c_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1c_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1c_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1c_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1c_activation[0][0]',     Y          \n",
      "                                )                                 'block1c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1c_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1c_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1c_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1c_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1c_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1c_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1c_add (Add)              (None, 112, 112, 32  0           ['block1c_drop[0][0]',           Y          \n",
      "                                )                                 'block1b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block1d_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1c_add[0][0]']            Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1d_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1d_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1d_activation (Activation  (None, 112, 112, 32  0          ['block1d_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1d_se_squeeze (GlobalAver  (None, 32)          0           ['block1d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1d_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1d_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1d_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1d_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1d_activation[0][0]',     Y          \n",
      "                                )                                 'block1d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1d_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1d_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1d_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1d_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1d_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1d_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1d_add (Add)              (None, 112, 112, 32  0           ['block1d_drop[0][0]',           Y          \n",
      "                                )                                 'block1c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 19  6144        ['block1d_add[0][0]']            Y          \n",
      "                                2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 19  768        ['block2a_expand_conv[0][0]']    Y          \n",
      " ization)                       2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_expand_activation (Act  (None, 112, 112, 19  0          ['block2a_expand_bn[0][0]']      Y          \n",
      " ivation)                       2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 192)  1728       ['block2a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 192)  768        ['block2a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_activation (Activation  (None, 56, 56, 192)  0          ['block2a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_se_squeeze (GlobalAver  (None, 192)         0           ['block2a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 192)  0           ['block2a_activation[0][0]',     Y          \n",
      "                                                                  'block2a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 48)   9216        ['block2a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_expand_activation (Act  (None, 56, 56, 288)  0          ['block2b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_activation (Activation  (None, 56, 56, 288)  0          ['block2b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_se_squeeze (GlobalAver  (None, 288)         0           ['block2b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2b_activation[0][0]',     Y          \n",
      "                                                                  'block2b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_add (Add)              (None, 56, 56, 48)   0           ['block2b_drop[0][0]',           Y          \n",
      "                                                                  'block2a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block2c_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2c_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2c_expand_activation (Act  (None, 56, 56, 288)  0          ['block2c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2c_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2c_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2c_activation (Activation  (None, 56, 56, 288)  0          ['block2c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2c_se_squeeze (GlobalAver  (None, 288)         0           ['block2c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2c_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2c_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2c_activation[0][0]',     Y          \n",
      "                                                                  'block2c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2c_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2c_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2c_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_add (Add)              (None, 56, 56, 48)   0           ['block2c_drop[0][0]',           Y          \n",
      "                                                                  'block2b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2d_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2d_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2d_expand_activation (Act  (None, 56, 56, 288)  0          ['block2d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2d_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2d_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2d_activation (Activation  (None, 56, 56, 288)  0          ['block2d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2d_se_squeeze (GlobalAver  (None, 288)         0           ['block2d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2d_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2d_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2d_activation[0][0]',     Y          \n",
      "                                                                  'block2d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2d_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2d_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2d_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_add (Add)              (None, 56, 56, 48)   0           ['block2d_drop[0][0]',           Y          \n",
      "                                                                  'block2c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2e_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2e_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2e_expand_activation (Act  (None, 56, 56, 288)  0          ['block2e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2e_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2e_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2e_activation (Activation  (None, 56, 56, 288)  0          ['block2e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2e_se_squeeze (GlobalAver  (None, 288)         0           ['block2e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2e_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2e_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2e_activation[0][0]',     Y          \n",
      "                                                                  'block2e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2e_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2e_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2e_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_add (Add)              (None, 56, 56, 48)   0           ['block2e_drop[0][0]',           Y          \n",
      "                                                                  'block2d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2f_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2f_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2f_expand_activation (Act  (None, 56, 56, 288)  0          ['block2f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2f_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2f_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2f_activation (Activation  (None, 56, 56, 288)  0          ['block2f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2f_se_squeeze (GlobalAver  (None, 288)         0           ['block2f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2f_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2f_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2f_activation[0][0]',     Y          \n",
      "                                                                  'block2f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2f_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2f_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2f_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_add (Add)              (None, 56, 56, 48)   0           ['block2f_drop[0][0]',           Y          \n",
      "                                                                  'block2e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2g_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2g_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2g_expand_activation (Act  (None, 56, 56, 288)  0          ['block2g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2g_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2g_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2g_activation (Activation  (None, 56, 56, 288)  0          ['block2g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2g_se_squeeze (GlobalAver  (None, 288)         0           ['block2g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2g_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2g_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2g_activation[0][0]',     Y          \n",
      "                                                                  'block2g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2g_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2g_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2g_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_add (Add)              (None, 56, 56, 48)   0           ['block2g_drop[0][0]',           Y          \n",
      "                                                                  'block2f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block3a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_expand_activation (Act  (None, 56, 56, 288)  0          ['block3a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 288)  7200       ['block3a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 288)  1152       ['block3a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_activation (Activation  (None, 28, 28, 288)  0          ['block3a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_se_squeeze (GlobalAver  (None, 288)         0           ['block3a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block3a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block3a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block3a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 288)  0           ['block3a_activation[0][0]',     Y          \n",
      "                                                                  'block3a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 80)   23040       ['block3a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_expand_activation (Act  (None, 28, 28, 480)  0          ['block3b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_activation (Activation  (None, 28, 28, 480)  0          ['block3b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_se_squeeze (GlobalAver  (None, 480)         0           ['block3b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3b_activation[0][0]',     Y          \n",
      "                                                                  'block3b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_add (Add)              (None, 28, 28, 80)   0           ['block3b_drop[0][0]',           Y          \n",
      "                                                                  'block3a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block3c_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3c_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3c_expand_activation (Act  (None, 28, 28, 480)  0          ['block3c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3c_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3c_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3c_activation (Activation  (None, 28, 28, 480)  0          ['block3c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3c_se_squeeze (GlobalAver  (None, 480)         0           ['block3c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3c_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3c_activation[0][0]',     Y          \n",
      "                                                                  'block3c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3c_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3c_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3c_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_add (Add)              (None, 28, 28, 80)   0           ['block3c_drop[0][0]',           Y          \n",
      "                                                                  'block3b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3d_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3d_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3d_expand_activation (Act  (None, 28, 28, 480)  0          ['block3d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3d_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3d_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3d_activation (Activation  (None, 28, 28, 480)  0          ['block3d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3d_se_squeeze (GlobalAver  (None, 480)         0           ['block3d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3d_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3d_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3d_activation[0][0]',     Y          \n",
      "                                                                  'block3d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3d_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3d_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3d_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_add (Add)              (None, 28, 28, 80)   0           ['block3d_drop[0][0]',           Y          \n",
      "                                                                  'block3c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3e_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3e_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3e_expand_activation (Act  (None, 28, 28, 480)  0          ['block3e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3e_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3e_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3e_activation (Activation  (None, 28, 28, 480)  0          ['block3e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3e_se_squeeze (GlobalAver  (None, 480)         0           ['block3e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3e_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3e_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3e_activation[0][0]',     Y          \n",
      "                                                                  'block3e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3e_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3e_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3e_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_add (Add)              (None, 28, 28, 80)   0           ['block3e_drop[0][0]',           Y          \n",
      "                                                                  'block3d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3f_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3f_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3f_expand_activation (Act  (None, 28, 28, 480)  0          ['block3f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3f_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3f_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3f_activation (Activation  (None, 28, 28, 480)  0          ['block3f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3f_se_squeeze (GlobalAver  (None, 480)         0           ['block3f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3f_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3f_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3f_activation[0][0]',     Y          \n",
      "                                                                  'block3f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3f_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3f_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3f_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_add (Add)              (None, 28, 28, 80)   0           ['block3f_drop[0][0]',           Y          \n",
      "                                                                  'block3e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3g_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3g_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3g_expand_activation (Act  (None, 28, 28, 480)  0          ['block3g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3g_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3g_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3g_activation (Activation  (None, 28, 28, 480)  0          ['block3g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3g_se_squeeze (GlobalAver  (None, 480)         0           ['block3g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3g_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3g_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3g_activation[0][0]',     Y          \n",
      "                                                                  'block3g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3g_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3g_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3g_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_add (Add)              (None, 28, 28, 80)   0           ['block3g_drop[0][0]',           Y          \n",
      "                                                                  'block3f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block4a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_expand_activation (Act  (None, 28, 28, 480)  0          ['block4a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_activation (Activation  (None, 14, 14, 480)  0          ['block4a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_se_squeeze (GlobalAver  (None, 480)         0           ['block4a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4a_activation[0][0]',     Y          \n",
      "                                                                  'block4a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 160)  76800       ['block4a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_expand_activation (Act  (None, 14, 14, 960)  0          ['block4b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_activation (Activation  (None, 14, 14, 960)  0          ['block4b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_se_squeeze (GlobalAver  (None, 960)         0           ['block4b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4b_activation[0][0]',     Y          \n",
      "                                                                  'block4b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_add (Add)              (None, 14, 14, 160)  0           ['block4b_drop[0][0]',           Y          \n",
      "                                                                  'block4a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_expand_activation (Act  (None, 14, 14, 960)  0          ['block4c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_activation (Activation  (None, 14, 14, 960)  0          ['block4c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_se_squeeze (GlobalAver  (None, 960)         0           ['block4c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4c_activation[0][0]',     Y          \n",
      "                                                                  'block4c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4c_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_add (Add)              (None, 14, 14, 160)  0           ['block4c_drop[0][0]',           Y          \n",
      "                                                                  'block4b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4d_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4d_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4d_expand_activation (Act  (None, 14, 14, 960)  0          ['block4d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4d_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4d_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4d_activation (Activation  (None, 14, 14, 960)  0          ['block4d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4d_se_squeeze (GlobalAver  (None, 960)         0           ['block4d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4d_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4d_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4d_activation[0][0]',     Y          \n",
      "                                                                  'block4d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4d_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4d_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4d_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_add (Add)              (None, 14, 14, 160)  0           ['block4d_drop[0][0]',           Y          \n",
      "                                                                  'block4c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4e_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4e_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4e_expand_activation (Act  (None, 14, 14, 960)  0          ['block4e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4e_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4e_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4e_activation (Activation  (None, 14, 14, 960)  0          ['block4e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4e_se_squeeze (GlobalAver  (None, 960)         0           ['block4e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4e_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4e_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4e_activation[0][0]',     Y          \n",
      "                                                                  'block4e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4e_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4e_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4e_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_add (Add)              (None, 14, 14, 160)  0           ['block4e_drop[0][0]',           Y          \n",
      "                                                                  'block4d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4f_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4f_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4f_expand_activation (Act  (None, 14, 14, 960)  0          ['block4f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4f_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4f_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4f_activation (Activation  (None, 14, 14, 960)  0          ['block4f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4f_se_squeeze (GlobalAver  (None, 960)         0           ['block4f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4f_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4f_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4f_activation[0][0]',     Y          \n",
      "                                                                  'block4f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4f_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4f_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4f_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_add (Add)              (None, 14, 14, 160)  0           ['block4f_drop[0][0]',           Y          \n",
      "                                                                  'block4e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4g_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4g_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4g_expand_activation (Act  (None, 14, 14, 960)  0          ['block4g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4g_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4g_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4g_activation (Activation  (None, 14, 14, 960)  0          ['block4g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4g_se_squeeze (GlobalAver  (None, 960)         0           ['block4g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4g_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4g_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4g_activation[0][0]',     Y          \n",
      "                                                                  'block4g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4g_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4g_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4g_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_add (Add)              (None, 14, 14, 160)  0           ['block4g_drop[0][0]',           Y          \n",
      "                                                                  'block4f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4h_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4h_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4h_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4h_expand_activation (Act  (None, 14, 14, 960)  0          ['block4h_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4h_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4h_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4h_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4h_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4h_activation (Activation  (None, 14, 14, 960)  0          ['block4h_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4h_se_squeeze (GlobalAver  (None, 960)         0           ['block4h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4h_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4h_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4h_activation[0][0]',     Y          \n",
      "                                                                  'block4h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4h_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4h_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4h_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_add (Add)              (None, 14, 14, 160)  0           ['block4h_drop[0][0]',           Y          \n",
      "                                                                  'block4g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4i_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4h_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4i_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4i_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4i_expand_activation (Act  (None, 14, 14, 960)  0          ['block4i_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4i_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4i_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4i_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4i_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4i_activation (Activation  (None, 14, 14, 960)  0          ['block4i_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4i_se_squeeze (GlobalAver  (None, 960)         0           ['block4i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4i_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4i_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4i_activation[0][0]',     Y          \n",
      "                                                                  'block4i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4i_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4i_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4i_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_add (Add)              (None, 14, 14, 160)  0           ['block4i_drop[0][0]',           Y          \n",
      "                                                                  'block4h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4j_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4i_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4j_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4j_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4j_expand_activation (Act  (None, 14, 14, 960)  0          ['block4j_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4j_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4j_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4j_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4j_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4j_activation (Activation  (None, 14, 14, 960)  0          ['block4j_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4j_se_squeeze (GlobalAver  (None, 960)         0           ['block4j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4j_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4j_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4j_activation[0][0]',     Y          \n",
      "                                                                  'block4j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4j_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4j_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4j_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_add (Add)              (None, 14, 14, 160)  0           ['block4j_drop[0][0]',           Y          \n",
      "                                                                  'block4i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4j_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block5a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_expand_activation (Act  (None, 14, 14, 960)  0          ['block5a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 960)  24000      ['block5a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block5a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_activation (Activation  (None, 14, 14, 960)  0          ['block5a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_se_squeeze (GlobalAver  (None, 960)         0           ['block5a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block5a_activation[0][0]',     Y          \n",
      "                                                                  'block5a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 224)  215040      ['block5a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5a_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5b_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5b_expand_activation (Act  (None, 14, 14, 1344  0          ['block5b_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5b_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5b_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5b_activation (Activation  (None, 14, 14, 1344  0          ['block5b_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5b_se_squeeze (GlobalAver  (None, 1344)        0           ['block5b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5b_activation[0][0]',     Y          \n",
      "                                )                                 'block5b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_add (Add)              (None, 14, 14, 224)  0           ['block5b_drop[0][0]',           Y          \n",
      "                                                                  'block5a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5b_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5c_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5c_expand_activation (Act  (None, 14, 14, 1344  0          ['block5c_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5c_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5c_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5c_activation (Activation  (None, 14, 14, 1344  0          ['block5c_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5c_se_squeeze (GlobalAver  (None, 1344)        0           ['block5c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5c_activation[0][0]',     Y          \n",
      "                                )                                 'block5c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5c_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_add (Add)              (None, 14, 14, 224)  0           ['block5c_drop[0][0]',           Y          \n",
      "                                                                  'block5b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5d_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5c_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5d_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5d_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5d_expand_activation (Act  (None, 14, 14, 1344  0          ['block5d_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5d_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5d_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5d_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5d_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5d_activation (Activation  (None, 14, 14, 1344  0          ['block5d_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5d_se_squeeze (GlobalAver  (None, 1344)        0           ['block5d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5d_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5d_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5d_activation[0][0]',     Y          \n",
      "                                )                                 'block5d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5d_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5d_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5d_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_add (Add)              (None, 14, 14, 224)  0           ['block5d_drop[0][0]',           Y          \n",
      "                                                                  'block5c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5e_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5d_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5e_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5e_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5e_expand_activation (Act  (None, 14, 14, 1344  0          ['block5e_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5e_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5e_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5e_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5e_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5e_activation (Activation  (None, 14, 14, 1344  0          ['block5e_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5e_se_squeeze (GlobalAver  (None, 1344)        0           ['block5e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5e_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5e_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5e_activation[0][0]',     Y          \n",
      "                                )                                 'block5e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5e_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5e_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5e_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_add (Add)              (None, 14, 14, 224)  0           ['block5e_drop[0][0]',           Y          \n",
      "                                                                  'block5d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5f_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5e_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5f_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5f_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5f_expand_activation (Act  (None, 14, 14, 1344  0          ['block5f_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5f_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5f_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5f_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5f_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5f_activation (Activation  (None, 14, 14, 1344  0          ['block5f_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5f_se_squeeze (GlobalAver  (None, 1344)        0           ['block5f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5f_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5f_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5f_activation[0][0]',     Y          \n",
      "                                )                                 'block5f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5f_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5f_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5f_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_add (Add)              (None, 14, 14, 224)  0           ['block5f_drop[0][0]',           Y          \n",
      "                                                                  'block5e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5g_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5f_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5g_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5g_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5g_expand_activation (Act  (None, 14, 14, 1344  0          ['block5g_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5g_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5g_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5g_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5g_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5g_activation (Activation  (None, 14, 14, 1344  0          ['block5g_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5g_se_squeeze (GlobalAver  (None, 1344)        0           ['block5g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5g_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5g_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5g_activation[0][0]',     Y          \n",
      "                                )                                 'block5g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5g_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5g_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5g_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_add (Add)              (None, 14, 14, 224)  0           ['block5g_drop[0][0]',           Y          \n",
      "                                                                  'block5f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5h_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5g_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5h_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5h_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5h_expand_activation (Act  (None, 14, 14, 1344  0          ['block5h_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5h_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5h_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5h_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5h_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5h_activation (Activation  (None, 14, 14, 1344  0          ['block5h_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5h_se_squeeze (GlobalAver  (None, 1344)        0           ['block5h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5h_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5h_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5h_activation[0][0]',     Y          \n",
      "                                )                                 'block5h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5h_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5h_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5h_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_add (Add)              (None, 14, 14, 224)  0           ['block5h_drop[0][0]',           Y          \n",
      "                                                                  'block5g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5i_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5h_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5i_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5i_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5i_expand_activation (Act  (None, 14, 14, 1344  0          ['block5i_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5i_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5i_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5i_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5i_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5i_activation (Activation  (None, 14, 14, 1344  0          ['block5i_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5i_se_squeeze (GlobalAver  (None, 1344)        0           ['block5i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5i_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5i_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5i_activation[0][0]',     Y          \n",
      "                                )                                 'block5i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5i_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5i_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5i_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_add (Add)              (None, 14, 14, 224)  0           ['block5i_drop[0][0]',           Y          \n",
      "                                                                  'block5h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5j_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5i_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5j_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5j_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5j_expand_activation (Act  (None, 14, 14, 1344  0          ['block5j_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5j_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5j_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5j_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5j_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5j_activation (Activation  (None, 14, 14, 1344  0          ['block5j_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5j_se_squeeze (GlobalAver  (None, 1344)        0           ['block5j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5j_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5j_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5j_activation[0][0]',     Y          \n",
      "                                )                                 'block5j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5j_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5j_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5j_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_add (Add)              (None, 14, 14, 224)  0           ['block5j_drop[0][0]',           Y          \n",
      "                                                                  'block5i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5j_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block6a_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block6a_expand_activation (Act  (None, 14, 14, 1344  0          ['block6a_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 1344)  33600       ['block6a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 1344)  5376        ['block6a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_activation (Activation  (None, 7, 7, 1344)  0           ['block6a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_se_squeeze (GlobalAver  (None, 1344)        0           ['block6a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block6a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block6a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block6a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 1344)   0           ['block6a_activation[0][0]',     Y          \n",
      "                                                                  'block6a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 384)    516096      ['block6a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_activation (Activation  (None, 7, 7, 2304)  0           ['block6b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_se_squeeze (GlobalAver  (None, 2304)        0           ['block6b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6b_activation[0][0]',     Y          \n",
      "                                                                  'block6b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_add (Add)              (None, 7, 7, 384)    0           ['block6b_drop[0][0]',           Y          \n",
      "                                                                  'block6a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_activation (Activation  (None, 7, 7, 2304)  0           ['block6c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_se_squeeze (GlobalAver  (None, 2304)        0           ['block6c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6c_activation[0][0]',     Y          \n",
      "                                                                  'block6c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6c_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_add (Add)              (None, 7, 7, 384)    0           ['block6c_drop[0][0]',           Y          \n",
      "                                                                  'block6b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_activation (Activation  (None, 7, 7, 2304)  0           ['block6d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_se_squeeze (GlobalAver  (None, 2304)        0           ['block6d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6d_activation[0][0]',     Y          \n",
      "                                                                  'block6d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6d_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_add (Add)              (None, 7, 7, 384)    0           ['block6d_drop[0][0]',           Y          \n",
      "                                                                  'block6c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6e_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6e_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6e_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6e_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6e_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6e_activation (Activation  (None, 7, 7, 2304)  0           ['block6e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6e_se_squeeze (GlobalAver  (None, 2304)        0           ['block6e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6e_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6e_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6e_activation[0][0]',     Y          \n",
      "                                                                  'block6e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6e_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6e_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6e_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_add (Add)              (None, 7, 7, 384)    0           ['block6e_drop[0][0]',           Y          \n",
      "                                                                  'block6d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6f_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6f_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6f_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6f_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6f_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6f_activation (Activation  (None, 7, 7, 2304)  0           ['block6f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6f_se_squeeze (GlobalAver  (None, 2304)        0           ['block6f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6f_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6f_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6f_activation[0][0]',     Y          \n",
      "                                                                  'block6f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6f_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6f_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6f_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_add (Add)              (None, 7, 7, 384)    0           ['block6f_drop[0][0]',           Y          \n",
      "                                                                  'block6e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6g_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6g_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6g_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6g_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6g_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6g_activation (Activation  (None, 7, 7, 2304)  0           ['block6g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6g_se_squeeze (GlobalAver  (None, 2304)        0           ['block6g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6g_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6g_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6g_activation[0][0]',     Y          \n",
      "                                                                  'block6g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6g_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6g_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6g_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_add (Add)              (None, 7, 7, 384)    0           ['block6g_drop[0][0]',           Y          \n",
      "                                                                  'block6f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6h_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6h_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6h_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6h_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6h_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6h_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6h_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6h_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6h_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6h_activation (Activation  (None, 7, 7, 2304)  0           ['block6h_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6h_se_squeeze (GlobalAver  (None, 2304)        0           ['block6h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6h_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6h_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6h_activation[0][0]',     Y          \n",
      "                                                                  'block6h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6h_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6h_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6h_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_add (Add)              (None, 7, 7, 384)    0           ['block6h_drop[0][0]',           Y          \n",
      "                                                                  'block6g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6i_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6h_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6i_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6i_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6i_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6i_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6i_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6i_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6i_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6i_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6i_activation (Activation  (None, 7, 7, 2304)  0           ['block6i_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6i_se_squeeze (GlobalAver  (None, 2304)        0           ['block6i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6i_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6i_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6i_activation[0][0]',     Y          \n",
      "                                                                  'block6i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6i_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6i_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6i_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_add (Add)              (None, 7, 7, 384)    0           ['block6i_drop[0][0]',           Y          \n",
      "                                                                  'block6h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6j_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6i_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6j_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6j_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6j_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6j_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6j_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6j_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6j_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6j_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6j_activation (Activation  (None, 7, 7, 2304)  0           ['block6j_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6j_se_squeeze (GlobalAver  (None, 2304)        0           ['block6j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6j_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6j_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6j_activation[0][0]',     Y          \n",
      "                                                                  'block6j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6j_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6j_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6j_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_add (Add)              (None, 7, 7, 384)    0           ['block6j_drop[0][0]',           Y          \n",
      "                                                                  'block6i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6k_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6j_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6k_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6k_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6k_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6k_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6k_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6k_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6k_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6k_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6k_activation (Activation  (None, 7, 7, 2304)  0           ['block6k_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6k_se_squeeze (GlobalAver  (None, 2304)        0           ['block6k_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6k_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6k_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6k_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6k_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6k_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6k_activation[0][0]',     Y          \n",
      "                                                                  'block6k_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6k_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6k_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6k_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6k_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6k_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6k_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_add (Add)              (None, 7, 7, 384)    0           ['block6k_drop[0][0]',           Y          \n",
      "                                                                  'block6j_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6l_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6k_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6l_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6l_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6l_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6l_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6l_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6l_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6l_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6l_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6l_activation (Activation  (None, 7, 7, 2304)  0           ['block6l_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6l_se_squeeze (GlobalAver  (None, 2304)        0           ['block6l_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6l_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6l_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6l_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6l_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6l_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6l_activation[0][0]',     Y          \n",
      "                                                                  'block6l_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6l_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6l_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6l_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6l_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6l_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6l_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_add (Add)              (None, 7, 7, 384)    0           ['block6l_drop[0][0]',           Y          \n",
      "                                                                  'block6k_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6m_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6l_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6m_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6m_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6m_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6m_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6m_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6m_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6m_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6m_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6m_activation (Activation  (None, 7, 7, 2304)  0           ['block6m_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6m_se_squeeze (GlobalAver  (None, 2304)        0           ['block6m_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6m_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6m_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6m_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6m_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6m_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6m_activation[0][0]',     Y          \n",
      "                                                                  'block6m_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6m_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6m_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6m_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6m_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6m_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6m_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_add (Add)              (None, 7, 7, 384)    0           ['block6m_drop[0][0]',           Y          \n",
      "                                                                  'block6l_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6m_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block7a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_expand_activation (Act  (None, 7, 7, 2304)  0           ['block7a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  20736       ['block7a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block7a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_activation (Activation  (None, 7, 7, 2304)  0           ['block7a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_se_squeeze (GlobalAver  (None, 2304)        0           ['block7a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block7a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block7a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block7a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block7a_activation[0][0]',     Y          \n",
      "                                                                  'block7a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 640)    1474560     ['block7a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7b_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7b_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7b_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7b_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7b_activation (Activation  (None, 7, 7, 3840)  0           ['block7b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7b_se_squeeze (GlobalAver  (None, 3840)        0           ['block7b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7b_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7b_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7b_activation[0][0]',     Y          \n",
      "                                                                  'block7b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7b_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7b_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7b_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_add (Add)              (None, 7, 7, 640)    0           ['block7b_drop[0][0]',           Y          \n",
      "                                                                  'block7a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block7c_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7c_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7c_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7c_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7c_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7c_activation (Activation  (None, 7, 7, 3840)  0           ['block7c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7c_se_squeeze (GlobalAver  (None, 3840)        0           ['block7c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7c_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7c_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7c_activation[0][0]',     Y          \n",
      "                                                                  'block7c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7c_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7c_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7c_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_add (Add)              (None, 7, 7, 640)    0           ['block7c_drop[0][0]',           Y          \n",
      "                                                                  'block7b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7d_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7d_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7d_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7d_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7d_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7d_activation (Activation  (None, 7, 7, 3840)  0           ['block7d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7d_se_squeeze (GlobalAver  (None, 3840)        0           ['block7d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7d_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7d_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7d_activation[0][0]',     Y          \n",
      "                                                                  'block7d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7d_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7d_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7d_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_add (Add)              (None, 7, 7, 640)    0           ['block7d_drop[0][0]',           Y          \n",
      "                                                                  'block7c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " top_conv (Conv2D)              (None, 7, 7, 2560)   1638400     ['block7d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 2560)   10240       ['top_conv[0][0]']               Y          \n",
      "                                                                                                             \n",
      " top_activation (Activation)    (None, 7, 7, 2560)   0           ['top_bn[0][0]']                 Y          \n",
      "                                                                                                             \n",
      " FC_INPUT_Avg-Pooling (GlobalAv  (None, 2560)        0           ['top_activation[0][0]']         Y          \n",
      " eragePooling2D)                                                                                             \n",
      "                                                                                                             \n",
      " FC_C_Dense-L1-512 (Dense)      (None, 512)          1311232     ['FC_INPUT_Avg-Pooling[0][0]']   Y          \n",
      "                                                                                                             \n",
      " FC_C_Dropout-L1-0.1 (Dropout)  (None, 512)          0           ['FC_C_Dense-L1-512[0][0]']      Y          \n",
      "                                                                                                             \n",
      " FC_C_Avg-BatchNormalization-L1  (None, 512)         2048        ['FC_C_Dropout-L1-0.1[0][0]']    Y          \n",
      "  (BatchNormalization)                                                                                       \n",
      "                                                                                                             \n",
      " FC_C_Dense-L2-512 (Dense)      (None, 512)          262656      ['FC_C_Avg-BatchNormalization-L  Y          \n",
      "                                                                 1[0][0]']                                   \n",
      "                                                                                                             \n",
      " FC_C_Avg-BatchNormalization-L2  (None, 512)         2048        ['FC_C_Dense-L2-512[0][0]']      Y          \n",
      "  (BatchNormalization)                                                                                       \n",
      "                                                                                                             \n",
      " FC_C_Dense-L3-128 (Dense)      (None, 128)          65664       ['FC_C_Avg-BatchNormalization-L  Y          \n",
      "                                                                 2[0][0]']                                   \n",
      "                                                                                                             \n",
      " FC_OUTPUT_Dense-2 (Dense)      (None, 2)            258         ['FC_C_Dense-L3-128[0][0]']      Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 65,741,586\n",
      "Trainable params: 65,428,818\n",
      "Non-trainable params: 312,768\n",
      "_____________________________________________________________________________________________________________\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from efficientnet.keras import EfficientNetB7 as KENB7\n",
    "# FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENB7(input_shape=(\n",
    "        img_res[0], img_res[1], img_res[2]), weights='noisy-student', include_top=False)\n",
    "    print('Total layers in the base model: ', len(base_model.layers))\n",
    "    print(f'Freezing {freeze_layers} layers in the base model...')\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) /\n",
    "                         len(base_model.layers)) * 100\n",
    "    print(\n",
    "        f'Percentage of the base model that is frozen: {frozen_percentage:.2f}%')\n",
    "    # adding CDL>>>\n",
    "    #GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name='FC_INPUT_Avg-Pooling')(base_model.output)\n",
    "    #Dense\n",
    "    Dense_L1 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.008),\n",
    "                     name='FC_C_Dense-L1-512'\n",
    "                     )(base_model_FT)\n",
    "    #Dropout\n",
    "    Dropout_L1 = Dropout(0.125,\n",
    "                         name='FC_C_Dropout-L1-0.1'\n",
    "                         )(Dense_L1)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L1'\n",
    "                                      )(Dropout_L1)\n",
    "    #Dense\n",
    "    Dense_L2 = Dense(512, activation='swish',\n",
    "                     kernel_regularizer=l2(0.004),\n",
    "                     name='FC_C_Dense-L2-512'\n",
    "                     )(BatchNorm_L2)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L2'\n",
    "                                      )(Dense_L2)\n",
    "    #Dense\n",
    "    Dense_L3 = Dense(128, activation='relu',\n",
    "                     name='FC_C_Dense-L3-128'\n",
    "                     )(BatchNorm_L3)\n",
    "    #Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation='softmax',\n",
    "                        name='FC_OUTPUT_Dense-2')(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB7_NS = Model(\n",
    "        inputs=base_model.input, outputs=predictions)\n",
    "    print('Total model layers: ', len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9, nesterov=False)\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.3\n",
    "```\n",
    "recommended: ‚ùå\n",
    "statuses: Test\n",
    "Working: ‚úÖ\n",
    "Max fine tuned acc: ‚ö†Ô∏è\n",
    "Max fine tuned acc TLRev2: ‚ö†Ô∏è\n",
    "type: transfer learning>>>(EfficientNetB7|Xception::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB7 as KENB7\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "#FUNC\n",
    "def Combo_Model(freeze_layers1, freeze_layers2):\n",
    "    # Define a common input\n",
    "    common_input = Input(shape=(img_res[0], img_res[1], img_res[2]))\n",
    "\n",
    "    # Base model 1\n",
    "    base_model1 = KENB7(input_shape=(img_res[0], img_res[1], img_res[2]), weights='noisy-student', include_top=False)\n",
    "    # base_model1.load_weights('models\\Ready\\Other\\EfficientNetB7_PRET.h5', by_name=True, skip_mismatch=True)\n",
    "    base_model1_out = base_model1(common_input)\n",
    "    \n",
    "    # Base model 2\n",
    "    base_model2 = Xception(input_shape=(img_res[0], img_res[1], img_res[2]), weights='imagenet', include_top=False)\n",
    "    # base_model1.load_weights('models\\Ready\\Other\\Xception_PRET.h5', by_name=True, skip_mismatch=True)\n",
    "    base_model2_out = base_model2(common_input)\n",
    "\n",
    "    print('Total base_model1 layers: ', len(base_model1.layers))\n",
    "    print('Total base_model2 layers: ', len(base_model2.layers))\n",
    "    \n",
    "    # Freeze the specified number of layers in both models\n",
    "    for layer in base_model1.layers[:freeze_layers1]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model2.layers[:freeze_layers2]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest in both models\n",
    "    for layer in base_model1.layers[freeze_layers1:]:\n",
    "        layer.trainable = True\n",
    "    for layer in base_model2.layers[freeze_layers2:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Combine the output of the two base models\n",
    "    combined = concatenate([Dense(512,\n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=l2(0.01)\n",
    "                                  )(GlobalAveragePooling2D()(base_model1_out)),\n",
    "                            Dense(512,\n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=l2(0.01)\n",
    "                                  )(GlobalAveragePooling2D()(base_model2_out))])\n",
    "\n",
    "    # adding CDL\n",
    "    Dense_L1 = Dense(1024, activation='relu', kernel_regularizer=l2(0.02))(combined)\n",
    "    Dropout_L1 = Dropout(0.4)(Dense_L1) \n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation='relu', kernel_regularizer=l2(0.003))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation='relu')(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation='softmax')(Dense_L3)\n",
    "\n",
    "    combo_model = Model(inputs=common_input, outputs=predictions)   \n",
    "    print('Total model layers: ', len(combo_model.layers))\n",
    "    \n",
    "    #OPT/compile\n",
    "    opt = SGD(momentum=0.9)\n",
    "    combo_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return combo_model\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers_1 = 0\n",
    "freeze_layers_2 = 0\n",
    "model = Combo_Model(freeze_layers_1, freeze_layers_2)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.4\n",
    "```\n",
    "recommended: ‚ö†Ô∏è\n",
    "statuses: Test\n",
    "Working: ‚úÖ\n",
    "Max fine tuned acc: ‚ö†Ô∏è\n",
    "Max fine tuned acc TLRev2: ‚âÖ95.64\n",
    "type: transfer learning>>>(EfficientNetV2XL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_efficientnet_v2 import EfficientNetV2XL\n",
    "\n",
    "EfficientNet_M = EfficientNetV2XL(input_shape=(img_res[0], img_res[1], img_res[2]), pretrained='imagenet21k-ft1k', num_classes=2, dropout=0.4)\n",
    "# define new model\n",
    "model = Model(inputs=EfficientNet_M.inputs, outputs=EfficientNet_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)\n",
    "# opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-2, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "# opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-3)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "freeze_layers = 0\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.5 (The best one)\n",
    "```\n",
    "recommended: ‚úÖ\n",
    "statuses: Ready\n",
    "Working: ‚úÖ\n",
    "Max fine tuned acc: 95.3\n",
    "Max fine tuned acc TLRev2: 97.12\n",
    "type: transfer learning>>>(EfficientNetB4::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB4 as KENB4\n",
    "# FUNC\n",
    "def Eff_B4_NS(freeze_layers):\n",
    "    base_model = KENB4(input_shape=(\n",
    "        img_res[0], img_res[1], img_res[2]), weights='noisy-student', include_top=False)\n",
    "    print('Total layers in the base model: ', len(base_model.layers))\n",
    "    print(f'Freezing {freeze_layers} layers in the base model...')\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) /\n",
    "                         len(base_model.layers)) * 100\n",
    "    print(\n",
    "        f'Percentage of the base model that is frozen: {frozen_percentage:.2f}%')\n",
    "    # adding CDL>>>\n",
    "    #GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name='FC_INPUT_Avg-Pooling')(base_model.output)\n",
    "    #Dense\n",
    "    Dense_L1 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.02),\n",
    "                     name='FC_C_Dense-L1-512'\n",
    "                     )(base_model_FT)\n",
    "    #Dropout\n",
    "    Dropout_L1 = Dropout(0.1,\n",
    "                         name='FC_C_Dropout-L1-0.1'\n",
    "                         )(Dense_L1)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L1'\n",
    "                                      )(Dropout_L1)\n",
    "    #Dense\n",
    "    Dense_L2 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.01),\n",
    "                     name='FC_C_Dense-L2-512'\n",
    "                     )(BatchNorm_L2)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L2'\n",
    "                                      )(Dense_L2)\n",
    "    #Dense\n",
    "    Dense_L3 = Dense(128, activation='relu',\n",
    "                     name='FC_C_Dense-L3-128'\n",
    "                     )(BatchNorm_L3)\n",
    "    #Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation='softmax',\n",
    "                        name='FC_OUTPUT_Dense-2')(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB4_NS = Model(\n",
    "        inputs=base_model.input, outputs=predictions)\n",
    "    print('Total model layers: ', len(model_EfficientNetB4_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9, nesterov=False)\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB4_NS.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB4_NS\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B4_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetL2 as KENBL2\n",
    "#FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENBL2(input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "                        weights='./download/Models/EFN_L2/efficientnet-l2_noisy-student_notop.h5',\n",
    "                        include_top=False,\n",
    "                        drop_connect_rate=0)\n",
    "    print('Total layers in the base model: ', len(base_model.layers))\n",
    "    print(f'Freezing {freeze_layers} layers in the base model...')\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) / len(base_model.layers)) * 100\n",
    "    print(f'Percentage of the base model that is frozen: {frozen_percentage:.2f}%')\n",
    "    # adding CDL\n",
    "    base_model_FT = GlobalAveragePooling2D()(base_model.output)\n",
    "    Dense_L1 = Dense(512, activation='relu', kernel_regularizer=l2(0.02))(base_model_FT)\n",
    "    Dropout_L1 = Dropout(0.1)(Dense_L1) \n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation='relu')(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation='softmax')(Dense_L3)\n",
    "\n",
    "    model_EfficientNetB7_NS = Model(inputs=base_model.input, outputs=predictions)   \n",
    "    print('Total model layers: ', len(model_EfficientNetB7_NS.layers))\n",
    "    #OPT/compile\n",
    "    opt = SGD(momentum=0.9)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer = opt,  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:31:32.994176700Z",
     "start_time": "2023-12-28T02:31:27.381088600Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB7 as KENB7\n",
    "# FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENB7(input_shape=(\n",
    "        img_res[0], img_res[1], img_res[2]), weights=None, include_top=False)\n",
    "    print('Total layers in the base model: ', len(base_model.layers))\n",
    "    print(f'Freezing {freeze_layers} layers in the base model...')\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) /\n",
    "                         len(base_model.layers)) * 100\n",
    "    print(\n",
    "        f'Percentage of the base model that is frozen: {frozen_percentage:.2f}%')\n",
    "    # adding CDL>>>\n",
    "    #GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name='FC_INPUT_Avg-Pooling')(base_model.output)\n",
    "    #Dense\n",
    "    Dense_L1 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.02),\n",
    "                     name='FC_C_Dense-L1-512'\n",
    "                     )(base_model_FT)\n",
    "    #Dropout\n",
    "    Dropout_L1 = Dropout(0.1,\n",
    "                         name='FC_C_Dropout-L1-0.1'\n",
    "                         )(Dense_L1)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name='FC_C_Avg-Pooling-L1'\n",
    "                                      )(Dropout_L1)\n",
    "    #Dense\n",
    "    Dense_L2 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.01),\n",
    "                     name='FC_C_Dense-L2-512'\n",
    "                     )(BatchNorm_L2)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name='FC_C_Avg-Pooling-L2'\n",
    "                                      )(Dense_L2)\n",
    "    #Dense\n",
    "    Dense_L3 = Dense(128, activation='relu',\n",
    "                     name='FC_C_Dense-L3-128'\n",
    "                     )(BatchNorm_L3)\n",
    "    #Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation='softmax',\n",
    "                        name='FC_OUTPUT_Dense-2')(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB7_NS = Model(\n",
    "        inputs=base_model.input, outputs=predictions)\n",
    "    print('Total model layers: ', len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9, nesterov=False)\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ConvNeXtXLarge\n",
    "from keras.layers import Lambda\n",
    "#FUNC\n",
    "def Eff_B7_NS():\n",
    "    # Add a Lambda layer at the beginning to scale the input\n",
    "    input = Input(shape=(img_res[0], img_res[1], img_res[2]))\n",
    "    x = Lambda(lambda image: image * 255)(input)\n",
    "    \n",
    "    base_model = ConvNeXtXLarge(include_top=False, weights='imagenet', classes=2, classifier_activation='softmax', include_preprocessing=True)(x)\n",
    "    # adding CDL\n",
    "    base_model_FT = GlobalAveragePooling2D()(base_model)\n",
    "    Dense_L1 = Dense(512, activation='relu', kernel_regularizer=l2(0.02))(base_model_FT)\n",
    "    Dropout_L1 = Dropout(0.1)(Dense_L1) \n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation='relu')(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation='softmax')(Dense_L3)\n",
    "\n",
    "    model_EfficientNetB7_NS = Model(inputs=input, outputs=predictions)   \n",
    "    print('Total model layers: ', len(model_EfficientNetB7_NS.layers))\n",
    "    #OPT/compile\n",
    "    opt = SGD(momentum=0.9)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt,  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "model = Eff_B7_NS()\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB5 as KENB5\n",
    "# FUNC\n",
    "def Eff_B5_NS(freeze_layers):\n",
    "    base_model = KENB5(input_shape=(\n",
    "        img_res[0], img_res[1], img_res[2]), weights='noisy-student', include_top=False)\n",
    "    print('Total layers in the base model: ', len(base_model.layers))\n",
    "    print(f'Freezing {freeze_layers} layers in the base model...')\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) /\n",
    "                         len(base_model.layers)) * 100\n",
    "    print(\n",
    "        f'Percentage of the base model that is frozen: {frozen_percentage:.2f}%')\n",
    "    # adding CDL>>>\n",
    "    #GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name='FC_INPUT_Avg-Pooling')(base_model.output)\n",
    "    #Dense\n",
    "    Dense_L1 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.008),\n",
    "                     name='FC_C_Dense-L1-512'\n",
    "                     )(base_model_FT)\n",
    "    #Dropout\n",
    "    Dropout_L1 = Dropout(0.125,\n",
    "                         name='FC_C_Dropout-L1-0.1'\n",
    "                         )(Dense_L1)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L1'\n",
    "                                      )(Dropout_L1)\n",
    "    #Dense\n",
    "    Dense_L2 = Dense(512, activation='swish',\n",
    "                     kernel_regularizer=l2(0.004),\n",
    "                     name='FC_C_Dense-L2-512'\n",
    "                     )(BatchNorm_L2)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L2'\n",
    "                                      )(Dense_L2)\n",
    "    #Dense\n",
    "    Dense_L3 = Dense(128, activation='relu',\n",
    "                     name='FC_C_Dense-L3-128'\n",
    "                     )(BatchNorm_L3)\n",
    "    #Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation='softmax',\n",
    "                        name='FC_OUTPUT_Dense-2')(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB7_NS = Model(\n",
    "        inputs=base_model.input, outputs=predictions)\n",
    "    print('Total model layers: ', len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9, nesterov=False)\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B5_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "#CONF/Other\n",
    "LRF_OPT = SGD(momentum=0.9)\n",
    "LFR_batch_size = 1  # or any other batch size that fits in your memory\n",
    "LRF_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(LFR_batch_size)\n",
    "# Instantiate LrFinder\n",
    "lr_find = LrFinder(model, LRF_OPT, tf.keras.losses.categorical_crossentropy)\n",
    "\n",
    "# Start range_test\n",
    "lr_find.range_test(LRF_dataset)\n",
    "lr_find.plot_lrs(skip_end=0, suggestion=True, show_grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_img_file = 'model_1.png'\n",
    "keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Save (Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Aydin Hamedi\n",
    "# \n",
    "# This software is released under the MIT License.\n",
    "# https://opensource.org/licenses/MIT\n",
    "import json\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import get as get_optimizer\n",
    "\n",
    "def save_model(model, optimizer, filename):\n",
    "    \"\"\"\n",
    "    Save a Keras model's architecture and weights into a single gzipped file.\n",
    "\n",
    "    Args:\n",
    "    model (tf.keras.Model): The Keras model to save.\n",
    "    optimizer (str): The name of the Keras optimizer to use.\n",
    "    filename (str): The filename to use for the saved file.\n",
    "    \"\"\"\n",
    "    # Save the architecture, weights and optimizer into a dictionary\n",
    "    model_dict = {\n",
    "        'architecture': model.to_json(),\n",
    "        'weights': [w.tolist() for w in model.get_weights()],\n",
    "        'optimizer': optimizer.get_config()['name']\n",
    "    }\n",
    "\n",
    "    # Write the dictionary to a gzipped file\n",
    "    with gzip.GzipFile(f'{filename}.gz', 'w') as f:\n",
    "        f.write(json.dumps(model_dict).encode('utf-8'))\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Load a Keras model's architecture and weights from a gzipped file.\n",
    "\n",
    "    Args:\n",
    "    filename (str): The filename of the saved file.\n",
    "\n",
    "    Returns:\n",
    "    tf.keras.Model: The loaded Keras model.\n",
    "    \"\"\"\n",
    "    # Read the dictionary from the gzipped file\n",
    "    with gzip.GzipFile(f'{filename}.gz', 'r') as f:\n",
    "        model_dict = json.loads(f.read().decode('utf-8'))\n",
    "\n",
    "    # Create a model from the architecture\n",
    "    model = model_from_json(model_dict['architecture'])\n",
    "\n",
    "    # Set the model's weights\n",
    "    model.set_weights([np.array(w) for w in model_dict['weights']])\n",
    "\n",
    "    # Get the optimizer\n",
    "    optimizer = get_optimizer(model_dict['optimizer'])\n",
    "\n",
    "    # Compile the model with the loaded optimizer\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "save_model(model, SGD(), 'PAI_model_REV2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras\n",
    "# Configuration\n",
    "PRMC = False\n",
    "freeze_from_opposite = False\n",
    "Extra_EXT = '_T'\n",
    "freeze_layers = 0  \n",
    "randomly_frozen_layers = 0 \n",
    "freeze_last_seven = False  \n",
    "# CEC_opt = Adagrad()\n",
    "# CEC_opt = Yogi()\n",
    "# CEC_opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-3)\n",
    "CEC_opt = SGD(momentum=0.9, nesterov=False)\n",
    "# CEC_opt = Adam()\n",
    "# Main\n",
    "try:\n",
    "    if SAVE_TYPE == 'TF':\n",
    "        model = load_model(f'PAI_model{Extra_EXT}', compile=PRMC)\n",
    "    else:\n",
    "        model = load_model(f'PAI_model{Extra_EXT}.h5', compile=PRMC)\n",
    "except (ImportError, IOError) as e:\n",
    "    print(f'\\033[91mfailed to load the model ERROR:\\n{e}')\n",
    "else:\n",
    "    print('\\033[92mLoading model done.')\n",
    "    if not PRMC:\n",
    "        print('Compiling the AI model...\\033[0m')\n",
    "        \n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "        \n",
    "        # Select random layers to freeze\n",
    "        frozen_layer_indices = random.sample(range(len(model.layers)), randomly_frozen_layers)\n",
    "        \n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if i in frozen_layer_indices:\n",
    "                layer.trainable = False\n",
    "            else:\n",
    "                if freeze_from_opposite and (i > len(model.layers) - freeze_layers):\n",
    "                    layer.trainable = False\n",
    "                elif (not freeze_from_opposite) and i < freeze_layers:\n",
    "                    layer.trainable = False\n",
    "                else:\n",
    "                    layer.trainable = True\n",
    "        \n",
    "        for layer in model.layers[-7:]:\n",
    "            layer.trainable = not freeze_last_seven\n",
    "            \n",
    "        model.compile(optimizer=CEC_opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.summary(show_trainable=True, expand_nested=True)\n",
    "        print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('PAI_model_weights.h5')\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[-7:]:\n",
    "    if hasattr(layer, 'kernel_initializer') and hasattr(layer, 'bias_initializer'):\n",
    "        weight_initializer = layer.kernel_initializer\n",
    "        bias_initializer = layer.bias_initializer\n",
    "\n",
    "        old_weights, old_biases = layer.get_weights()\n",
    "\n",
    "        layer.set_weights([\n",
    "            weight_initializer(shape=old_weights.shape),\n",
    "            bias_initializer(shape=len(old_biases))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rev2 (THE BEST)\n",
    "```\n",
    "Working: ‚úÖ\n",
    "Other:\n",
    " + Tensorboard works.\n",
    " + Perverts overfitting.\n",
    " + Lower memory usage.\n",
    " - Slow training.\n",
    " + Achieving higher acc.\n",
    " - Some models dont work.\n",
    "```\n",
    "- TODO:\n",
    "    - add Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T07:04:23.573633300Z",
     "start_time": "2023-12-28T02:31:32.468641900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "\u001b[0;33m\n",
      "Setup Verbose:\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSetting TensorBoard Log dir to \u001b[0m\u001b[0;32m[logs/fit/y2024_m02_d10-h22_m26_s36]\u001b[0m\u001b[0;36m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mUse_extended_tensorboard \u001b[0m\u001b[0;32m[False]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mDebug_OUTPUT_DPS \u001b[0m\u001b[0;32m[True]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mOneCycleLr_UFTS \u001b[0m\u001b[0;32m[False]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0;33mSetup Verbose END.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m1\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 0)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Fitting ImageDataGenerator...\u001b[0m\n",
      "\u001b[0;33m- ImageDataGenerator fit done.\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;31m- Debug DP Sample dir: \u001b[0m\u001b[0;32mSamples/TSR_SUB_400_y2024_m02_d10-h22_m31_s37\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/5\n",
      "256/256 [==============================] - 94s 296ms/step - loss: 8.9916 - accuracy: 0.6338 - val_loss: 7.7967 - val_accuracy: 0.6426\n",
      "Epoch 2/5\n",
      "256/256 [==============================] - 74s 287ms/step - loss: 6.1337 - accuracy: 0.8259 - val_loss: 4.7673 - val_accuracy: 0.9087\n",
      "Epoch 3/5\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 3.9763 - accuracy: 0.8716 - val_loss: 3.2140 - val_accuracy: 0.9087\n",
      "Epoch 4/5\n",
      "256/256 [==============================] - 73s 284ms/step - loss: 2.8076 - accuracy: 0.8950 - val_loss: 2.4469 - val_accuracy: 0.9119\n",
      "Epoch 5/5\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 2.3100 - accuracy: 0.9197 - val_loss: 2.2669 - val_accuracy: 0.9071\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-004-0.9119.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9119\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m2.4469\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.000000 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.911859\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32minf \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m2.4468944073\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m706.31 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m385.10 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m321.21 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [1] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m2\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 5)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 77s 286ms/step - loss: 2.3668 - accuracy: 0.8865 - val_loss: 2.0180 - val_accuracy: 0.9327\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 1.7620 - accuracy: 0.8967 - val_loss: 1.4830 - val_accuracy: 0.8542\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 70s 275ms/step - loss: 1.2376 - accuracy: 0.9116 - val_loss: 1.1233 - val_accuracy: 0.9247\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.9137 - accuracy: 0.9351 - val_loss: 0.8593 - val_accuracy: 0.9327\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.7719 - accuracy: 0.9514 - val_loss: 0.7985 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-006-0.9327.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9327\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m2.0180\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.911859 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.932692\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m2.4468944073 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m2.0180051327\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m432.36 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m362.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m69.49 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [2] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m3\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 10)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 11/15\n",
      "256/256 [==============================] - 77s 284ms/step - loss: 1.9864 - accuracy: 0.8862 - val_loss: 1.7049 - val_accuracy: 0.9006\n",
      "Epoch 12/15\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 1.5094 - accuracy: 0.8855 - val_loss: 1.3095 - val_accuracy: 0.8638\n",
      "Epoch 13/15\n",
      "256/256 [==============================] - 74s 288ms/step - loss: 1.0756 - accuracy: 0.9089 - val_loss: 0.8998 - val_accuracy: 0.9279\n",
      "Epoch 14/15\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.8140 - accuracy: 0.9226 - val_loss: 0.7405 - val_accuracy: 0.9279\n",
      "Epoch 15/15\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.6749 - accuracy: 0.9421 - val_loss: 0.7089 - val_accuracy: 0.9231\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-013-0.9279.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9279\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.8998\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9326922894. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m2.0180051327 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.8998246789\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m432.99 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m366.10 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m66.88 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [3] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m4\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 15)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 76s 281ms/step - loss: 0.9486 - accuracy: 0.8918 - val_loss: 0.8013 - val_accuracy: 0.9215\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.7551 - accuracy: 0.9028 - val_loss: 0.6535 - val_accuracy: 0.9423\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 70s 274ms/step - loss: 0.5823 - accuracy: 0.9116 - val_loss: 0.5232 - val_accuracy: 0.9279\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 70s 274ms/step - loss: 0.4692 - accuracy: 0.9268 - val_loss: 0.5104 - val_accuracy: 0.8910\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 70s 274ms/step - loss: 0.3963 - accuracy: 0.9407 - val_loss: 0.4346 - val_accuracy: 0.9215\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-017-0.9423.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.6535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.932692 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.942308\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.8998246789 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.6534923315\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m422.79 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m358.88 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m63.91 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [4] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m5\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 20)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 21/25\n",
      "256/256 [==============================] - 76s 282ms/step - loss: 0.6513 - accuracy: 0.9023 - val_loss: 0.5251 - val_accuracy: 0.9487\n",
      "Epoch 22/25\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.5438 - accuracy: 0.9146 - val_loss: 0.4947 - val_accuracy: 0.9006\n",
      "Epoch 23/25\n",
      "256/256 [==============================] - 70s 274ms/step - loss: 0.4469 - accuracy: 0.9197 - val_loss: 0.3740 - val_accuracy: 0.9263\n",
      "Epoch 24/25\n",
      "256/256 [==============================] - 70s 275ms/step - loss: 0.3559 - accuracy: 0.9294 - val_loss: 0.3444 - val_accuracy: 0.9199\n",
      "Epoch 25/25\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.3051 - accuracy: 0.9480 - val_loss: 0.3006 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-021-0.9487.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.5252\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.942308 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.948718\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.6534923315 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.5251612067\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m423.41 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m358.89 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m64.52 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [5] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m6\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 25)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - 76s 282ms/step - loss: 0.5957 - accuracy: 0.9026 - val_loss: 0.4776 - val_accuracy: 0.9375\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.5126 - accuracy: 0.9058 - val_loss: 0.4120 - val_accuracy: 0.9199\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.4235 - accuracy: 0.9167 - val_loss: 0.3756 - val_accuracy: 0.9054\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - 71s 274ms/step - loss: 0.3236 - accuracy: 0.9373 - val_loss: 0.3085 - val_accuracy: 0.9343\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.2646 - accuracy: 0.9509 - val_loss: 0.2954 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-030-0.9407.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2954\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9487179518. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.5251612067 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.2953910232\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m423.00 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m360.17 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m62.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [6] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m7\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 30)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 31/35\n",
      "256/256 [==============================] - 76s 281ms/step - loss: 0.3706 - accuracy: 0.9121 - val_loss: 0.3335 - val_accuracy: 0.9263\n",
      "Epoch 32/35\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.3320 - accuracy: 0.9160 - val_loss: 0.3178 - val_accuracy: 0.9391\n",
      "Epoch 33/35\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.2857 - accuracy: 0.9304 - val_loss: 0.2395 - val_accuracy: 0.9423\n",
      "Epoch 34/35\n",
      "256/256 [==============================] - 70s 275ms/step - loss: 0.2240 - accuracy: 0.9465 - val_loss: 0.2295 - val_accuracy: 0.9375\n",
      "Epoch 35/35\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.1803 - accuracy: 0.9585 - val_loss: 0.2400 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-033-0.9423.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2395\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9487179518. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.2953910232 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.2394996583\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m424.72 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m360.85 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m63.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [7] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m8\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 35)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 36/40\n",
      "256/256 [==============================] - 76s 283ms/step - loss: 0.2897 - accuracy: 0.9189 - val_loss: 0.2349 - val_accuracy: 0.9407\n",
      "Epoch 37/40\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.2718 - accuracy: 0.9299 - val_loss: 0.2442 - val_accuracy: 0.9151\n",
      "Epoch 38/40\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.2210 - accuracy: 0.9399 - val_loss: 0.2340 - val_accuracy: 0.9183\n",
      "Epoch 39/40\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1810 - accuracy: 0.9543 - val_loss: 0.2087 - val_accuracy: 0.9391\n",
      "Epoch 40/40\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1488 - accuracy: 0.9570 - val_loss: 0.2215 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-040-0.9487.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2215\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9487179518. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.2394996583 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.2214751095\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m425.09 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m360.66 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m64.43 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [8] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m9\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 40)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 41/45\n",
      "256/256 [==============================] - 76s 282ms/step - loss: 0.2390 - accuracy: 0.9248 - val_loss: 0.1881 - val_accuracy: 0.9487\n",
      "Epoch 42/45\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.2255 - accuracy: 0.9309 - val_loss: 0.2069 - val_accuracy: 0.9343\n",
      "Epoch 43/45\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1903 - accuracy: 0.9436 - val_loss: 0.1883 - val_accuracy: 0.9263\n",
      "Epoch 44/45\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1580 - accuracy: 0.9526 - val_loss: 0.2372 - val_accuracy: 0.9279\n",
      "Epoch 45/45\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1054 - accuracy: 0.9709 - val_loss: 0.2970 - val_accuracy: 0.8990\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-041-0.9487.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1881\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9487179518. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.2214751095 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1881304681\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m426.24 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m360.37 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m65.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [9] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m10\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 45)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 46/50\n",
      "256/256 [==============================] - 76s 281ms/step - loss: 0.2512 - accuracy: 0.9204 - val_loss: 0.1974 - val_accuracy: 0.9391\n",
      "Epoch 47/50\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.2516 - accuracy: 0.9216 - val_loss: 0.2488 - val_accuracy: 0.9071\n",
      "Epoch 48/50\n",
      "256/256 [==============================] - 70s 274ms/step - loss: 0.2008 - accuracy: 0.9397 - val_loss: 0.2710 - val_accuracy: 0.9038\n",
      "Epoch 49/50\n",
      "256/256 [==============================] - 70s 274ms/step - loss: 0.1534 - accuracy: 0.9561 - val_loss: 0.3517 - val_accuracy: 0.8494\n",
      "Epoch 50/50\n",
      "256/256 [==============================] - 70s 275ms/step - loss: 0.1231 - accuracy: 0.9658 - val_loss: 0.2678 - val_accuracy: 0.9135\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-046-0.9391.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9391\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1974\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9487179518. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1881304681. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m421.48 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m358.11 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m63.37 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [10] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m11\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 50)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 51/55\n",
      "256/256 [==============================] - 76s 283ms/step - loss: 0.2550 - accuracy: 0.9194 - val_loss: 0.2137 - val_accuracy: 0.9311\n",
      "Epoch 52/55\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.2314 - accuracy: 0.9287 - val_loss: 0.2029 - val_accuracy: 0.9439\n",
      "Epoch 53/55\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1955 - accuracy: 0.9402 - val_loss: 0.2266 - val_accuracy: 0.9231\n",
      "Epoch 54/55\n",
      "256/256 [==============================] - 71s 279ms/step - loss: 0.1637 - accuracy: 0.9492 - val_loss: 0.1905 - val_accuracy: 0.9455\n",
      "Epoch 55/55\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1143 - accuracy: 0.9663 - val_loss: 0.2001 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-054-0.9455.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1905\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9487179518. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1881304681. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m426.66 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m362.25 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m64.41 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [11] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m12\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 55)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 56/60\n",
      "256/256 [==============================] - 76s 282ms/step - loss: 0.2267 - accuracy: 0.9294 - val_loss: 0.2024 - val_accuracy: 0.9407\n",
      "Epoch 57/60\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.2144 - accuracy: 0.9314 - val_loss: 0.1797 - val_accuracy: 0.9519\n",
      "Epoch 58/60\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.1783 - accuracy: 0.9458 - val_loss: 0.1882 - val_accuracy: 0.9343\n",
      "Epoch 59/60\n",
      "256/256 [==============================] - 71s 274ms/step - loss: 0.1450 - accuracy: 0.9556 - val_loss: 0.1828 - val_accuracy: 0.9391\n",
      "Epoch 60/60\n",
      "256/256 [==============================] - 70s 274ms/step - loss: 0.0947 - accuracy: 0.9756 - val_loss: 0.1968 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-057-0.9519.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9519\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1797\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.948718 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.951923\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1881304681 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1796902567\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m429.46 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m359.94 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m69.52 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [12] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m13\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 60)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 61/65\n",
      "256/256 [==============================] - 76s 282ms/step - loss: 0.2183 - accuracy: 0.9297 - val_loss: 0.2184 - val_accuracy: 0.9295\n",
      "Epoch 62/65\n",
      "256/256 [==============================] - 70s 275ms/step - loss: 0.2024 - accuracy: 0.9368 - val_loss: 0.2169 - val_accuracy: 0.9183\n",
      "Epoch 63/65\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.1674 - accuracy: 0.9456 - val_loss: 0.2852 - val_accuracy: 0.8830\n",
      "Epoch 64/65\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.1269 - accuracy: 0.9622 - val_loss: 0.2518 - val_accuracy: 0.9279\n",
      "Epoch 65/65\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0902 - accuracy: 0.9761 - val_loss: 0.2251 - val_accuracy: 0.9343\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-065-0.9343.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9343\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2250\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9519230723. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1796902567. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m427.30 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m360.43 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m66.86 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [13] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m14\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 65)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 66/70\n",
      "256/256 [==============================] - 76s 282ms/step - loss: 0.1974 - accuracy: 0.9319 - val_loss: 0.1898 - val_accuracy: 0.9407\n",
      "Epoch 67/70\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1961 - accuracy: 0.9358 - val_loss: 0.3430 - val_accuracy: 0.9487\n",
      "Epoch 68/70\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.1543 - accuracy: 0.9551 - val_loss: 0.2650 - val_accuracy: 0.9455\n",
      "Epoch 69/70\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1147 - accuracy: 0.9658 - val_loss: 0.1721 - val_accuracy: 0.9391\n",
      "Epoch 70/70\n",
      "256/256 [==============================] - 70s 274ms/step - loss: 0.0867 - accuracy: 0.9768 - val_loss: 0.1958 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-067-0.9487.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.3429\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9519230723. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1796902567. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m427.10 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m360.48 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m66.61 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [14] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m15\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 70)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 71/75\n",
      "256/256 [==============================] - 76s 282ms/step - loss: 0.1970 - accuracy: 0.9419 - val_loss: 0.2369 - val_accuracy: 0.9487\n",
      "Epoch 72/75\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1913 - accuracy: 0.9375 - val_loss: 0.2406 - val_accuracy: 0.8894\n",
      "Epoch 73/75\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.1551 - accuracy: 0.9504 - val_loss: 0.2724 - val_accuracy: 0.9407\n",
      "Epoch 74/75\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1212 - accuracy: 0.9658 - val_loss: 0.2557 - val_accuracy: 0.9471\n",
      "Epoch 75/75\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.0973 - accuracy: 0.9773 - val_loss: 0.2182 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-071-0.9487.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2369\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9519230723. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1796902567. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m427.70 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m360.11 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m67.59 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [15] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m16\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 75)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 76/80\n",
      "256/256 [==============================] - 76s 284ms/step - loss: 0.2101 - accuracy: 0.9304 - val_loss: 0.1545 - val_accuracy: 0.9391\n",
      "Epoch 77/80\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.2028 - accuracy: 0.9316 - val_loss: 0.1670 - val_accuracy: 0.9551\n",
      "Epoch 78/80\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.1747 - accuracy: 0.9426 - val_loss: 0.2755 - val_accuracy: 0.9455\n",
      "Epoch 79/80\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1417 - accuracy: 0.9624 - val_loss: 0.2086 - val_accuracy: 0.9487\n",
      "Epoch 80/80\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1011 - accuracy: 0.9722 - val_loss: 0.1948 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-080-0.9583.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9583\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1948\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.951923 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.958333\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1796902567. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m433.00 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m362.43 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m70.57 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [16] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m17\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 80)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 81/85\n",
      "256/256 [==============================] - 76s 281ms/step - loss: 0.2072 - accuracy: 0.9326 - val_loss: 0.2086 - val_accuracy: 0.9183\n",
      "Epoch 82/85\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1873 - accuracy: 0.9385 - val_loss: 0.1693 - val_accuracy: 0.9439\n",
      "Epoch 83/85\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1579 - accuracy: 0.9524 - val_loss: 0.1667 - val_accuracy: 0.9503\n",
      "Epoch 84/85\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1244 - accuracy: 0.9634 - val_loss: 0.1926 - val_accuracy: 0.9311\n",
      "Epoch 85/85\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.0787 - accuracy: 0.9788 - val_loss: 0.2159 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-083-0.9503.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1667\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1796902567 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1667200625\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m433.47 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m361.35 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m72.12 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [17] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m18\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 85)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 86/90\n",
      "256/256 [==============================] - 76s 283ms/step - loss: 0.2017 - accuracy: 0.9363 - val_loss: 0.2046 - val_accuracy: 0.9423\n",
      "Epoch 87/90\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1824 - accuracy: 0.9419 - val_loss: 0.1731 - val_accuracy: 0.9503\n",
      "Epoch 88/90\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1613 - accuracy: 0.9512 - val_loss: 0.1717 - val_accuracy: 0.9519\n",
      "Epoch 89/90\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1200 - accuracy: 0.9670 - val_loss: 0.1687 - val_accuracy: 0.9551\n",
      "Epoch 90/90\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0884 - accuracy: 0.9758 - val_loss: 0.1759 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-090-0.9583.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9583\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1759\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1667200625. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m433.69 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m363.55 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m70.15 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [18] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m19\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 90)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 91/95\n",
      "256/256 [==============================] - 76s 283ms/step - loss: 0.1744 - accuracy: 0.9451 - val_loss: 0.2413 - val_accuracy: 0.9439\n",
      "Epoch 92/95\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1618 - accuracy: 0.9478 - val_loss: 0.1581 - val_accuracy: 0.9503\n",
      "Epoch 93/95\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1261 - accuracy: 0.9626 - val_loss: 0.2248 - val_accuracy: 0.9471\n",
      "Epoch 94/95\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.0903 - accuracy: 0.9751 - val_loss: 0.2343 - val_accuracy: 0.9471\n",
      "Epoch 95/95\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.0599 - accuracy: 0.9856 - val_loss: 0.2387 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-092-0.9503.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1581\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1667200625 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1581309438\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m435.53 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m361.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m73.66 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [19] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m20\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 95)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 96/100\n",
      "256/256 [==============================] - 76s 282ms/step - loss: 0.1786 - accuracy: 0.9399 - val_loss: 0.1902 - val_accuracy: 0.9487\n",
      "Epoch 97/100\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1794 - accuracy: 0.9453 - val_loss: 0.1680 - val_accuracy: 0.9503\n",
      "Epoch 98/100\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.1451 - accuracy: 0.9558 - val_loss: 0.3610 - val_accuracy: 0.8814\n",
      "Epoch 99/100\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.1137 - accuracy: 0.9697 - val_loss: 0.2149 - val_accuracy: 0.9439\n",
      "Epoch 100/100\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.0774 - accuracy: 0.9790 - val_loss: 0.2226 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-097-0.9503.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1680\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1581309438. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m432.19 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m360.56 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m71.64 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [20] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m21\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 100)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 101/105\n",
      "256/256 [==============================] - 77s 284ms/step - loss: 0.1854 - accuracy: 0.9429 - val_loss: 0.2017 - val_accuracy: 0.9503\n",
      "Epoch 102/105\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1876 - accuracy: 0.9399 - val_loss: 0.1601 - val_accuracy: 0.9503\n",
      "Epoch 103/105\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1388 - accuracy: 0.9563 - val_loss: 0.2547 - val_accuracy: 0.9295\n",
      "Epoch 104/105\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1030 - accuracy: 0.9719 - val_loss: 0.2077 - val_accuracy: 0.9263\n",
      "Epoch 105/105\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0806 - accuracy: 0.9792 - val_loss: 0.2528 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-101-0.9503.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2017\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1581309438. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m432.54 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m361.75 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m70.79 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [21] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m22\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 105)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 106/110\n",
      "256/256 [==============================] - 76s 283ms/step - loss: 0.1915 - accuracy: 0.9409 - val_loss: 0.1463 - val_accuracy: 0.9471\n",
      "Epoch 107/110\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.1747 - accuracy: 0.9480 - val_loss: 0.2243 - val_accuracy: 0.9487\n",
      "Epoch 108/110\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1351 - accuracy: 0.9607 - val_loss: 0.2938 - val_accuracy: 0.9487\n",
      "Epoch 109/110\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1038 - accuracy: 0.9714 - val_loss: 0.1606 - val_accuracy: 0.9519\n",
      "Epoch 110/110\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.0910 - accuracy: 0.9734 - val_loss: 0.1991 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-109-0.9519.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9519\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1606\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1581309438. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m434.39 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m362.98 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m71.42 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [22] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m23\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 110)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 111/115\n",
      "256/256 [==============================] - 77s 283ms/step - loss: 0.1865 - accuracy: 0.9404 - val_loss: 0.1681 - val_accuracy: 0.9439\n",
      "Epoch 112/115\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1662 - accuracy: 0.9502 - val_loss: 0.1739 - val_accuracy: 0.9471\n",
      "Epoch 113/115\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1306 - accuracy: 0.9636 - val_loss: 0.2110 - val_accuracy: 0.9471\n",
      "Epoch 114/115\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1102 - accuracy: 0.9675 - val_loss: 0.5707 - val_accuracy: 0.8301\n",
      "Epoch 115/115\n",
      "256/256 [==============================] - 71s 275ms/step - loss: 0.0743 - accuracy: 0.9812 - val_loss: 0.2822 - val_accuracy: 0.9199\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-112-0.9471.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1739\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1581309438. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m435.05 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m362.24 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m72.81 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [23] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m24\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 115)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 116/120\n",
      "256/256 [==============================] - 77s 284ms/step - loss: 0.1837 - accuracy: 0.9397 - val_loss: 0.1891 - val_accuracy: 0.9407\n",
      "Epoch 117/120\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1732 - accuracy: 0.9426 - val_loss: 0.4782 - val_accuracy: 0.8301\n",
      "Epoch 118/120\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.1405 - accuracy: 0.9578 - val_loss: 0.1871 - val_accuracy: 0.9551\n",
      "Epoch 119/120\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1138 - accuracy: 0.9695 - val_loss: 0.1488 - val_accuracy: 0.9535\n",
      "Epoch 120/120\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0761 - accuracy: 0.9797 - val_loss: 0.1835 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-118-0.9551.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9551\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1871\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1581309438. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m437.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m362.67 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m75.11 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [24] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m25\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 120)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.01\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 121/125\n",
      "256/256 [==============================] - 77s 284ms/step - loss: 0.1635 - accuracy: 0.9500 - val_loss: 0.1566 - val_accuracy: 0.9551\n",
      "Epoch 122/125\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1506 - accuracy: 0.9517 - val_loss: 0.1574 - val_accuracy: 0.9471\n",
      "Epoch 123/125\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1205 - accuracy: 0.9656 - val_loss: 0.1595 - val_accuracy: 0.9519\n",
      "Epoch 124/125\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0889 - accuracy: 0.9766 - val_loss: 0.1813 - val_accuracy: 0.9519\n",
      "Epoch 125/125\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0600 - accuracy: 0.9817 - val_loss: 0.1777 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-121-0.9551.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9551\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1566\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1581309438 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1566060036\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m439.02 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m361.97 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m77.05 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [25] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m26\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 125)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00994\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 126/130\n",
      "256/256 [==============================] - 77s 284ms/step - loss: 0.1687 - accuracy: 0.9421 - val_loss: 0.1855 - val_accuracy: 0.9343\n",
      "Epoch 127/130\n",
      "256/256 [==============================] - 71s 276ms/step - loss: 0.1627 - accuracy: 0.9473 - val_loss: 0.2196 - val_accuracy: 0.9199\n",
      "Epoch 128/130\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1267 - accuracy: 0.9624 - val_loss: 0.2044 - val_accuracy: 0.9455\n",
      "Epoch 129/130\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0936 - accuracy: 0.9751 - val_loss: 0.1908 - val_accuracy: 0.9503\n",
      "Epoch 130/130\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0651 - accuracy: 0.9805 - val_loss: 0.2133 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-130-0.9535.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2133\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1566060036. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m439.01 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m363.95 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m75.05 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [26] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m27\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 130)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00988\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 131/135\n",
      "256/256 [==============================] - 77s 284ms/step - loss: 0.1947 - accuracy: 0.9382 - val_loss: 0.1536 - val_accuracy: 0.9487\n",
      "Epoch 132/135\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1733 - accuracy: 0.9453 - val_loss: 0.1914 - val_accuracy: 0.9535\n",
      "Epoch 133/135\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1369 - accuracy: 0.9585 - val_loss: 0.1519 - val_accuracy: 0.9503\n",
      "Epoch 134/135\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1031 - accuracy: 0.9670 - val_loss: 0.1592 - val_accuracy: 0.9503\n",
      "Epoch 135/135\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0689 - accuracy: 0.9834 - val_loss: 0.1786 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-132-0.9535.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1914\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1566060036. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m440.27 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m363.88 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m76.38 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [27] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m28\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 135)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00982\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 136/140\n",
      "256/256 [==============================] - 77s 286ms/step - loss: 0.1806 - accuracy: 0.9395 - val_loss: 0.1641 - val_accuracy: 0.9487\n",
      "Epoch 137/140\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1651 - accuracy: 0.9500 - val_loss: 0.1882 - val_accuracy: 0.9551\n",
      "Epoch 138/140\n",
      "256/256 [==============================] - 72s 278ms/step - loss: 0.1289 - accuracy: 0.9648 - val_loss: 0.1548 - val_accuracy: 0.9519\n",
      "Epoch 139/140\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0971 - accuracy: 0.9766 - val_loss: 0.2030 - val_accuracy: 0.9311\n",
      "Epoch 140/140\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0724 - accuracy: 0.9817 - val_loss: 0.1836 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-137-0.9551.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9551\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1881\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1566060036. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m441.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m364.46 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m77.41 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [28] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m29\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 140)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00976\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 141/145\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1833 - accuracy: 0.9426 - val_loss: 0.1816 - val_accuracy: 0.9535\n",
      "Epoch 142/145\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1543 - accuracy: 0.9519 - val_loss: 0.2133 - val_accuracy: 0.9471\n",
      "Epoch 143/145\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1350 - accuracy: 0.9600 - val_loss: 0.1828 - val_accuracy: 0.9503\n",
      "Epoch 144/145\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0994 - accuracy: 0.9707 - val_loss: 0.1925 - val_accuracy: 0.9567\n",
      "Epoch 145/145\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0654 - accuracy: 0.9814 - val_loss: 0.2118 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9567}, \u001b[0m\u001b[0;33mloss{0.1816}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1566}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2118\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1566060036. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m440.62 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m363.79 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m76.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [29] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m30\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 145)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.0097\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 146/150\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1715 - accuracy: 0.9482 - val_loss: 0.2515 - val_accuracy: 0.9455\n",
      "Epoch 147/150\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1475 - accuracy: 0.9551 - val_loss: 0.1663 - val_accuracy: 0.9551\n",
      "Epoch 148/150\n",
      "256/256 [==============================] - 72s 278ms/step - loss: 0.1151 - accuracy: 0.9641 - val_loss: 0.2541 - val_accuracy: 0.9551\n",
      "Epoch 149/150\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0804 - accuracy: 0.9802 - val_loss: 0.2602 - val_accuracy: 0.9487\n",
      "Epoch 150/150\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0562 - accuracy: 0.9854 - val_loss: 0.1979 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9583}, \u001b[0m\u001b[0;33mloss{0.1663}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1566}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9583\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1979\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1566060036. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m444.77 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m365.10 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m79.67 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [30] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m31\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 150)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00964\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 151/155\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1695 - accuracy: 0.9490 - val_loss: 0.1764 - val_accuracy: 0.9583\n",
      "Epoch 152/155\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1385 - accuracy: 0.9573 - val_loss: 0.1922 - val_accuracy: 0.9407\n",
      "Epoch 153/155\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1127 - accuracy: 0.9656 - val_loss: 0.1862 - val_accuracy: 0.9471\n",
      "Epoch 154/155\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0712 - accuracy: 0.9771 - val_loss: 0.2005 - val_accuracy: 0.9407\n",
      "Epoch 155/155\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0533 - accuracy: 0.9858 - val_loss: 0.1977 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9583}, \u001b[0m\u001b[0;33mloss{0.1764}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1566}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1977\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1566060036. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m443.65 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m362.96 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m80.69 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [31] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m32\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 155)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33m‚îî‚îÄ‚îÄ‚îÄShuffling data...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00958\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 156/160\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1664 - accuracy: 0.9517 - val_loss: 0.2044 - val_accuracy: 0.9551\n",
      "Epoch 157/160\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1405 - accuracy: 0.9551 - val_loss: 0.1902 - val_accuracy: 0.9407\n",
      "Epoch 158/160\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1056 - accuracy: 0.9724 - val_loss: 0.4340 - val_accuracy: 0.9279\n",
      "Epoch 159/160\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0763 - accuracy: 0.9802 - val_loss: 0.2011 - val_accuracy: 0.9487\n",
      "Epoch 160/160\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0560 - accuracy: 0.9861 - val_loss: 0.2239 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9551}, \u001b[0m\u001b[0;33mloss{0.1902}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1566}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2238\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1566060036. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m446.65 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m363.56 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m83.09 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [32] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m33\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 160)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00952\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 161/165\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1723 - accuracy: 0.9456 - val_loss: 0.1998 - val_accuracy: 0.9295\n",
      "Epoch 162/165\n",
      "256/256 [==============================] - 71s 279ms/step - loss: 0.1558 - accuracy: 0.9492 - val_loss: 0.5200 - val_accuracy: 0.9247\n",
      "Epoch 163/165\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.1163 - accuracy: 0.9678 - val_loss: 0.2447 - val_accuracy: 0.9487\n",
      "Epoch 164/165\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0829 - accuracy: 0.9802 - val_loss: 0.1901 - val_accuracy: 0.9551\n",
      "Epoch 165/165\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0632 - accuracy: 0.9824 - val_loss: 0.2210 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9551}, \u001b[0m\u001b[0;33mloss{0.1901}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1566}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9519\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2210\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1566060036. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m445.62 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m364.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m80.76 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [33] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m34\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 165)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00946\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 166/170\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1697 - accuracy: 0.9490 - val_loss: 0.2075 - val_accuracy: 0.9455\n",
      "Epoch 167/170\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1437 - accuracy: 0.9553 - val_loss: 0.3030 - val_accuracy: 0.9551\n",
      "Epoch 168/170\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1057 - accuracy: 0.9692 - val_loss: 0.4606 - val_accuracy: 0.9391\n",
      "Epoch 169/170\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0752 - accuracy: 0.9785 - val_loss: 0.1888 - val_accuracy: 0.9503\n",
      "Epoch 170/170\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0474 - accuracy: 0.9885 - val_loss: 0.2047 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9551}, \u001b[0m\u001b[0;33mloss{0.1888}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1566}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2047\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1566060036. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m444.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m363.85 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m81.02 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [34] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m35\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 170)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.0094\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 171/175\n",
      "256/256 [==============================] - 77s 286ms/step - loss: 0.1482 - accuracy: 0.9524 - val_loss: 0.2038 - val_accuracy: 0.9407\n",
      "Epoch 172/175\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1325 - accuracy: 0.9587 - val_loss: 0.1661 - val_accuracy: 0.9503\n",
      "Epoch 173/175\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1017 - accuracy: 0.9707 - val_loss: 0.1788 - val_accuracy: 0.9583\n",
      "Epoch 174/175\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0713 - accuracy: 0.9797 - val_loss: 0.2595 - val_accuracy: 0.9167\n",
      "Epoch 175/175\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0453 - accuracy: 0.9883 - val_loss: 0.2039 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9583}, \u001b[0m\u001b[0;33mloss{0.1661}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1566}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2039\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1566060036. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m447.14 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m365.64 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m81.50 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [35] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m36\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 175)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00934\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 176/180\n",
      "256/256 [==============================] - 77s 286ms/step - loss: 0.1770 - accuracy: 0.9490 - val_loss: 0.1965 - val_accuracy: 0.9327\n",
      "Epoch 177/180\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1447 - accuracy: 0.9531 - val_loss: 0.1468 - val_accuracy: 0.9567\n",
      "Epoch 178/180\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1120 - accuracy: 0.9661 - val_loss: 0.2001 - val_accuracy: 0.9343\n",
      "Epoch 179/180\n",
      "256/256 [==============================] - 72s 278ms/step - loss: 0.0766 - accuracy: 0.9775 - val_loss: 0.1707 - val_accuracy: 0.9567\n",
      "Epoch 180/180\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0482 - accuracy: 0.9880 - val_loss: 0.1961 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-177-0.9567.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9567\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1468\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1566060036 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1468076557\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m449.65 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m364.86 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m84.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [36] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m37\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 180)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00928\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 181/185\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1628 - accuracy: 0.9487 - val_loss: 0.1431 - val_accuracy: 0.9567\n",
      "Epoch 182/185\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1522 - accuracy: 0.9512 - val_loss: 0.1581 - val_accuracy: 0.9519\n",
      "Epoch 183/185\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1117 - accuracy: 0.9668 - val_loss: 0.1627 - val_accuracy: 0.9503\n",
      "Epoch 184/185\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0809 - accuracy: 0.9744 - val_loss: 0.1857 - val_accuracy: 0.9535\n",
      "Epoch 185/185\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0550 - accuracy: 0.9873 - val_loss: 0.2241 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-181-0.9567.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9567\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1431\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1468076557 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1431476325\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m450.16 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m363.04 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m87.13 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [37] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m38\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 185)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00922\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 186/190\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1629 - accuracy: 0.9485 - val_loss: 0.1468 - val_accuracy: 0.9519\n",
      "Epoch 187/190\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1285 - accuracy: 0.9595 - val_loss: 0.1630 - val_accuracy: 0.9439\n",
      "Epoch 188/190\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1103 - accuracy: 0.9648 - val_loss: 0.2302 - val_accuracy: 0.9503\n",
      "Epoch 189/190\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0732 - accuracy: 0.9814 - val_loss: 0.1727 - val_accuracy: 0.9519\n",
      "Epoch 190/190\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0535 - accuracy: 0.9858 - val_loss: 0.2002 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9535}, \u001b[0m\u001b[0;33mloss{0.1468}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1431}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2002\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1431476325. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m448.53 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m363.70 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m84.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [38] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m39\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 190)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00916\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 191/195\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1674 - accuracy: 0.9456 - val_loss: 0.1840 - val_accuracy: 0.9439\n",
      "Epoch 192/195\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1385 - accuracy: 0.9512 - val_loss: 0.1800 - val_accuracy: 0.9567\n",
      "Epoch 193/195\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1037 - accuracy: 0.9678 - val_loss: 0.1807 - val_accuracy: 0.9519\n",
      "Epoch 194/195\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0806 - accuracy: 0.9761 - val_loss: 0.1640 - val_accuracy: 0.9519\n",
      "Epoch 195/195\n",
      "256/256 [==============================] - 72s 278ms/step - loss: 0.0552 - accuracy: 0.9856 - val_loss: 0.1919 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9567}, \u001b[0m\u001b[0;33mloss{0.1640}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1431}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1919\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1431476325. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m449.67 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m364.99 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m84.68 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [39] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m40\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 195)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.0091\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 196/200\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1509 - accuracy: 0.9519 - val_loss: 0.2117 - val_accuracy: 0.9519\n",
      "Epoch 197/200\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.1213 - accuracy: 0.9578 - val_loss: 0.2241 - val_accuracy: 0.9455\n",
      "Epoch 198/200\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0924 - accuracy: 0.9722 - val_loss: 0.2508 - val_accuracy: 0.9439\n",
      "Epoch 199/200\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0568 - accuracy: 0.9849 - val_loss: 0.2383 - val_accuracy: 0.9503\n",
      "Epoch 200/200\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0379 - accuracy: 0.9915 - val_loss: 0.2560 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.2117}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1431}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2559\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1431476325. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m448.43 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m363.49 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m84.94 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [40] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m41\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 200)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00904\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 201/205\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1615 - accuracy: 0.9504 - val_loss: 0.4663 - val_accuracy: 0.8974\n",
      "Epoch 202/205\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1202 - accuracy: 0.9607 - val_loss: 0.1542 - val_accuracy: 0.9343\n",
      "Epoch 203/205\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0930 - accuracy: 0.9734 - val_loss: 0.2617 - val_accuracy: 0.9487\n",
      "Epoch 204/205\n",
      "256/256 [==============================] - 72s 278ms/step - loss: 0.0547 - accuracy: 0.9851 - val_loss: 0.1657 - val_accuracy: 0.9471\n",
      "Epoch 205/205\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0424 - accuracy: 0.9890 - val_loss: 0.2375 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9503}, \u001b[0m\u001b[0;33mloss{0.1542}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1431}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2375\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1431476325. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m453.21 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m366.56 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m86.65 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [41] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m42\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 205)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;31m- Debug DP Sample dir: \u001b[0m\u001b[0;32mSamples/TSR_SUB_400_y2024_m02_d11-h03_m30_s36\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00898\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 206/210\n",
      "256/256 [==============================] - 77s 286ms/step - loss: 0.1543 - accuracy: 0.9536 - val_loss: 0.2061 - val_accuracy: 0.9375\n",
      "Epoch 207/210\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.1239 - accuracy: 0.9626 - val_loss: 0.1280 - val_accuracy: 0.9567\n",
      "Epoch 208/210\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0980 - accuracy: 0.9763 - val_loss: 0.1329 - val_accuracy: 0.9567\n",
      "Epoch 209/210\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0704 - accuracy: 0.9824 - val_loss: 0.1375 - val_accuracy: 0.9583\n",
      "Epoch 210/210\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0495 - accuracy: 0.9888 - val_loss: 0.1542 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-209-0.9583.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9583\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1375\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1431476325 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1375079602\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m465.19 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m365.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m99.41 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [42] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m43\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 210)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00892\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 211/215\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1558 - accuracy: 0.9509 - val_loss: 0.1366 - val_accuracy: 0.9631\n",
      "Epoch 212/215\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1504 - accuracy: 0.9512 - val_loss: 0.1814 - val_accuracy: 0.9471\n",
      "Epoch 213/215\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0966 - accuracy: 0.9705 - val_loss: 0.1321 - val_accuracy: 0.9615\n",
      "Epoch 214/215\n",
      "256/256 [==============================] - 71s 279ms/step - loss: 0.0704 - accuracy: 0.9810 - val_loss: 0.1665 - val_accuracy: 0.9535\n",
      "Epoch 215/215\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0563 - accuracy: 0.9851 - val_loss: 0.1738 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-211-0.9631.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9631\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1366\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.958333 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.963141\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1375079602 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1365689486\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m458.06 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m365.32 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m92.75 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [43] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m44\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 215)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00886\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 216/220\n",
      "256/256 [==============================] - 77s 284ms/step - loss: 0.1489 - accuracy: 0.9529 - val_loss: 0.1593 - val_accuracy: 0.9487\n",
      "Epoch 217/220\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1328 - accuracy: 0.9565 - val_loss: 0.1691 - val_accuracy: 0.9535\n",
      "Epoch 218/220\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0952 - accuracy: 0.9727 - val_loss: 0.1699 - val_accuracy: 0.9311\n",
      "Epoch 219/220\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0773 - accuracy: 0.9773 - val_loss: 0.1459 - val_accuracy: 0.9631\n",
      "Epoch 220/220\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0524 - accuracy: 0.9885 - val_loss: 0.1670 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9631}, \u001b[0m\u001b[0;33mloss{0.1459}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9631}, loss{0.1366}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9551\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1670\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9631410241. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1365689486. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m452.76 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m364.76 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m88.00 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [44] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m45\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 220)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.0088\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 221/225\n",
      "256/256 [==============================] - 77s 285ms/step - loss: 0.1540 - accuracy: 0.9512 - val_loss: 0.1609 - val_accuracy: 0.9567\n",
      "Epoch 222/225\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.1300 - accuracy: 0.9609 - val_loss: 0.2000 - val_accuracy: 0.9327\n",
      "Epoch 223/225\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.1078 - accuracy: 0.9695 - val_loss: 0.1381 - val_accuracy: 0.9615\n",
      "Epoch 224/225\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0659 - accuracy: 0.9832 - val_loss: 0.1155 - val_accuracy: 0.9583\n",
      "Epoch 225/225\n",
      "256/256 [==============================] - 71s 277ms/step - loss: 0.0441 - accuracy: 0.9917 - val_loss: 0.1818 - val_accuracy: 0.9599\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-223-0.9615.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9615\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1381\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9631410241. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1365689486. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m455.29 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m363.61 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m91.68 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [45] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m46\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 225)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00874\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 226/230\n",
      "256/256 [==============================] - 77s 287ms/step - loss: 0.1363 - accuracy: 0.9631 - val_loss: 0.1162 - val_accuracy: 0.9647\n",
      "Epoch 227/230\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1174 - accuracy: 0.9619 - val_loss: 0.1411 - val_accuracy: 0.9551\n",
      "Epoch 228/230\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0840 - accuracy: 0.9741 - val_loss: 0.1599 - val_accuracy: 0.9583\n",
      "Epoch 229/230\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0560 - accuracy: 0.9836 - val_loss: 0.1340 - val_accuracy: 0.9583\n",
      "Epoch 230/230\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0432 - accuracy: 0.9900 - val_loss: 0.1479 - val_accuracy: 0.9615\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-226-0.9647.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9647\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1162\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.963141 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.964744\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1365689486 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1162088364\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m462.49 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m365.89 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m96.61 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [46] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m47\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 230)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00868\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 231/235\n",
      "256/256 [==============================] - 78s 287ms/step - loss: 0.1248 - accuracy: 0.9592 - val_loss: 0.1226 - val_accuracy: 0.9583\n",
      "Epoch 232/235\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1084 - accuracy: 0.9651 - val_loss: 0.1441 - val_accuracy: 0.9551\n",
      "Epoch 233/235\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0757 - accuracy: 0.9751 - val_loss: 0.2594 - val_accuracy: 0.9263\n",
      "Epoch 234/235\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0596 - accuracy: 0.9832 - val_loss: 0.1511 - val_accuracy: 0.9567\n",
      "Epoch 235/235\n",
      "256/256 [==============================] - 72s 278ms/step - loss: 0.0373 - accuracy: 0.9907 - val_loss: 0.1756 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9583}, \u001b[0m\u001b[0;33mloss{0.1226}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9647}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9583\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1756\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9647436142. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m458.07 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m365.00 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m93.07 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [47] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m48\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 235)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00862\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 236/240\n",
      "256/256 [==============================] - 77s 286ms/step - loss: 0.1520 - accuracy: 0.9568 - val_loss: 0.1466 - val_accuracy: 0.9583\n",
      "Epoch 237/240\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1215 - accuracy: 0.9612 - val_loss: 0.1195 - val_accuracy: 0.9631\n",
      "Epoch 238/240\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0988 - accuracy: 0.9717 - val_loss: 0.1404 - val_accuracy: 0.9583\n",
      "Epoch 239/240\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0717 - accuracy: 0.9817 - val_loss: 0.1478 - val_accuracy: 0.9503\n",
      "Epoch 240/240\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0447 - accuracy: 0.9888 - val_loss: 0.1716 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9631}, \u001b[0m\u001b[0;33mloss{0.1195}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9647}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9551\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1715\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9647436142. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m457.23 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m365.74 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m91.49 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [48] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m49\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 240)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00856\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 241/245\n",
      "256/256 [==============================] - 77s 286ms/step - loss: 0.1729 - accuracy: 0.9482 - val_loss: 0.1430 - val_accuracy: 0.9551\n",
      "Epoch 242/245\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1356 - accuracy: 0.9580 - val_loss: 0.2007 - val_accuracy: 0.9583\n",
      "Epoch 243/245\n",
      "256/256 [==============================] - 73s 283ms/step - loss: 0.1036 - accuracy: 0.9712 - val_loss: 0.1372 - val_accuracy: 0.9615\n",
      "Epoch 244/245\n",
      "256/256 [==============================] - 71s 278ms/step - loss: 0.0779 - accuracy: 0.9783 - val_loss: 0.1494 - val_accuracy: 0.9599\n",
      "Epoch 245/245\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0496 - accuracy: 0.9878 - val_loss: 0.1663 - val_accuracy: 0.9663\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-245-0.9663.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9663\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1663\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.964744 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.966346\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m461.57 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m366.72 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m94.85 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [49] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m50\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 245)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.0085\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 246/250\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1505 - accuracy: 0.9543 - val_loss: 0.3530 - val_accuracy: 0.9071\n",
      "Epoch 247/250\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1335 - accuracy: 0.9575 - val_loss: 0.1489 - val_accuracy: 0.9631\n",
      "Epoch 248/250\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0909 - accuracy: 0.9729 - val_loss: 0.1645 - val_accuracy: 0.9551\n",
      "Epoch 249/250\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0639 - accuracy: 0.9807 - val_loss: 0.2372 - val_accuracy: 0.9551\n",
      "Epoch 250/250\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0406 - accuracy: 0.9878 - val_loss: 0.1849 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9631}, \u001b[0m\u001b[0;33mloss{0.1489}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9663}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9567\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1849\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9663461447. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m458.72 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m366.36 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m92.36 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [50] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m51\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 250)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00844\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 251/255\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1543 - accuracy: 0.9526 - val_loss: 0.1496 - val_accuracy: 0.9567\n",
      "Epoch 252/255\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1221 - accuracy: 0.9585 - val_loss: 0.1797 - val_accuracy: 0.9407\n",
      "Epoch 253/255\n",
      "256/256 [==============================] - 73s 283ms/step - loss: 0.0865 - accuracy: 0.9746 - val_loss: 0.2097 - val_accuracy: 0.9647\n",
      "Epoch 254/255\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0680 - accuracy: 0.9783 - val_loss: 0.1848 - val_accuracy: 0.9519\n",
      "Epoch 255/255\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0394 - accuracy: 0.9907 - val_loss: 0.2067 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9647}, \u001b[0m\u001b[0;33mloss{0.1496}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9663}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9583\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2067\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9663461447. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m462.35 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m366.39 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m95.96 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [51] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m52\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 255)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00838\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 256/260\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1542 - accuracy: 0.9536 - val_loss: 0.1339 - val_accuracy: 0.9663\n",
      "Epoch 257/260\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1253 - accuracy: 0.9641 - val_loss: 0.2985 - val_accuracy: 0.9311\n",
      "Epoch 258/260\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0888 - accuracy: 0.9749 - val_loss: 0.1963 - val_accuracy: 0.9599\n",
      "Epoch 259/260\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0584 - accuracy: 0.9849 - val_loss: 0.1898 - val_accuracy: 0.9471\n",
      "Epoch 260/260\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0482 - accuracy: 0.9875 - val_loss: 0.1953 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9663}, \u001b[0m\u001b[0;33mloss{0.1339}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9663}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9551\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1953\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9663461447. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m460.77 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m365.88 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m94.89 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [52] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m53\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 260)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00832\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 261/265\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1371 - accuracy: 0.9561 - val_loss: 0.2234 - val_accuracy: 0.9423\n",
      "Epoch 262/265\n",
      "256/256 [==============================] - 73s 282ms/step - loss: 0.1143 - accuracy: 0.9619 - val_loss: 0.1963 - val_accuracy: 0.9631\n",
      "Epoch 263/265\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0854 - accuracy: 0.9749 - val_loss: 0.1909 - val_accuracy: 0.9583\n",
      "Epoch 264/265\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0547 - accuracy: 0.9866 - val_loss: 0.2006 - val_accuracy: 0.9519\n",
      "Epoch 265/265\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0387 - accuracy: 0.9917 - val_loss: 0.2101 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9631}, \u001b[0m\u001b[0;33mloss{0.1909}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9663}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2101\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9663461447. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m462.16 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m366.82 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m95.35 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [53] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m54\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 265)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00826\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 266/270\n",
      "256/256 [==============================] - 78s 287ms/step - loss: 0.1529 - accuracy: 0.9534 - val_loss: 0.1653 - val_accuracy: 0.9599\n",
      "Epoch 267/270\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1135 - accuracy: 0.9646 - val_loss: 0.1619 - val_accuracy: 0.9679\n",
      "Epoch 268/270\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0865 - accuracy: 0.9739 - val_loss: 0.1322 - val_accuracy: 0.9647\n",
      "Epoch 269/270\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0703 - accuracy: 0.9807 - val_loss: 0.1328 - val_accuracy: 0.9647\n",
      "Epoch 270/270\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0422 - accuracy: 0.9900 - val_loss: 0.1364 - val_accuracy: 0.9663\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-267-0.9679.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9679\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1619\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.966346 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.967949\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m465.15 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m366.37 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m98.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [54] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m55\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 270)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.0082\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 271/275\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1581 - accuracy: 0.9492 - val_loss: 0.1655 - val_accuracy: 0.9631\n",
      "Epoch 272/275\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.1315 - accuracy: 0.9578 - val_loss: 0.1363 - val_accuracy: 0.9567\n",
      "Epoch 273/275\n",
      "256/256 [==============================] - 72s 283ms/step - loss: 0.1006 - accuracy: 0.9692 - val_loss: 0.1588 - val_accuracy: 0.9551\n",
      "Epoch 274/275\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0790 - accuracy: 0.9807 - val_loss: 0.1472 - val_accuracy: 0.9567\n",
      "Epoch 275/275\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0542 - accuracy: 0.9866 - val_loss: 0.1733 - val_accuracy: 0.9599\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9631}, \u001b[0m\u001b[0;33mloss{0.1363}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9599\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1733\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m466.46 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m367.01 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m99.45 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [55] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m56\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 275)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00814\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 276/280\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1433 - accuracy: 0.9529 - val_loss: 0.1396 - val_accuracy: 0.9599\n",
      "Epoch 277/280\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.1078 - accuracy: 0.9626 - val_loss: 0.2158 - val_accuracy: 0.9519\n",
      "Epoch 278/280\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1169 - accuracy: 0.9666 - val_loss: 0.1657 - val_accuracy: 0.9583\n",
      "Epoch 279/280\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0628 - accuracy: 0.9834 - val_loss: 0.1703 - val_accuracy: 0.9535\n",
      "Epoch 280/280\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0439 - accuracy: 0.9897 - val_loss: 0.1810 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9599}, \u001b[0m\u001b[0;33mloss{0.1396}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1810\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m463.71 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m366.60 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m97.10 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [56] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m57\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 280)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00808\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 281/285\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1582 - accuracy: 0.9507 - val_loss: 0.1576 - val_accuracy: 0.9375\n",
      "Epoch 282/285\n",
      "256/256 [==============================] - 73s 283ms/step - loss: 0.1298 - accuracy: 0.9553 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 283/285\n",
      "256/256 [==============================] - 73s 283ms/step - loss: 0.0929 - accuracy: 0.9724 - val_loss: 0.1686 - val_accuracy: 0.9567\n",
      "Epoch 284/285\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0692 - accuracy: 0.9761 - val_loss: 0.1627 - val_accuracy: 0.9503\n",
      "Epoch 285/285\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0450 - accuracy: 0.9873 - val_loss: 0.1836 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9567}, \u001b[0m\u001b[0;33mloss{0.1356}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9519\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1836\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m462.79 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m367.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m94.92 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [57] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m58\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 285)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00802\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 286/290\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1390 - accuracy: 0.9575 - val_loss: 0.1994 - val_accuracy: 0.9471\n",
      "Epoch 287/290\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1074 - accuracy: 0.9675 - val_loss: 0.1547 - val_accuracy: 0.9519\n",
      "Epoch 288/290\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0671 - accuracy: 0.9839 - val_loss: 0.2848 - val_accuracy: 0.9407\n",
      "Epoch 289/290\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0473 - accuracy: 0.9885 - val_loss: 0.2358 - val_accuracy: 0.9455\n",
      "Epoch 290/290\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.0349 - accuracy: 0.9907 - val_loss: 0.3111 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1547}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9375\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.3111\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m463.37 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m366.53 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m96.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [58] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m59\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 290)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00796\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 291/295\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1351 - accuracy: 0.9565 - val_loss: 0.1725 - val_accuracy: 0.9487\n",
      "Epoch 292/295\n",
      "256/256 [==============================] - 73s 283ms/step - loss: 0.1100 - accuracy: 0.9639 - val_loss: 0.2242 - val_accuracy: 0.9519\n",
      "Epoch 293/295\n",
      "256/256 [==============================] - 73s 283ms/step - loss: 0.0711 - accuracy: 0.9792 - val_loss: 0.1755 - val_accuracy: 0.9567\n",
      "Epoch 294/295\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0570 - accuracy: 0.9844 - val_loss: 0.2386 - val_accuracy: 0.9535\n",
      "Epoch 295/295\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0364 - accuracy: 0.9917 - val_loss: 0.2109 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9567}, \u001b[0m\u001b[0;33mloss{0.1725}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9519\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2109\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m466.96 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m368.39 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m98.57 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [59] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m60\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 295)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.0079\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 296/300\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1535 - accuracy: 0.9556 - val_loss: 0.1615 - val_accuracy: 0.9519\n",
      "Epoch 297/300\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1101 - accuracy: 0.9619 - val_loss: 0.1388 - val_accuracy: 0.9631\n",
      "Epoch 298/300\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0847 - accuracy: 0.9731 - val_loss: 0.1544 - val_accuracy: 0.9471\n",
      "Epoch 299/300\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0600 - accuracy: 0.9814 - val_loss: 0.1768 - val_accuracy: 0.9567\n",
      "Epoch 300/300\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0397 - accuracy: 0.9897 - val_loss: 0.1894 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9631}, \u001b[0m\u001b[0;33mloss{0.1388}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9567\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1894\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m466.48 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m367.19 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m99.28 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [60] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m61\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 300)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00784\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 301/305\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1513 - accuracy: 0.9519 - val_loss: 0.2169 - val_accuracy: 0.9535\n",
      "Epoch 302/305\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1204 - accuracy: 0.9614 - val_loss: 0.1566 - val_accuracy: 0.9439\n",
      "Epoch 303/305\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0919 - accuracy: 0.9719 - val_loss: 0.1661 - val_accuracy: 0.9567\n",
      "Epoch 304/305\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0704 - accuracy: 0.9795 - val_loss: 0.1649 - val_accuracy: 0.9503\n",
      "Epoch 305/305\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0382 - accuracy: 0.9917 - val_loss: 0.1964 - val_accuracy: 0.9599\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9599}, \u001b[0m\u001b[0;33mloss{0.1566}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9599\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1964\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m465.94 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m368.06 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m97.88 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [61] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m62\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 305)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00778\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 306/310\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1359 - accuracy: 0.9551 - val_loss: 0.2810 - val_accuracy: 0.9503\n",
      "Epoch 307/310\n",
      "256/256 [==============================] - 73s 284ms/step - loss: 0.1095 - accuracy: 0.9639 - val_loss: 0.1407 - val_accuracy: 0.9519\n",
      "Epoch 308/310\n",
      "256/256 [==============================] - 73s 284ms/step - loss: 0.0786 - accuracy: 0.9749 - val_loss: 0.2361 - val_accuracy: 0.9567\n",
      "Epoch 309/310\n",
      "256/256 [==============================] - 73s 284ms/step - loss: 0.0563 - accuracy: 0.9868 - val_loss: 0.1773 - val_accuracy: 0.9599\n",
      "Epoch 310/310\n",
      "256/256 [==============================] - 73s 284ms/step - loss: 0.0377 - accuracy: 0.9915 - val_loss: 0.2092 - val_accuracy: 0.9647\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9647}, \u001b[0m\u001b[0;33mloss{0.1407}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9647\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2092\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m472.35 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m370.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m101.58 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [62] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m63\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 310)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00772\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 311/315\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1465 - accuracy: 0.9565 - val_loss: 0.1305 - val_accuracy: 0.9599\n",
      "Epoch 312/315\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.1184 - accuracy: 0.9641 - val_loss: 0.1408 - val_accuracy: 0.9503\n",
      "Epoch 313/315\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0817 - accuracy: 0.9763 - val_loss: 0.1710 - val_accuracy: 0.9551\n",
      "Epoch 314/315\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0553 - accuracy: 0.9827 - val_loss: 0.1910 - val_accuracy: 0.9599\n",
      "Epoch 315/315\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0349 - accuracy: 0.9922 - val_loss: 0.2152 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9599}, \u001b[0m\u001b[0;33mloss{0.1305}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9567\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2152\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m470.23 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m367.20 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m103.03 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [63] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m64\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 315)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33m‚îî‚îÄ‚îÄ‚îÄShuffling data...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00766\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 316/320\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1298 - accuracy: 0.9597 - val_loss: 0.1650 - val_accuracy: 0.9535\n",
      "Epoch 317/320\n",
      "256/256 [==============================] - 73s 284ms/step - loss: 0.0969 - accuracy: 0.9709 - val_loss: 0.1551 - val_accuracy: 0.9599\n",
      "Epoch 318/320\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0721 - accuracy: 0.9814 - val_loss: 0.2079 - val_accuracy: 0.9551\n",
      "Epoch 319/320\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0560 - accuracy: 0.9844 - val_loss: 0.1557 - val_accuracy: 0.9535\n",
      "Epoch 320/320\n",
      "256/256 [==============================] - 73s 282ms/step - loss: 0.0309 - accuracy: 0.9934 - val_loss: 0.1711 - val_accuracy: 0.9599\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9599}, \u001b[0m\u001b[0;33mloss{0.1551}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9599\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1711\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m472.73 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m368.55 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m104.18 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [64] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m65\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 320)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.0076\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 321/325\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1414 - accuracy: 0.9580 - val_loss: 0.1324 - val_accuracy: 0.9567\n",
      "Epoch 322/325\n",
      "256/256 [==============================] - 72s 279ms/step - loss: 0.1076 - accuracy: 0.9670 - val_loss: 0.2095 - val_accuracy: 0.9279\n",
      "Epoch 323/325\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0814 - accuracy: 0.9756 - val_loss: 0.2206 - val_accuracy: 0.9551\n",
      "Epoch 324/325\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0618 - accuracy: 0.9832 - val_loss: 0.1822 - val_accuracy: 0.9503\n",
      "Epoch 325/325\n",
      "256/256 [==============================] - 73s 283ms/step - loss: 0.0405 - accuracy: 0.9902 - val_loss: 0.2001 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9583}, \u001b[0m\u001b[0;33mloss{0.1324}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9567\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2001\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m467.00 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m367.52 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m99.47 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [65] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m66\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 325)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00754\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 326/330\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1259 - accuracy: 0.9578 - val_loss: 0.1747 - val_accuracy: 0.9567\n",
      "Epoch 327/330\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1065 - accuracy: 0.9668 - val_loss: 0.1312 - val_accuracy: 0.9535\n",
      "Epoch 328/330\n",
      "256/256 [==============================] - 73s 285ms/step - loss: 0.0720 - accuracy: 0.9761 - val_loss: 0.1616 - val_accuracy: 0.9583\n",
      "Epoch 329/330\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0391 - accuracy: 0.9890 - val_loss: 0.1867 - val_accuracy: 0.9503\n",
      "Epoch 330/330\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0261 - accuracy: 0.9946 - val_loss: 0.1988 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9583}, \u001b[0m\u001b[0;33mloss{0.1312}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9551\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1988\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m469.50 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m368.58 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m100.92 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [66] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m67\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 330)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00748\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 331/335\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1330 - accuracy: 0.9558 - val_loss: 0.1367 - val_accuracy: 0.9471\n",
      "Epoch 332/335\n",
      "256/256 [==============================] - 73s 284ms/step - loss: 0.1057 - accuracy: 0.9675 - val_loss: 0.1691 - val_accuracy: 0.9551\n",
      "Epoch 333/335\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0649 - accuracy: 0.9802 - val_loss: 0.2639 - val_accuracy: 0.9343\n",
      "Epoch 334/335\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0493 - accuracy: 0.9854 - val_loss: 0.2221 - val_accuracy: 0.9503\n",
      "Epoch 335/335\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0307 - accuracy: 0.9941 - val_loss: 0.2549 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9551}, \u001b[0m\u001b[0;33mloss{0.1367}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2549\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m471.22 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m367.91 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m103.31 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [67] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m68\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 335)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00742\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 336/340\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1340 - accuracy: 0.9600 - val_loss: 0.1412 - val_accuracy: 0.9583\n",
      "Epoch 337/340\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1050 - accuracy: 0.9695 - val_loss: 0.1418 - val_accuracy: 0.9567\n",
      "Epoch 338/340\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0750 - accuracy: 0.9795 - val_loss: 0.1968 - val_accuracy: 0.9567\n",
      "Epoch 339/340\n",
      "256/256 [==============================] - 73s 283ms/step - loss: 0.0504 - accuracy: 0.9854 - val_loss: 0.1996 - val_accuracy: 0.9615\n",
      "Epoch 340/340\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0387 - accuracy: 0.9905 - val_loss: 0.2066 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9615}, \u001b[0m\u001b[0;33mloss{0.1412}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9567\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2067\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m472.31 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m368.73 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m103.58 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [68] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m69\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 340)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00736\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 341/345\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1368 - accuracy: 0.9570 - val_loss: 0.1472 - val_accuracy: 0.9503\n",
      "Epoch 342/345\n",
      "256/256 [==============================] - 73s 285ms/step - loss: 0.1080 - accuracy: 0.9653 - val_loss: 0.1548 - val_accuracy: 0.9567\n",
      "Epoch 343/345\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0805 - accuracy: 0.9746 - val_loss: 0.1455 - val_accuracy: 0.9439\n",
      "Epoch 344/345\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0568 - accuracy: 0.9839 - val_loss: 0.1997 - val_accuracy: 0.9423\n",
      "Epoch 345/345\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.1738 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9567}, \u001b[0m\u001b[0;33mloss{0.1455}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1738\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m473.80 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m369.40 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m104.40 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [69] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m70\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 345)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.0073\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 346/350\n",
      "256/256 [==============================] - 78s 290ms/step - loss: 0.1145 - accuracy: 0.9634 - val_loss: 0.1347 - val_accuracy: 0.9567\n",
      "Epoch 347/350\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0898 - accuracy: 0.9744 - val_loss: 0.1515 - val_accuracy: 0.9455\n",
      "Epoch 348/350\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0644 - accuracy: 0.9817 - val_loss: 0.1519 - val_accuracy: 0.9503\n",
      "Epoch 349/350\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0426 - accuracy: 0.9868 - val_loss: 0.1899 - val_accuracy: 0.9519\n",
      "Epoch 350/350\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0298 - accuracy: 0.9934 - val_loss: 0.2036 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9567}, \u001b[0m\u001b[0;33mloss{0.1347}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2036\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m471.32 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m368.10 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m103.22 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [70] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m71\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 350)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00724\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 351/355\n",
      "256/256 [==============================] - 78s 290ms/step - loss: 0.1558 - accuracy: 0.9548 - val_loss: 0.2013 - val_accuracy: 0.9503\n",
      "Epoch 352/355\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1259 - accuracy: 0.9609 - val_loss: 0.1785 - val_accuracy: 0.9455\n",
      "Epoch 353/355\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0846 - accuracy: 0.9761 - val_loss: 0.2421 - val_accuracy: 0.9471\n",
      "Epoch 354/355\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0598 - accuracy: 0.9854 - val_loss: 0.1833 - val_accuracy: 0.9471\n",
      "Epoch 355/355\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.0421 - accuracy: 0.9922 - val_loss: 0.2641 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9503}, \u001b[0m\u001b[0;33mloss{0.1785}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2641\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m473.17 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m367.51 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m105.66 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [71] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m72\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 355)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00718\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 356/360\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1279 - accuracy: 0.9622 - val_loss: 0.2312 - val_accuracy: 0.9503\n",
      "Epoch 357/360\n",
      "256/256 [==============================] - 72s 280ms/step - loss: 0.1043 - accuracy: 0.9678 - val_loss: 0.1771 - val_accuracy: 0.9471\n",
      "Epoch 358/360\n",
      "256/256 [==============================] - 73s 286ms/step - loss: 0.0651 - accuracy: 0.9819 - val_loss: 0.1557 - val_accuracy: 0.9599\n",
      "Epoch 359/360\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0423 - accuracy: 0.9885 - val_loss: 0.2236 - val_accuracy: 0.9519\n",
      "Epoch 360/360\n",
      "256/256 [==============================] - 73s 284ms/step - loss: 0.0286 - accuracy: 0.9929 - val_loss: 0.2017 - val_accuracy: 0.9615\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9615}, \u001b[0m\u001b[0;33mloss{0.1557}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9615\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2017\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m474.50 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m369.57 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m104.93 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [72] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m73\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 360)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00712\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 361/365\n",
      "256/256 [==============================] - 78s 290ms/step - loss: 0.1378 - accuracy: 0.9546 - val_loss: 0.1951 - val_accuracy: 0.9599\n",
      "Epoch 362/365\n",
      "256/256 [==============================] - 73s 282ms/step - loss: 0.1065 - accuracy: 0.9653 - val_loss: 0.1374 - val_accuracy: 0.9519\n",
      "Epoch 363/365\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0748 - accuracy: 0.9788 - val_loss: 0.1582 - val_accuracy: 0.9535\n",
      "Epoch 364/365\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0522 - accuracy: 0.9849 - val_loss: 0.1623 - val_accuracy: 0.9551\n",
      "Epoch 365/365\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0443 - accuracy: 0.9893 - val_loss: 0.1564 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9599}, \u001b[0m\u001b[0;33mloss{0.1374}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1564\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m473.15 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m368.77 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m104.38 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [73] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m74\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 365)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00706\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 366/370\n",
      "256/256 [==============================] - 78s 290ms/step - loss: 0.1440 - accuracy: 0.9578 - val_loss: 0.1293 - val_accuracy: 0.9519\n",
      "Epoch 367/370\n",
      "256/256 [==============================] - 73s 283ms/step - loss: 0.1165 - accuracy: 0.9641 - val_loss: 0.1620 - val_accuracy: 0.9567\n",
      "Epoch 368/370\n",
      "256/256 [==============================] - 73s 285ms/step - loss: 0.0801 - accuracy: 0.9788 - val_loss: 0.1384 - val_accuracy: 0.9583\n",
      "Epoch 369/370\n",
      "256/256 [==============================] - 73s 286ms/step - loss: 0.0449 - accuracy: 0.9866 - val_loss: 0.1493 - val_accuracy: 0.9599\n",
      "Epoch 370/370\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 0.1637 - val_accuracy: 0.9599\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9599}, \u001b[0m\u001b[0;33mloss{0.1293}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9599\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1637\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m474.27 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m370.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m103.50 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [74] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m75\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 370)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.007\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 371/375\n",
      "256/256 [==============================] - 78s 288ms/step - loss: 0.1342 - accuracy: 0.9583 - val_loss: 0.1575 - val_accuracy: 0.9503\n",
      "Epoch 372/375\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1141 - accuracy: 0.9683 - val_loss: 0.1725 - val_accuracy: 0.9455\n",
      "Epoch 373/375\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0798 - accuracy: 0.9773 - val_loss: 0.2291 - val_accuracy: 0.9327\n",
      "Epoch 374/375\n",
      "256/256 [==============================] - 73s 285ms/step - loss: 0.0553 - accuracy: 0.9851 - val_loss: 0.1462 - val_accuracy: 0.9567\n",
      "Epoch 375/375\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0300 - accuracy: 0.9944 - val_loss: 0.1649 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9567}, \u001b[0m\u001b[0;33mloss{0.1462}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1649\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m473.96 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m369.04 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m104.92 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [75] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m76\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 375)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00694\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 376/380\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1311 - accuracy: 0.9590 - val_loss: 0.1276 - val_accuracy: 0.9583\n",
      "Epoch 377/380\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.1029 - accuracy: 0.9712 - val_loss: 0.1279 - val_accuracy: 0.9535\n",
      "Epoch 378/380\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0736 - accuracy: 0.9802 - val_loss: 0.1284 - val_accuracy: 0.9519\n",
      "Epoch 379/380\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0539 - accuracy: 0.9851 - val_loss: 0.1608 - val_accuracy: 0.9567\n",
      "Epoch 380/380\n",
      "256/256 [==============================] - 73s 284ms/step - loss: 0.0398 - accuracy: 0.9902 - val_loss: 0.1575 - val_accuracy: 0.9599\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9599}, \u001b[0m\u001b[0;33mloss{0.1276}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9615\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1575\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m474.64 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m369.54 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m105.10 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [76] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m77\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 380)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00688\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 381/385\n",
      "256/256 [==============================] - 79s 291ms/step - loss: 0.1472 - accuracy: 0.9580 - val_loss: 0.1385 - val_accuracy: 0.9599\n",
      "Epoch 382/385\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1162 - accuracy: 0.9626 - val_loss: 0.1531 - val_accuracy: 0.9583\n",
      "Epoch 383/385\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0793 - accuracy: 0.9780 - val_loss: 0.1436 - val_accuracy: 0.9583\n",
      "Epoch 384/385\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0593 - accuracy: 0.9834 - val_loss: 0.1897 - val_accuracy: 0.9599\n",
      "Epoch 385/385\n",
      "256/256 [==============================] - 73s 285ms/step - loss: 0.0354 - accuracy: 0.9917 - val_loss: 0.1613 - val_accuracy: 0.9647\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9647}, \u001b[0m\u001b[0;33mloss{0.1385}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9647\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1613\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m473.41 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m369.06 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m104.35 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [77] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m78\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 385)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00682\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 386/390\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1225 - accuracy: 0.9629 - val_loss: 0.1213 - val_accuracy: 0.9551\n",
      "Epoch 387/390\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0945 - accuracy: 0.9685 - val_loss: 0.3275 - val_accuracy: 0.9471\n",
      "Epoch 388/390\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.0677 - accuracy: 0.9817 - val_loss: 0.1697 - val_accuracy: 0.9535\n",
      "Epoch 389/390\n",
      "256/256 [==============================] - 73s 285ms/step - loss: 0.0477 - accuracy: 0.9854 - val_loss: 0.2536 - val_accuracy: 0.9567\n",
      "Epoch 390/390\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0371 - accuracy: 0.9905 - val_loss: 0.1897 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9567}, \u001b[0m\u001b[0;33mloss{0.1213}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9567\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1897\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m476.57 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m369.21 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m107.36 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [78] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m79\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 390)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00676\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 391/395\n",
      "256/256 [==============================] - 78s 289ms/step - loss: 0.1168 - accuracy: 0.9634 - val_loss: 0.1862 - val_accuracy: 0.9503\n",
      "Epoch 392/395\n",
      "256/256 [==============================] - 73s 286ms/step - loss: 0.0963 - accuracy: 0.9663 - val_loss: 0.1607 - val_accuracy: 0.9583\n",
      "Epoch 393/395\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0674 - accuracy: 0.9788 - val_loss: 0.1917 - val_accuracy: 0.9551\n",
      "Epoch 394/395\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.1808 - val_accuracy: 0.9583\n",
      "Epoch 395/395\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0299 - accuracy: 0.9919 - val_loss: 0.1983 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9583}, \u001b[0m\u001b[0;33mloss{0.1607}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1983\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m478.53 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m369.54 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m108.99 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [79] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m80\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 395)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.0067\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 396/400\n",
      "256/256 [==============================] - 78s 290ms/step - loss: 0.1282 - accuracy: 0.9612 - val_loss: 0.1346 - val_accuracy: 0.9551\n",
      "Epoch 397/400\n",
      "256/256 [==============================] - 72s 281ms/step - loss: 0.1095 - accuracy: 0.9666 - val_loss: 0.1426 - val_accuracy: 0.9551\n",
      "Epoch 398/400\n",
      "256/256 [==============================] - 73s 284ms/step - loss: 0.0751 - accuracy: 0.9797 - val_loss: 0.1415 - val_accuracy: 0.9599\n",
      "Epoch 399/400\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0723 - accuracy: 0.9822 - val_loss: 0.1433 - val_accuracy: 0.9519\n",
      "Epoch 400/400\n",
      "256/256 [==============================] - 72s 282ms/step - loss: 0.0451 - accuracy: 0.9893 - val_loss: 0.1775 - val_accuracy: 0.9599\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9599}, \u001b[0m\u001b[0;33mloss{0.1346}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9599\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1774\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m477.03 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m369.41 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m107.62 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [80] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m81\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 400)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00664\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 401/405\n",
      "256/256 [==============================] - 81s 299ms/step - loss: 0.1305 - accuracy: 0.9602 - val_loss: 0.1395 - val_accuracy: 0.9551\n",
      "Epoch 402/405\n",
      "256/256 [==============================] - 74s 287ms/step - loss: 0.0977 - accuracy: 0.9705 - val_loss: 0.1623 - val_accuracy: 0.9631\n",
      "Epoch 403/405\n",
      "256/256 [==============================] - 73s 285ms/step - loss: 0.0673 - accuracy: 0.9790 - val_loss: 0.1921 - val_accuracy: 0.9471\n",
      "Epoch 404/405\n",
      "256/256 [==============================] - 74s 287ms/step - loss: 0.0437 - accuracy: 0.9854 - val_loss: 0.1976 - val_accuracy: 0.9599\n",
      "Epoch 405/405\n",
      "256/256 [==============================] - 73s 286ms/step - loss: 0.0337 - accuracy: 0.9907 - val_loss: 0.2166 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9631}, \u001b[0m\u001b[0;33mloss{0.1395}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9679}, loss{0.1162}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9583\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2166\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9679487348. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1162088364. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m506.49 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m376.22 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m130.28 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [81] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m82\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 405)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.00658\u001b[0m\u001b[0;31m\u001b[0m\u001b[0;32m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[5]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 406/410\n",
      "121/256 [=============>................] - ETA: 33s - loss: 0.1526 - accuracy: 0.9525"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "# CONF <-------------------------------------------------------------------------->\n",
    "# Hyperparameters for training the model:\n",
    "max_epoch = 489 # max_epoch: Maximum number of epochs to train for. Use >=256 for full fine-tuning of large models.\n",
    "subset_epoch = 5 # subset_epoch: Number of epochs to train each subset.\n",
    "subset_epoch_FT = 5 # subset_epoch_FT: subset_epoch after pre-training epochs.\n",
    "PL_epoch = 26 # PL_epoch: Number of pre-training epochs. Use >=24 for large models or 0/1 for fine-tuning only.\n",
    "subset_size = 4096 # subset_size: Size of each training subset. Common values: 512, 1024, 2048, 3200, 4096, 8192.\n",
    "Conf_batch_size_REV2 = 16 # Conf_batch_size_REV2: Batch size.\n",
    "RES_Train = False # RES_Train: Resume training if True.\n",
    "MAX_LR = 0.01 # MAX_LR: Maximum learning rate.\n",
    "DEC_LR = 0.00006 # DEC_LR: Learning rate decay.\n",
    "MIN_LR = 0.0005 # MIN_LR: Minimum learning rate.\n",
    "RES_LR = 0.006 # RES_LR: Resuming learning rate.\n",
    "OneCycleLr_UFTS = False # OneCycleLr_UFTS: Set the OneCycleLr max epochs to the estimated full training SUB epochs. (DEC_LR and MIN_LR dont have any effect if True)\n",
    "Debug_OUTPUT_DPS = True # Debug_OUTPUT_DPS: Output debug image samples if True.\n",
    "Debug_OUTPUT_DPS_freq = 42 # Debug_OUTPUT_DPS_freq: Debug image output frequency(epoch).\n",
    "TerminateOnHighTemp_M = True # TerminateOnHighTemp_M: Terminate training on high GPU temp to prevent damage.\n",
    "SAVE_FULLM = True # SAVE_FULLM: Save full model if True.\n",
    "AdvSubsetC = True  # AdvSubsetC: Use advanced subset sampling to prevent overfitting if True.\n",
    "AdvSubsetC_SHR = 32 # AdvSubsetC_SHR: Parameter for advanced subset sampling (shuffling data after n epochs).\n",
    "load_SUB_BRW = True # load_SUB_BRW: Load previous subset weights to speed up training if True. May reduce max accuracy.\n",
    "load_SUB_BRW_MODE = 'val_accuracy' # load_SUB_BRW_MODE: Previous subset weights loading mode - 'val_accuracy' or 'val_loss'.\n",
    "load_SUB_BRW_LMODE = 0 # load_SUB_BRW_LMODE: Previous subset weights loading mode parameter (1 for only on imp and !1 for normal mode (for subset_epoch > 6 normal mode is better)).\n",
    "load_SUB_BRW_LMODE_FN = True # load_SUB_BRW_LMODE_FN: Set load_SUB_BRW_LMODE=1 during fine-tuning if True.\n",
    "ModelCheckpoint_mode = 'auto' # ModelCheckpoint_mode: 'auto', 'min', or 'max' - how to monitor ModelCheckpoint.\n",
    "ModelCheckpoint_Reset_TO = 0.6251 # ModelCheckpoint_Reset_TO: Reset ModelCheckpoint monitor to this value, e.g. 0 or float('inf').\n",
    "Auto_clear_cache = True # Auto_clear_cache: Clear cache during training if True to reduce memory usage.\n",
    "Use_ES_ONSUBT = False # Use_ES_ONSUBT: Early stopping per subset (‚ö†Ô∏èdeprecated‚ö†Ô∏è).\n",
    "EarlyStopping_P = 5 # EarlyStopping_P: Early stopping patience (‚ö†Ô∏èdeprecated‚ö†Ô∏è).\n",
    "Use_tensorboard_profiler = False # Use_tensorboard_profiler: Enable tensorboard profiler.\n",
    "Use_extended_tensorboard = False # Use_extended_tensorboard: Enable extended tensorboard (Some funcs may not work).\n",
    "Use_tensorBoard_img = False # Use_tensorBoard_img: Enable tensorboard image logging.\n",
    "Use_noise_func_TRLRev2 = True # Use_noise_func_TRLRev2: Use noise function for IDG if True.\n",
    "Show_confusion_matrix_tensorBoard = False # Show_confusion_matrix_tensorBoard: Show confusion matrix on tensorboard.\n",
    "BEST_RSN = 'PAI_model_T' # Best model save name prefix. (Uses a lot of memory and storage).\n",
    "ALWAYS_REFIT_IDG = 1 # ALWAYS_REFIT_IDG: if 0/False - do not always refit IDG. if 1 - always refit IDG (In Start). if 2 - always refit IDG (After each epoch) (slow).\n",
    "IDG_FitP_PATH = 'Data\\\\image_SUB_generator.pkl'\n",
    "# CONF END <---------------------------------------------------------------------->\n",
    "#Prep\n",
    "if RES_Train:\n",
    "    MAX_LR = RES_LR\n",
    "    PL_epoch = 1\n",
    "#VAR\n",
    "Total_SUB_epoch_C = 0 # TO FIX TensorBoard\n",
    "CU_LR = MAX_LR\n",
    "all_histories = []\n",
    "chosen_indices = []\n",
    "subset_sizes = []\n",
    "best_acc = 0\n",
    "best_loss = float('inf')\n",
    "#Funcs\n",
    "def normalize_TO_RANGE(arr, min_val, max_val):\n",
    "  arr = arr.astype('float32')\n",
    "  arr = (arr - arr.min()) / (arr.max() - arr.min())\n",
    "  arr = arr * (max_val - min_val) + min_val\n",
    "  return arr\n",
    "\n",
    "def Z_SCORE_normalize(arr):\n",
    "   arr = arr.astype('float32')\n",
    "   mean = np.mean(arr)\n",
    "   std_dev = np.std(arr)\n",
    "   arr = (arr - mean) / std_dev\n",
    "   return arr\n",
    "\n",
    "def add_image_grain_TRLRev2(image, intensity = 0.01):\n",
    "    # Generate random noise array\n",
    "    noise = (np.random.randint(-255, 255, size=image.shape, dtype=np.int16) \\\n",
    "          + np.random.randint(-255, 255, size=image.shape, dtype=np.int16)) / 2\n",
    "\n",
    "    # Scale the noise array\n",
    "    scaled_noise = (noise * intensity).astype(np.float32)\n",
    "    # Add the noise to the image\n",
    "    noisy_image = cv2.add(image, scaled_noise)\n",
    "\n",
    "    return noisy_image\n",
    "# noise_func_TRLRev2 ([REV1 OLD])\n",
    "def noise_func_TRLRev2(image): \n",
    "    noise_type = np.random.choice(['L1', 'L2', 'L3', 'none'])\n",
    "    new_image = np.copy(image)\n",
    "    \n",
    "    if noise_type == 'L3':\n",
    "        intensityL2 = random.uniform(-0.08, 0.08)\n",
    "        intensityL1 = random.uniform(-0.05, 0.05)\n",
    "    else:\n",
    "        intensityL2 = random.uniform(-0.09, 0.09)\n",
    "        intensityL1 = random.uniform(-0.06, 0.06)\n",
    "        \n",
    "    block_size_L1 = random.randint(16, 32)\n",
    "    block_size_L2 = random.randint(32, 112)\n",
    "    \n",
    "    if noise_type == 'L2' or noise_type == 'L3':\n",
    "        for i in range(0, image.shape[0], block_size_L2):\n",
    "            for j in range(0, image.shape[1], block_size_L2):\n",
    "                block = image[i:i+block_size_L2, j:j+block_size_L2]\n",
    "                block = (np.random.rand() * intensityL2 + 1) * block\n",
    "                new_image[i:i+block_size_L2, j:j+block_size_L2] = block\n",
    "        image = new_image      \n",
    "        \n",
    "    if noise_type == 'L1' or noise_type == 'L3': \n",
    "        for i in range(0, image.shape[0], block_size_L1):\n",
    "            for j in range(0, image.shape[1], block_size_L1):\n",
    "                block = image[i:i+block_size_L1, j:j+block_size_L1]\n",
    "                block = (np.random.rand() * intensityL1 + 1) * block\n",
    "                new_image[i:i+block_size_L1, j:j+block_size_L1] = block\n",
    "    \n",
    "    if add_img_grain:\n",
    "        intensity = random.uniform(0, 0.07)  # Random intensity \n",
    "        new_image = add_image_grain_TRLRev2(new_image, intensity=intensity)\n",
    "    return new_image\n",
    "#CONST\n",
    "train_SUB_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=179,\n",
    "        zoom_range=0.18, \n",
    "        shear_range=0.18,\n",
    "        width_shift_range=0.18,\n",
    "        brightness_range=(0.82, 1.18),\n",
    "        height_shift_range=0.18,\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        zca_whitening=False,\n",
    "        interpolation_order=2,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=noise_func_TRLRev2 if Use_noise_func_TRLRev2 else None\n",
    "    )\n",
    "class TerminateOnHighTemp(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, active=True, check_every_n_batches=2, high_temp=75, low_temp=60, pause_time=60):\n",
    "        super().__init__()\n",
    "        self.active = active\n",
    "        self.check_every_n_batches = check_every_n_batches\n",
    "        self.high_temp = high_temp\n",
    "        self.low_temp = low_temp\n",
    "        self.pause_time = pause_time\n",
    "        self.batch_counter = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if not self.active:\n",
    "            return\n",
    "        self.batch_counter += 1\n",
    "        if self.batch_counter % self.check_every_n_batches == 0:\n",
    "            temperature = gpu_control.get_temperature()\n",
    "            if temperature > self.high_temp:\n",
    "                print_Color(f'\\nPausing training due to high GPU temperature! (for [{self.pause_time}]sec)', ['red'], advanced_mode=False)\n",
    "                time.sleep(self.pause_time) \n",
    "                while gpu_control.get_temperature() > self.low_temp:\n",
    "                    time.sleep(4)\n",
    "                print_Color('Resuming training...', ['yellow'])\n",
    "class ExtendedTensorBoard(TensorBoard):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        logs['momentum'] = self.model.optimizer.momentum  \n",
    "        super().on_epoch_end(epoch, logs)\n",
    "class DummyCallback(Callback):\n",
    "    pass\n",
    "# Define a function to plot the confusion matrix\n",
    "def plot_confusion_matrix_TensorBoard(epoch, logs):\n",
    "    # Use the model to predict the values from the test dataset.\n",
    "    test_pred_raw = model.predict(x_test, verbose=0)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)  # Convert predictions from one-hot encoded to binary\n",
    "\n",
    "    # Convert true labels from one-hot encoded to binary\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = confusion_matrix(y_true, test_pred)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=plt.cm.Blues)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    # Add image summary\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", image, step=epoch)\n",
    "steps_per_epoch_train_SUB = subset_size // Conf_batch_size_REV2\n",
    "#callbacks>>>\n",
    "# EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                               patience=EarlyStopping_P,\n",
    "                               verbose=1, restore_best_weights=True,\n",
    "                               mode='max'\n",
    "                               ) if Use_ES_ONSUBT else DummyCallback()\n",
    "# ModelCheckpoint \n",
    "checkpoint_SUB = ModelCheckpoint(f'cache\\\\model_SUB_checkpoint-{{epoch:03d}}-{{{load_SUB_BRW_MODE}:.4f}}.h5', # f'cache\\\\model_SUB_checkpoint-{{epoch:03d}}-{{{load_SUB_BRW_MODE}:.4f}}.h5', \n",
    "                                 monitor=load_SUB_BRW_MODE,\n",
    "                                 save_best_only=True, mode=ModelCheckpoint_mode,\n",
    "                                 save_weights_only = True\n",
    "                                 ) if load_SUB_BRW else DummyCallback()\n",
    "checkpoint_SUB.best = ModelCheckpoint_Reset_TO\n",
    "# TerminateOnHighTemp\n",
    "TerminateOnHighTemp_CB = TerminateOnHighTemp(active=TerminateOnHighTemp_M,\n",
    "                                             check_every_n_batches=6,\n",
    "                                             high_temp=73,\n",
    "                                             low_temp=58,\n",
    "                                             pause_time=60)\n",
    "# confusion_matrix_callback\n",
    "confusion_matrix_callback = LambdaCallback(on_epoch_end=plot_confusion_matrix_TensorBoard) if Show_confusion_matrix_tensorBoard else DummyCallback()\n",
    "# TensorBoard\n",
    "log_dir = 'logs/fit/' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')\n",
    "if Show_confusion_matrix_tensorBoard:\n",
    "    file_writer = tf.summary.create_file_writer(log_dir)\n",
    "if Use_extended_tensorboard:\n",
    "    tensorboard_callback = ExtendedTensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        write_images=Use_tensorBoard_img,  \n",
    "        histogram_freq=1,\n",
    "        update_freq='epoch',\n",
    "        write_grads=True,\n",
    "        profile_batch='256,512' if Use_tensorboard_profiler else 0\n",
    "    )\n",
    "else:\n",
    "    tensorboard_callback = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        write_images=Use_tensorBoard_img, \n",
    "        histogram_freq=1,\n",
    "        update_freq='epoch',\n",
    "        write_grads=True,\n",
    "        profile_batch='256,512' if Use_tensorboard_profiler else 0\n",
    "    )\n",
    "# OneCycleLr\n",
    "if OneCycleLr_UFTS:    \n",
    "    learning_rate_schedule_SUB = OneCycleLr(max_lr=MAX_LR,\n",
    "                                            steps_per_epoch=steps_per_epoch_train_SUB,\n",
    "                                            epochs=(PL_epoch * subset_epoch) + ((max_epoch - PL_epoch) * subset_epoch_FT))    \n",
    "#PRES\n",
    "# ...\n",
    "#MAIN\n",
    "print('Training the model...')\n",
    "# INFOp\n",
    "print_Color('\\nSetup Verbose:', ['yellow'])\n",
    "print_Color(f'~*Setting TensorBoard Log dir to ~*[{log_dir}]~*...', ['cyan', 'green', 'cyan'], advanced_mode=True)\n",
    "print_Color(f'~*Use_extended_tensorboard ~*[{Use_extended_tensorboard}]~*.', ['cyan', 'green', 'cyan'], advanced_mode=True)\n",
    "print_Color(f'~*Debug_OUTPUT_DPS ~*[{Debug_OUTPUT_DPS}]~*.', ['cyan', 'green', 'cyan'], advanced_mode=True)\n",
    "print_Color(f'~*OneCycleLr_UFTS ~*[{OneCycleLr_UFTS}]~*.', ['cyan', 'green', 'cyan'], advanced_mode=True)\n",
    "#warnings\n",
    "P_warning('RES_Train is True.') if RES_Train else None\n",
    "print_Color('Setup Verbose END.', ['yellow'])\n",
    "# MAIN LOOP\n",
    "try:\n",
    "    for epoch in range(1, max_epoch):\n",
    "        # Start Epoch\n",
    "        STG = 'Learning the patterns' if epoch < PL_epoch else 'Fine tuning'\n",
    "        C_subset_epoch = subset_epoch if epoch < PL_epoch else subset_epoch_FT\n",
    "        if epoch > PL_epoch and load_SUB_BRW_LMODE_FN: load_SUB_BRW_LMODE = 1\n",
    "        start_FULL_time = time.time()\n",
    "        if Auto_clear_cache:\n",
    "            subprocess.run([\"Cache_clear.cmd\"], shell=True)\n",
    "        # TSEC: Total-Subset-Epoch-Count\n",
    "        print_Color(f'\\n~*Epoch: ~*{epoch}~*/~*{max_epoch} (TSEC: {Total_SUB_epoch_C})~* | ~*[{STG}]', ['normal', 'cyan', 'normal', 'green', 'blue', 'green'], advanced_mode=True)\n",
    "        # DP\n",
    "        if not AdvSubsetC:\n",
    "            print_Color('Shuffling data...', ['yellow'])\n",
    "            x_train, y_train = shuffle_data(x_train, y_train)\n",
    "        print_Color(f'~*Taking a subset of ~*[|{subset_size}|AdvSubset:{AdvSubsetC}]~*...', ['yellow', 'green', 'yellow'], advanced_mode=True)\n",
    "        if AdvSubsetC:\n",
    "            if AdvSubsetC_SHR > 0 and epoch % AdvSubsetC_SHR == 0:\n",
    "                print_Color('‚îî‚îÄ‚îÄ‚îÄShuffling data...', ['yellow'])\n",
    "                x_train, y_train = shuffle_data(x_train, y_train)\n",
    "                chosen_indices = []  # Reset chosen_indices\n",
    "\n",
    "            available_indices = list(set(range(x_train.shape[0])) - set(chosen_indices))\n",
    "            \n",
    "            if len(available_indices) < subset_size:\n",
    "                #DEBUG\n",
    "                # print('[DEBUG]-[AdvSubset]: Not enough available indices using the indices that were chosen the longest time ago.')\n",
    "                # If there are not enough available indices, choose from the indices that were chosen the longest time ago\n",
    "                old_indices = chosen_indices[:subset_size - len(available_indices)]\n",
    "                subset_indices = old_indices + list(np.random.choice(available_indices, len(available_indices), replace=False))\n",
    "                \n",
    "                # Update the list of chosen indices and their sizes\n",
    "                chosen_indices = chosen_indices[len(old_indices):] + subset_indices\n",
    "                subset_sizes = subset_sizes[len(old_indices):] + [subset_size] * len(subset_indices)\n",
    "            else:\n",
    "                subset_indices = list(np.random.choice(available_indices, subset_size, replace=False))\n",
    "                \n",
    "                # Add the chosen indices to the list of already chosen indices\n",
    "                chosen_indices += subset_indices\n",
    "                subset_sizes += [subset_size] * len(subset_indices)\n",
    "        else:\n",
    "            subset_indices = np.random.choice(x_train.shape[0], subset_size, replace=False)\n",
    "        # Taking the subset\n",
    "        x_SUB_train = x_train[subset_indices]\n",
    "        y_SUB_train = y_train[subset_indices]\n",
    "        x_SUB_train, y_SUB_train = shuffle_data(x_SUB_train, y_SUB_train)\n",
    "        assert len(x_SUB_train) == subset_size, f'Expected subset size of {subset_size}, but got {len(x_SUB_train)}'\n",
    "        print_Color('Preparing train data...', ['yellow']) \n",
    "        # if epoch == 1: # OLD\n",
    "        #     print_Color('- ImageDataGenerator fit...', ['yellow']) \n",
    "        #     train_SUB_datagen.fit(x_SUB_train * 255, augment=True, rounds=6)\n",
    "        #     print_Color('- ImageDataGenerator fit done.', ['yellow'])\n",
    "        if epoch == 1 or ALWAYS_REFIT_IDG == 2:\n",
    "            if os.path.exists(IDG_FitP_PATH) and not ALWAYS_REFIT_IDG:\n",
    "                print_Color('- Loading fitted ImageDataGenerator...', ['yellow'])\n",
    "                train_SUB_datagen = pickle.load(open(IDG_FitP_PATH, 'rb')) \n",
    "            else:\n",
    "                print_Color('- Fitting ImageDataGenerator...', ['yellow'])\n",
    "                IDG_FIT_rc = 3 if ALWAYS_REFIT_IDG == 2 else 12\n",
    "                train_SUB_datagen.fit(x_SUB_train * 255, augment=True, rounds=6)\n",
    "                pickle.dump(train_SUB_datagen, open(IDG_FitP_PATH, 'wb'))\n",
    "            print_Color('- ImageDataGenerator fit done.', ['yellow']) \n",
    "\n",
    "        print_Color('- Augmenting Image Data...', ['yellow'])    \n",
    "        train_SUB_augmented_images = train_SUB_datagen.flow(x_SUB_train * 255,\n",
    "                                                            y_SUB_train,\n",
    "                                                            shuffle=False,\n",
    "                                                            batch_size=len(x_SUB_train)\n",
    "                                                            ).next()\n",
    "        print_Color('- Normalizing Image Data...', ['yellow'])\n",
    "        x_SUB_train = normalize_TO_RANGE(train_SUB_augmented_images[0], 0, 255)\n",
    "        x_SUB_train = apply_clahe_rgb_array(x_SUB_train, 0.5) / 255\n",
    "        # x_SUB_train = x_SUB_train / 255\n",
    "        x_SUB_train = normalize_TO_RANGE(Z_SCORE_normalize(x_SUB_train), 0, 1)\n",
    "        y_SUB_train = train_SUB_augmented_images[1]\n",
    "        # DEBUG\n",
    "        if Debug_OUTPUT_DPS and (epoch % Debug_OUTPUT_DPS_freq == 0 or epoch == 1):\n",
    "            SITD = np.random.choice(subset_size, size=400, replace=False)\n",
    "            S_dir = 'Samples/TSR_SUB_400_' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')\n",
    "            print_Color(f'~*- Debug DP Sample dir: ~*{S_dir}', ['red', 'green'], advanced_mode=True)\n",
    "            save_images_to_dir(np.clip(x_SUB_train[SITD], 0, 1), y_SUB_train[SITD], S_dir)\n",
    "        # learning_rate_schedule_SUB\n",
    "        if PL_epoch == 0:\n",
    "            CU_LR = MIN_LR\n",
    "        elif epoch >= PL_epoch and CU_LR > MIN_LR:\n",
    "            if (CU_LR - DEC_LR) < MIN_LR:\n",
    "                CU_LR = MIN_LR\n",
    "            else:\n",
    "                CU_LR -= DEC_LR\n",
    "        if not OneCycleLr_UFTS:    \n",
    "            learning_rate_schedule_SUB = OneCycleLr(max_lr=CU_LR,\n",
    "                                                    steps_per_epoch=steps_per_epoch_train_SUB,\n",
    "                                                    epochs=C_subset_epoch)\n",
    "        #FV\n",
    "        print_Color(f'~*Setting training OneCycleLr::maxlr to ~*[{(str(round(CU_LR, 8)) + \"~*~*\") if not OneCycleLr_UFTS else \"~*OneCycleLr_UFTS Is ON~*\"}]~*...',\n",
    "                    ['yellow', 'green', 'red', 'green', 'yellow'], advanced_mode=True)\n",
    "        print_Color(f'~*Setting training subset epoch.c to ~*[{C_subset_epoch}]~*...', ['yellow', 'green', 'yellow'], advanced_mode=True)\n",
    "        # Train\n",
    "        print_Color('Training on subset...', ['green'])\n",
    "        start_SUBO_time = time.time()\n",
    "        SUB_history = model.fit(x_SUB_train,\n",
    "                            y_SUB_train,\n",
    "                            epochs=C_subset_epoch + Total_SUB_epoch_C, # TO FIX TensorBoard (Total_SUB_epoch_C)\n",
    "                            batch_size=Conf_batch_size_REV2,\n",
    "                            validation_data=(x_test, y_test),\n",
    "                            verbose='auto',\n",
    "                            initial_epoch=Total_SUB_epoch_C, # TO FIX TensorBoard\n",
    "                            callbacks=[\n",
    "                                        learning_rate_schedule_SUB,\n",
    "                                        TerminateOnHighTemp_CB,\n",
    "                                        checkpoint_SUB,\n",
    "                                        early_stopping,\n",
    "                                        tensorboard_callback,\n",
    "                                        confusion_matrix_callback\n",
    "                                        ]\n",
    "        )\n",
    "        end_SUBO_time = time.time()\n",
    "        print_Color('Subset training done.', ['green'])\n",
    "        if load_SUB_BRW_LMODE == 1:\n",
    "            if max(SUB_history.history['val_accuracy']) > best_acc: \n",
    "                load_weights = True \n",
    "            elif min(SUB_history.history['val_loss']) < best_loss:\n",
    "                load_weights = True \n",
    "            else:\n",
    "                load_weights = False    \n",
    "        else: \n",
    "            load_weights = True \n",
    "        \n",
    "        if load_SUB_BRW and load_weights:\n",
    "            print_Color('Loading the best weights...', ['yellow'])\n",
    "            # Get the filename of the best weights file\n",
    "            list_of_files = glob.glob('cache\\\\*.h5') \n",
    "            try:\n",
    "                best_weights_filename = max(list_of_files, key=os.path.getctime)\n",
    "                print_Color(f'Loading weights from file {best_weights_filename}...', ['yellow'])\n",
    "                model.load_weights(best_weights_filename)\n",
    "            except Exception as Err:\n",
    "                print_Color(f'ERROR: Failed to load weights. Error: {Err}', ['red'])\n",
    "        elif load_SUB_BRW and (not load_weights):\n",
    "            print_Color_V2(f'<light_red>Not loading weights<green>[<light_blue>BSR:<yellow>acc{{{max(SUB_history.history[\"val_accuracy\"]):.4f}}}, <yellow>loss{{{min(SUB_history.history[\"val_loss\"]):.4f}}}<light_magenta>|<light_blue>BTR:<green>acc{{{best_acc:.4f}}}, loss{{{best_loss:.4f}}}]')\n",
    "        all_histories.append(SUB_history.history)\n",
    "        checkpoint_SUB.best = ModelCheckpoint_Reset_TO\n",
    "        # Garbage Collection (memory)\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()   \n",
    "        # Evaluate the model on the test data\n",
    "        evaluation = model.evaluate(x_test, y_test, verbose=0)\n",
    "        \n",
    "        # Extract the loss and accuracy from the evaluation results\n",
    "        loss = evaluation[0]\n",
    "        acc = evaluation[1]\n",
    "        print_Color(f'~*Model Test acc: ~*{acc:.4f}', ['yellow', 'green'], advanced_mode=True)\n",
    "        print_Color(f'~*Model Test loss: ~*{loss:.4f}', ['yellow', 'green'], advanced_mode=True)\n",
    "        # If the accuracy is higher than the best_acc\n",
    "        if acc > best_acc:\n",
    "            print_Color_V2(f'<yellow>Improved model accuracy from <green>{best_acc:10f} <yellow>to <green>{acc:10f}<yellow>. <light_cyan>Saving model.')\n",
    "            # Update the best_acc\n",
    "            best_acc = acc\n",
    "            if SAVE_FULLM:\n",
    "                # Save the model\n",
    "                if SAVE_TYPE == 'TF':\n",
    "                    print_Color_V2(f'<cyan>Saving full model tf format...')\n",
    "                    model.save(BEST_RSN, save_format='tf')\n",
    "                else:\n",
    "                    print_Color_V2(f'<cyan>Saving full model H5 format...')\n",
    "                    model.save(f'{BEST_RSN}.h5')\n",
    "            model.save_weights('PAI_model_weights.h5')\n",
    "        else:\n",
    "            print_Color_V2(f'<light_red>Model accuracy did not improve from {best_acc:.10f}. Not saving model.')\n",
    "            \n",
    "        # If the loss is higher than the best_loss\n",
    "        if loss < best_loss:\n",
    "            print_Color_V2(f'<yellow>Improved model loss from <green>{best_loss:.10f} <yellow>to <green>{loss:.10f}<yellow>. <light_cyan>Saving model.')\n",
    "            \n",
    "            # Update the best_acc\n",
    "            best_loss = loss\n",
    "            \n",
    "            if SAVE_FULLM:\n",
    "                # Save the model\n",
    "                if SAVE_TYPE == 'TF':\n",
    "                    print_Color_V2(f'<cyan>Saving full model tf format...')\n",
    "                    model.save(BEST_RSN + '_BL', save_format='tf')\n",
    "                else:\n",
    "                    print_Color_V2(f'<cyan>Saving full model H5 format...')\n",
    "                    model.save(f'{BEST_RSN}_BL.h5')\n",
    "            model.save_weights('PAI_model_weights_BL.h5')\n",
    "        else:\n",
    "            print_Color_V2(f'<light_red>Model loss did not improve from {best_loss:.10f}. Not saving model.') \n",
    "        # Garbage Collection (memory)\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()   \n",
    "        # Epoch end\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_FULL_time\n",
    "        print_Color_V2(f'<yellow>Time taken for epoch(FULL): <green>{epoch_time:.2f} <cyan>sec')\n",
    "        epoch_SUB_time = end_SUBO_time - start_SUBO_time\n",
    "        print_Color_V2(f'<yellow>Time taken for epoch(SUBo): <green>{epoch_SUB_time:.2f} <cyan>sec')\n",
    "        epoch_OTHERO_time = epoch_time - epoch_SUB_time\n",
    "        print_Color_V2(f'<yellow>Time taken for epoch(OTHERo): <green>{epoch_OTHERO_time:.2f} <cyan>sec')\n",
    "        print_Color(f'<---------------------------------------|Epoch [{epoch}] END|--------------------------------------->', ['cyan'])\n",
    "        Total_SUB_epoch_C += C_subset_epoch # TO FIX TensorBoard\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nKeyboardInterrupt.')\n",
    "# End\n",
    "try:\n",
    "    history = {}\n",
    "    for key in all_histories[0].keys():\n",
    "        # For each metric, concatenate the values from all histories\n",
    "        history[key] = np.concatenate([h[key] for h in all_histories])\n",
    "except Exception as Err:\n",
    "    print(f'Failed to make model `history` var.\\nERROR: {Err}')\n",
    "    \n",
    "print('Training done.\\n')\n",
    "# del vars\n",
    "try:\n",
    "    del train_SUB_datagen\n",
    "    del train_SUB_augmented_images\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rev1 (‚ö†Ô∏èdeprecated‚ö†Ô∏è)\n",
    "```\n",
    "Working: ‚úÖ\n",
    "Other:\n",
    " + Tensorboard works.\n",
    " - Can cause overfitting.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "#CONF\n",
    "Conf_batch_size = 8 \n",
    "OneCycleLr_epoch = 20\n",
    "Learning_rate_conf = 3 # 1 and 2 for custom learning_rate_fn and 3 for OneCycleLr (Better for full training)\n",
    "#TensorBoard conf\n",
    "TensorBoard_UF = 1 # 1 for Slow 2 for fast (very slow tarining)\n",
    "# Learning rate configuration\n",
    "Learning_rate_conf_SET2C = 3 # 1 for SGD and 2 for Adam and... for lower lr 3 for very high lr\n",
    "MAX_LR = 0.0174\n",
    "# First time\n",
    "if Learning_rate_conf == 1:\n",
    "    learning_rate_start = 8e-04\n",
    "    learning_rate_max = 5e-03\n",
    "    learning_rate_min = 5e-05\n",
    "    learning_rate_rampup_epochs = 5\n",
    "    learning_rate_sustain_epochs = 1\n",
    "    learning_rate_exp_decay = .3\n",
    "    #TEMP\n",
    "    # learning_rate_start = 8e-04\n",
    "    # learning_rate_max = 1e-02\n",
    "    # learning_rate_min = 8e-04\n",
    "    # learning_rate_rampup_epochs = 5\n",
    "    # learning_rate_sustain_epochs = 3\n",
    "    # learning_rate_exp_decay = .45\n",
    "# 2th time\n",
    "if Learning_rate_conf == 2:\n",
    "    if Learning_rate_conf_SET2C == 1:\n",
    "        learning_rate_start = 4.10e-06\n",
    "        learning_rate_max = 4.10e-06\n",
    "        learning_rate_min = 4.10e-06\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = .1\n",
    "        \n",
    "    elif Learning_rate_conf_SET2C == 2:\n",
    "        learning_rate_start = 4e-07\n",
    "        learning_rate_max = 4e-07\n",
    "        learning_rate_min = 4e-07\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = .1\n",
    "    \n",
    "    elif Learning_rate_conf_SET2C == 3:\n",
    "        learning_rate_start = 5e-04\n",
    "        learning_rate_max = 5e-04\n",
    "        learning_rate_min = 5e-04\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = .1\n",
    "# Function to build learning rate schedule\n",
    "if Learning_rate_conf in [1,2]:\n",
    "    def build_learning_rate_fn(lr_start=learning_rate_start,\n",
    "                            lr_max=learning_rate_max,\n",
    "                            lr_min=learning_rate_min,\n",
    "                            lr_rampup_epochs=learning_rate_rampup_epochs,\n",
    "                            lr_sustain_epochs=learning_rate_sustain_epochs,\n",
    "                            lr_exp_decay=learning_rate_exp_decay):    \n",
    "        lr_max = lr_max * tf.distribute.get_strategy().num_replicas_in_sync\n",
    "        def learning_rate_fn(epoch):\n",
    "            if epoch < lr_rampup_epochs:\n",
    "                lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "            elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "                lr = lr_max\n",
    "            else:\n",
    "                lr = (lr_max - lr_min) *\\\n",
    "                    lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "            return lr\n",
    "        return learning_rate_fn\n",
    "    \n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch_train = len(x_train) // Conf_batch_size\n",
    "\n",
    "# Set up callbacks\n",
    "class EpochEndMON(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        optimizer = self.model.optimizer\n",
    "        if hasattr(optimizer, 'lr'):\n",
    "            lr = tf.keras.backend.get_value(optimizer.lr)\n",
    "            print(f'\\nLearning rate for epoch {epoch+1} is {lr}')\n",
    "        if hasattr(optimizer, 'momentum'):\n",
    "            momentum = tf.keras.backend.get_value(optimizer.momentum)\n",
    "            print(f'Momentum for epoch {epoch+1} is {momentum}')\n",
    "        if logs:\n",
    "            val_loss = logs.get('val_loss')\n",
    "            val_acc = logs.get('val_accuracy')\n",
    "            print(f'Validation loss for epoch {epoch+1} is {val_loss}')\n",
    "            print(f'Validation accuracy for epoch {epoch+1} is {val_acc}')\n",
    "\n",
    "        print_Color_V2(f'`red`<!--------------------------------------|Epoch`yellow` [{epoch+1}]`red` End|--------------------------------------!> `green`PBE‚Üì', start_char='`', end_char='`')\n",
    "\n",
    "# Instantiate the callback\n",
    "EpochEndMON_callback = EpochEndMON()\n",
    "if Learning_rate_conf in [1,2]:\n",
    "    learning_rate_fn = build_learning_rate_fn()\n",
    "    learning_rate_schedule = LearningRateScheduler(learning_rate_fn, verbose=1)\n",
    "else:\n",
    "    learning_rate_schedule = OneCycleLr(max_lr=MAX_LR, steps_per_epoch=steps_per_epoch_train, epochs=OneCycleLr_epoch)\n",
    "if SAVE_TYPE == 'TF':\n",
    "    checkpoint_BVAC = ModelCheckpoint('models\\\\Temp\\\\bestVAC_model', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "    checkpoint_BVL = ModelCheckpoint('models\\\\Temp\\\\bestVL_model', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "else:\n",
    "    checkpoint_BVAC = ModelCheckpoint('models\\\\Temp\\\\bestVAC_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "    checkpoint_BVL = ModelCheckpoint('models\\\\Temp\\\\bestVL_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1, restore_best_weights=True)\n",
    "log_dir = 'logs/fit/' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')\n",
    "TensorBoard_update_freq = 'batch' if TensorBoard_UF == 2 else 'epoch'\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, write_images=True, histogram_freq=1, update_freq=TensorBoard_update_freq, write_grads=True)\n",
    "\n",
    "# Train the model\n",
    "print('Log dir:', log_dir)\n",
    "#MInfo\n",
    "print('Input Shape:', model.input_shape)\n",
    "print('Output Shape:', model.output_shape)\n",
    "print('Loss Function:', model.loss)\n",
    "print('Training the model...\\n')\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=256,\n",
    "                    batch_size=Conf_batch_size,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose='auto',\n",
    "                    callbacks=[early_stopping,\n",
    "                            tensorboard_callback,\n",
    "                            learning_rate_schedule,\n",
    "                            checkpoint_BVAC,\n",
    "                            checkpoint_BVL,\n",
    "                            EpochEndMON_callback])\n",
    "print('Training done.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "Extra_EXT = '_T'\n",
    "# Save the weights\n",
    "print('Saving weights...')\n",
    "model.save_weights('PAI_model_weights.h5')\n",
    "print('Saving full model...')\n",
    "if SAVE_TYPE == 'TF':\n",
    "    print('Saving full model tf format...')\n",
    "    model.save(f'PAI_model{Extra_EXT}', save_format='tf')\n",
    "else:\n",
    "    try:\n",
    "        model.save(f'PAI_model{Extra_EXT}.h5')\n",
    "    except ValueError:\n",
    "        print('failed to save in .h5 format!')\n",
    "        print('Saving full model in tf format...')\n",
    "        model.save(f'PAI_model{Extra_EXT}', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage Collection (memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse model Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "save_list(history, 'history\\\\model_history.pkl.gz', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load history\n",
    "history = load_list('history\\\\model_history.pkl.gz', compressed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T07:04:52.565658900Z",
     "start_time": "2023-12-28T07:04:51.032425100Z"
    }
   },
   "outputs": [],
   "source": [
    "from turtle import left\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Chunk size for 3D plot\n",
    "chunk_size = 6  # Change this to your desired chunk size\n",
    "    \n",
    "def convert_history(history):\n",
    "    if isinstance(history, tf.keras.callbacks.History):\n",
    "        return history.history\n",
    "    else:\n",
    "        return history\n",
    "    \n",
    "def chunked_data(data, chunk_size):\n",
    "    return [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "\n",
    "try:\n",
    "    EPM = 'Epoch(Subset)' if not isinstance(history, tf.keras.callbacks.History) else 'Epoch'    \n",
    "    history = convert_history(history)\n",
    "\n",
    "    # Calculate deltas\n",
    "    delta_loss = np.diff(history['loss'])\n",
    "    delta_accuracy = np.diff(history['accuracy'])\n",
    "\n",
    "    try:\n",
    "        delta_val_loss = np.diff(history['val_loss'])\n",
    "        delta_val_accuracy = np.diff(history['val_accuracy'])\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load val_loss or val_accuracy for delta calculation.')\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    # Loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history['loss'], label='loss')\n",
    "    try:\n",
    "        plt.plot(history['val_loss'], label='val_loss', color='orange')\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load val_loss.')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel(EPM)\n",
    "    plt.ylim(top=max(history['val_loss'][10:]), bottom=0) # (max(history['val_loss'][8:]) + min(history['val_loss'])) / 2\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Density plot for loss\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hist(history['loss'], label='loss density', color='blue', alpha=0.5, bins=100)\n",
    "    try:\n",
    "        plt.hist(history['val_loss'], label='val_loss density', color='orange', alpha=0.5, bins=100)\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load val_loss (density plot).')\n",
    "    plt.title('Density Plot for Loss')\n",
    "    plt.xlabel('Loss')\n",
    "    plt.xlim(right=max(history['val_loss'][10:]), left=0) # (max(history['val_loss'][8:]) + min(history['val_loss'])) / 2\n",
    "    plt.grid(True)\n",
    "    \n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history['accuracy'], label='accuracy')\n",
    "    try:\n",
    "        plt.plot(history['val_accuracy'], label='val_accuracy', color='orange')\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load val_accuracy.')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Density plot for accuracy\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.hist(history['accuracy'], label='accuracy density', color='blue', alpha=0.5, bins=40)\n",
    "    try:\n",
    "        plt.hist(history['val_accuracy'], label='val_accuracy density', color='orange', alpha=0.5, bins=40)\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load val_accuracy (density plot).')\n",
    "    plt.title('Density Plot for Accuracy')\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Delta Loss\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(delta_loss, label='delta_loss')\n",
    "    try:\n",
    "        plt.plot(delta_val_loss, label='delta_val_loss', color='orange')\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load delta_val_loss.')\n",
    "    plt.title('Delta Model Loss')\n",
    "    plt.ylabel('Delta Loss')\n",
    "    plt.ylim(top=1.5, bottom=-1.5) \n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "    # Delta Accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(delta_accuracy, label='delta_accuracy')\n",
    "    try:\n",
    "        plt.plot(delta_val_accuracy, label='delta_val_accuracy', color='orange')\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load delta_val_accuracy.')\n",
    "    plt.title('Delta Model Accuracy')\n",
    "    plt.ylabel('Delta Accuracy')\n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Calculate chunked data\n",
    "    chunked_loss = chunked_data(history['val_loss'], chunk_size)\n",
    "    chunked_accuracy = chunked_data(history['val_accuracy'], chunk_size)\n",
    "\n",
    "    # Clip the loss values to a maximum of max(history['val_loss'][10:])\n",
    "    max_loss = max(history['val_loss'][10:])\n",
    "    chunked_loss = np.clip(chunked_loss, a_min=None, a_max=max_loss)\n",
    "\n",
    "    # Create 3D surface plots for each chunk\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    ax = fig.add_subplot(121, projection='3d')\n",
    "    X = np.arange(len(chunked_loss))\n",
    "    Y = np.arange(chunk_size)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = np.array(chunked_loss).T  # Transpose the array to match the shape of X and Y\n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    ax.set_title('3D Surface Plot of Chunked Loss')\n",
    "    ax.set_xlabel('Chunk Index')\n",
    "    ax.set_ylabel('Epoch')\n",
    "    ax.set_zlabel('Loss')\n",
    "\n",
    "    ax = fig.add_subplot(122, projection='3d')\n",
    "    X = np.arange(len(chunked_accuracy))\n",
    "    Y = np.arange(chunk_size)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = np.array(chunked_accuracy).T  # Transpose the array to match the shape of X and Y\n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    ax.set_title('3D Surface Plot of Chunked Accuracy')\n",
    "    ax.set_xlabel('Chunk Index')\n",
    "    ax.set_ylabel('Epoch')\n",
    "    ax.set_zlabel('Accuracy')\n",
    "\n",
    "        # Function to calculate the average of chunks\n",
    "    def chunked_average(values, chunk_size):\n",
    "        return [np.mean(values[i:i + chunk_size]) for i in range(0, len(values), chunk_size)]\n",
    "\n",
    "    avg_accuracy_chunks = chunked_average(history['val_accuracy'], chunk_size)\n",
    "    avg_loss_chunks = chunked_average(history['val_loss'], chunk_size)\n",
    "\n",
    "    # Find the chunk with the highest average accuracy\n",
    "    max_acc_chunk_index = np.argmax(avg_accuracy_chunks)\n",
    "    max_acc_value = avg_accuracy_chunks[max_acc_chunk_index]\n",
    "\n",
    "    # Create a pile plot for accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(avg_accuracy_chunks)), avg_accuracy_chunks, label='Average Accuracy')\n",
    "    plt.bar(max_acc_chunk_index, max_acc_value, color='red', label='Highest Average Accuracy')\n",
    "    plt.xlabel('Chunk')\n",
    "    plt.ylabel('Average Accuracy')\n",
    "    plt.title('Average Validation Accuracy per Chunk')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create a pile plot for loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(avg_loss_chunks)), avg_loss_chunks, color='green', label='Average Loss')\n",
    "    plt.xlabel('Chunk')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title('Average Validation Loss per Chunk')\n",
    "    plt.legend()\n",
    "\n",
    "    # Function to calculate the average of each epoch across chunks, ignoring the first chunk\n",
    "    def average_across_chunks(values, chunk_size):\n",
    "        num_chunks = len(values) // chunk_size\n",
    "        avg_values = []\n",
    "        for epoch in range(chunk_size):\n",
    "            epoch_values = [values[chunk * chunk_size + epoch] for chunk in range(1, num_chunks)]\n",
    "            avg_values.append(np.mean(epoch_values))\n",
    "        return avg_values\n",
    "\n",
    "    # Calculate the average accuracy and loss for each epoch across chunks, ignoring the first chunk\n",
    "    avg_accuracy_epochs = average_across_chunks(history['val_accuracy'], chunk_size)\n",
    "    avg_loss_epochs = average_across_chunks(history['val_loss'], chunk_size)\n",
    "\n",
    "    # Create a bar plot for average accuracy and loss of each epoch across chunks\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create an index for each epoch\n",
    "    epoch_indices = np.arange(len(avg_accuracy_epochs))\n",
    "\n",
    "    # Plot accuracy and loss as bars\n",
    "    plt.bar(epoch_indices - 0.2, avg_accuracy_epochs, width=0.4, label='Average Accuracy', color='blue', alpha=0.6)\n",
    "    plt.bar(epoch_indices + 0.2, avg_loss_epochs, width=0.4, label='Average Loss', color='orange', alpha=0.6)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Epoch (within chunk)')\n",
    "    plt.ylabel('Average Value')\n",
    "    plt.title('Average Validation Accuracy and Loss for Each Epoch Across Chunks (Ignoring First Chunk)')\n",
    "    plt.xticks(epoch_indices, [f'Epoch {i+1}' for i in epoch_indices])  # Set x-tick labels to epoch numbers\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except (ValueError, NameError) as E:\n",
    "    print(f'\\033[91mFailed to load model history.\\nError: {E}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse model Predicting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from scipy.stats import binom\n",
    "from tqdm import tqdm\n",
    "import efficientnet.tfkeras\n",
    "import cv2\n",
    "import gc\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "\n",
    "Extra_EXT = '_T' # _T or _T_BL\n",
    "Train_data_test = False\n",
    "if SAVE_TYPE == 'TF':\n",
    "    # Load the pre-trained model\n",
    "    model = load_model(f'PAI_model{Extra_EXT}')\n",
    "else:\n",
    "    # Load the pre-trained model\n",
    "    model = load_model(f'PAI_model{Extra_EXT}.h5')\n",
    "\n",
    "# Ensure the model's input_shape matches your data\n",
    "assert model.input_shape[1:] == (img_res[0], img_res[1], img_res[2]), 'Models input shape doesnt match data.'\n",
    "\n",
    "# Make predictions on validation data\n",
    "val_predictions = model.predict(x_val)\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = model.predict(x_test)\n",
    "\n",
    "# Print acc\n",
    "print('Val data acc:')\n",
    "evaluate_model_full(y_val, val_predictions)\n",
    "print('Test data acc:')\n",
    "evaluate_model_full(y_test, test_predictions)\n",
    "\n",
    "# format data\n",
    "val_predictions = np.argmax(val_predictions, axis=1)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "y_val_original = np.argmax(y_val, axis=1)\n",
    "y_test_original = np.argmax(y_test, axis=1)\n",
    "# Visualize the predictions on validation data as a grid of squares\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_val[i])\n",
    "    plt.title(f'True: {y_val_original[i]}\\nPredicted: {val_predictions[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#Heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    img = x_val[i]\n",
    "    heatmap = make_gradcam_heatmap(img[np.newaxis, ...], model, 'top_activation', second_last_conv_layer_name = 'top_conv', sensitivity_map = 2) \n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    # Apply Adaptive Histogram Equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=1, tileGridSize=(8,8))  # Create CLAHE object\n",
    "    heatmap = clahe.apply(heatmap)\n",
    "    heatmap = cv2.applyColorMap(np.max(heatmap) - heatmap, cv2.COLORMAP_JET)\n",
    "    if RANGE_NOM:\n",
    "        superimposed_img = (heatmap / 255) * 0.4 + img \n",
    "    else:\n",
    "        superimposed_img = (heatmap / 255) * 0.4 + (img / 255)\n",
    "    #clip\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 1)  # ensure the values are in the range [0, 1]\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.title(f'True: {y_val_original[i]}\\nPredicted: {val_predictions[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define the list of labels\n",
    "labels = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "# Create a confusion matrix for validation data\n",
    "val_cm = confusion_matrix(y_val_original, val_predictions)\n",
    "\n",
    "# Create a confusion matrix for test data\n",
    "test_cm = confusion_matrix(y_test_original, test_predictions)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap for validation data\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(val_cm, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix - Validation Data')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Plot the confusion matrix as a heatmap for test data\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(test_cm, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix - Test Data')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Define the range of test data sizes to use\n",
    "data_sizes = range(1, len(x_test), 4)  \n",
    "\n",
    "# Create a list to store the number of incorrect predictions for each test data size\n",
    "incorrect_predictions = []\n",
    "\n",
    "# Generate predictions and track incorrect predictions for each data size\n",
    "for size in tqdm(data_sizes, desc='Predicting', unit='dpb'):\n",
    "    # Garbage Collection (memory)\n",
    "    gc.collect()\n",
    "    # Randomly select a subset of test data\n",
    "    indices = np.random.choice(len(x_test), size, replace=False)\n",
    "    x_test_subset = x_test[indices]\n",
    "    y_test_subset = y_test[indices]\n",
    "\n",
    "    # Make predictions on the subset of test data\n",
    "    test_predictions = model.predict(x_test_subset, batch_size=1, verbose=0, max_queue_size=120, workers=1, use_multiprocessing=False)\n",
    "    test_predictions = np.argmax(test_predictions, axis=1)\n",
    "    y_test_original_subset = np.argmax(y_test_subset, axis=1)\n",
    "\n",
    "    # Calculate the number of incorrect predictions\n",
    "    incorrect_preds = np.sum(test_predictions != y_test_original_subset)\n",
    "    incorrect_predictions.append(incorrect_preds)\n",
    "    \n",
    "# Plot the number of incorrect predictions vs. the number of data points\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_sizes, incorrect_predictions)\n",
    "plt.xlabel('Number of Data Points')\n",
    "plt.ylabel('Number of Incorrect Predictions')\n",
    "# Add gridlines for the x and y axes\n",
    "plt.grid(True)\n",
    "\n",
    "# Change the tick spacing for the x and y axes\n",
    "plt.xticks(np.arange(min(data_sizes), max(data_sizes)+1, 50))\n",
    "plt.yticks(np.arange(0, max(incorrect_predictions) + 5, 3))\n",
    "\n",
    "plt.title('Number of Incorrect Predictions vs. Number of Data Points')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
