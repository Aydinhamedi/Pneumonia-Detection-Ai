{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras/TF model\n",
    "<pre>\n",
    " Copyright (c) 2024 Aydin Hamedi\n",
    " \n",
    " This software is released under the MIT License.\n",
    " https://opensource.org/licenses/MIT\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:44.939427800Z",
     "start_time": "2023-12-28T02:27:44.923095500Z"
    },
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "outputs": [],
   "source": [
    "CPU_only = False # True to Force TF to use the cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pylibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:47.128539500Z",
     "start_time": "2023-12-28T02:27:44.940432900Z"
    },
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "if CPU_only:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import cv2\n",
    "import glob \n",
    "import keras\n",
    "import pprint\n",
    "import random\n",
    "import shutil\n",
    "import gzip\n",
    "import glob\n",
    "import pickle\n",
    "import datetime\n",
    "import subprocess\n",
    "import gpu_control\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from hyperas import optim\n",
    "# import tensorflow_addons as tfa\n",
    "from keras_adabound import AdaBound\n",
    "from importlib import reload\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.losses import categorical_crossentropy\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "from model_profiler import model_profiler\n",
    "from keras_gradient_noise import add_gradient_noise\n",
    "from keras.optimizers import SGD, Adam, Adagrad, Adadelta, Nadam, RMSprop, Adamax\n",
    "# from tensorflow_addons.optimizers import Yogi\n",
    "from adabelief_tf import AdaBeliefOptimizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from keras import Sequential\n",
    "from random import randint, choice, shuffle\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard, LambdaCallback\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    Callback,\n",
    "    LearningRateScheduler,\n",
    "    ReduceLROnPlateau)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Flatten,\n",
    "    Dense, Dropout, BatchNormalization,\n",
    "    SeparableConv2D, Input, Concatenate,\n",
    "    GlobalAveragePooling2D, CuDNNLSTM,\n",
    "    concatenate, Reshape, Multiply,\n",
    "    Conv1D, MaxPooling1D)\n",
    "# Utils\n",
    "from Utils.one_cycle import OneCycleLr\n",
    "from Utils.lr_find import LrFinder\n",
    "from Utils.Grad_cam import make_gradcam_heatmap\n",
    "from Utils.print_color_V2_NEW import print_Color_V2\n",
    "from Utils.print_color_V1_OLD import print_Color\n",
    "from Utils.FixedDropout import FixedDropout\n",
    "from Utils.Other import *\n",
    "# Other\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu_instance in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:47.139048Z",
     "start_time": "2023-12-28T02:27:47.116546100Z"
    },
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Directory paths# Directory paths for training, test and validation image data\n",
    "train_dir = 'Database\\\\Train\\\\Data\\\\train'\n",
    "test_dir = 'Database\\\\Train\\\\Data\\\\test'\n",
    "validation_dir = 'Database\\\\Train\\\\Data\\\\val'\n",
    "img_res = [224, 224, 3]\n",
    "# img_res = [324, 324, 3]\n",
    "# img_res = [224, 224, 3]\n",
    "# img_res = [384, 384, 3] # Very slow needs >=24Gb Vram for batch size of 1 (NR!)\n",
    "interpolation_order_IFG = 2\n",
    "categorical_IMP = True\n",
    "Make_EV_DATA = False\n",
    "R_fill_mode = True\n",
    "add_img_grain = True\n",
    "Save_TS = True\n",
    "Img_Data_type = 'float16' # float32 / float16\n",
    "Use_SMOTE = False # (‚ö†Ô∏èBeta‚ö†Ô∏è)\n",
    "ADBD = 0\n",
    "OP_HDC = False\n",
    "SL_EX = '_V1' # _NONOM_V1 | _V1 | _SDNP_V1\n",
    "LNTS = 0\n",
    "Debug_OUT = False\n",
    "adjust_brightness_Mode = True\n",
    "RANGE_NOM = True # False for 0 to 255 True for 0 to 1 >> use False for models like ConvNeXtXLarge (‚ö†Ô∏èdeprecated‚ö†Ô∏è)\n",
    "scale_data_NP_M = False # (‚ö†Ô∏èdeprecated‚ö†Ô∏è)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:27:48.287855100Z",
     "start_time": "2023-12-28T02:27:48.252944800Z"
    },
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Policy \"float32\">\n"
     ]
    }
   ],
   "source": [
    "SAVE_TYPE = 'H5'\n",
    "Use_mixed_float16 = False\n",
    "#Other\n",
    "if Use_mixed_float16:\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "else:\n",
    "    tf.keras.mixed_precision.set_global_policy('float32')\n",
    "    \n",
    "print(tf.keras.mixed_precision.global_policy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:31:27.059139500Z",
     "start_time": "2023-12-28T02:27:50.219209700Z"
    },
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33mUsing Def IDG...\u001b[0m\n",
      "Found 23681 images belonging to 2 classes.\n",
      "\u001b[0;33mLoading all images and labels into memory...\u001b[0m\n",
      "\u001b[0;33mMaking categorical data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mGenerating augmented data \u001b[0m\u001b[0;36m[\u001b[0m\u001b[0;32mADBD: \u001b[0m\u001b[0;31m0\u001b[0m\u001b[0;36m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mNormalizing image data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mData type: \u001b[0m\u001b[0;32mfloat16\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mRGB Range: \u001b[0m\u001b[0;34mMin = 0.0\u001b[0m\u001b[0m | \u001b[0m\u001b[0;31mMax = 1.0\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mLabel ratio: \u001b[0m\u001b[0;31m49.35% PNEUMONIA \u001b[0m\u001b[0;35m| \u001b[0m\u001b[0;32m50.65% NORMAL\u001b[0m\n",
      "\u001b[0;33mSetting LNTS...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mOriginal num_samples: \u001b[0m\u001b[0;32m23681\u001b[0m\n",
      "\u001b[0;33mshuffling data...\u001b[0m\n",
      "\u001b[0;33mSaving TS...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mSample dir: \u001b[0m\u001b[0;32mSamples/TSR400_y2024_m02_d17-h23_m16_s45\u001b[0m\n",
      "\u001b[0;32mDone.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Z_SCORE_normalize\n",
    "def Z_SCORE_normalize(arr):\n",
    "   arr = arr.astype(Img_Data_type)\n",
    "   mean = np.mean(arr)\n",
    "   std_dev = np.std(arr)\n",
    "   arr = (arr - mean) / std_dev\n",
    "   return arr\n",
    "#normalize_TO_RANGE\n",
    "def normalize_TO_RANGE(arr, min_val, max_val):\n",
    "  arr = arr.astype(Img_Data_type)\n",
    "  arr = (arr - arr.min()) / (arr.max() - arr.min())\n",
    "  arr = arr * (max_val - min_val) + min_val\n",
    "  return arr\n",
    "#scale_data\n",
    "def scale_data_NP(data):\n",
    "    if scale_data_NP_M:\n",
    "        data = data.astype(Img_Data_type)\n",
    "        data = (data - 127.5) / 127.5\n",
    "        return data\n",
    "    else:\n",
    "        return data / 255\n",
    "#add_image_grain\n",
    "def add_image_grain(image, intensity = 0.01):\n",
    "    # Generate random noise array\n",
    "    noise = np.random.randint(0, 255, size=image.shape, dtype=np.uint8)\n",
    "\n",
    "    # Scale the noise array\n",
    "    scaled_noise = (noise * intensity).astype(np.float32 if Img_Data_type == 'float32' else 'float16')\n",
    "    # Add the noise to the image\n",
    "    noisy_image = cv2.add(image, scaled_noise)\n",
    "\n",
    "    return noisy_image\n",
    "#apply_clahe_rgb_array\n",
    "def apply_clahe_rgb_array(images, clip_limit=1.8, tile_grid_size=(8, 8)):\n",
    "    # Create a CLAHE object\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    \n",
    "    # Iterate over each image in the array\n",
    "    for i in range(len(images)):\n",
    "        # Split the image into color channels\n",
    "        b, g, r = cv2.split(images[i])\n",
    "        \n",
    "        # Convert the channels to the appropriate format\n",
    "        b = cv2.convertScaleAbs(b)\n",
    "        g = cv2.convertScaleAbs(g)\n",
    "        r = cv2.convertScaleAbs(r)\n",
    "        \n",
    "        # Apply adaptive histogram equalization to each channel\n",
    "        equalized_b = clahe.apply(b)\n",
    "        equalized_g = clahe.apply(g)\n",
    "        equalized_r = clahe.apply(r)\n",
    "\n",
    "        # Merge the equalized channels back into an image\n",
    "        equalized_image = cv2.merge((equalized_b, equalized_g, equalized_r))\n",
    "\n",
    "        # Replace the original image with the equalized image in the array\n",
    "        images[i] = equalized_image\n",
    "\n",
    "    return images\n",
    "#noise_func\n",
    "def noise_func(image):\n",
    "    noise_type = np.random.choice(['L1', 'L2', 'L3', 'none'])\n",
    "    new_image = np.copy(image)\n",
    "    \n",
    "    if noise_type == 'L3':\n",
    "        intensityL2 = random.uniform(-0.05, 0.05)\n",
    "        intensityL1 = random.uniform(-0.04, 0.04)\n",
    "    else:\n",
    "        intensityL2 = random.uniform(-0.06, 0.06)\n",
    "        intensityL1 = random.uniform(-0.04, 0.04)\n",
    "    \n",
    "    block_size_L1 = random.randint(16, 32)\n",
    "    block_size_L2 = random.randint(32, 64)\n",
    "    \n",
    "    if noise_type == 'L2' or noise_type == 'L3':\n",
    "        for i in range(0, image.shape[0], block_size_L2):\n",
    "            for j in range(0, image.shape[1], block_size_L2):\n",
    "                block = image[i:i+block_size_L2, j:j+block_size_L2]\n",
    "                block = (np.random.rand() * intensityL2 + 1) * block\n",
    "                new_image[i:i+block_size_L2, j:j+block_size_L2] = block\n",
    "        image = new_image      \n",
    "        \n",
    "    if noise_type == 'L1' or noise_type == 'L3': \n",
    "        for i in range(0, image.shape[0], block_size_L1):\n",
    "            for j in range(0, image.shape[1], block_size_L1):\n",
    "                block = image[i:i+block_size_L1, j:j+block_size_L1]\n",
    "                block = (np.random.rand() * intensityL1 + 1) * block\n",
    "                new_image[i:i+block_size_L1, j:j+block_size_L1] = block\n",
    "    \n",
    "    if add_img_grain:\n",
    "        intensity = random.uniform(0, 0.045)  # Random intensity between 0 and 0.026\n",
    "        new_image = add_image_grain(new_image, intensity=intensity)\n",
    "    return new_image\n",
    "#shuffle_data\n",
    "def shuffle_data(x, y):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    return x, y\n",
    "#save_images_to_dir\n",
    "def save_images_to_dir(images, labels, dir_path):\n",
    "    # create the directory if it doesn't exist\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    # iterate over the images and labels\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        # get the class label\n",
    "        class_label = np.argmax(label)\n",
    "        # create the file path\n",
    "        file_path = os.path.join(dir_path, f'image_{i}_class_{class_label}.png')\n",
    "        # save the image to the file path\n",
    "        plt.imsave(file_path, image.squeeze())\n",
    "    # compress the directory\n",
    "    shutil.make_archive(dir_path, 'gztar', dir_path)\n",
    "    # remove the original directory\n",
    "    shutil.rmtree(dir_path)\n",
    "#Debug_img_Save\n",
    "def Debug_img_Save(img, id = 'DEF'):    \n",
    "    SITD = np.random.choice(img.shape[0], size=400, replace=False)\n",
    "    S_dir = f'Samples\\\\Debug\\\\{id}\\\\TSR_SUB_400_' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')\n",
    "    print_Color(f'~*[Debug] (DPO) Sample dir: ~*{S_dir}', ['red', 'green'], advanced_mode=True)\n",
    "    save_images_to_dir(normalize_TO_RANGE(img[SITD], 0, 1), img[SITD], S_dir)\n",
    "# Create an ImageDataGenerator for the training set\n",
    "if OP_HDC:\n",
    "    print_Color('Using OP_HDC IDG...', ['yellow'])\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=179,\n",
    "        zoom_range=0.24, \n",
    "        shear_range=0.22,\n",
    "        width_shift_range=0.21,\n",
    "        brightness_range=(0.86, 1.1),\n",
    "        height_shift_range=0.21,\n",
    "        channel_shift_range=100,\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        fill_mode='nearest', # constant\n",
    "        preprocessing_function=noise_func,\n",
    "        dtype=Img_Data_type\n",
    "    )\n",
    "else:\n",
    "    print_Color('Using Def IDG...', ['yellow'])\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=179,\n",
    "        zoom_range=0.26, \n",
    "        shear_range=0.25,\n",
    "        width_shift_range=0.25,\n",
    "        brightness_range=(0.78, 1.1),\n",
    "        height_shift_range=0.25,\n",
    "        channel_shift_range=100,\n",
    "        featurewise_center=False,\n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        featurewise_std_normalization=False,\n",
    "        fill_mode='nearest', # constant\n",
    "        preprocessing_function=noise_func,\n",
    "        dtype=Img_Data_type\n",
    "    )\n",
    "train_datagen_SM = ImageDataGenerator(\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.07, \n",
    "    shear_range=0.07,\n",
    "    width_shift_range=0.07,\n",
    "    brightness_range=(0.99, 1.01),\n",
    "    height_shift_range=0.07,\n",
    "    channel_shift_range=0,\n",
    "    featurewise_center=False,\n",
    "    interpolation_order=interpolation_order_IFG,\n",
    "    featurewise_std_normalization=False,\n",
    "    dtype=Img_Data_type\n",
    ")\n",
    "# Create an iterator for the training set\n",
    "train_generator_SM = train_datagen_SM.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_res[0], img_res[1]),\n",
    "    batch_size=sum([len(files) for r, d, files in os.walk(train_dir)]),\n",
    "    class_mode='binary')\n",
    "# Create an ImageDataGenerator for the validation set (OP)\n",
    "if Make_EV_DATA:\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=False,\n",
    "        zoom_range = 0.01, \n",
    "        width_shift_range=0.01, \n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        dtype=Img_Data_type,\n",
    "        height_shift_range=0.01)\n",
    "\n",
    "    # Create an iterator for the validation set\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_res[0], img_res[1]),\n",
    "        batch_size=sum([len(files) for r, d, files in os.walk(validation_dir)]),\n",
    "        class_mode='binary',\n",
    "        color_mode='rgb')\n",
    "\n",
    "    # Create an ImageDataGenerator for the test set\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=False,\n",
    "        zoom_range = 0.01, \n",
    "        width_shift_range=0.01, \n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        dtype=Img_Data_type,\n",
    "        height_shift_range=0.01)\n",
    "\n",
    "    # Create an iterator for the test set\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_res[0], img_res[1]),\n",
    "        batch_size=sum([len(files) for r, d, files in os.walk(test_dir)]),\n",
    "        class_mode='binary',\n",
    "        color_mode='rgb')\n",
    "# Load all images and labels into memory\n",
    "print_Color('Loading all images and labels into memory...', ['yellow'])\n",
    "x_train, y_train = next(iter(train_generator_SM))\n",
    "if Make_EV_DATA:\n",
    "    x_val, y_val = next(iter(val_generator))\n",
    "    x_test, y_test = next(iter(test_generator))\n",
    "if Debug_OUT: Debug_img_Save(x_train, 'ST1') # DEBUG\n",
    "# fit parameters from data\n",
    "# train_datagen.fit(x_train)\n",
    "#to_categorical (TEMP)\n",
    "if categorical_IMP:\n",
    "    print_Color('Making categorical data...', ['yellow'])\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    if Make_EV_DATA:\n",
    "        y_val = to_categorical(y_val, num_classes=2)\n",
    "        y_test = to_categorical(y_test, num_classes=2)\n",
    "# Use_SMOTE\n",
    "if Use_SMOTE:\n",
    "    print_Color('SMOTE...', ['yellow'])\n",
    "    # Convert y_train from one-hot encoding to label encoding\n",
    "    y_train_label_encoded = np.argmax(y_train, axis=1)\n",
    "\n",
    "    # Print the original label distribution\n",
    "    unique, counts = np.unique(y_train_label_encoded, return_counts=True)\n",
    "    print_Color(f'~*- Original label distribution: ~*{dict(zip(unique, counts))}', ['normal', 'blue'], advanced_mode=True)\n",
    "\n",
    "    # Use SMOTE to oversample the minority class\n",
    "    smote = SMOTE(random_state=42)\n",
    "    x_train_res, y_train_res_label_encoded = smote.fit_resample(x_train.reshape(x_train.shape[0], -1), y_train_label_encoded)\n",
    "\n",
    "    # Print the resampled label distribution\n",
    "    unique_res, counts_res = np.unique(y_train_res_label_encoded, return_counts=True)\n",
    "    print_Color(f'~*- Resampled label distribution: ~*{dict(zip(unique_res, counts_res))}', ['normal', 'blue'], advanced_mode=True)\n",
    "\n",
    "    # Reshape x_train_res back to the original x_train shape\n",
    "    x_train_res = x_train_res.reshape(-1, x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "\n",
    "    # Convert y_train_res from label encoding back to one-hot encoding\n",
    "    y_train_res = to_categorical(y_train_res_label_encoded)\n",
    "\n",
    "    # Calculate the ratio of two labels after resampling\n",
    "    pneumonia_count = np.sum(y_train_res[:, 1])\n",
    "    total_count = y_train_res.shape[0]\n",
    "    label_ratio_res = pneumonia_count / total_count\n",
    "    label_ratio_percentage_res = label_ratio_res * 100\n",
    "\n",
    "    # Replace the original data with the resampled data\n",
    "    x_train = x_train_res\n",
    "    y_train = y_train_res\n",
    "\n",
    "    # Delete the resampled data to free up memory\n",
    "    del x_train_res, y_train_res_label_encoded, y_train_res\n",
    "# Generating augmented data\n",
    "print_Color(f'~*Generating augmented data ~*[~*ADBD: ~*{str(ADBD)}~*]~*...',\n",
    "            ['yellow', 'cyan', 'green', 'red', 'cyan', 'yellow'],\n",
    "            advanced_mode=True)\n",
    "if ADBD > 0:\n",
    "    for i in range(ADBD):\n",
    "        # ADB_clip_limit Scheduler>>>\n",
    "        if i == 0:\n",
    "            ADB_clip_limit = 0.8\n",
    "        else:\n",
    "            #V1>>>\n",
    "            CL_SLM = 2.4\n",
    "            ADB_clip_limit = max(2 / (i + 1)**CL_SLM, 0.05)\n",
    "            # Try it in win graphing calculator copy and paste:\n",
    "            #  ‚îå-------------‚î¨--‚î¨---------------‚îê\n",
    "            #  ‚îÇ ùë¶=2/(ùë•+1)^ùëß ‚îúOR‚î§ ùë¶=2/(ùë•+1)^2.4 ‚îÇ\n",
    "            #  ‚îî-------------‚î¥--‚î¥---------------‚îò\n",
    "            #V2>>>\n",
    "            # CL_SLM_2 = 1.4\n",
    "            # CL_SLM_Start_2 = 2\n",
    "            # ADB_clip_limit = CL_SLM_Start_2/(i+1)**(i+CL_SLM_2) \n",
    "            # Try it in win graphing calculator copy and paste:\n",
    "            #  ‚îå-----------------‚î¨--‚î¨-------------------‚îê\n",
    "            #  ‚îÇ ùë¶=2/(ùë•+1)^(ùë•+ùëâ) ‚îúOR‚î§ ùë¶=2/(ùë•+1)^(ùë•+1.4) ‚îÇ\n",
    "            #  ‚îî-----------------‚î¥--‚î¥-------------------‚îò\n",
    "        print(f'>   Generating ADB[{i+1}/{ADBD}]...')\n",
    "        # prepare an iterators to scale images\n",
    "        train_iterator = train_datagen.flow(x_train, y_train, batch_size=len(x_train))\n",
    "\n",
    "        # get augmented data\n",
    "        x_train_augmented, y_train_augmented = train_iterator.next()\n",
    "        print(f'>   ‚îú‚îÄ‚îÄ‚îÄApplying adaptive histogram equalization...')\n",
    "        print(f'>   ‚îú‚îÄ‚îÄ‚îÄAdaptive histogram equalization clip limit = {round(ADB_clip_limit, 2)}')\n",
    "        x_train_augmented = np.clip(x_train_augmented, 0, 255) \n",
    "        if Debug_OUT: Debug_img_Save(x_train_augmented, 'ST2') # DEBUG\n",
    "        #print_Color(f'~*>   |---Grayscale range: ~*Min = {np.min(x_train_augmented)}~* | ~*Max = {np.max(x_train_augmented)}', ['normal', 'blue', 'normal', 'red'], advanced_mode=True)\n",
    "        x_train_augmented = apply_clahe_rgb_array(x_train_augmented, clip_limit=ADB_clip_limit) # compensating the image info loss\n",
    "        print(f'>   ‚îî‚îÄ‚îÄ‚îÄAdding the Generated ADB...')\n",
    "        if Debug_OUT: Debug_img_Save(x_train_augmented, 'ST3') # DEBUG\n",
    "        # append augmented data to original data\n",
    "        x_train = np.concatenate([x_train, x_train_augmented])\n",
    "        y_train = np.concatenate([y_train, y_train_augmented])\n",
    "        #free up memory\n",
    "        del y_train_augmented\n",
    "        del x_train_augmented\n",
    "# normalizing \n",
    "print_Color('Normalizing image data...', ['yellow'])\n",
    "if Debug_OUT: Debug_img_Save(x_train, 'ST4') # DEBUG\n",
    "x_train = np.clip(x_train, 0, 255)\n",
    "if RANGE_NOM:\n",
    "    x_train = scale_data_NP(x_train)\n",
    "y_train = np.array(y_train) \n",
    "if Make_EV_DATA:\n",
    "    x_test = np.clip(x_test, 0, 255)  \n",
    "    x_val = np.clip(x_val, 0, 255)  \n",
    "    if RANGE_NOM:\n",
    "        x_val = scale_data_NP(x_val)\n",
    "    y_val = np.array(y_val)  \n",
    "    if RANGE_NOM: \n",
    "        x_test = scale_data_NP(x_test)\n",
    "    y_test = np.array(y_test) \n",
    "if Debug_OUT: Debug_img_Save(x_train, 'ST5') # DEBUG\n",
    "# Check the data type of image data\n",
    "print_Color(f'~*Data type: ~*{x_train.dtype}', ['normal', 'green'], advanced_mode=True)\n",
    "# Check the range of image data\n",
    "print_Color(f'~*RGB Range: ~*Min = {np.min(x_train)}~* | ~*Max = {np.max(x_train)}', ['normal', 'blue', 'normal', 'red'], advanced_mode=True)\n",
    "# Calculate the ratio of two labels\n",
    "if categorical_IMP:\n",
    "    label_sums = np.sum(y_train, axis=0)\n",
    "    label_ratio = label_sums / (np.sum(y_train) + 1e-10)\n",
    "    label_ratio_percentage = label_ratio * 100\n",
    "    print_Color(f'~*Label ratio: ~*{100 - label_ratio_percentage[0]:.2f}% PNEUMONIA ~*| ~*{label_ratio_percentage[0]:.2f}% NORMAL',\n",
    "                ['normal', 'red', 'magenta', 'green'], advanced_mode=True)    \n",
    "print_Color('Setting LNTS...', ['yellow'])\n",
    "# Get the total number of samples in the arrays\n",
    "num_samples = x_train.shape[0]\n",
    "print_Color(f'~*Original num_samples: ~*{num_samples}', ['normal', 'green'], advanced_mode=True)\n",
    "if LNTS != 0:\n",
    "    print_Color(f'~*Applying LNTS of: ~*{LNTS}', ['normal', 'green'], advanced_mode=True)\n",
    "    print_Color(f'~*SNC: ~*{num_samples - LNTS}', ['normal', 'green'], advanced_mode=True)\n",
    "    # Generate random indices to select LNTS samples\n",
    "    indices = np.random.choice(num_samples, size=LNTS, replace=False)\n",
    "    # Select the samples using the generated indices\n",
    "    x_selected = x_train[indices]\n",
    "    y_selected = y_train[indices]\n",
    "    x_train = x_selected\n",
    "    y_train = y_selected\n",
    "    #free up memory\n",
    "    del x_selected\n",
    "    del y_selected\n",
    "    del indices\n",
    "    #Debug\n",
    "    num_samples = x_train.shape[0]\n",
    "    print_Color(f'~*New num_samples: ~*{num_samples}', ['normal', 'green'], advanced_mode=True)\n",
    "# Shuffle the training data\n",
    "print_Color('shuffling data...', ['yellow'])\n",
    "x_train, y_train = shuffle_data(x_train, y_train)\n",
    "#save_images_to_dir    \n",
    "if Save_TS:\n",
    "    print_Color('Saving TS...', ['yellow'])\n",
    "    SITD = np.random.choice(num_samples, size=400, replace=False)\n",
    "    S_dir = 'Samples/TSR400_' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')\n",
    "    print_Color(f'~*Sample dir: ~*{S_dir}', ['normal', 'green'], advanced_mode=True)\n",
    "    if RANGE_NOM:\n",
    "        if scale_data_NP_M:\n",
    "            save_images_to_dir((x_train[SITD] + 1) / 2.0, y_train[SITD], S_dir)\n",
    "        else:\n",
    "            save_images_to_dir(x_train[SITD], y_train[SITD], S_dir)\n",
    "    else:\n",
    "        save_images_to_dir(x_train[SITD] / 255, y_train[SITD], S_dir)\n",
    "print_Color('Done.', ['green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save EV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'Database\\\\Test\\\\Data\\\\x_val{SL_EX}.npy', x_val)\n",
    "np.save(f'Database\\\\Test\\\\Data\\\\y_val{SL_EX}.npy', y_val)\n",
    "np.save(f'Database\\\\Test\\\\Data\\\\x_test{SL_EX}.npy', x_test)\n",
    "np.save(f'Database\\\\Test\\\\Data\\\\y_test{SL_EX}.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load EV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:31:27.380088800Z",
     "start_time": "2023-12-28T02:31:27.270860200Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "x_val = np.load(f'Database\\\\Test\\\\Data\\\\x_val{SL_EX}.npy')\n",
    "y_val = np.load(f'Database\\\\Test\\\\Data\\\\y_val{SL_EX}.npy')\n",
    "x_test = np.load(f'Database\\\\Test\\\\Data\\\\x_test{SL_EX}.npy')\n",
    "y_test = np.load(f'Database\\\\Test\\\\Data\\\\y_test{SL_EX}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyzation (Removed temporary‚ö†Ô∏è)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1\n",
    "```\n",
    "recommended: ‚ö†Ô∏è\n",
    "statuses: Ready\n",
    "Working: ‚úÖ\n",
    "Max fine tuned acc: ‚âÖ95.1\n",
    "Max fine tuned acc TLRev2: N/A\n",
    "type: transfer learning>>>(EfficientNetB7)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import EfficientNetB7\n",
    "\n",
    "EfficientNet_M = EfficientNetB7(include_top=True, input_shape=(img_res[0], img_res[1], img_res[2]), weights=None, classes=2, classifier_activation='softmax')\n",
    "# define new model\n",
    "model = Model(inputs=EfficientNet_M.inputs, outputs=EfficientNet_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)\n",
    "# opt = SGD(learning_rate=0.008, momentum=0.85, decay=0.001)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.1\n",
    "```\n",
    "recommended: ‚ùå\n",
    "statuses: S.Ready (can improve)\n",
    "Working: ‚ùå\n",
    "Max fine tuned acc: ‚âÖ93.2\n",
    "Max fine tuned acc TLRev2: N/A\n",
    "type: transfer learning>>>(ConvNeXtLarge)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ConvNeXtLarge\n",
    "\n",
    "ConvNeXtLarge_M = ConvNeXtLarge(include_top=False, input_shape=(img_res[0], img_res[1], img_res[2]), weights='imagenet', classes=2, classifier_activation='softmax', include_preprocessing=False)\n",
    "# define new model\n",
    "model = Model(inputs=ConvNeXtLarge_M.inputs, outputs=ConvNeXtLarge_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)\n",
    "# opt = SGD(learning_rate=0.008, momentum=0.85, decay=0.001)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "### Rev1.2\n",
    "```\n",
    "recommended: ‚úÖ\n",
    "statuses: Ready\n",
    "Working: ‚úÖ\n",
    "Max fine tuned acc: 95.3\n",
    "Max fine tuned acc TLRev2: 97.12\n",
    "type: transfer learning>>>(EfficientNetB7::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T17:34:12.077394600Z",
     "start_time": "2023-12-27T17:34:05.068171500Z"
    },
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Total layers in the base model:  806\n",
      "Freezing 0 layers in the base model...\n",
      "Percentage of the base model that is frozen: 0.00%\n",
      "Total model layers:  814\n",
      "Model: \"model\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     Trainable  \n",
      "=============================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               Y          \n",
      "                                )]                                                                           \n",
      "                                                                                                             \n",
      " stem_conv (Conv2D)             (None, 112, 112, 64  1728        ['input_1[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 64  256         ['stem_conv[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_activation (Activation)   (None, 112, 112, 64  0           ['stem_bn[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 64  576        ['stem_activation[0][0]']        Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 64  256        ['block1a_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_activation (Activation  (None, 112, 112, 64  0          ['block1a_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_se_squeeze (GlobalAver  (None, 64)          0           ['block1a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 64)     0           ['block1a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 16)     1040        ['block1a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 64)     1088        ['block1a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 64  0           ['block1a_activation[0][0]',     Y          \n",
      "                                )                                 'block1a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 32  2048        ['block1a_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1a_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1b_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1a_project_bn[0][0]']     Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1b_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1b_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1b_activation (Activation  (None, 112, 112, 32  0          ['block1b_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1b_se_squeeze (GlobalAver  (None, 32)          0           ['block1b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1b_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1b_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1b_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1b_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1b_activation[0][0]',     Y          \n",
      "                                )                                 'block1b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1b_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1b_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1b_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1b_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1b_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1b_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1b_add (Add)              (None, 112, 112, 32  0           ['block1b_drop[0][0]',           Y          \n",
      "                                )                                 'block1a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block1c_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1b_add[0][0]']            Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1c_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1c_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1c_activation (Activation  (None, 112, 112, 32  0          ['block1c_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1c_se_squeeze (GlobalAver  (None, 32)          0           ['block1c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1c_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1c_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1c_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1c_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1c_activation[0][0]',     Y          \n",
      "                                )                                 'block1c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1c_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1c_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1c_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1c_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1c_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1c_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1c_add (Add)              (None, 112, 112, 32  0           ['block1c_drop[0][0]',           Y          \n",
      "                                )                                 'block1b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block1d_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1c_add[0][0]']            Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1d_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1d_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1d_activation (Activation  (None, 112, 112, 32  0          ['block1d_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1d_se_squeeze (GlobalAver  (None, 32)          0           ['block1d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1d_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1d_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1d_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1d_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1d_activation[0][0]',     Y          \n",
      "                                )                                 'block1d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1d_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1d_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1d_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1d_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1d_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1d_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1d_add (Add)              (None, 112, 112, 32  0           ['block1d_drop[0][0]',           Y          \n",
      "                                )                                 'block1c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 19  6144        ['block1d_add[0][0]']            Y          \n",
      "                                2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 19  768        ['block2a_expand_conv[0][0]']    Y          \n",
      " ization)                       2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_expand_activation (Act  (None, 112, 112, 19  0          ['block2a_expand_bn[0][0]']      Y          \n",
      " ivation)                       2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 192)  1728       ['block2a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 192)  768        ['block2a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_activation (Activation  (None, 56, 56, 192)  0          ['block2a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_se_squeeze (GlobalAver  (None, 192)         0           ['block2a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 192)  0           ['block2a_activation[0][0]',     Y          \n",
      "                                                                  'block2a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 48)   9216        ['block2a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_expand_activation (Act  (None, 56, 56, 288)  0          ['block2b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_activation (Activation  (None, 56, 56, 288)  0          ['block2b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_se_squeeze (GlobalAver  (None, 288)         0           ['block2b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2b_activation[0][0]',     Y          \n",
      "                                                                  'block2b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_add (Add)              (None, 56, 56, 48)   0           ['block2b_drop[0][0]',           Y          \n",
      "                                                                  'block2a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block2c_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2c_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2c_expand_activation (Act  (None, 56, 56, 288)  0          ['block2c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2c_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2c_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2c_activation (Activation  (None, 56, 56, 288)  0          ['block2c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2c_se_squeeze (GlobalAver  (None, 288)         0           ['block2c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2c_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2c_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2c_activation[0][0]',     Y          \n",
      "                                                                  'block2c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2c_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2c_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2c_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_add (Add)              (None, 56, 56, 48)   0           ['block2c_drop[0][0]',           Y          \n",
      "                                                                  'block2b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2d_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2d_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2d_expand_activation (Act  (None, 56, 56, 288)  0          ['block2d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2d_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2d_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2d_activation (Activation  (None, 56, 56, 288)  0          ['block2d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2d_se_squeeze (GlobalAver  (None, 288)         0           ['block2d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2d_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2d_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2d_activation[0][0]',     Y          \n",
      "                                                                  'block2d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2d_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2d_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2d_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_add (Add)              (None, 56, 56, 48)   0           ['block2d_drop[0][0]',           Y          \n",
      "                                                                  'block2c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2e_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2e_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2e_expand_activation (Act  (None, 56, 56, 288)  0          ['block2e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2e_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2e_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2e_activation (Activation  (None, 56, 56, 288)  0          ['block2e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2e_se_squeeze (GlobalAver  (None, 288)         0           ['block2e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2e_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2e_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2e_activation[0][0]',     Y          \n",
      "                                                                  'block2e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2e_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2e_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2e_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_add (Add)              (None, 56, 56, 48)   0           ['block2e_drop[0][0]',           Y          \n",
      "                                                                  'block2d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2f_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2f_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2f_expand_activation (Act  (None, 56, 56, 288)  0          ['block2f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2f_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2f_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2f_activation (Activation  (None, 56, 56, 288)  0          ['block2f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2f_se_squeeze (GlobalAver  (None, 288)         0           ['block2f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2f_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2f_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2f_activation[0][0]',     Y          \n",
      "                                                                  'block2f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2f_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2f_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2f_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_add (Add)              (None, 56, 56, 48)   0           ['block2f_drop[0][0]',           Y          \n",
      "                                                                  'block2e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2g_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2g_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2g_expand_activation (Act  (None, 56, 56, 288)  0          ['block2g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2g_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2g_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2g_activation (Activation  (None, 56, 56, 288)  0          ['block2g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2g_se_squeeze (GlobalAver  (None, 288)         0           ['block2g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2g_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2g_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2g_activation[0][0]',     Y          \n",
      "                                                                  'block2g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2g_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2g_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2g_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_add (Add)              (None, 56, 56, 48)   0           ['block2g_drop[0][0]',           Y          \n",
      "                                                                  'block2f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block3a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_expand_activation (Act  (None, 56, 56, 288)  0          ['block3a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 288)  7200       ['block3a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 288)  1152       ['block3a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_activation (Activation  (None, 28, 28, 288)  0          ['block3a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_se_squeeze (GlobalAver  (None, 288)         0           ['block3a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block3a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block3a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block3a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 288)  0           ['block3a_activation[0][0]',     Y          \n",
      "                                                                  'block3a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 80)   23040       ['block3a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_expand_activation (Act  (None, 28, 28, 480)  0          ['block3b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_activation (Activation  (None, 28, 28, 480)  0          ['block3b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_se_squeeze (GlobalAver  (None, 480)         0           ['block3b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3b_activation[0][0]',     Y          \n",
      "                                                                  'block3b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_add (Add)              (None, 28, 28, 80)   0           ['block3b_drop[0][0]',           Y          \n",
      "                                                                  'block3a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block3c_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3c_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3c_expand_activation (Act  (None, 28, 28, 480)  0          ['block3c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3c_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3c_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3c_activation (Activation  (None, 28, 28, 480)  0          ['block3c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3c_se_squeeze (GlobalAver  (None, 480)         0           ['block3c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3c_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3c_activation[0][0]',     Y          \n",
      "                                                                  'block3c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3c_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3c_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3c_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_add (Add)              (None, 28, 28, 80)   0           ['block3c_drop[0][0]',           Y          \n",
      "                                                                  'block3b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3d_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3d_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3d_expand_activation (Act  (None, 28, 28, 480)  0          ['block3d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3d_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3d_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3d_activation (Activation  (None, 28, 28, 480)  0          ['block3d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3d_se_squeeze (GlobalAver  (None, 480)         0           ['block3d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3d_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3d_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3d_activation[0][0]',     Y          \n",
      "                                                                  'block3d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3d_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3d_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3d_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_add (Add)              (None, 28, 28, 80)   0           ['block3d_drop[0][0]',           Y          \n",
      "                                                                  'block3c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3e_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3e_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3e_expand_activation (Act  (None, 28, 28, 480)  0          ['block3e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3e_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3e_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3e_activation (Activation  (None, 28, 28, 480)  0          ['block3e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3e_se_squeeze (GlobalAver  (None, 480)         0           ['block3e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3e_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3e_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3e_activation[0][0]',     Y          \n",
      "                                                                  'block3e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3e_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3e_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3e_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_add (Add)              (None, 28, 28, 80)   0           ['block3e_drop[0][0]',           Y          \n",
      "                                                                  'block3d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3f_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3f_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3f_expand_activation (Act  (None, 28, 28, 480)  0          ['block3f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3f_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3f_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3f_activation (Activation  (None, 28, 28, 480)  0          ['block3f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3f_se_squeeze (GlobalAver  (None, 480)         0           ['block3f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3f_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3f_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3f_activation[0][0]',     Y          \n",
      "                                                                  'block3f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3f_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3f_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3f_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_add (Add)              (None, 28, 28, 80)   0           ['block3f_drop[0][0]',           Y          \n",
      "                                                                  'block3e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3g_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3g_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3g_expand_activation (Act  (None, 28, 28, 480)  0          ['block3g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3g_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3g_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3g_activation (Activation  (None, 28, 28, 480)  0          ['block3g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3g_se_squeeze (GlobalAver  (None, 480)         0           ['block3g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3g_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3g_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3g_activation[0][0]',     Y          \n",
      "                                                                  'block3g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3g_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3g_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3g_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_add (Add)              (None, 28, 28, 80)   0           ['block3g_drop[0][0]',           Y          \n",
      "                                                                  'block3f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block4a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_expand_activation (Act  (None, 28, 28, 480)  0          ['block4a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_activation (Activation  (None, 14, 14, 480)  0          ['block4a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_se_squeeze (GlobalAver  (None, 480)         0           ['block4a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4a_activation[0][0]',     Y          \n",
      "                                                                  'block4a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 160)  76800       ['block4a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_expand_activation (Act  (None, 14, 14, 960)  0          ['block4b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_activation (Activation  (None, 14, 14, 960)  0          ['block4b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_se_squeeze (GlobalAver  (None, 960)         0           ['block4b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4b_activation[0][0]',     Y          \n",
      "                                                                  'block4b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_add (Add)              (None, 14, 14, 160)  0           ['block4b_drop[0][0]',           Y          \n",
      "                                                                  'block4a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_expand_activation (Act  (None, 14, 14, 960)  0          ['block4c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_activation (Activation  (None, 14, 14, 960)  0          ['block4c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_se_squeeze (GlobalAver  (None, 960)         0           ['block4c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4c_activation[0][0]',     Y          \n",
      "                                                                  'block4c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4c_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_add (Add)              (None, 14, 14, 160)  0           ['block4c_drop[0][0]',           Y          \n",
      "                                                                  'block4b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4d_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4d_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4d_expand_activation (Act  (None, 14, 14, 960)  0          ['block4d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4d_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4d_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4d_activation (Activation  (None, 14, 14, 960)  0          ['block4d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4d_se_squeeze (GlobalAver  (None, 960)         0           ['block4d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4d_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4d_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4d_activation[0][0]',     Y          \n",
      "                                                                  'block4d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4d_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4d_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4d_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_add (Add)              (None, 14, 14, 160)  0           ['block4d_drop[0][0]',           Y          \n",
      "                                                                  'block4c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4e_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4e_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4e_expand_activation (Act  (None, 14, 14, 960)  0          ['block4e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4e_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4e_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4e_activation (Activation  (None, 14, 14, 960)  0          ['block4e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4e_se_squeeze (GlobalAver  (None, 960)         0           ['block4e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4e_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4e_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4e_activation[0][0]',     Y          \n",
      "                                                                  'block4e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4e_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4e_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4e_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_add (Add)              (None, 14, 14, 160)  0           ['block4e_drop[0][0]',           Y          \n",
      "                                                                  'block4d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4f_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4f_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4f_expand_activation (Act  (None, 14, 14, 960)  0          ['block4f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4f_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4f_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4f_activation (Activation  (None, 14, 14, 960)  0          ['block4f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4f_se_squeeze (GlobalAver  (None, 960)         0           ['block4f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4f_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4f_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4f_activation[0][0]',     Y          \n",
      "                                                                  'block4f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4f_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4f_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4f_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_add (Add)              (None, 14, 14, 160)  0           ['block4f_drop[0][0]',           Y          \n",
      "                                                                  'block4e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4g_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4g_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4g_expand_activation (Act  (None, 14, 14, 960)  0          ['block4g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4g_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4g_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4g_activation (Activation  (None, 14, 14, 960)  0          ['block4g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4g_se_squeeze (GlobalAver  (None, 960)         0           ['block4g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4g_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4g_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4g_activation[0][0]',     Y          \n",
      "                                                                  'block4g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4g_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4g_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4g_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_add (Add)              (None, 14, 14, 160)  0           ['block4g_drop[0][0]',           Y          \n",
      "                                                                  'block4f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4h_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4h_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4h_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4h_expand_activation (Act  (None, 14, 14, 960)  0          ['block4h_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4h_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4h_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4h_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4h_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4h_activation (Activation  (None, 14, 14, 960)  0          ['block4h_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4h_se_squeeze (GlobalAver  (None, 960)         0           ['block4h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4h_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4h_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4h_activation[0][0]',     Y          \n",
      "                                                                  'block4h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4h_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4h_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4h_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_add (Add)              (None, 14, 14, 160)  0           ['block4h_drop[0][0]',           Y          \n",
      "                                                                  'block4g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4i_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4h_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4i_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4i_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4i_expand_activation (Act  (None, 14, 14, 960)  0          ['block4i_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4i_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4i_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4i_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4i_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4i_activation (Activation  (None, 14, 14, 960)  0          ['block4i_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4i_se_squeeze (GlobalAver  (None, 960)         0           ['block4i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4i_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4i_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4i_activation[0][0]',     Y          \n",
      "                                                                  'block4i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4i_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4i_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4i_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_add (Add)              (None, 14, 14, 160)  0           ['block4i_drop[0][0]',           Y          \n",
      "                                                                  'block4h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4j_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4i_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4j_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4j_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4j_expand_activation (Act  (None, 14, 14, 960)  0          ['block4j_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4j_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4j_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4j_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4j_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4j_activation (Activation  (None, 14, 14, 960)  0          ['block4j_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4j_se_squeeze (GlobalAver  (None, 960)         0           ['block4j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4j_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4j_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4j_activation[0][0]',     Y          \n",
      "                                                                  'block4j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4j_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4j_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4j_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_add (Add)              (None, 14, 14, 160)  0           ['block4j_drop[0][0]',           Y          \n",
      "                                                                  'block4i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4j_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block5a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_expand_activation (Act  (None, 14, 14, 960)  0          ['block5a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 960)  24000      ['block5a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block5a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_activation (Activation  (None, 14, 14, 960)  0          ['block5a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_se_squeeze (GlobalAver  (None, 960)         0           ['block5a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block5a_activation[0][0]',     Y          \n",
      "                                                                  'block5a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 224)  215040      ['block5a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5a_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5b_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5b_expand_activation (Act  (None, 14, 14, 1344  0          ['block5b_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5b_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5b_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5b_activation (Activation  (None, 14, 14, 1344  0          ['block5b_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5b_se_squeeze (GlobalAver  (None, 1344)        0           ['block5b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5b_activation[0][0]',     Y          \n",
      "                                )                                 'block5b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_add (Add)              (None, 14, 14, 224)  0           ['block5b_drop[0][0]',           Y          \n",
      "                                                                  'block5a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5b_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5c_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5c_expand_activation (Act  (None, 14, 14, 1344  0          ['block5c_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5c_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5c_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5c_activation (Activation  (None, 14, 14, 1344  0          ['block5c_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5c_se_squeeze (GlobalAver  (None, 1344)        0           ['block5c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5c_activation[0][0]',     Y          \n",
      "                                )                                 'block5c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5c_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_add (Add)              (None, 14, 14, 224)  0           ['block5c_drop[0][0]',           Y          \n",
      "                                                                  'block5b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5d_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5c_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5d_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5d_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5d_expand_activation (Act  (None, 14, 14, 1344  0          ['block5d_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5d_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5d_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5d_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5d_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5d_activation (Activation  (None, 14, 14, 1344  0          ['block5d_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5d_se_squeeze (GlobalAver  (None, 1344)        0           ['block5d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5d_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5d_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5d_activation[0][0]',     Y          \n",
      "                                )                                 'block5d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5d_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5d_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5d_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_add (Add)              (None, 14, 14, 224)  0           ['block5d_drop[0][0]',           Y          \n",
      "                                                                  'block5c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5e_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5d_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5e_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5e_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5e_expand_activation (Act  (None, 14, 14, 1344  0          ['block5e_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5e_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5e_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5e_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5e_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5e_activation (Activation  (None, 14, 14, 1344  0          ['block5e_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5e_se_squeeze (GlobalAver  (None, 1344)        0           ['block5e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5e_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5e_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5e_activation[0][0]',     Y          \n",
      "                                )                                 'block5e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5e_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5e_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5e_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_add (Add)              (None, 14, 14, 224)  0           ['block5e_drop[0][0]',           Y          \n",
      "                                                                  'block5d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5f_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5e_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5f_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5f_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5f_expand_activation (Act  (None, 14, 14, 1344  0          ['block5f_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5f_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5f_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5f_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5f_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5f_activation (Activation  (None, 14, 14, 1344  0          ['block5f_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5f_se_squeeze (GlobalAver  (None, 1344)        0           ['block5f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5f_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5f_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5f_activation[0][0]',     Y          \n",
      "                                )                                 'block5f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5f_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5f_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5f_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_add (Add)              (None, 14, 14, 224)  0           ['block5f_drop[0][0]',           Y          \n",
      "                                                                  'block5e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5g_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5f_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5g_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5g_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5g_expand_activation (Act  (None, 14, 14, 1344  0          ['block5g_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5g_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5g_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5g_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5g_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5g_activation (Activation  (None, 14, 14, 1344  0          ['block5g_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5g_se_squeeze (GlobalAver  (None, 1344)        0           ['block5g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5g_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5g_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5g_activation[0][0]',     Y          \n",
      "                                )                                 'block5g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5g_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5g_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5g_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_add (Add)              (None, 14, 14, 224)  0           ['block5g_drop[0][0]',           Y          \n",
      "                                                                  'block5f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5h_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5g_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5h_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5h_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5h_expand_activation (Act  (None, 14, 14, 1344  0          ['block5h_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5h_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5h_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5h_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5h_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5h_activation (Activation  (None, 14, 14, 1344  0          ['block5h_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5h_se_squeeze (GlobalAver  (None, 1344)        0           ['block5h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5h_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5h_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5h_activation[0][0]',     Y          \n",
      "                                )                                 'block5h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5h_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5h_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5h_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_add (Add)              (None, 14, 14, 224)  0           ['block5h_drop[0][0]',           Y          \n",
      "                                                                  'block5g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5i_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5h_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5i_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5i_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5i_expand_activation (Act  (None, 14, 14, 1344  0          ['block5i_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5i_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5i_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5i_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5i_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5i_activation (Activation  (None, 14, 14, 1344  0          ['block5i_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5i_se_squeeze (GlobalAver  (None, 1344)        0           ['block5i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5i_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5i_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5i_activation[0][0]',     Y          \n",
      "                                )                                 'block5i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5i_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5i_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5i_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_add (Add)              (None, 14, 14, 224)  0           ['block5i_drop[0][0]',           Y          \n",
      "                                                                  'block5h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5j_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5i_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5j_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5j_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5j_expand_activation (Act  (None, 14, 14, 1344  0          ['block5j_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5j_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5j_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5j_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5j_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5j_activation (Activation  (None, 14, 14, 1344  0          ['block5j_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5j_se_squeeze (GlobalAver  (None, 1344)        0           ['block5j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5j_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5j_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5j_activation[0][0]',     Y          \n",
      "                                )                                 'block5j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5j_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5j_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5j_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_add (Add)              (None, 14, 14, 224)  0           ['block5j_drop[0][0]',           Y          \n",
      "                                                                  'block5i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5j_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block6a_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block6a_expand_activation (Act  (None, 14, 14, 1344  0          ['block6a_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 1344)  33600       ['block6a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 1344)  5376        ['block6a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_activation (Activation  (None, 7, 7, 1344)  0           ['block6a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_se_squeeze (GlobalAver  (None, 1344)        0           ['block6a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block6a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block6a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block6a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 1344)   0           ['block6a_activation[0][0]',     Y          \n",
      "                                                                  'block6a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 384)    516096      ['block6a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_activation (Activation  (None, 7, 7, 2304)  0           ['block6b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_se_squeeze (GlobalAver  (None, 2304)        0           ['block6b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6b_activation[0][0]',     Y          \n",
      "                                                                  'block6b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_add (Add)              (None, 7, 7, 384)    0           ['block6b_drop[0][0]',           Y          \n",
      "                                                                  'block6a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_activation (Activation  (None, 7, 7, 2304)  0           ['block6c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_se_squeeze (GlobalAver  (None, 2304)        0           ['block6c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6c_activation[0][0]',     Y          \n",
      "                                                                  'block6c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6c_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_add (Add)              (None, 7, 7, 384)    0           ['block6c_drop[0][0]',           Y          \n",
      "                                                                  'block6b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_activation (Activation  (None, 7, 7, 2304)  0           ['block6d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_se_squeeze (GlobalAver  (None, 2304)        0           ['block6d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6d_activation[0][0]',     Y          \n",
      "                                                                  'block6d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6d_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_add (Add)              (None, 7, 7, 384)    0           ['block6d_drop[0][0]',           Y          \n",
      "                                                                  'block6c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6e_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6e_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6e_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6e_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6e_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6e_activation (Activation  (None, 7, 7, 2304)  0           ['block6e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6e_se_squeeze (GlobalAver  (None, 2304)        0           ['block6e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6e_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6e_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6e_activation[0][0]',     Y          \n",
      "                                                                  'block6e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6e_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6e_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6e_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_add (Add)              (None, 7, 7, 384)    0           ['block6e_drop[0][0]',           Y          \n",
      "                                                                  'block6d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6f_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6f_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6f_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6f_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6f_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6f_activation (Activation  (None, 7, 7, 2304)  0           ['block6f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6f_se_squeeze (GlobalAver  (None, 2304)        0           ['block6f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6f_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6f_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6f_activation[0][0]',     Y          \n",
      "                                                                  'block6f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6f_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6f_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6f_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_add (Add)              (None, 7, 7, 384)    0           ['block6f_drop[0][0]',           Y          \n",
      "                                                                  'block6e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6g_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6g_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6g_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6g_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6g_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6g_activation (Activation  (None, 7, 7, 2304)  0           ['block6g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6g_se_squeeze (GlobalAver  (None, 2304)        0           ['block6g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6g_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6g_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6g_activation[0][0]',     Y          \n",
      "                                                                  'block6g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6g_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6g_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6g_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_add (Add)              (None, 7, 7, 384)    0           ['block6g_drop[0][0]',           Y          \n",
      "                                                                  'block6f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6h_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6h_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6h_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6h_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6h_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6h_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6h_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6h_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6h_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6h_activation (Activation  (None, 7, 7, 2304)  0           ['block6h_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6h_se_squeeze (GlobalAver  (None, 2304)        0           ['block6h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6h_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6h_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6h_activation[0][0]',     Y          \n",
      "                                                                  'block6h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6h_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6h_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6h_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_add (Add)              (None, 7, 7, 384)    0           ['block6h_drop[0][0]',           Y          \n",
      "                                                                  'block6g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6i_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6h_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6i_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6i_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6i_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6i_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6i_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6i_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6i_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6i_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6i_activation (Activation  (None, 7, 7, 2304)  0           ['block6i_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6i_se_squeeze (GlobalAver  (None, 2304)        0           ['block6i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6i_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6i_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6i_activation[0][0]',     Y          \n",
      "                                                                  'block6i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6i_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6i_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6i_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_add (Add)              (None, 7, 7, 384)    0           ['block6i_drop[0][0]',           Y          \n",
      "                                                                  'block6h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6j_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6i_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6j_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6j_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6j_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6j_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6j_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6j_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6j_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6j_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6j_activation (Activation  (None, 7, 7, 2304)  0           ['block6j_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6j_se_squeeze (GlobalAver  (None, 2304)        0           ['block6j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6j_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6j_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6j_activation[0][0]',     Y          \n",
      "                                                                  'block6j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6j_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6j_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6j_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_add (Add)              (None, 7, 7, 384)    0           ['block6j_drop[0][0]',           Y          \n",
      "                                                                  'block6i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6k_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6j_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6k_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6k_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6k_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6k_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6k_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6k_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6k_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6k_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6k_activation (Activation  (None, 7, 7, 2304)  0           ['block6k_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6k_se_squeeze (GlobalAver  (None, 2304)        0           ['block6k_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6k_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6k_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6k_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6k_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6k_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6k_activation[0][0]',     Y          \n",
      "                                                                  'block6k_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6k_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6k_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6k_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6k_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6k_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6k_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_add (Add)              (None, 7, 7, 384)    0           ['block6k_drop[0][0]',           Y          \n",
      "                                                                  'block6j_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6l_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6k_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6l_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6l_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6l_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6l_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6l_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6l_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6l_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6l_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6l_activation (Activation  (None, 7, 7, 2304)  0           ['block6l_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6l_se_squeeze (GlobalAver  (None, 2304)        0           ['block6l_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6l_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6l_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6l_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6l_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6l_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6l_activation[0][0]',     Y          \n",
      "                                                                  'block6l_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6l_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6l_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6l_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6l_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6l_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6l_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_add (Add)              (None, 7, 7, 384)    0           ['block6l_drop[0][0]',           Y          \n",
      "                                                                  'block6k_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6m_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6l_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6m_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6m_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6m_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6m_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6m_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6m_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6m_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6m_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6m_activation (Activation  (None, 7, 7, 2304)  0           ['block6m_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6m_se_squeeze (GlobalAver  (None, 2304)        0           ['block6m_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6m_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6m_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6m_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6m_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6m_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6m_activation[0][0]',     Y          \n",
      "                                                                  'block6m_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6m_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6m_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6m_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6m_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6m_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6m_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_add (Add)              (None, 7, 7, 384)    0           ['block6m_drop[0][0]',           Y          \n",
      "                                                                  'block6l_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6m_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block7a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_expand_activation (Act  (None, 7, 7, 2304)  0           ['block7a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  20736       ['block7a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block7a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_activation (Activation  (None, 7, 7, 2304)  0           ['block7a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_se_squeeze (GlobalAver  (None, 2304)        0           ['block7a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block7a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block7a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block7a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block7a_activation[0][0]',     Y          \n",
      "                                                                  'block7a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 640)    1474560     ['block7a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7b_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7b_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7b_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7b_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7b_activation (Activation  (None, 7, 7, 3840)  0           ['block7b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7b_se_squeeze (GlobalAver  (None, 3840)        0           ['block7b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7b_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7b_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7b_activation[0][0]',     Y          \n",
      "                                                                  'block7b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7b_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7b_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7b_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_add (Add)              (None, 7, 7, 640)    0           ['block7b_drop[0][0]',           Y          \n",
      "                                                                  'block7a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block7c_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7c_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7c_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7c_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7c_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7c_activation (Activation  (None, 7, 7, 3840)  0           ['block7c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7c_se_squeeze (GlobalAver  (None, 3840)        0           ['block7c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7c_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7c_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7c_activation[0][0]',     Y          \n",
      "                                                                  'block7c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7c_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7c_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7c_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_add (Add)              (None, 7, 7, 640)    0           ['block7c_drop[0][0]',           Y          \n",
      "                                                                  'block7b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7d_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7d_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7d_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7d_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7d_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7d_activation (Activation  (None, 7, 7, 3840)  0           ['block7d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7d_se_squeeze (GlobalAver  (None, 3840)        0           ['block7d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7d_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7d_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7d_activation[0][0]',     Y          \n",
      "                                                                  'block7d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7d_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7d_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7d_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_add (Add)              (None, 7, 7, 640)    0           ['block7d_drop[0][0]',           Y          \n",
      "                                                                  'block7c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " top_conv (Conv2D)              (None, 7, 7, 2560)   1638400     ['block7d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 2560)   10240       ['top_conv[0][0]']               Y          \n",
      "                                                                                                             \n",
      " top_activation (Activation)    (None, 7, 7, 2560)   0           ['top_bn[0][0]']                 Y          \n",
      "                                                                                                             \n",
      " FC_INPUT_Avg-Pooling (GlobalAv  (None, 2560)        0           ['top_activation[0][0]']         Y          \n",
      " eragePooling2D)                                                                                             \n",
      "                                                                                                             \n",
      " FC_C_Dense-L1-512 (Dense)      (None, 512)          1311232     ['FC_INPUT_Avg-Pooling[0][0]']   Y          \n",
      "                                                                                                             \n",
      " FC_C_Dropout-L1-0.1 (Dropout)  (None, 512)          0           ['FC_C_Dense-L1-512[0][0]']      Y          \n",
      "                                                                                                             \n",
      " FC_C_Avg-BatchNormalization-L1  (None, 512)         2048        ['FC_C_Dropout-L1-0.1[0][0]']    Y          \n",
      "  (BatchNormalization)                                                                                       \n",
      "                                                                                                             \n",
      " FC_C_Dense-L2-512 (Dense)      (None, 512)          262656      ['FC_C_Avg-BatchNormalization-L  Y          \n",
      "                                                                 1[0][0]']                                   \n",
      "                                                                                                             \n",
      " FC_C_Avg-BatchNormalization-L2  (None, 512)         2048        ['FC_C_Dense-L2-512[0][0]']      Y          \n",
      "  (BatchNormalization)                                                                                       \n",
      "                                                                                                             \n",
      " FC_C_Dense-L3-128 (Dense)      (None, 128)          65664       ['FC_C_Avg-BatchNormalization-L  Y          \n",
      "                                                                 2[0][0]']                                   \n",
      "                                                                                                             \n",
      " FC_OUTPUT_Dense-2 (Dense)      (None, 2)            258         ['FC_C_Dense-L3-128[0][0]']      Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 65,741,586\n",
      "Trainable params: 65,428,818\n",
      "Non-trainable params: 312,768\n",
      "_____________________________________________________________________________________________________________\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from efficientnet.keras import EfficientNetB7 as KENB7\n",
    "# FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENB7(input_shape=(\n",
    "        img_res[0], img_res[1], img_res[2]), weights='noisy-student', include_top=False)\n",
    "    print('Total layers in the base model: ', len(base_model.layers))\n",
    "    print(f'Freezing {freeze_layers} layers in the base model...')\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) /\n",
    "                         len(base_model.layers)) * 100\n",
    "    print(\n",
    "        f'Percentage of the base model that is frozen: {frozen_percentage:.2f}%')\n",
    "    # adding CDL>>>\n",
    "    #GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name='FC_INPUT_Avg-Pooling')(base_model.output)\n",
    "    #Dense\n",
    "    Dense_L1 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.008),\n",
    "                     name='FC_C_Dense-L1-512'\n",
    "                     )(base_model_FT)\n",
    "    #Dropout\n",
    "    Dropout_L1 = Dropout(0.125,\n",
    "                         name='FC_C_Dropout-L1-0.1'\n",
    "                         )(Dense_L1)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L1'\n",
    "                                      )(Dropout_L1)\n",
    "    #Dense\n",
    "    Dense_L2 = Dense(512, activation='swish',\n",
    "                     kernel_regularizer=l2(0.004),\n",
    "                     name='FC_C_Dense-L2-512'\n",
    "                     )(BatchNorm_L2)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L2'\n",
    "                                      )(Dense_L2)\n",
    "    #Dense\n",
    "    Dense_L3 = Dense(128, activation='relu',\n",
    "                     name='FC_C_Dense-L3-128'\n",
    "                     )(BatchNorm_L3)\n",
    "    #Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation='softmax',\n",
    "                        name='FC_OUTPUT_Dense-2')(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB7_NS = Model(\n",
    "        inputs=base_model.input, outputs=predictions)\n",
    "    print('Total model layers: ', len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.92, nesterov=False)\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.3\n",
    "```\n",
    "recommended: ‚ùå\n",
    "statuses: Test\n",
    "Working: ‚úÖ\n",
    "Max fine tuned acc: ‚ö†Ô∏è\n",
    "Max fine tuned acc TLRev2: ‚ö†Ô∏è\n",
    "type: transfer learning>>>(EfficientNetB7|Xception::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB7 as KENB7\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "#FUNC\n",
    "def Combo_Model(freeze_layers1, freeze_layers2):\n",
    "    # Define a common input\n",
    "    common_input = Input(shape=(img_res[0], img_res[1], img_res[2]))\n",
    "\n",
    "    # Base model 1\n",
    "    base_model1 = KENB7(input_shape=(img_res[0], img_res[1], img_res[2]), weights='noisy-student', include_top=False)\n",
    "    # base_model1.load_weights('models\\Ready\\Other\\EfficientNetB7_PRET.h5', by_name=True, skip_mismatch=True)\n",
    "    base_model1_out = base_model1(common_input)\n",
    "    \n",
    "    # Base model 2\n",
    "    base_model2 = Xception(input_shape=(img_res[0], img_res[1], img_res[2]), weights='imagenet', include_top=False)\n",
    "    # base_model1.load_weights('models\\Ready\\Other\\Xception_PRET.h5', by_name=True, skip_mismatch=True)\n",
    "    base_model2_out = base_model2(common_input)\n",
    "\n",
    "    print('Total base_model1 layers: ', len(base_model1.layers))\n",
    "    print('Total base_model2 layers: ', len(base_model2.layers))\n",
    "    \n",
    "    # Freeze the specified number of layers in both models\n",
    "    for layer in base_model1.layers[:freeze_layers1]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model2.layers[:freeze_layers2]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest in both models\n",
    "    for layer in base_model1.layers[freeze_layers1:]:\n",
    "        layer.trainable = True\n",
    "    for layer in base_model2.layers[freeze_layers2:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Combine the output of the two base models\n",
    "    combined = concatenate([Dense(512,\n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=l2(0.01)\n",
    "                                  )(GlobalAveragePooling2D()(base_model1_out)),\n",
    "                            Dense(512,\n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=l2(0.01)\n",
    "                                  )(GlobalAveragePooling2D()(base_model2_out))])\n",
    "\n",
    "    # adding CDL\n",
    "    Dense_L1 = Dense(1024, activation='relu', kernel_regularizer=l2(0.02))(combined)\n",
    "    Dropout_L1 = Dropout(0.4)(Dense_L1) \n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation='relu', kernel_regularizer=l2(0.003))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation='relu')(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation='softmax')(Dense_L3)\n",
    "\n",
    "    combo_model = Model(inputs=common_input, outputs=predictions)   \n",
    "    print('Total model layers: ', len(combo_model.layers))\n",
    "    \n",
    "    #OPT/compile\n",
    "    opt = SGD(momentum=0.9)\n",
    "    combo_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return combo_model\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers_1 = 0\n",
    "freeze_layers_2 = 0\n",
    "model = Combo_Model(freeze_layers_1, freeze_layers_2)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.4\n",
    "```\n",
    "recommended: ‚ö†Ô∏è\n",
    "statuses: Test\n",
    "Working: ‚úÖ\n",
    "Max fine tuned acc: ‚ö†Ô∏è\n",
    "Max fine tuned acc TLRev2: ‚âÖ95.64\n",
    "type: transfer learning>>>(EfficientNetV2XL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_efficientnet_v2 import EfficientNetV2XL\n",
    "\n",
    "EfficientNet_M = EfficientNetV2XL(input_shape=(img_res[0], img_res[1], img_res[2]), pretrained='imagenet21k-ft1k', num_classes=2, dropout=0.4)\n",
    "# define new model\n",
    "model = Model(inputs=EfficientNet_M.inputs, outputs=EfficientNet_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)\n",
    "# opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-2, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "# opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-3)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "freeze_layers = 0\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.5 (The best one)\n",
    "```\n",
    "recommended: ‚úÖ\n",
    "statuses: Ready\n",
    "Working: ‚úÖ\n",
    "Max fine tuned acc: 95.3\n",
    "Max fine tuned acc TLRev2: 97.12\n",
    "type: transfer learning>>>(EfficientNetB4::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB4 as KENB4\n",
    "# FUNC\n",
    "def Eff_B4_NS(freeze_layers):\n",
    "    base_model = KENB4(input_shape=(\n",
    "        img_res[0], img_res[1], img_res[2]), weights='noisy-student', include_top=False)\n",
    "    print('Total layers in the base model: ', len(base_model.layers))\n",
    "    print(f'Freezing {freeze_layers} layers in the base model...')\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) /\n",
    "                         len(base_model.layers)) * 100\n",
    "    print(\n",
    "        f'Percentage of the base model that is frozen: {frozen_percentage:.2f}%')\n",
    "    # adding CDL>>>\n",
    "    #GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name='FC_INPUT_Avg-Pooling')(base_model.output)\n",
    "    #Dense\n",
    "    Dense_L1 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.02),\n",
    "                     name='FC_C_Dense-L1-512'\n",
    "                     )(base_model_FT)\n",
    "    #Dropout\n",
    "    Dropout_L1 = Dropout(0.1,\n",
    "                         name='FC_C_Dropout-L1-0.1'\n",
    "                         )(Dense_L1)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L1'\n",
    "                                      )(Dropout_L1)\n",
    "    #Dense\n",
    "    Dense_L2 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.01),\n",
    "                     name='FC_C_Dense-L2-512'\n",
    "                     )(BatchNorm_L2)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L2'\n",
    "                                      )(Dense_L2)\n",
    "    #Dense\n",
    "    Dense_L3 = Dense(128, activation='relu',\n",
    "                     name='FC_C_Dense-L3-128'\n",
    "                     )(BatchNorm_L3)\n",
    "    #Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation='softmax',\n",
    "                        name='FC_OUTPUT_Dense-2')(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB4_NS = Model(\n",
    "        inputs=base_model.input, outputs=predictions)\n",
    "    print('Total model layers: ', len(model_EfficientNetB4_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.92, nesterov=False)\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB4_NS.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB4_NS\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B4_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetL2 as KENBL2\n",
    "#FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENBL2(input_shape=(img_res[0], img_res[1], img_res[2]),\n",
    "                        weights='./download/Models/EFN_L2/efficientnet-l2_noisy-student_notop.h5',\n",
    "                        include_top=False,\n",
    "                        drop_connect_rate=0)\n",
    "    print('Total layers in the base model: ', len(base_model.layers))\n",
    "    print(f'Freezing {freeze_layers} layers in the base model...')\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) / len(base_model.layers)) * 100\n",
    "    print(f'Percentage of the base model that is frozen: {frozen_percentage:.2f}%')\n",
    "    # adding CDL\n",
    "    base_model_FT = GlobalAveragePooling2D()(base_model.output)\n",
    "    Dense_L1 = Dense(512, activation='relu', kernel_regularizer=l2(0.02))(base_model_FT)\n",
    "    Dropout_L1 = Dropout(0.1)(Dense_L1) \n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation='relu')(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation='softmax')(Dense_L3)\n",
    "\n",
    "    model_EfficientNetB7_NS = Model(inputs=base_model.input, outputs=predictions)   \n",
    "    print('Total model layers: ', len(model_EfficientNetB7_NS.layers))\n",
    "    #OPT/compile\n",
    "    opt = SGD(momentum=0.9)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer = opt,  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T02:31:32.994176700Z",
     "start_time": "2023-12-28T02:31:27.381088600Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB7 as KENB7\n",
    "# FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENB7(input_shape=(\n",
    "        img_res[0], img_res[1], img_res[2]), weights=None, include_top=False)\n",
    "    print('Total layers in the base model: ', len(base_model.layers))\n",
    "    print(f'Freezing {freeze_layers} layers in the base model...')\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) /\n",
    "                         len(base_model.layers)) * 100\n",
    "    print(\n",
    "        f'Percentage of the base model that is frozen: {frozen_percentage:.2f}%')\n",
    "    # adding CDL>>>\n",
    "    #GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name='FC_INPUT_Avg-Pooling')(base_model.output)\n",
    "    #Dense\n",
    "    Dense_L1 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.02),\n",
    "                     name='FC_C_Dense-L1-512'\n",
    "                     )(base_model_FT)\n",
    "    #Dropout\n",
    "    Dropout_L1 = Dropout(0.1,\n",
    "                         name='FC_C_Dropout-L1-0.1'\n",
    "                         )(Dense_L1)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name='FC_C_Avg-Pooling-L1'\n",
    "                                      )(Dropout_L1)\n",
    "    #Dense\n",
    "    Dense_L2 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.01),\n",
    "                     name='FC_C_Dense-L2-512'\n",
    "                     )(BatchNorm_L2)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name='FC_C_Avg-Pooling-L2'\n",
    "                                      )(Dense_L2)\n",
    "    #Dense\n",
    "    Dense_L3 = Dense(128, activation='relu',\n",
    "                     name='FC_C_Dense-L3-128'\n",
    "                     )(BatchNorm_L3)\n",
    "    #Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation='softmax',\n",
    "                        name='FC_OUTPUT_Dense-2')(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB7_NS = Model(\n",
    "        inputs=base_model.input, outputs=predictions)\n",
    "    print('Total model layers: ', len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9, nesterov=False)\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ConvNeXtXLarge\n",
    "from keras.layers import Lambda\n",
    "#FUNC\n",
    "def Eff_B7_NS():\n",
    "    # Add a Lambda layer at the beginning to scale the input\n",
    "    input = Input(shape=(img_res[0], img_res[1], img_res[2]))\n",
    "    x = Lambda(lambda image: image * 255)(input)\n",
    "    \n",
    "    base_model = ConvNeXtXLarge(include_top=False, weights='imagenet', classes=2, classifier_activation='softmax', include_preprocessing=True)(x)\n",
    "    # adding CDL\n",
    "    base_model_FT = GlobalAveragePooling2D()(base_model)\n",
    "    Dense_L1 = Dense(512, activation='relu', kernel_regularizer=l2(0.02))(base_model_FT)\n",
    "    Dropout_L1 = Dropout(0.1)(Dense_L1) \n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation='relu')(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation='softmax')(Dense_L3)\n",
    "\n",
    "    model_EfficientNetB7_NS = Model(inputs=input, outputs=predictions)   \n",
    "    print('Total model layers: ', len(model_EfficientNetB7_NS.layers))\n",
    "    #OPT/compile\n",
    "    opt = SGD(momentum=0.9)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt,  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "model = Eff_B7_NS()\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.keras import EfficientNetB5 as KENB5\n",
    "# FUNC\n",
    "def Eff_B5_NS(freeze_layers):\n",
    "    base_model = KENB5(input_shape=(\n",
    "        img_res[0], img_res[1], img_res[2]), weights='noisy-student', include_top=False)\n",
    "    print('Total layers in the base model: ', len(base_model.layers))\n",
    "    print(f'Freezing {freeze_layers} layers in the base model...')\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) /\n",
    "                         len(base_model.layers)) * 100\n",
    "    print(\n",
    "        f'Percentage of the base model that is frozen: {frozen_percentage:.2f}%')\n",
    "    # adding CDL>>>\n",
    "    #GlobalAveragePooling2D\n",
    "    base_model_FT = GlobalAveragePooling2D(name='FC_INPUT_Avg-Pooling')(base_model.output)\n",
    "    #Dense\n",
    "    Dense_L1 = Dense(512, activation='relu',\n",
    "                     kernel_regularizer=l2(0.008),\n",
    "                     name='FC_C_Dense-L1-512'\n",
    "                     )(base_model_FT)\n",
    "    #Dropout\n",
    "    Dropout_L1 = Dropout(0.125,\n",
    "                         name='FC_C_Dropout-L1-0.1'\n",
    "                         )(Dense_L1)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L2 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L1'\n",
    "                                      )(Dropout_L1)\n",
    "    #Dense\n",
    "    Dense_L2 = Dense(512, activation='swish',\n",
    "                     kernel_regularizer=l2(0.004),\n",
    "                     name='FC_C_Dense-L2-512'\n",
    "                     )(BatchNorm_L2)\n",
    "    #BatchNormalization\n",
    "    BatchNorm_L3 = BatchNormalization(name='FC_C_Avg-BatchNormalization-L2'\n",
    "                                      )(Dense_L2)\n",
    "    #Dense\n",
    "    Dense_L3 = Dense(128, activation='relu',\n",
    "                     name='FC_C_Dense-L3-128'\n",
    "                     )(BatchNorm_L3)\n",
    "    #Dense\n",
    "    # predictions = Dense(2, activation='softmax')(Dense_L3) / predictions = Dense(1, activation='sigmoid')(Dense_L3)\n",
    "    predictions = Dense(2, activation='softmax',\n",
    "                        name='FC_OUTPUT_Dense-2')(Dense_L3)\n",
    "    # CDL<<<\n",
    "    model_EfficientNetB7_NS = Model(\n",
    "        inputs=base_model.input, outputs=predictions)\n",
    "    print('Total model layers: ', len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9, nesterov=False)\n",
    "    # opt = Nadam()\n",
    "    # opt = Adamax()\n",
    "    # opt = RMSprop(momentum=0.9)\n",
    "    # opt = Adagrad()\n",
    "    # opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=5e-4, print_change_log=False, total_steps=0, amsgrad=False)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # categorical_crossentropy / binary_crossentropy\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "print('Creating the model...')\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B5_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "#CONF/Other\n",
    "LRF_OPT = SGD(momentum=0.9)\n",
    "LFR_batch_size = 1  # or any other batch size that fits in your memory\n",
    "LRF_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(LFR_batch_size)\n",
    "# Instantiate LrFinder\n",
    "lr_find = LrFinder(model, LRF_OPT, tf.keras.losses.categorical_crossentropy)\n",
    "\n",
    "# Start range_test\n",
    "lr_find.range_test(LRF_dataset)\n",
    "lr_find.plot_lrs(skip_end=0, suggestion=True, show_grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_img_file = 'model_1.png'\n",
    "keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Save (Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Aydin Hamedi\n",
    "# \n",
    "# This software is released under the MIT License.\n",
    "# https://opensource.org/licenses/MIT\n",
    "import json\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import get as get_optimizer\n",
    "\n",
    "def save_model(model, optimizer, filename):\n",
    "    \"\"\"\n",
    "    Save a Keras model's architecture and weights into a single gzipped file.\n",
    "\n",
    "    Args:\n",
    "    model (tf.keras.Model): The Keras model to save.\n",
    "    optimizer (str): The name of the Keras optimizer to use.\n",
    "    filename (str): The filename to use for the saved file.\n",
    "    \"\"\"\n",
    "    # Save the architecture, weights and optimizer into a dictionary\n",
    "    model_dict = {\n",
    "        'architecture': model.to_json(),\n",
    "        'weights': [w.tolist() for w in model.get_weights()],\n",
    "        'optimizer': optimizer.get_config()['name']\n",
    "    }\n",
    "\n",
    "    # Write the dictionary to a gzipped file\n",
    "    with gzip.GzipFile(f'{filename}.gz', 'w') as f:\n",
    "        f.write(json.dumps(model_dict).encode('utf-8'))\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Load a Keras model's architecture and weights from a gzipped file.\n",
    "\n",
    "    Args:\n",
    "    filename (str): The filename of the saved file.\n",
    "\n",
    "    Returns:\n",
    "    tf.keras.Model: The loaded Keras model.\n",
    "    \"\"\"\n",
    "    # Read the dictionary from the gzipped file\n",
    "    with gzip.GzipFile(f'{filename}.gz', 'r') as f:\n",
    "        model_dict = json.loads(f.read().decode('utf-8'))\n",
    "\n",
    "    # Create a model from the architecture\n",
    "    model = model_from_json(model_dict['architecture'])\n",
    "\n",
    "    # Set the model's weights\n",
    "    model.set_weights([np.array(w) for w in model_dict['weights']])\n",
    "\n",
    "    # Get the optimizer\n",
    "    optimizer = get_optimizer(model_dict['optimizer'])\n",
    "\n",
    "    # Compile the model with the loaded optimizer\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "save_model(model, SGD(), 'PAI_model_REV2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras\n",
    "# Configuration\n",
    "PRMC = False\n",
    "freeze_from_opposite = False\n",
    "Extra_EXT = '_T'\n",
    "freeze_layers = 0  \n",
    "randomly_frozen_layers = 0 \n",
    "freeze_last_seven = False  \n",
    "# CEC_opt = Adagrad()\n",
    "# CEC_opt = Yogi()\n",
    "# CEC_opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-3)\n",
    "CEC_opt = SGD(momentum=0.9, nesterov=False)\n",
    "# CEC_opt = Adam()\n",
    "# Main\n",
    "try:\n",
    "    if SAVE_TYPE == 'TF':\n",
    "        model = load_model(f'PAI_model{Extra_EXT}', compile=PRMC)\n",
    "    else:\n",
    "        model = load_model(f'PAI_model{Extra_EXT}.h5', compile=PRMC)\n",
    "except (ImportError, IOError) as e:\n",
    "    print(f'\\033[91mfailed to load the model ERROR:\\n{e}')\n",
    "else:\n",
    "    print('\\033[92mLoading model done.')\n",
    "    if not PRMC:\n",
    "        print('Compiling the AI model...\\033[0m')\n",
    "        \n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "        \n",
    "        # Select random layers to freeze\n",
    "        frozen_layer_indices = random.sample(range(len(model.layers)), randomly_frozen_layers)\n",
    "        \n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if i in frozen_layer_indices:\n",
    "                layer.trainable = False\n",
    "            else:\n",
    "                if freeze_from_opposite and (i > len(model.layers) - freeze_layers):\n",
    "                    layer.trainable = False\n",
    "                elif (not freeze_from_opposite) and i < freeze_layers:\n",
    "                    layer.trainable = False\n",
    "                else:\n",
    "                    layer.trainable = True\n",
    "        \n",
    "        for layer in model.layers[-7:]:\n",
    "            layer.trainable = not freeze_last_seven\n",
    "            \n",
    "        model.compile(optimizer=CEC_opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.summary(show_trainable=True, expand_nested=True)\n",
    "        print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('PAI_model_weights.h5')\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[-7:]:\n",
    "    if hasattr(layer, 'kernel_initializer') and hasattr(layer, 'bias_initializer'):\n",
    "        weight_initializer = layer.kernel_initializer\n",
    "        bias_initializer = layer.bias_initializer\n",
    "\n",
    "        old_weights, old_biases = layer.get_weights()\n",
    "\n",
    "        layer.set_weights([\n",
    "            weight_initializer(shape=old_weights.shape),\n",
    "            bias_initializer(shape=len(old_biases))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rev2 (THE BEST)\n",
    "```\n",
    "Working: ‚úÖ\n",
    "Other:\n",
    " + Tensorboard works.\n",
    " + Perverts overfitting.\n",
    " + Lower memory usage.\n",
    " - Slow training.\n",
    " + Achieving higher acc.\n",
    " - Some models dont work.\n",
    "```\n",
    "- TODO:\n",
    "    - add Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T07:04:23.573633300Z",
     "start_time": "2023-12-28T02:31:32.468641900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "\u001b[0;33m\n",
      "Setup Verbose:\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSetting TensorBoard Log dir to \u001b[0m\u001b[0;32m[logs/fit/y2024_m02_d17-h23_m16_s58]\u001b[0m\u001b[0;36m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mUse_extended_tensorboard \u001b[0m\u001b[0;32m[False]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mDebug_OUTPUT_DPS \u001b[0m\u001b[0;32m[True]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mUse_OneCycleLr \u001b[0m\u001b[0;32m[False]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mOneCycleLr_UFTS \u001b[0m\u001b[0;32m[False]\u001b[0m\u001b[0;36m.\u001b[0m\n",
      "\u001b[0;33mSetup Verbose END.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m1\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 0)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Fitting ImageDataGenerator...\u001b[0m\n",
      "\u001b[0;33m- ImageDataGenerator fit done.\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;31m- Debug DP Sample dir: \u001b[0m\u001b[0;32mSamples/TSR_SUB_400_y2024_m02_d17-h23_m22_s10\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 112s 363ms/step - loss: 7.1283 - accuracy: 0.5090 - val_loss: 4.6667 - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 96s 376ms/step - loss: 3.2733 - accuracy: 0.6890 - val_loss: 2.1362 - val_accuracy: 0.7853 - lr: 0.0100\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 101s 394ms/step - loss: 1.6445 - accuracy: 0.8176 - val_loss: 1.1380 - val_accuracy: 0.8814 - lr: 0.0100\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 101s 394ms/step - loss: 0.9876 - accuracy: 0.8521 - val_loss: 0.6707 - val_accuracy: 0.8926 - lr: 0.0100\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 99s 388ms/step - loss: 0.6460 - accuracy: 0.8723 - val_loss: 0.6975 - val_accuracy: 0.7612 - lr: 0.0100\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 100s 392ms/step - loss: 0.4603 - accuracy: 0.8994 - val_loss: 0.5359 - val_accuracy: 0.7724 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-004-0.8926.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.8926\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.6707\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.000000 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.892628\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32minf \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.6707034707\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m941.73 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m611.41 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m330.32 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [1] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m2\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 6)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 7/12\n",
      "256/256 [==============================] - 101s 380ms/step - loss: 0.6842 - accuracy: 0.8606 - val_loss: 0.4796 - val_accuracy: 0.9151 - lr: 0.0100\n",
      "Epoch 8/12\n",
      "256/256 [==============================] - 102s 399ms/step - loss: 0.5021 - accuracy: 0.8823 - val_loss: 0.6667 - val_accuracy: 0.7340 - lr: 0.0100\n",
      "Epoch 9/12\n",
      "256/256 [==============================] - 102s 397ms/step - loss: 0.4081 - accuracy: 0.8923 - val_loss: 0.5067 - val_accuracy: 0.9247 - lr: 0.0100\n",
      "Epoch 10/12\n",
      "256/256 [==============================] - 102s 398ms/step - loss: 0.3109 - accuracy: 0.9106 - val_loss: 0.3329 - val_accuracy: 0.9006 - lr: 0.0100\n",
      "Epoch 11/12\n",
      "256/256 [==============================] - 102s 396ms/step - loss: 0.2886 - accuracy: 0.9185 - val_loss: 0.2278 - val_accuracy: 0.9343 - lr: 0.0100\n",
      "Epoch 12/12\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.2299 - accuracy: 0.9319 - val_loss: 0.6328 - val_accuracy: 0.8734 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-011-0.9343.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9343\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2278\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.892628 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.934295\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.6707034707 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.2277684361\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m674.79 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m608.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m65.97 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [2] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m3\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 12)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 13/18\n",
      "256/256 [==============================] - 101s 382ms/step - loss: 0.3353 - accuracy: 0.8936 - val_loss: 0.2317 - val_accuracy: 0.9359 - lr: 0.0100\n",
      "Epoch 14/18\n",
      "256/256 [==============================] - 100s 392ms/step - loss: 0.2979 - accuracy: 0.9004 - val_loss: 0.1880 - val_accuracy: 0.9423 - lr: 0.0100\n",
      "Epoch 15/18\n",
      "256/256 [==============================] - 96s 375ms/step - loss: 0.2394 - accuracy: 0.9255 - val_loss: 0.5667 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 16/18\n",
      "256/256 [==============================] - 97s 380ms/step - loss: 0.2147 - accuracy: 0.9312 - val_loss: 0.4449 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 17/18\n",
      "256/256 [==============================] - 97s 379ms/step - loss: 0.1955 - accuracy: 0.9404 - val_loss: 0.2868 - val_accuracy: 0.9359 - lr: 0.0100\n",
      "Epoch 18/18\n",
      "256/256 [==============================] - 102s 399ms/step - loss: 0.1741 - accuracy: 0.9478 - val_loss: 0.3708 - val_accuracy: 0.9327 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-014-0.9423.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1880\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.934295 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.942308\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.2277684361 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1880175322\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m663.48 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m595.88 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m67.59 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [3] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m4\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 18)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 19/24\n",
      "256/256 [==============================] - 101s 379ms/step - loss: 0.3215 - accuracy: 0.8926 - val_loss: 0.1962 - val_accuracy: 0.9423 - lr: 0.0100\n",
      "Epoch 20/24\n",
      "256/256 [==============================] - 101s 394ms/step - loss: 0.2743 - accuracy: 0.9155 - val_loss: 0.2456 - val_accuracy: 0.9199 - lr: 0.0100\n",
      "Epoch 21/24\n",
      "256/256 [==============================] - 103s 401ms/step - loss: 0.2349 - accuracy: 0.9250 - val_loss: 0.5406 - val_accuracy: 0.8926 - lr: 0.0100\n",
      "Epoch 22/24\n",
      "256/256 [==============================] - 101s 394ms/step - loss: 0.2349 - accuracy: 0.9250 - val_loss: 0.2288 - val_accuracy: 0.9199 - lr: 0.0100\n",
      "Epoch 23/24\n",
      "256/256 [==============================] - 103s 401ms/step - loss: 0.1787 - accuracy: 0.9485 - val_loss: 0.2014 - val_accuracy: 0.9455 - lr: 0.0100\n",
      "Epoch 24/24\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1740 - accuracy: 0.9470 - val_loss: 0.4441 - val_accuracy: 0.8990 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-023-0.9455.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2014\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.942308 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.945513\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1880175322. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m675.00 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m608.13 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m66.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [4] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m5\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 24)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 25/30\n",
      "256/256 [==============================] - 100s 375ms/step - loss: 0.2860 - accuracy: 0.9102 - val_loss: 0.2977 - val_accuracy: 0.9183 - lr: 0.0100\n",
      "Epoch 26/30\n",
      "256/256 [==============================] - 101s 394ms/step - loss: 0.2466 - accuracy: 0.9163 - val_loss: 0.2273 - val_accuracy: 0.9423 - lr: 0.0100\n",
      "Epoch 27/30\n",
      "256/256 [==============================] - 99s 386ms/step - loss: 0.2184 - accuracy: 0.9319 - val_loss: 0.2345 - val_accuracy: 0.9359 - lr: 0.0100\n",
      "Epoch 28/30\n",
      "256/256 [==============================] - 102s 398ms/step - loss: 0.1889 - accuracy: 0.9429 - val_loss: 0.2118 - val_accuracy: 0.9263 - lr: 0.0100\n",
      "Epoch 29/30\n",
      "256/256 [==============================] - 101s 395ms/step - loss: 0.1691 - accuracy: 0.9482 - val_loss: 0.3478 - val_accuracy: 0.9038 - lr: 0.0100\n",
      "Epoch 30/30\n",
      "256/256 [==============================] - 97s 380ms/step - loss: 0.1479 - accuracy: 0.9631 - val_loss: 0.2684 - val_accuracy: 0.9038 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-026-0.9423.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2272\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9455128312. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1880175322. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m666.94 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m601.54 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m65.41 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [5] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m6\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 30)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 31/36\n",
      "256/256 [==============================] - 103s 387ms/step - loss: 0.2926 - accuracy: 0.9055 - val_loss: 0.1994 - val_accuracy: 0.9391 - lr: 0.0100\n",
      "Epoch 32/36\n",
      "256/256 [==============================] - 100s 390ms/step - loss: 0.2459 - accuracy: 0.9229 - val_loss: 0.1988 - val_accuracy: 0.9311 - lr: 0.0100\n",
      "Epoch 33/36\n",
      "256/256 [==============================] - 103s 400ms/step - loss: 0.1866 - accuracy: 0.9426 - val_loss: 0.2473 - val_accuracy: 0.9311 - lr: 0.0100\n",
      "Epoch 34/36\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1694 - accuracy: 0.9526 - val_loss: 0.3695 - val_accuracy: 0.9295 - lr: 0.0100\n",
      "Epoch 35/36\n",
      "256/256 [==============================] - 100s 390ms/step - loss: 0.1620 - accuracy: 0.9573 - val_loss: 0.4695 - val_accuracy: 0.9263 - lr: 0.0100\n",
      "Epoch 36/36\n",
      "256/256 [==============================] - 97s 380ms/step - loss: 0.1678 - accuracy: 0.9514 - val_loss: 0.2931 - val_accuracy: 0.9167 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-031-0.9391.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9391\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1994\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9455128312. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1880175322. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m668.57 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m602.79 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m65.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [6] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m7\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 36)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 37/42\n",
      "256/256 [==============================] - 102s 382ms/step - loss: 0.2835 - accuracy: 0.9060 - val_loss: 0.1842 - val_accuracy: 0.9455 - lr: 0.0100\n",
      "Epoch 38/42\n",
      "256/256 [==============================] - 98s 383ms/step - loss: 0.2643 - accuracy: 0.9167 - val_loss: 0.3530 - val_accuracy: 0.9183 - lr: 0.0100\n",
      "Epoch 39/42\n",
      "256/256 [==============================] - 96s 375ms/step - loss: 0.1828 - accuracy: 0.9465 - val_loss: 0.2193 - val_accuracy: 0.9311 - lr: 0.0100\n",
      "Epoch 40/42\n",
      "256/256 [==============================] - 96s 376ms/step - loss: 0.1743 - accuracy: 0.9465 - val_loss: 0.2400 - val_accuracy: 0.9391 - lr: 0.0100\n",
      "Epoch 41/42\n",
      "256/256 [==============================] - 96s 375ms/step - loss: 0.1513 - accuracy: 0.9578 - val_loss: 0.3145 - val_accuracy: 0.8766 - lr: 0.0100\n",
      "Epoch 42/42\n",
      "256/256 [==============================] - 98s 381ms/step - loss: 0.1342 - accuracy: 0.9646 - val_loss: 0.2169 - val_accuracy: 0.9391 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-037-0.9455.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1842\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9455128312. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1880175322 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1841763705\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m655.37 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m587.17 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m68.21 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [7] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m8\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 42)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 43/48\n",
      "256/256 [==============================] - 100s 378ms/step - loss: 0.2630 - accuracy: 0.9138 - val_loss: 0.2486 - val_accuracy: 0.9119 - lr: 0.0100\n",
      "Epoch 44/48\n",
      "256/256 [==============================] - 102s 396ms/step - loss: 0.2565 - accuracy: 0.9182 - val_loss: 0.1904 - val_accuracy: 0.9535 - lr: 0.0100\n",
      "Epoch 45/48\n",
      "256/256 [==============================] - 101s 395ms/step - loss: 0.2104 - accuracy: 0.9380 - val_loss: 0.2425 - val_accuracy: 0.9487 - lr: 0.0100\n",
      "Epoch 46/48\n",
      "256/256 [==============================] - 104s 405ms/step - loss: 0.1861 - accuracy: 0.9478 - val_loss: 0.5963 - val_accuracy: 0.8205 - lr: 0.0100\n",
      "Epoch 47/48\n",
      "256/256 [==============================] - 100s 391ms/step - loss: 0.1398 - accuracy: 0.9595 - val_loss: 0.4671 - val_accuracy: 0.8878 - lr: 0.0100\n",
      "Epoch 48/48\n",
      "256/256 [==============================] - 98s 381ms/step - loss: 0.1285 - accuracy: 0.9661 - val_loss: 0.7364 - val_accuracy: 0.7885 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-044-0.9535.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1905\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.945513 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.953526\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1841763705. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m674.30 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m605.59 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m68.71 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [8] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m9\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 48)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 49/54\n",
      "256/256 [==============================] - 103s 387ms/step - loss: 0.2792 - accuracy: 0.9106 - val_loss: 0.1871 - val_accuracy: 0.9407 - lr: 0.0100\n",
      "Epoch 50/54\n",
      "256/256 [==============================] - 95s 369ms/step - loss: 0.2003 - accuracy: 0.9343 - val_loss: 0.1856 - val_accuracy: 0.9343 - lr: 0.0100\n",
      "Epoch 51/54\n",
      "256/256 [==============================] - 95s 370ms/step - loss: 0.1818 - accuracy: 0.9475 - val_loss: 0.4352 - val_accuracy: 0.8782 - lr: 0.0100\n",
      "Epoch 52/54\n",
      "256/256 [==============================] - 96s 374ms/step - loss: 0.1485 - accuracy: 0.9531 - val_loss: 0.1813 - val_accuracy: 0.9359 - lr: 0.0100\n",
      "Epoch 53/54\n",
      "256/256 [==============================] - 97s 376ms/step - loss: 0.1220 - accuracy: 0.9658 - val_loss: 0.4157 - val_accuracy: 0.9247 - lr: 0.0100\n",
      "Epoch 54/54\n",
      "256/256 [==============================] - 97s 378ms/step - loss: 0.1259 - accuracy: 0.9641 - val_loss: 0.3071 - val_accuracy: 0.9391 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-049-0.9407.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1871\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1841763705. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m650.75 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m582.73 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m68.02 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [9] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m10\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 54)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 55/60\n",
      "256/256 [==============================] - 104s 393ms/step - loss: 0.2572 - accuracy: 0.9187 - val_loss: 0.2462 - val_accuracy: 0.9054 - lr: 0.0100\n",
      "Epoch 56/60\n",
      "256/256 [==============================] - 101s 394ms/step - loss: 0.2368 - accuracy: 0.9265 - val_loss: 0.2266 - val_accuracy: 0.9423 - lr: 0.0100\n",
      "Epoch 57/60\n",
      "256/256 [==============================] - 101s 393ms/step - loss: 0.1814 - accuracy: 0.9446 - val_loss: 0.1603 - val_accuracy: 0.9487 - lr: 0.0100\n",
      "Epoch 58/60\n",
      "256/256 [==============================] - 104s 404ms/step - loss: 0.1633 - accuracy: 0.9519 - val_loss: 0.1789 - val_accuracy: 0.9423 - lr: 0.0100\n",
      "Epoch 59/60\n",
      "256/256 [==============================] - 101s 396ms/step - loss: 0.1376 - accuracy: 0.9609 - val_loss: 0.2384 - val_accuracy: 0.9391 - lr: 0.0100\n",
      "Epoch 60/60\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1100 - accuracy: 0.9712 - val_loss: 0.2274 - val_accuracy: 0.9471 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-057-0.9487.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1603\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1841763705 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1602820307\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m681.69 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m611.45 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m70.24 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [10] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m11\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 60)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 61/66\n",
      "256/256 [==============================] - 99s 370ms/step - loss: 0.2621 - accuracy: 0.9126 - val_loss: 0.1781 - val_accuracy: 0.9471 - lr: 0.0100\n",
      "Epoch 62/66\n",
      "256/256 [==============================] - 92s 359ms/step - loss: 0.1977 - accuracy: 0.9358 - val_loss: 0.2605 - val_accuracy: 0.9295 - lr: 0.0100\n",
      "Epoch 63/66\n",
      "256/256 [==============================] - 95s 372ms/step - loss: 0.1650 - accuracy: 0.9502 - val_loss: 0.2032 - val_accuracy: 0.9151 - lr: 0.0100\n",
      "Epoch 64/66\n",
      "256/256 [==============================] - 95s 370ms/step - loss: 0.1322 - accuracy: 0.9619 - val_loss: 0.3898 - val_accuracy: 0.8830 - lr: 0.0100\n",
      "Epoch 65/66\n",
      "256/256 [==============================] - 96s 373ms/step - loss: 0.1158 - accuracy: 0.9670 - val_loss: 0.2746 - val_accuracy: 0.9263 - lr: 0.0100\n",
      "Epoch 66/66\n",
      "256/256 [==============================] - 97s 379ms/step - loss: 0.1034 - accuracy: 0.9722 - val_loss: 0.3558 - val_accuracy: 0.9006 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-061-0.9471.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1781\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1602820307. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m644.29 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m574.95 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m69.34 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [11] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m12\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 66)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 67/72\n",
      "256/256 [==============================] - 100s 375ms/step - loss: 0.2306 - accuracy: 0.9272 - val_loss: 0.1928 - val_accuracy: 0.9439 - lr: 0.0100\n",
      "Epoch 68/72\n",
      "256/256 [==============================] - 101s 392ms/step - loss: 0.2051 - accuracy: 0.9373 - val_loss: 0.1938 - val_accuracy: 0.9455 - lr: 0.0100\n",
      "Epoch 69/72\n",
      "256/256 [==============================] - 100s 389ms/step - loss: 0.1722 - accuracy: 0.9453 - val_loss: 0.2313 - val_accuracy: 0.9167 - lr: 0.0100\n",
      "Epoch 70/72\n",
      "256/256 [==============================] - 97s 377ms/step - loss: 0.1301 - accuracy: 0.9634 - val_loss: 0.2942 - val_accuracy: 0.8958 - lr: 0.0100\n",
      "Epoch 71/72\n",
      "256/256 [==============================] - 95s 369ms/step - loss: 0.1197 - accuracy: 0.9680 - val_loss: 0.2169 - val_accuracy: 0.9263 - lr: 0.0100\n",
      "Epoch 72/72\n",
      "256/256 [==============================] - 98s 381ms/step - loss: 0.1049 - accuracy: 0.9773 - val_loss: 0.3938 - val_accuracy: 0.9151 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-068-0.9455.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1938\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1602820307. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m660.00 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m589.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m70.17 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [12] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m13\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 72)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 73/78\n",
      "256/256 [==============================] - 103s 388ms/step - loss: 0.2483 - accuracy: 0.9280 - val_loss: 0.1994 - val_accuracy: 0.9375 - lr: 0.0100\n",
      "Epoch 74/78\n",
      "256/256 [==============================] - 96s 376ms/step - loss: 0.1871 - accuracy: 0.9424 - val_loss: 0.1789 - val_accuracy: 0.9407 - lr: 0.0100\n",
      "Epoch 75/78\n",
      "256/256 [==============================] - 96s 376ms/step - loss: 0.1788 - accuracy: 0.9451 - val_loss: 0.1951 - val_accuracy: 0.9439 - lr: 0.0100\n",
      "Epoch 76/78\n",
      "256/256 [==============================] - 96s 375ms/step - loss: 0.1408 - accuracy: 0.9585 - val_loss: 0.2842 - val_accuracy: 0.9215 - lr: 0.0100\n",
      "Epoch 77/78\n",
      "256/256 [==============================] - 96s 373ms/step - loss: 0.1204 - accuracy: 0.9663 - val_loss: 0.2714 - val_accuracy: 0.9359 - lr: 0.0100\n",
      "Epoch 78/78\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1016 - accuracy: 0.9724 - val_loss: 0.2670 - val_accuracy: 0.9215 - lr: 0.0100\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-075-0.9439.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9439\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1951\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1602820307. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m660.31 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m587.92 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m72.38 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [13] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m14\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 78)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 79/84\n",
      "256/256 [==============================] - 104s 391ms/step - loss: 0.2218 - accuracy: 0.9324 - val_loss: 0.2859 - val_accuracy: 0.9135 - lr: 0.0100\n",
      "Epoch 80/84\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9497\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "256/256 [==============================] - 102s 397ms/step - loss: 0.1733 - accuracy: 0.9497 - val_loss: 0.3786 - val_accuracy: 0.9022 - lr: 0.0100\n",
      "Epoch 81/84\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1299 - accuracy: 0.9644 - val_loss: 0.1974 - val_accuracy: 0.9327 - lr: 1.0000e-03\n",
      "Epoch 82/84\n",
      "256/256 [==============================] - 104s 405ms/step - loss: 0.1255 - accuracy: 0.9651 - val_loss: 0.1761 - val_accuracy: 0.9295 - lr: 1.0000e-03\n",
      "Epoch 83/84\n",
      "256/256 [==============================] - 101s 393ms/step - loss: 0.1087 - accuracy: 0.9688 - val_loss: 0.1990 - val_accuracy: 0.9359 - lr: 1.0000e-03\n",
      "Epoch 84/84\n",
      "256/256 [==============================] - 96s 375ms/step - loss: 0.0943 - accuracy: 0.9746 - val_loss: 0.1967 - val_accuracy: 0.9343 - lr: 1.0000e-03\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-083-0.9359.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9359\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1989\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1602820307. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m678.68 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m606.47 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m72.21 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [14] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m15\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 84)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 85/90\n",
      "256/256 [==============================] - 103s 386ms/step - loss: 0.1920 - accuracy: 0.9392 - val_loss: 0.2229 - val_accuracy: 0.9279 - lr: 1.0000e-03\n",
      "Epoch 86/90\n",
      "256/256 [==============================] - 99s 388ms/step - loss: 0.1734 - accuracy: 0.9424 - val_loss: 0.2139 - val_accuracy: 0.9295 - lr: 1.0000e-03\n",
      "Epoch 87/90\n",
      "256/256 [==============================] - 102s 398ms/step - loss: 0.1657 - accuracy: 0.9475 - val_loss: 0.1940 - val_accuracy: 0.9327 - lr: 1.0000e-03\n",
      "Epoch 88/90\n",
      "256/256 [==============================] - 100s 391ms/step - loss: 0.1607 - accuracy: 0.9480 - val_loss: 0.1888 - val_accuracy: 0.9343 - lr: 1.0000e-03\n",
      "Epoch 89/90\n",
      "256/256 [==============================] - 102s 396ms/step - loss: 0.1523 - accuracy: 0.9517 - val_loss: 0.1611 - val_accuracy: 0.9423 - lr: 1.0000e-03\n",
      "Epoch 90/90\n",
      "256/256 [==============================] - 102s 396ms/step - loss: 0.1407 - accuracy: 0.9536 - val_loss: 0.1995 - val_accuracy: 0.9327 - lr: 1.0000e-03\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-089-0.9423.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1611\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1602820307. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m681.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m608.38 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m73.45 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [15] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m16\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 90)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 91/96\n",
      "256/256 [==============================] - 102s 385ms/step - loss: 0.1897 - accuracy: 0.9363 - val_loss: 0.1646 - val_accuracy: 0.9391 - lr: 1.0000e-03\n",
      "Epoch 92/96\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1915 - accuracy: 0.9380 - val_loss: 0.1689 - val_accuracy: 0.9407 - lr: 1.0000e-03\n",
      "Epoch 93/96\n",
      "256/256 [==============================] - 102s 399ms/step - loss: 0.1633 - accuracy: 0.9478 - val_loss: 0.1787 - val_accuracy: 0.9391 - lr: 1.0000e-03\n",
      "Epoch 94/96\n",
      "256/256 [==============================] - 100s 389ms/step - loss: 0.1642 - accuracy: 0.9429 - val_loss: 0.1624 - val_accuracy: 0.9375 - lr: 1.0000e-03\n",
      "Epoch 95/96\n",
      "256/256 [==============================] - 98s 384ms/step - loss: 0.1556 - accuracy: 0.9495 - val_loss: 0.1524 - val_accuracy: 0.9343 - lr: 1.0000e-03\n",
      "Epoch 96/96\n",
      "256/256 [==============================] - 99s 385ms/step - loss: 0.1447 - accuracy: 0.9514 - val_loss: 0.1603 - val_accuracy: 0.9423 - lr: 1.0000e-03\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-096-0.9423.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1603\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1602820307. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m676.36 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m601.68 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m74.68 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [16] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m17\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 96)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 97/102\n",
      "256/256 [==============================] - 103s 386ms/step - loss: 0.1811 - accuracy: 0.9387 - val_loss: 0.1600 - val_accuracy: 0.9375 - lr: 1.0000e-03\n",
      "Epoch 98/102\n",
      "256/256 [==============================] - 100s 389ms/step - loss: 0.1574 - accuracy: 0.9446 - val_loss: 0.1712 - val_accuracy: 0.9407 - lr: 1.0000e-03\n",
      "Epoch 99/102\n",
      "256/256 [==============================] - 98s 382ms/step - loss: 0.1530 - accuracy: 0.9478 - val_loss: 0.1583 - val_accuracy: 0.9391 - lr: 1.0000e-03\n",
      "Epoch 100/102\n",
      "256/256 [==============================] - 96s 374ms/step - loss: 0.1421 - accuracy: 0.9526 - val_loss: 0.1583 - val_accuracy: 0.9407 - lr: 1.0000e-03\n",
      "Epoch 101/102\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1336 - accuracy: 0.9551 - val_loss: 0.1562 - val_accuracy: 0.9343 - lr: 1.0000e-03\n",
      "Epoch 102/102\n",
      "256/256 [==============================] - 101s 394ms/step - loss: 0.1281 - accuracy: 0.9570 - val_loss: 0.1973 - val_accuracy: 0.9359 - lr: 1.0000e-03\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-098-0.9407.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1712\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1602820307. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m673.60 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m597.26 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m76.35 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [17] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m18\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 102)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 103/108\n",
      "256/256 [==============================] - 103s 385ms/step - loss: 0.1703 - accuracy: 0.9429 - val_loss: 0.1672 - val_accuracy: 0.9375 - lr: 1.0000e-03\n",
      "Epoch 104/108\n",
      "256/256 [==============================] - 100s 392ms/step - loss: 0.1590 - accuracy: 0.9438 - val_loss: 0.1633 - val_accuracy: 0.9391 - lr: 1.0000e-03\n",
      "Epoch 105/108\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1485 - accuracy: 0.9534 - val_loss: 0.1552 - val_accuracy: 0.9391 - lr: 1.0000e-03\n",
      "Epoch 106/108\n",
      "256/256 [==============================] - 103s 401ms/step - loss: 0.1381 - accuracy: 0.9536 - val_loss: 0.1532 - val_accuracy: 0.9407 - lr: 1.0000e-03\n",
      "Epoch 107/108\n",
      "256/256 [==============================] - 104s 406ms/step - loss: 0.1363 - accuracy: 0.9504 - val_loss: 0.1533 - val_accuracy: 0.9455 - lr: 1.0000e-03\n",
      "Epoch 108/108\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1267 - accuracy: 0.9592 - val_loss: 0.1566 - val_accuracy: 0.9455 - lr: 1.0000e-03\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-107-0.9455.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1533\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1602820307 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1533284783\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m689.11 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m609.37 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m79.74 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [18] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m19\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 108)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 109/114\n",
      "256/256 [==============================] - 104s 389ms/step - loss: 0.1702 - accuracy: 0.9419 - val_loss: 0.1620 - val_accuracy: 0.9359 - lr: 1.0000e-03\n",
      "Epoch 110/114\n",
      "256/256 [==============================] - 97s 379ms/step - loss: 0.1555 - accuracy: 0.9426 - val_loss: 0.1721 - val_accuracy: 0.9439 - lr: 1.0000e-03\n",
      "Epoch 111/114\n",
      "256/256 [==============================] - 97s 379ms/step - loss: 0.1405 - accuracy: 0.9485 - val_loss: 0.1658 - val_accuracy: 0.9391 - lr: 1.0000e-03\n",
      "Epoch 112/114\n",
      "256/256 [==============================] - 99s 385ms/step - loss: 0.1367 - accuracy: 0.9502 - val_loss: 0.1994 - val_accuracy: 0.9343 - lr: 1.0000e-03\n",
      "Epoch 113/114\n",
      "256/256 [==============================] - 102s 397ms/step - loss: 0.1382 - accuracy: 0.9524 - val_loss: 0.1762 - val_accuracy: 0.9455 - lr: 1.0000e-03\n",
      "Epoch 114/114\n",
      "256/256 [==============================] - 100s 391ms/step - loss: 0.1252 - accuracy: 0.9556 - val_loss: 0.1941 - val_accuracy: 0.9359 - lr: 1.0000e-03\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-113-0.9455.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1762\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1533284783. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m678.43 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m599.93 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m78.50 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [19] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m20\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 114)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 115/120\n",
      "256/256 [==============================] - 106s 398ms/step - loss: 0.1458 - accuracy: 0.9504 - val_loss: 0.2119 - val_accuracy: 0.9311 - lr: 1.0000e-03\n",
      "Epoch 116/120\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9543\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.0005.\n",
      "256/256 [==============================] - 104s 408ms/step - loss: 0.1433 - accuracy: 0.9543 - val_loss: 0.1867 - val_accuracy: 0.9343 - lr: 1.0000e-03\n",
      "Epoch 117/120\n",
      "256/256 [==============================] - 102s 398ms/step - loss: 0.1368 - accuracy: 0.9539 - val_loss: 0.1581 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 118/120\n",
      "256/256 [==============================] - 98s 381ms/step - loss: 0.1289 - accuracy: 0.9578 - val_loss: 0.1651 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 119/120\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1296 - accuracy: 0.9597 - val_loss: 0.1606 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 120/120\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1272 - accuracy: 0.9583 - val_loss: 0.1724 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-117-0.9423.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1581\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1533284783. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m689.55 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m609.08 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m80.47 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [20] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m21\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 120)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 121/126\n",
      "256/256 [==============================] - 103s 389ms/step - loss: 0.1666 - accuracy: 0.9434 - val_loss: 0.1792 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 122/126\n",
      "256/256 [==============================] - 101s 394ms/step - loss: 0.1495 - accuracy: 0.9470 - val_loss: 0.1726 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 123/126\n",
      "256/256 [==============================] - 99s 388ms/step - loss: 0.1453 - accuracy: 0.9473 - val_loss: 0.1613 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 124/126\n",
      "256/256 [==============================] - 102s 398ms/step - loss: 0.1471 - accuracy: 0.9453 - val_loss: 0.1650 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 125/126\n",
      "256/256 [==============================] - 104s 404ms/step - loss: 0.1492 - accuracy: 0.9458 - val_loss: 0.1673 - val_accuracy: 0.9327 - lr: 5.0000e-04\n",
      "Epoch 126/126\n",
      "256/256 [==============================] - 103s 401ms/step - loss: 0.1380 - accuracy: 0.9497 - val_loss: 0.2337 - val_accuracy: 0.9183 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-123-0.9423.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1613\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1533284783. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m695.36 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m613.07 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m82.29 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [21] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m22\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 126)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 127/132\n",
      "256/256 [==============================] - 101s 378ms/step - loss: 0.1683 - accuracy: 0.9446 - val_loss: 0.1585 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 128/132\n",
      "256/256 [==============================] - 98s 383ms/step - loss: 0.1610 - accuracy: 0.9429 - val_loss: 0.1632 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 129/132\n",
      "256/256 [==============================] - 100s 391ms/step - loss: 0.1563 - accuracy: 0.9463 - val_loss: 0.1552 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 130/132\n",
      "256/256 [==============================] - 103s 400ms/step - loss: 0.1579 - accuracy: 0.9478 - val_loss: 0.1670 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 131/132\n",
      "256/256 [==============================] - 105s 411ms/step - loss: 0.1410 - accuracy: 0.9521 - val_loss: 0.1569 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 132/132\n",
      "256/256 [==============================] - 104s 408ms/step - loss: 0.1415 - accuracy: 0.9502 - val_loss: 0.1735 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-131-0.9423.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1569\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1533284783. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m695.82 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m612.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m82.94 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [22] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m23\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 132)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 133/138\n",
      "256/256 [==============================] - 104s 390ms/step - loss: 0.1598 - accuracy: 0.9424 - val_loss: 0.1569 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 134/138\n",
      "256/256 [==============================] - 104s 404ms/step - loss: 0.1534 - accuracy: 0.9451 - val_loss: 0.1549 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 135/138\n",
      "256/256 [==============================] - 103s 402ms/step - loss: 0.1435 - accuracy: 0.9495 - val_loss: 0.1686 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 136/138\n",
      "256/256 [==============================] - 102s 396ms/step - loss: 0.1486 - accuracy: 0.9485 - val_loss: 0.1449 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 137/138\n",
      "256/256 [==============================] - 103s 402ms/step - loss: 0.1341 - accuracy: 0.9526 - val_loss: 0.1562 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 138/138\n",
      "256/256 [==============================] - 102s 397ms/step - loss: 0.1393 - accuracy: 0.9529 - val_loss: 0.1488 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-134-0.9471.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1549\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1533284783. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m701.34 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m617.30 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m84.04 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [23] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m24\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 138)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 139/144\n",
      "256/256 [==============================] - 105s 395ms/step - loss: 0.1624 - accuracy: 0.9465 - val_loss: 0.1550 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 140/144\n",
      "256/256 [==============================] - 104s 406ms/step - loss: 0.1580 - accuracy: 0.9487 - val_loss: 0.1615 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 141/144\n",
      "256/256 [==============================] - 102s 399ms/step - loss: 0.1575 - accuracy: 0.9465 - val_loss: 0.1796 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 142/144\n",
      "256/256 [==============================] - 98s 383ms/step - loss: 0.1485 - accuracy: 0.9480 - val_loss: 0.1562 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 143/144\n",
      "256/256 [==============================] - 99s 388ms/step - loss: 0.1411 - accuracy: 0.9534 - val_loss: 0.1533 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 144/144\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1408 - accuracy: 0.9500 - val_loss: 0.1589 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-139-0.9423.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1550\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1533284783. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m693.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m608.99 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m84.88 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [24] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m25\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 144)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 145/150\n",
      "256/256 [==============================] - 104s 390ms/step - loss: 0.1449 - accuracy: 0.9512 - val_loss: 0.1658 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 146/150\n",
      "256/256 [==============================] - 100s 390ms/step - loss: 0.1411 - accuracy: 0.9536 - val_loss: 0.1552 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 147/150\n",
      "256/256 [==============================] - 103s 403ms/step - loss: 0.1394 - accuracy: 0.9507 - val_loss: 0.1540 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 148/150\n",
      "256/256 [==============================] - 101s 394ms/step - loss: 0.1290 - accuracy: 0.9587 - val_loss: 0.1678 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 149/150\n",
      "256/256 [==============================] - 99s 386ms/step - loss: 0.1241 - accuracy: 0.9587 - val_loss: 0.1934 - val_accuracy: 0.9247 - lr: 5.0000e-04\n",
      "Epoch 150/150\n",
      "256/256 [==============================] - 100s 389ms/step - loss: 0.1242 - accuracy: 0.9573 - val_loss: 0.1980 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-147-0.9407.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1540\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1533284783. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m694.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m608.14 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m86.69 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [25] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m26\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 150)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 151/156\n",
      "256/256 [==============================] - 106s 399ms/step - loss: 0.1489 - accuracy: 0.9514 - val_loss: 0.1560 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 152/156\n",
      "256/256 [==============================] - 98s 383ms/step - loss: 0.1425 - accuracy: 0.9514 - val_loss: 0.1465 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 153/156\n",
      "256/256 [==============================] - 98s 381ms/step - loss: 0.1340 - accuracy: 0.9541 - val_loss: 0.1592 - val_accuracy: 0.9279 - lr: 5.0000e-04\n",
      "Epoch 154/156\n",
      "256/256 [==============================] - 100s 390ms/step - loss: 0.1363 - accuracy: 0.9539 - val_loss: 0.1418 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 155/156\n",
      "256/256 [==============================] - 100s 390ms/step - loss: 0.1274 - accuracy: 0.9585 - val_loss: 0.1495 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 156/156\n",
      "256/256 [==============================] - 103s 403ms/step - loss: 0.1216 - accuracy: 0.9575 - val_loss: 0.1476 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-154-0.9487.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1418\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1533284783 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1417625248\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m696.48 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m606.10 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m90.38 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [26] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m27\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 156)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 157/162\n",
      "256/256 [==============================] - 105s 393ms/step - loss: 0.1537 - accuracy: 0.9434 - val_loss: 0.1535 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 158/162\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1417 - accuracy: 0.9490 - val_loss: 0.1670 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 159/162\n",
      "256/256 [==============================] - 99s 386ms/step - loss: 0.1487 - accuracy: 0.9487 - val_loss: 0.1720 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 160/162\n",
      "256/256 [==============================] - 96s 376ms/step - loss: 0.1453 - accuracy: 0.9502 - val_loss: 0.1698 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 161/162\n",
      "256/256 [==============================] - 99s 386ms/step - loss: 0.1390 - accuracy: 0.9487 - val_loss: 0.1609 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 162/162\n",
      "256/256 [==============================] - 100s 392ms/step - loss: 0.1403 - accuracy: 0.9512 - val_loss: 0.1635 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9439}, \u001b[0m\u001b[0;33mloss{0.1535}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1418}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9439\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1635\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1417625248. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m687.90 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m599.53 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m88.37 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [27] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m28\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 162)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 163/168\n",
      "256/256 [==============================] - 110s 414ms/step - loss: 0.1375 - accuracy: 0.9521 - val_loss: 0.1853 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 164/168\n",
      "256/256 [==============================] - 101s 393ms/step - loss: 0.1355 - accuracy: 0.9541 - val_loss: 0.1581 - val_accuracy: 0.9327 - lr: 5.0000e-04\n",
      "Epoch 165/168\n",
      "256/256 [==============================] - 98s 383ms/step - loss: 0.1434 - accuracy: 0.9509 - val_loss: 0.1691 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 166/168\n",
      "256/256 [==============================] - 100s 388ms/step - loss: 0.1336 - accuracy: 0.9531 - val_loss: 0.1393 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 167/168\n",
      "256/256 [==============================] - 99s 384ms/step - loss: 0.1288 - accuracy: 0.9592 - val_loss: 0.1829 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 168/168\n",
      "256/256 [==============================] - 99s 386ms/step - loss: 0.1193 - accuracy: 0.9614 - val_loss: 0.1474 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-166-0.9471.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1393\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1417625248 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1392505765\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m698.88 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m606.88 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m92.00 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [28] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m29\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 168)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 169/174\n",
      "256/256 [==============================] - 105s 395ms/step - loss: 0.1624 - accuracy: 0.9460 - val_loss: 0.1457 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 170/174\n",
      "256/256 [==============================] - 104s 407ms/step - loss: 0.1434 - accuracy: 0.9502 - val_loss: 0.1541 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 171/174\n",
      "256/256 [==============================] - 104s 406ms/step - loss: 0.1391 - accuracy: 0.9509 - val_loss: 0.1444 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 172/174\n",
      "256/256 [==============================] - 101s 395ms/step - loss: 0.1378 - accuracy: 0.9553 - val_loss: 0.1459 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 173/174\n",
      "256/256 [==============================] - 99s 387ms/step - loss: 0.1298 - accuracy: 0.9592 - val_loss: 0.1439 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 174/174\n",
      "256/256 [==============================] - 101s 393ms/step - loss: 0.1236 - accuracy: 0.9565 - val_loss: 0.1387 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-174-0.9503.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1387\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1392505765 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1387259513\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m712.11 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m615.64 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m96.47 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [29] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m30\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 174)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 175/180\n",
      "256/256 [==============================] - 105s 395ms/step - loss: 0.1629 - accuracy: 0.9441 - val_loss: 0.1477 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 176/180\n",
      "256/256 [==============================] - 103s 401ms/step - loss: 0.1530 - accuracy: 0.9490 - val_loss: 0.1343 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 177/180\n",
      "256/256 [==============================] - 102s 399ms/step - loss: 0.1427 - accuracy: 0.9470 - val_loss: 0.1468 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 178/180\n",
      "256/256 [==============================] - 98s 382ms/step - loss: 0.1420 - accuracy: 0.9495 - val_loss: 0.1458 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 179/180\n",
      "256/256 [==============================] - 101s 393ms/step - loss: 0.1395 - accuracy: 0.9492 - val_loss: 0.1535 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 180/180\n",
      "256/256 [==============================] - 101s 395ms/step - loss: 0.1394 - accuracy: 0.9526 - val_loss: 0.1343 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-176-0.9503.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1343\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1387259513 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1342520118\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m706.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m610.91 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m95.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [30] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m31\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 180)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 181/186\n",
      "256/256 [==============================] - 108s 405ms/step - loss: 0.1364 - accuracy: 0.9502 - val_loss: 0.1472 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 182/186\n",
      "256/256 [==============================] - 104s 404ms/step - loss: 0.1460 - accuracy: 0.9470 - val_loss: 0.1377 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 183/186\n",
      "256/256 [==============================] - 101s 393ms/step - loss: 0.1337 - accuracy: 0.9543 - val_loss: 0.1531 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 184/186\n",
      "256/256 [==============================] - 101s 392ms/step - loss: 0.1377 - accuracy: 0.9521 - val_loss: 0.1440 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 185/186\n",
      "256/256 [==============================] - 103s 404ms/step - loss: 0.1223 - accuracy: 0.9565 - val_loss: 0.1675 - val_accuracy: 0.9327 - lr: 5.0000e-04\n",
      "Epoch 186/186\n",
      "256/256 [==============================] - 102s 397ms/step - loss: 0.1184 - accuracy: 0.9575 - val_loss: 0.1721 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9487}, \u001b[0m\u001b[0;33mloss{0.1377}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9343\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1721\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m713.58 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m619.13 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m94.46 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [31] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m32\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 186)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33m‚îî‚îÄ‚îÄ‚îÄShuffling data...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 187/192\n",
      "256/256 [==============================] - 108s 407ms/step - loss: 0.1455 - accuracy: 0.9536 - val_loss: 0.1698 - val_accuracy: 0.9279 - lr: 5.0000e-04\n",
      "Epoch 188/192\n",
      "256/256 [==============================] - 104s 407ms/step - loss: 0.1406 - accuracy: 0.9556 - val_loss: 0.1428 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 189/192\n",
      "256/256 [==============================] - 99s 385ms/step - loss: 0.1346 - accuracy: 0.9558 - val_loss: 0.1725 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 190/192\n",
      "256/256 [==============================] - 102s 398ms/step - loss: 0.1349 - accuracy: 0.9529 - val_loss: 0.1828 - val_accuracy: 0.9327 - lr: 5.0000e-04\n",
      "Epoch 191/192\n",
      "256/256 [==============================] - 104s 407ms/step - loss: 0.1196 - accuracy: 0.9587 - val_loss: 0.1557 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 192/192\n",
      "256/256 [==============================] - 106s 413ms/step - loss: 0.1197 - accuracy: 0.9602 - val_loss: 0.1838 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9407}, \u001b[0m\u001b[0;33mloss{0.1428}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9311\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1838\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m723.55 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m624.47 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m99.08 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [32] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m33\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 192)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 193/198\n",
      "256/256 [==============================] - 110s 414ms/step - loss: 0.1485 - accuracy: 0.9512 - val_loss: 0.1506 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 194/198\n",
      "256/256 [==============================] - 109s 426ms/step - loss: 0.1418 - accuracy: 0.9490 - val_loss: 0.1592 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 195/198\n",
      "256/256 [==============================] - 107s 418ms/step - loss: 0.1363 - accuracy: 0.9534 - val_loss: 0.1592 - val_accuracy: 0.9327 - lr: 5.0000e-04\n",
      "Epoch 196/198\n",
      "256/256 [==============================] - 104s 406ms/step - loss: 0.1322 - accuracy: 0.9529 - val_loss: 0.1766 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 197/198\n",
      "256/256 [==============================] - 105s 408ms/step - loss: 0.1340 - accuracy: 0.9524 - val_loss: 0.1583 - val_accuracy: 0.9263 - lr: 5.0000e-04\n",
      "Epoch 198/198\n",
      "256/256 [==============================] - 105s 411ms/step - loss: 0.1263 - accuracy: 0.9534 - val_loss: 0.1569 - val_accuracy: 0.9279 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9359}, \u001b[0m\u001b[0;33mloss{0.1506}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9279\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1568\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m735.54 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m641.28 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m94.26 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [33] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m34\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 198)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 199/204\n",
      "256/256 [==============================] - 106s 397ms/step - loss: 0.1480 - accuracy: 0.9507 - val_loss: 0.1465 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 200/204\n",
      "256/256 [==============================] - 107s 418ms/step - loss: 0.1378 - accuracy: 0.9512 - val_loss: 0.1510 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 201/204\n",
      "256/256 [==============================] - 101s 394ms/step - loss: 0.1357 - accuracy: 0.9531 - val_loss: 0.1666 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 202/204\n",
      "256/256 [==============================] - 105s 408ms/step - loss: 0.1309 - accuracy: 0.9539 - val_loss: 0.1391 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 203/204\n",
      "256/256 [==============================] - 105s 410ms/step - loss: 0.1302 - accuracy: 0.9536 - val_loss: 0.1705 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 204/204\n",
      "256/256 [==============================] - 100s 389ms/step - loss: 0.1323 - accuracy: 0.9521 - val_loss: 0.2351 - val_accuracy: 0.9199 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9439}, \u001b[0m\u001b[0;33mloss{0.1391}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9199\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.2351\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m720.01 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m624.21 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m95.79 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [34] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m35\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 204)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 205/210\n",
      "256/256 [==============================] - 108s 407ms/step - loss: 0.1462 - accuracy: 0.9485 - val_loss: 0.1811 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 206/210\n",
      "256/256 [==============================] - 107s 416ms/step - loss: 0.1417 - accuracy: 0.9495 - val_loss: 0.1674 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 207/210\n",
      "256/256 [==============================] - 107s 418ms/step - loss: 0.1324 - accuracy: 0.9519 - val_loss: 0.1653 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 208/210\n",
      "256/256 [==============================] - 106s 414ms/step - loss: 0.1300 - accuracy: 0.9546 - val_loss: 0.1487 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 209/210\n",
      "256/256 [==============================] - 106s 413ms/step - loss: 0.1257 - accuracy: 0.9558 - val_loss: 0.1639 - val_accuracy: 0.9327 - lr: 5.0000e-04\n",
      "Epoch 210/210\n",
      "256/256 [==============================] - 108s 420ms/step - loss: 0.1194 - accuracy: 0.9590 - val_loss: 0.1526 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9471}, \u001b[0m\u001b[0;33mloss{0.1487}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9343\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1526\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m740.52 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m642.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m97.68 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [35] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m36\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 210)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 211/216\n",
      "256/256 [==============================] - 108s 407ms/step - loss: 0.1443 - accuracy: 0.9514 - val_loss: 0.1569 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 212/216\n",
      "256/256 [==============================] - 106s 412ms/step - loss: 0.1270 - accuracy: 0.9575 - val_loss: 0.1515 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 213/216\n",
      "256/256 [==============================] - 102s 397ms/step - loss: 0.1296 - accuracy: 0.9573 - val_loss: 0.1453 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 214/216\n",
      "256/256 [==============================] - 106s 415ms/step - loss: 0.1274 - accuracy: 0.9551 - val_loss: 0.1404 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 215/216\n",
      "256/256 [==============================] - 105s 408ms/step - loss: 0.1214 - accuracy: 0.9590 - val_loss: 0.1439 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 216/216\n",
      "256/256 [==============================] - 105s 410ms/step - loss: 0.1199 - accuracy: 0.9602 - val_loss: 0.1422 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9487}, \u001b[0m\u001b[0;33mloss{0.1404}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1422\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m728.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m632.19 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m96.63 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [36] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m37\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 216)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 217/222\n",
      "256/256 [==============================] - 108s 408ms/step - loss: 0.1481 - accuracy: 0.9497 - val_loss: 0.1465 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 218/222\n",
      "256/256 [==============================] - 103s 402ms/step - loss: 0.1529 - accuracy: 0.9507 - val_loss: 0.1492 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 219/222\n",
      "256/256 [==============================] - 98s 383ms/step - loss: 0.1456 - accuracy: 0.9502 - val_loss: 0.1492 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 220/222\n",
      "256/256 [==============================] - 104s 408ms/step - loss: 0.1409 - accuracy: 0.9543 - val_loss: 0.1495 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 221/222\n",
      "256/256 [==============================] - 102s 397ms/step - loss: 0.1360 - accuracy: 0.9507 - val_loss: 0.1987 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 222/222\n",
      "256/256 [==============================] - 102s 396ms/step - loss: 0.1312 - accuracy: 0.9561 - val_loss: 0.1724 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9439}, \u001b[0m\u001b[0;33mloss{0.1465}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9295\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1724\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m721.40 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m618.29 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m103.11 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [37] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m38\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 222)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 223/228\n",
      "256/256 [==============================] - 108s 405ms/step - loss: 0.1378 - accuracy: 0.9556 - val_loss: 0.2100 - val_accuracy: 0.9263 - lr: 5.0000e-04\n",
      "Epoch 224/228\n",
      "256/256 [==============================] - 105s 408ms/step - loss: 0.1333 - accuracy: 0.9536 - val_loss: 0.1480 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 225/228\n",
      "256/256 [==============================] - 108s 424ms/step - loss: 0.1297 - accuracy: 0.9568 - val_loss: 0.1816 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 226/228\n",
      "256/256 [==============================] - 110s 430ms/step - loss: 0.1226 - accuracy: 0.9602 - val_loss: 0.1571 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 227/228\n",
      "256/256 [==============================] - 108s 424ms/step - loss: 0.1118 - accuracy: 0.9626 - val_loss: 0.1858 - val_accuracy: 0.9263 - lr: 5.0000e-04\n",
      "Epoch 228/228\n",
      "256/256 [==============================] - 103s 401ms/step - loss: 0.1185 - accuracy: 0.9600 - val_loss: 0.1480 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9407}, \u001b[0m\u001b[0;33mloss{0.1480}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9375\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1480\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m745.20 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m643.31 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m101.89 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [38] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m39\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 228)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 229/234\n",
      "256/256 [==============================] - 106s 400ms/step - loss: 0.1538 - accuracy: 0.9438 - val_loss: 0.1473 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 230/234\n",
      "256/256 [==============================] - 108s 421ms/step - loss: 0.1451 - accuracy: 0.9473 - val_loss: 0.1454 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 231/234\n",
      "256/256 [==============================] - 102s 399ms/step - loss: 0.1450 - accuracy: 0.9480 - val_loss: 0.1446 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 232/234\n",
      "256/256 [==============================] - 107s 419ms/step - loss: 0.1358 - accuracy: 0.9478 - val_loss: 0.1593 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 233/234\n",
      "256/256 [==============================] - 105s 411ms/step - loss: 0.1324 - accuracy: 0.9517 - val_loss: 0.1355 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 234/234\n",
      "256/256 [==============================] - 107s 418ms/step - loss: 0.1236 - accuracy: 0.9548 - val_loss: 0.1445 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9471}, \u001b[0m\u001b[0;33mloss{0.1355}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1445\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m742.91 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m637.60 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m105.31 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [39] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m40\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 234)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 235/240\n",
      "256/256 [==============================] - 107s 404ms/step - loss: 0.1300 - accuracy: 0.9551 - val_loss: 0.1472 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 236/240\n",
      "256/256 [==============================] - 108s 421ms/step - loss: 0.1294 - accuracy: 0.9531 - val_loss: 0.1501 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 237/240\n",
      "256/256 [==============================] - 104s 405ms/step - loss: 0.1220 - accuracy: 0.9573 - val_loss: 0.1497 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 238/240\n",
      "256/256 [==============================] - 106s 415ms/step - loss: 0.1184 - accuracy: 0.9592 - val_loss: 0.1666 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 239/240\n",
      "256/256 [==============================] - 105s 410ms/step - loss: 0.1126 - accuracy: 0.9585 - val_loss: 0.1516 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 240/240\n",
      "256/256 [==============================] - 105s 411ms/step - loss: 0.1112 - accuracy: 0.9624 - val_loss: 0.1953 - val_accuracy: 0.9279 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9423}, \u001b[0m\u001b[0;33mloss{0.1472}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9279\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1953\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m740.18 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m636.92 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m103.26 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [40] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m41\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 240)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 241/246\n",
      "256/256 [==============================] - 110s 413ms/step - loss: 0.1443 - accuracy: 0.9475 - val_loss: 0.1543 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 242/246\n",
      "256/256 [==============================] - 109s 426ms/step - loss: 0.1426 - accuracy: 0.9487 - val_loss: 0.1537 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 243/246\n",
      "256/256 [==============================] - 104s 408ms/step - loss: 0.1285 - accuracy: 0.9563 - val_loss: 0.1443 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 244/246\n",
      "256/256 [==============================] - 103s 404ms/step - loss: 0.1259 - accuracy: 0.9578 - val_loss: 0.1438 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 245/246\n",
      "256/256 [==============================] - 108s 421ms/step - loss: 0.1298 - accuracy: 0.9546 - val_loss: 0.1366 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 246/246\n",
      "256/256 [==============================] - 101s 396ms/step - loss: 0.1247 - accuracy: 0.9565 - val_loss: 0.1419 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9471}, \u001b[0m\u001b[0;33mloss{0.1366}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1420\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m742.37 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m637.08 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m105.29 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [41] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m42\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 246)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;31m- Debug DP Sample dir: \u001b[0m\u001b[0;32mSamples/TSR_SUB_400_y2024_m02_d18-h07_m17_s23\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 247/252\n",
      "256/256 [==============================] - 107s 402ms/step - loss: 0.1335 - accuracy: 0.9565 - val_loss: 0.1475 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 248/252\n",
      "256/256 [==============================] - 111s 432ms/step - loss: 0.1345 - accuracy: 0.9551 - val_loss: 0.1511 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 249/252\n",
      "256/256 [==============================] - 103s 402ms/step - loss: 0.1323 - accuracy: 0.9536 - val_loss: 0.1446 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 250/252\n",
      "256/256 [==============================] - 110s 431ms/step - loss: 0.1230 - accuracy: 0.9587 - val_loss: 0.1382 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 251/252\n",
      "256/256 [==============================] - 106s 415ms/step - loss: 0.1170 - accuracy: 0.9595 - val_loss: 0.1548 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 252/252\n",
      "256/256 [==============================] - 108s 420ms/step - loss: 0.1169 - accuracy: 0.9600 - val_loss: 0.1475 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9455}, \u001b[0m\u001b[0;33mloss{0.1382}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1475\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m764.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m647.53 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m117.25 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [42] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m43\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 252)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 253/258\n",
      "256/256 [==============================] - 110s 413ms/step - loss: 0.1424 - accuracy: 0.9475 - val_loss: 0.1573 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 254/258\n",
      "256/256 [==============================] - 106s 414ms/step - loss: 0.1364 - accuracy: 0.9524 - val_loss: 0.1766 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 255/258\n",
      "256/256 [==============================] - 102s 399ms/step - loss: 0.1263 - accuracy: 0.9565 - val_loss: 0.1455 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 256/258\n",
      "256/256 [==============================] - 101s 395ms/step - loss: 0.1297 - accuracy: 0.9587 - val_loss: 0.1510 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 257/258\n",
      "256/256 [==============================] - 104s 406ms/step - loss: 0.1193 - accuracy: 0.9592 - val_loss: 0.2027 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 258/258\n",
      "256/256 [==============================] - 114s 444ms/step - loss: 0.1128 - accuracy: 0.9631 - val_loss: 0.1584 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1455}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1584\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m745.41 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m638.32 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m107.09 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [43] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m44\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 258)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 259/264\n",
      "256/256 [==============================] - 107s 403ms/step - loss: 0.1322 - accuracy: 0.9524 - val_loss: 0.1425 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 260/264\n",
      "256/256 [==============================] - 110s 427ms/step - loss: 0.1253 - accuracy: 0.9565 - val_loss: 0.1471 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 261/264\n",
      "256/256 [==============================] - 108s 421ms/step - loss: 0.1169 - accuracy: 0.9607 - val_loss: 0.1512 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 262/264\n",
      "256/256 [==============================] - 109s 427ms/step - loss: 0.1253 - accuracy: 0.9558 - val_loss: 0.1425 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 263/264\n",
      "256/256 [==============================] - 112s 439ms/step - loss: 0.1096 - accuracy: 0.9622 - val_loss: 0.1387 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 264/264\n",
      "256/256 [==============================] - 109s 427ms/step - loss: 0.1138 - accuracy: 0.9604 - val_loss: 0.1380 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9503}, \u001b[0m\u001b[0;33mloss{0.1380}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1380\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m765.83 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m656.73 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m109.10 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [44] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m45\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 264)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 265/270\n",
      "256/256 [==============================] - 107s 403ms/step - loss: 0.1521 - accuracy: 0.9473 - val_loss: 0.1394 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 266/270\n",
      "256/256 [==============================] - 107s 418ms/step - loss: 0.1423 - accuracy: 0.9502 - val_loss: 0.1367 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 267/270\n",
      "256/256 [==============================] - 108s 422ms/step - loss: 0.1398 - accuracy: 0.9509 - val_loss: 0.1437 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 268/270\n",
      "256/256 [==============================] - 102s 399ms/step - loss: 0.1370 - accuracy: 0.9534 - val_loss: 0.1367 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 269/270\n",
      "256/256 [==============================] - 105s 409ms/step - loss: 0.1284 - accuracy: 0.9570 - val_loss: 0.1365 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 270/270\n",
      "256/256 [==============================] - 110s 430ms/step - loss: 0.1233 - accuracy: 0.9551 - val_loss: 0.1439 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9503}, \u001b[0m\u001b[0;33mloss{0.1365}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1439\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m749.86 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m640.75 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m109.10 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [45] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m46\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 270)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 271/276\n",
      "256/256 [==============================] - 108s 406ms/step - loss: 0.1429 - accuracy: 0.9507 - val_loss: 0.1436 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 272/276\n",
      "256/256 [==============================] - 108s 423ms/step - loss: 0.1344 - accuracy: 0.9492 - val_loss: 0.1485 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 273/276\n",
      "256/256 [==============================] - 109s 425ms/step - loss: 0.1326 - accuracy: 0.9556 - val_loss: 0.1352 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 274/276\n",
      "256/256 [==============================] - 114s 443ms/step - loss: 0.1323 - accuracy: 0.9531 - val_loss: 0.1410 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 275/276\n",
      "256/256 [==============================] - 114s 443ms/step - loss: 0.1219 - accuracy: 0.9565 - val_loss: 0.1537 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 276/276\n",
      "256/256 [==============================] - 111s 435ms/step - loss: 0.1216 - accuracy: 0.9558 - val_loss: 0.1362 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1352}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1343}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1362\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1342520118. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m773.36 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m664.84 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m108.52 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [46] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m47\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 276)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 277/282\n",
      "256/256 [==============================] - 108s 406ms/step - loss: 0.1375 - accuracy: 0.9534 - val_loss: 0.1512 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 278/282\n",
      "256/256 [==============================] - 105s 409ms/step - loss: 0.1274 - accuracy: 0.9563 - val_loss: 0.1450 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 279/282\n",
      "256/256 [==============================] - 100s 389ms/step - loss: 0.1204 - accuracy: 0.9573 - val_loss: 0.1395 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 280/282\n",
      "256/256 [==============================] - 107s 417ms/step - loss: 0.1208 - accuracy: 0.9573 - val_loss: 0.1345 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 281/282\n",
      "256/256 [==============================] - 109s 425ms/step - loss: 0.1129 - accuracy: 0.9629 - val_loss: 0.1336 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 282/282\n",
      "256/256 [==============================] - 107s 417ms/step - loss: 0.1096 - accuracy: 0.9639 - val_loss: 0.1296 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-281-0.9503.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1336\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1342520118 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1335873008\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m749.58 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m635.95 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m113.63 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [47] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m48\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 282)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 283/288\n",
      "256/256 [==============================] - 108s 406ms/step - loss: 0.1374 - accuracy: 0.9541 - val_loss: 0.1349 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 284/288\n",
      "256/256 [==============================] - 105s 408ms/step - loss: 0.1280 - accuracy: 0.9587 - val_loss: 0.1419 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 285/288\n",
      "256/256 [==============================] - 114s 443ms/step - loss: 0.1278 - accuracy: 0.9595 - val_loss: 0.1444 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 286/288\n",
      "256/256 [==============================] - 113s 441ms/step - loss: 0.1194 - accuracy: 0.9580 - val_loss: 0.1376 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 287/288\n",
      "256/256 [==============================] - 117s 438ms/step - loss: 0.1185 - accuracy: 0.9612 - val_loss: 0.1398 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 288/288\n",
      "256/256 [==============================] - 112s 436ms/step - loss: 0.1175 - accuracy: 0.9592 - val_loss: 0.1512 - val_accuracy: 0.9327 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1349}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1336}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9327\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1512\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1335873008. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m783.06 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m668.51 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m114.54 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [48] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m49\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 288)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 289/294\n",
      "256/256 [==============================] - 109s 409ms/step - loss: 0.1448 - accuracy: 0.9507 - val_loss: 0.1683 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 290/294\n",
      "256/256 [==============================] - 110s 429ms/step - loss: 0.1384 - accuracy: 0.9521 - val_loss: 0.1511 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 291/294\n",
      "256/256 [==============================] - 106s 413ms/step - loss: 0.1269 - accuracy: 0.9570 - val_loss: 0.1993 - val_accuracy: 0.9279 - lr: 5.0000e-04\n",
      "Epoch 292/294\n",
      "256/256 [==============================] - 112s 439ms/step - loss: 0.1225 - accuracy: 0.9595 - val_loss: 0.1514 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 293/294\n",
      "256/256 [==============================] - 113s 442ms/step - loss: 0.1213 - accuracy: 0.9619 - val_loss: 0.1649 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 294/294\n",
      "256/256 [==============================] - 115s 449ms/step - loss: 0.1181 - accuracy: 0.9619 - val_loss: 0.1862 - val_accuracy: 0.9327 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9375}, \u001b[0m\u001b[0;33mloss{0.1511}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1336}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9327\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1862\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1335873008. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m778.24 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m666.34 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m111.90 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [49] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m50\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 294)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 295/300\n",
      "256/256 [==============================] - 108s 406ms/step - loss: 0.1277 - accuracy: 0.9543 - val_loss: 0.1805 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 296/300\n",
      "256/256 [==============================] - 107s 417ms/step - loss: 0.1304 - accuracy: 0.9531 - val_loss: 0.1472 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 297/300\n",
      "256/256 [==============================] - 106s 415ms/step - loss: 0.1264 - accuracy: 0.9578 - val_loss: 0.1501 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 298/300\n",
      "256/256 [==============================] - 113s 441ms/step - loss: 0.1168 - accuracy: 0.9622 - val_loss: 0.1897 - val_accuracy: 0.9263 - lr: 5.0000e-04\n",
      "Epoch 299/300\n",
      "256/256 [==============================] - 112s 436ms/step - loss: 0.1095 - accuracy: 0.9619 - val_loss: 0.1492 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 300/300\n",
      "256/256 [==============================] - 107s 417ms/step - loss: 0.1035 - accuracy: 0.9609 - val_loss: 0.1739 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9471}, \u001b[0m\u001b[0;33mloss{0.1472}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1336}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9295\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1739\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1335873008. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m764.88 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m654.07 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m110.81 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [50] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m51\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 300)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 301/306\n",
      "256/256 [==============================] - 110s 413ms/step - loss: 0.1430 - accuracy: 0.9490 - val_loss: 0.1395 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 302/306\n",
      "256/256 [==============================] - 110s 429ms/step - loss: 0.1414 - accuracy: 0.9509 - val_loss: 0.1300 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 303/306\n",
      "256/256 [==============================] - 104s 404ms/step - loss: 0.1330 - accuracy: 0.9563 - val_loss: 0.1336 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 304/306\n",
      "256/256 [==============================] - 105s 408ms/step - loss: 0.1277 - accuracy: 0.9583 - val_loss: 0.1324 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 305/306\n",
      "256/256 [==============================] - 106s 414ms/step - loss: 0.1241 - accuracy: 0.9551 - val_loss: 0.1352 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "Epoch 306/306\n",
      "256/256 [==============================] - 105s 410ms/step - loss: 0.1175 - accuracy: 0.9595 - val_loss: 0.1376 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-305-0.9535.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1352\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1335873008. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m754.96 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m639.79 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m115.17 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [51] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m52\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 306)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 307/312\n",
      "256/256 [==============================] - 110s 412ms/step - loss: 0.1326 - accuracy: 0.9517 - val_loss: 0.1323 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 308/312\n",
      "256/256 [==============================] - 106s 415ms/step - loss: 0.1339 - accuracy: 0.9514 - val_loss: 0.1342 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 309/312\n",
      "256/256 [==============================] - 104s 407ms/step - loss: 0.1235 - accuracy: 0.9561 - val_loss: 0.1438 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 310/312\n",
      "256/256 [==============================] - 104s 406ms/step - loss: 0.1237 - accuracy: 0.9583 - val_loss: 0.1388 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 311/312\n",
      "256/256 [==============================] - 107s 419ms/step - loss: 0.1164 - accuracy: 0.9636 - val_loss: 0.1458 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 312/312\n",
      "256/256 [==============================] - 108s 421ms/step - loss: 0.1093 - accuracy: 0.9626 - val_loss: 0.1324 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-307-0.9519.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9519\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1323\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1335873008 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1323240101\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m763.71 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m640.93 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m122.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [52] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m53\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 312)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 313/318\n",
      "256/256 [==============================] - 115s 433ms/step - loss: 0.1242 - accuracy: 0.9573 - val_loss: 0.1352 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "Epoch 314/318\n",
      "256/256 [==============================] - 105s 408ms/step - loss: 0.1274 - accuracy: 0.9565 - val_loss: 0.1367 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 315/318\n",
      "256/256 [==============================] - 105s 409ms/step - loss: 0.1214 - accuracy: 0.9580 - val_loss: 0.1460 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 316/318\n",
      "256/256 [==============================] - 110s 430ms/step - loss: 0.1202 - accuracy: 0.9585 - val_loss: 0.1388 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 317/318\n",
      "256/256 [==============================] - 113s 443ms/step - loss: 0.1147 - accuracy: 0.9604 - val_loss: 0.1518 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 318/318\n",
      "256/256 [==============================] - 110s 428ms/step - loss: 0.1088 - accuracy: 0.9631 - val_loss: 0.1503 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9535}, \u001b[0m\u001b[0;33mloss{0.1352}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1323}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9423\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1323240101. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m773.59 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m658.70 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m114.90 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [53] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m54\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 318)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 319/324\n",
      "256/256 [==============================] - 109s 411ms/step - loss: 0.1392 - accuracy: 0.9521 - val_loss: 0.1395 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 320/324\n",
      "256/256 [==============================] - 107s 419ms/step - loss: 0.1313 - accuracy: 0.9548 - val_loss: 0.1511 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 321/324\n",
      "256/256 [==============================] - 107s 418ms/step - loss: 0.1324 - accuracy: 0.9558 - val_loss: 0.1355 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 322/324\n",
      "256/256 [==============================] - 107s 419ms/step - loss: 0.1253 - accuracy: 0.9585 - val_loss: 0.1386 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 323/324\n",
      "256/256 [==============================] - 108s 422ms/step - loss: 0.1253 - accuracy: 0.9553 - val_loss: 0.1568 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 324/324\n",
      "256/256 [==============================] - 104s 408ms/step - loss: 0.1236 - accuracy: 0.9570 - val_loss: 0.1440 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9487}, \u001b[0m\u001b[0;33mloss{0.1355}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9535}, loss{0.1323}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9439\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1440\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9535256624. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1323240101. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m763.47 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m645.02 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m118.44 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [54] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m55\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 324)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 325/330\n",
      "256/256 [==============================] - 116s 438ms/step - loss: 0.1284 - accuracy: 0.9534 - val_loss: 0.1401 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 326/330\n",
      "256/256 [==============================] - 106s 414ms/step - loss: 0.1300 - accuracy: 0.9543 - val_loss: 0.1394 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 327/330\n",
      "256/256 [==============================] - 116s 455ms/step - loss: 0.1189 - accuracy: 0.9573 - val_loss: 0.1496 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 328/330\n",
      "256/256 [==============================] - 118s 459ms/step - loss: 0.1190 - accuracy: 0.9575 - val_loss: 0.1359 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 329/330\n",
      "256/256 [==============================] - 112s 436ms/step - loss: 0.1120 - accuracy: 0.9590 - val_loss: 0.1443 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 330/330\n",
      "256/256 [==============================] - 115s 448ms/step - loss: 0.1024 - accuracy: 0.9634 - val_loss: 0.1376 - val_accuracy: 0.9583 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-330-0.9583.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9583\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1376\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model accuracy from \u001b[0m\u001b[0;32m  0.953526 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m  0.958333\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1323240101. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m809.31 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m684.28 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m125.04 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [55] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m56\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 330)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 331/336\n",
      "256/256 [==============================] - 110s 415ms/step - loss: 0.1295 - accuracy: 0.9565 - val_loss: 0.1299 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 332/336\n",
      "256/256 [==============================] - 113s 440ms/step - loss: 0.1242 - accuracy: 0.9587 - val_loss: 0.1296 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 333/336\n",
      "256/256 [==============================] - 115s 448ms/step - loss: 0.1220 - accuracy: 0.9580 - val_loss: 0.1297 - val_accuracy: 0.9551 - lr: 5.0000e-04\n",
      "Epoch 334/336\n",
      "256/256 [==============================] - 114s 446ms/step - loss: 0.1165 - accuracy: 0.9602 - val_loss: 0.1328 - val_accuracy: 0.9551 - lr: 5.0000e-04\n",
      "Epoch 335/336\n",
      "256/256 [==============================] - 116s 452ms/step - loss: 0.1093 - accuracy: 0.9626 - val_loss: 0.1367 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 336/336\n",
      "256/256 [==============================] - 109s 425ms/step - loss: 0.1078 - accuracy: 0.9641 - val_loss: 0.1299 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-333-0.9551.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9551\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1296\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1323240101 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1296369284\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m799.45 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m677.55 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m121.90 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [56] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m57\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 336)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 337/342\n",
      "256/256 [==============================] - 113s 426ms/step - loss: 0.1318 - accuracy: 0.9565 - val_loss: 0.1331 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 338/342\n",
      "256/256 [==============================] - 112s 435ms/step - loss: 0.1256 - accuracy: 0.9590 - val_loss: 0.1347 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "Epoch 339/342\n",
      "256/256 [==============================] - 108s 421ms/step - loss: 0.1229 - accuracy: 0.9565 - val_loss: 0.1333 - val_accuracy: 0.9551 - lr: 5.0000e-04\n",
      "Epoch 340/342\n",
      "256/256 [==============================] - 114s 443ms/step - loss: 0.1162 - accuracy: 0.9585 - val_loss: 0.1347 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "Epoch 341/342\n",
      "256/256 [==============================] - 109s 425ms/step - loss: 0.1150 - accuracy: 0.9585 - val_loss: 0.1374 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "Epoch 342/342\n",
      "256/256 [==============================] - 111s 433ms/step - loss: 0.1039 - accuracy: 0.9629 - val_loss: 0.1319 - val_accuracy: 0.9551 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9551}, \u001b[0m\u001b[0;33mloss{0.1319}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1296}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9551\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1319\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1296369284. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m791.51 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m667.46 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m124.04 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [57] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m58\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 342)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 343/348\n",
      "256/256 [==============================] - 115s 434ms/step - loss: 0.1355 - accuracy: 0.9509 - val_loss: 0.1335 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 344/348\n",
      "256/256 [==============================] - 107s 418ms/step - loss: 0.1265 - accuracy: 0.9539 - val_loss: 0.1431 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 345/348\n",
      "256/256 [==============================] - 113s 440ms/step - loss: 0.1229 - accuracy: 0.9553 - val_loss: 0.1373 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 346/348\n",
      "256/256 [==============================] - 112s 435ms/step - loss: 0.1226 - accuracy: 0.9578 - val_loss: 0.1559 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 347/348\n",
      "256/256 [==============================] - 115s 448ms/step - loss: 0.1233 - accuracy: 0.9585 - val_loss: 0.1366 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 348/348\n",
      "256/256 [==============================] - 110s 429ms/step - loss: 0.1146 - accuracy: 0.9617 - val_loss: 0.1468 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9503}, \u001b[0m\u001b[0;33mloss{0.1335}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1296}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1468\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1296369284. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m796.50 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m672.43 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m124.07 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [58] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m59\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 348)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 349/354\n",
      "256/256 [==============================] - 115s 433ms/step - loss: 0.1168 - accuracy: 0.9602 - val_loss: 0.1817 - val_accuracy: 0.9327 - lr: 5.0000e-04\n",
      "Epoch 350/354\n",
      "256/256 [==============================] - 108s 423ms/step - loss: 0.1101 - accuracy: 0.9609 - val_loss: 0.1440 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 351/354\n",
      "256/256 [==============================] - 117s 458ms/step - loss: 0.1151 - accuracy: 0.9617 - val_loss: 0.1437 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 352/354\n",
      "256/256 [==============================] - 116s 452ms/step - loss: 0.1115 - accuracy: 0.9607 - val_loss: 0.1438 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 353/354\n",
      "256/256 [==============================] - 115s 450ms/step - loss: 0.1054 - accuracy: 0.9646 - val_loss: 0.1643 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 354/354\n",
      "256/256 [==============================] - 115s 450ms/step - loss: 0.1003 - accuracy: 0.9651 - val_loss: 0.1440 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9439}, \u001b[0m\u001b[0;33mloss{0.1437}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1296}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9439\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1440\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1296369284. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m809.90 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m688.34 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m121.56 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [59] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m60\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 354)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 355/360\n",
      "256/256 [==============================] - 115s 433ms/step - loss: 0.1408 - accuracy: 0.9512 - val_loss: 0.1382 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 356/360\n",
      "256/256 [==============================] - 107s 419ms/step - loss: 0.1331 - accuracy: 0.9526 - val_loss: 0.1420 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 357/360\n",
      "256/256 [==============================] - 116s 453ms/step - loss: 0.1319 - accuracy: 0.9539 - val_loss: 0.1673 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 358/360\n",
      "256/256 [==============================] - 116s 454ms/step - loss: 0.1250 - accuracy: 0.9539 - val_loss: 0.1384 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 359/360\n",
      "256/256 [==============================] - 115s 451ms/step - loss: 0.1205 - accuracy: 0.9595 - val_loss: 0.1436 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 360/360\n",
      "256/256 [==============================] - 125s 489ms/step - loss: 0.1138 - accuracy: 0.9607 - val_loss: 0.1653 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1382}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1296}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9375\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1653\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1296369284. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m818.77 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m696.39 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m122.38 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [60] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m61\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 360)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 361/366\n",
      "256/256 [==============================] - 114s 428ms/step - loss: 0.1249 - accuracy: 0.9570 - val_loss: 0.1380 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 362/366\n",
      "256/256 [==============================] - 113s 439ms/step - loss: 0.1246 - accuracy: 0.9553 - val_loss: 0.1344 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 363/366\n",
      "256/256 [==============================] - 109s 426ms/step - loss: 0.1171 - accuracy: 0.9629 - val_loss: 0.1459 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 364/366\n",
      "256/256 [==============================] - 113s 443ms/step - loss: 0.1154 - accuracy: 0.9614 - val_loss: 0.1418 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 365/366\n",
      "256/256 [==============================] - 115s 450ms/step - loss: 0.1125 - accuracy: 0.9629 - val_loss: 0.1385 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 366/366\n",
      "256/256 [==============================] - 109s 424ms/step - loss: 0.1033 - accuracy: 0.9668 - val_loss: 0.1602 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9487}, \u001b[0m\u001b[0;33mloss{0.1344}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1296}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9439\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1602\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1296369284. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m798.39 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m674.06 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m124.33 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [61] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m62\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 366)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 367/372\n",
      "256/256 [==============================] - 117s 440ms/step - loss: 0.1346 - accuracy: 0.9487 - val_loss: 0.1389 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 368/372\n",
      "256/256 [==============================] - 109s 424ms/step - loss: 0.1320 - accuracy: 0.9548 - val_loss: 0.1538 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 369/372\n",
      "256/256 [==============================] - 118s 460ms/step - loss: 0.1329 - accuracy: 0.9536 - val_loss: 0.1406 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 370/372\n",
      "256/256 [==============================] - 117s 457ms/step - loss: 0.1225 - accuracy: 0.9541 - val_loss: 0.1372 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 371/372\n",
      "256/256 [==============================] - 115s 449ms/step - loss: 0.1210 - accuracy: 0.9590 - val_loss: 0.1396 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 372/372\n",
      "256/256 [==============================] - 115s 448ms/step - loss: 0.1128 - accuracy: 0.9622 - val_loss: 0.1376 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1372}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1296}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1376\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1296369284. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m816.05 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m691.14 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m124.92 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [62] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m63\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 372)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 373/378\n",
      "256/256 [==============================] - 111s 416ms/step - loss: 0.1235 - accuracy: 0.9595 - val_loss: 0.1299 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 374/378\n",
      "256/256 [==============================] - 112s 436ms/step - loss: 0.1144 - accuracy: 0.9604 - val_loss: 0.1291 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 375/378\n",
      "256/256 [==============================] - 106s 416ms/step - loss: 0.1118 - accuracy: 0.9629 - val_loss: 0.1379 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 376/378\n",
      "256/256 [==============================] - 120s 469ms/step - loss: 0.1081 - accuracy: 0.9644 - val_loss: 0.1284 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 377/378\n",
      "256/256 [==============================] - 114s 443ms/step - loss: 0.1032 - accuracy: 0.9624 - val_loss: 0.1248 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 378/378\n",
      "256/256 [==============================] - 112s 439ms/step - loss: 0.0982 - accuracy: 0.9683 - val_loss: 0.1306 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-373-0.9487.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1299\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1296369284. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m801.06 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m676.18 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m124.87 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [63] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m64\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 378)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33m‚îî‚îÄ‚îÄ‚îÄShuffling data...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 379/384\n",
      "256/256 [==============================] - 115s 435ms/step - loss: 0.1396 - accuracy: 0.9507 - val_loss: 0.1307 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 380/384\n",
      "256/256 [==============================] - 109s 427ms/step - loss: 0.1309 - accuracy: 0.9531 - val_loss: 0.1346 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 381/384\n",
      "256/256 [==============================] - 121s 471ms/step - loss: 0.1325 - accuracy: 0.9514 - val_loss: 0.1301 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 382/384\n",
      "256/256 [==============================] - 117s 456ms/step - loss: 0.1230 - accuracy: 0.9558 - val_loss: 0.1278 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 383/384\n",
      "256/256 [==============================] - 118s 461ms/step - loss: 0.1105 - accuracy: 0.9575 - val_loss: 0.1352 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 384/384\n",
      "256/256 [==============================] - 114s 444ms/step - loss: 0.1097 - accuracy: 0.9597 - val_loss: 0.1332 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-384-0.9487.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1332\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1296369284. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m825.38 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m695.07 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m130.31 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [64] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m65\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 384)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 385/390\n",
      "256/256 [==============================] - 112s 422ms/step - loss: 0.1268 - accuracy: 0.9556 - val_loss: 0.1295 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 386/390\n",
      "256/256 [==============================] - 112s 436ms/step - loss: 0.1261 - accuracy: 0.9524 - val_loss: 0.1286 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 387/390\n",
      "256/256 [==============================] - 118s 461ms/step - loss: 0.1168 - accuracy: 0.9597 - val_loss: 0.1291 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 388/390\n",
      "256/256 [==============================] - 117s 456ms/step - loss: 0.1215 - accuracy: 0.9597 - val_loss: 0.1309 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 389/390\n",
      "256/256 [==============================] - 120s 469ms/step - loss: 0.1119 - accuracy: 0.9626 - val_loss: 0.1310 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "Epoch 390/390\n",
      "256/256 [==============================] - 113s 442ms/step - loss: 0.1024 - accuracy: 0.9609 - val_loss: 0.1276 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-389-0.9535.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1310\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1296369284. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m820.75 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m693.25 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m127.50 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [65] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m66\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 390)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 391/396\n",
      "256/256 [==============================] - 116s 438ms/step - loss: 0.1176 - accuracy: 0.9587 - val_loss: 0.1442 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 392/396\n",
      "256/256 [==============================] - 109s 425ms/step - loss: 0.1150 - accuracy: 0.9624 - val_loss: 0.1318 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 393/396\n",
      "256/256 [==============================] - 116s 451ms/step - loss: 0.1093 - accuracy: 0.9646 - val_loss: 0.1383 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 394/396\n",
      "256/256 [==============================] - 114s 443ms/step - loss: 0.1006 - accuracy: 0.9670 - val_loss: 0.1405 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 395/396\n",
      "256/256 [==============================] - 115s 450ms/step - loss: 0.1013 - accuracy: 0.9651 - val_loss: 0.1319 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 396/396\n",
      "256/256 [==============================] - 112s 437ms/step - loss: 0.0978 - accuracy: 0.9680 - val_loss: 0.1382 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1318}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1296}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1382\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1296369284. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m811.05 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m682.53 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m128.52 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [66] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m67\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 396)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 397/402\n",
      "256/256 [==============================] - 119s 447ms/step - loss: 0.1235 - accuracy: 0.9573 - val_loss: 0.1289 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 398/402\n",
      "256/256 [==============================] - 109s 424ms/step - loss: 0.1171 - accuracy: 0.9604 - val_loss: 0.1259 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 399/402\n",
      "256/256 [==============================] - 113s 442ms/step - loss: 0.1041 - accuracy: 0.9626 - val_loss: 0.1323 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 400/402\n",
      "256/256 [==============================] - 118s 460ms/step - loss: 0.1094 - accuracy: 0.9636 - val_loss: 0.1302 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 401/402\n",
      "256/256 [==============================] - 115s 448ms/step - loss: 0.1007 - accuracy: 0.9636 - val_loss: 0.1352 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 402/402\n",
      "256/256 [==============================] - 114s 446ms/step - loss: 0.1097 - accuracy: 0.9612 - val_loss: 0.1393 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0;33mLoading the best weights...\u001b[0m\n",
      "\u001b[0;33mLoading weights from file cache\\model_SUB_checkpoint-398-0.9503.h5...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1259\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mImproved model loss from \u001b[0m\u001b[0;32m0.1296369284 \u001b[0m\u001b[0;33mto \u001b[0m\u001b[0;32m0.1259101629\u001b[0m\u001b[0;33m. \u001b[0m\u001b[0;96mSaving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;36mSaving full model H5 format...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m821.31 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m687.99 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m133.33 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [67] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m68\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 402)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 403/408\n",
      "256/256 [==============================] - 112s 419ms/step - loss: 0.1364 - accuracy: 0.9521 - val_loss: 0.1278 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 404/408\n",
      "256/256 [==============================] - 113s 441ms/step - loss: 0.1308 - accuracy: 0.9524 - val_loss: 0.1292 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 405/408\n",
      "256/256 [==============================] - 117s 457ms/step - loss: 0.1224 - accuracy: 0.9551 - val_loss: 0.1285 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 406/408\n",
      "256/256 [==============================] - 118s 460ms/step - loss: 0.1253 - accuracy: 0.9573 - val_loss: 0.1350 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 407/408\n",
      "256/256 [==============================] - 113s 441ms/step - loss: 0.1173 - accuracy: 0.9600 - val_loss: 0.1307 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 408/408\n",
      "256/256 [==============================] - 116s 452ms/step - loss: 0.1105 - accuracy: 0.9602 - val_loss: 0.1404 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1278}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1404\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m821.27 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m689.35 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m131.93 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [68] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m69\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 408)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 409/414\n",
      "256/256 [==============================] - 112s 421ms/step - loss: 0.1357 - accuracy: 0.9485 - val_loss: 0.1557 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 410/414\n",
      "256/256 [==============================] - 114s 444ms/step - loss: 0.1304 - accuracy: 0.9517 - val_loss: 0.1309 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 411/414\n",
      "256/256 [==============================] - 120s 471ms/step - loss: 0.1222 - accuracy: 0.9583 - val_loss: 0.1527 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 412/414\n",
      "256/256 [==============================] - 116s 452ms/step - loss: 0.1234 - accuracy: 0.9541 - val_loss: 0.1362 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 413/414\n",
      "256/256 [==============================] - 116s 453ms/step - loss: 0.1192 - accuracy: 0.9565 - val_loss: 0.1313 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 414/414\n",
      "256/256 [==============================] - 114s 447ms/step - loss: 0.1080 - accuracy: 0.9624 - val_loss: 0.1272 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9471}, \u001b[0m\u001b[0;33mloss{0.1272}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1272\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m829.36 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m693.59 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m135.76 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [69] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m70\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 414)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 415/420\n",
      "256/256 [==============================] - 114s 431ms/step - loss: 0.1368 - accuracy: 0.9536 - val_loss: 0.1283 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "Epoch 416/420\n",
      "256/256 [==============================] - 113s 442ms/step - loss: 0.1330 - accuracy: 0.9568 - val_loss: 0.1463 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 417/420\n",
      "256/256 [==============================] - 118s 459ms/step - loss: 0.1244 - accuracy: 0.9543 - val_loss: 0.1317 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 418/420\n",
      "256/256 [==============================] - 117s 458ms/step - loss: 0.1241 - accuracy: 0.9561 - val_loss: 0.1527 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 419/420\n",
      "256/256 [==============================] - 120s 467ms/step - loss: 0.1183 - accuracy: 0.9629 - val_loss: 0.1653 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 420/420\n",
      "256/256 [==============================] - 114s 445ms/step - loss: 0.1125 - accuracy: 0.9597 - val_loss: 0.1307 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9535}, \u001b[0m\u001b[0;33mloss{0.1283}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1307\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m828.53 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m697.52 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m131.02 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [70] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m71\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 420)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 421/426\n",
      "256/256 [==============================] - 114s 428ms/step - loss: 0.1202 - accuracy: 0.9556 - val_loss: 0.1381 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 422/426\n",
      "256/256 [==============================] - 113s 439ms/step - loss: 0.1169 - accuracy: 0.9583 - val_loss: 0.1424 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 423/426\n",
      "256/256 [==============================] - 118s 462ms/step - loss: 0.1149 - accuracy: 0.9600 - val_loss: 0.1406 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 424/426\n",
      "256/256 [==============================] - 117s 457ms/step - loss: 0.1187 - accuracy: 0.9597 - val_loss: 0.1387 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 425/426\n",
      "256/256 [==============================] - 114s 445ms/step - loss: 0.1104 - accuracy: 0.9612 - val_loss: 0.1349 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 426/426\n",
      "256/256 [==============================] - 118s 460ms/step - loss: 0.1085 - accuracy: 0.9648 - val_loss: 0.1373 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9487}, \u001b[0m\u001b[0;33mloss{0.1349}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1373\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m830.19 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m694.33 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m135.85 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [71] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m72\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 426)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 427/432\n",
      "256/256 [==============================] - 112s 421ms/step - loss: 0.1240 - accuracy: 0.9570 - val_loss: 0.1357 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 428/432\n",
      "256/256 [==============================] - 116s 454ms/step - loss: 0.1176 - accuracy: 0.9604 - val_loss: 0.1341 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 429/432\n",
      "256/256 [==============================] - 121s 473ms/step - loss: 0.1142 - accuracy: 0.9629 - val_loss: 0.1354 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 430/432\n",
      "256/256 [==============================] - 120s 468ms/step - loss: 0.1066 - accuracy: 0.9661 - val_loss: 0.1334 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 431/432\n",
      "256/256 [==============================] - 120s 470ms/step - loss: 0.1024 - accuracy: 0.9673 - val_loss: 0.1596 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 432/432\n",
      "256/256 [==============================] - 116s 453ms/step - loss: 0.1049 - accuracy: 0.9634 - val_loss: 0.1332 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9471}, \u001b[0m\u001b[0;33mloss{0.1332}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1332\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m840.19 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m707.13 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m133.06 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [72] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m73\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 432)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 433/438\n",
      "256/256 [==============================] - 118s 447ms/step - loss: 0.1157 - accuracy: 0.9607 - val_loss: 0.1305 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 434/438\n",
      "256/256 [==============================] - 114s 446ms/step - loss: 0.1125 - accuracy: 0.9619 - val_loss: 0.1325 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 435/438\n",
      "256/256 [==============================] - 118s 460ms/step - loss: 0.1077 - accuracy: 0.9624 - val_loss: 0.1490 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 436/438\n",
      "256/256 [==============================] - 118s 460ms/step - loss: 0.1020 - accuracy: 0.9653 - val_loss: 0.1354 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 437/438\n",
      "256/256 [==============================] - 117s 458ms/step - loss: 0.0988 - accuracy: 0.9656 - val_loss: 0.1410 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 438/438\n",
      "256/256 [==============================] - 119s 463ms/step - loss: 0.0945 - accuracy: 0.9656 - val_loss: 0.1442 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9487}, \u001b[0m\u001b[0;33mloss{0.1305}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1442\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m839.19 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m705.50 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m133.69 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [73] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m74\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 438)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 439/444\n",
      "256/256 [==============================] - 122s 462ms/step - loss: 0.1340 - accuracy: 0.9548 - val_loss: 0.1560 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 440/444\n",
      "256/256 [==============================] - 114s 445ms/step - loss: 0.1326 - accuracy: 0.9546 - val_loss: 0.1504 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 441/444\n",
      "256/256 [==============================] - 119s 465ms/step - loss: 0.1280 - accuracy: 0.9536 - val_loss: 0.1411 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 442/444\n",
      "256/256 [==============================] - 123s 480ms/step - loss: 0.1175 - accuracy: 0.9590 - val_loss: 0.1484 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 443/444\n",
      "256/256 [==============================] - 119s 466ms/step - loss: 0.1167 - accuracy: 0.9585 - val_loss: 0.1598 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 444/444\n",
      "256/256 [==============================] - 121s 472ms/step - loss: 0.1141 - accuracy: 0.9597 - val_loss: 0.1357 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9487}, \u001b[0m\u001b[0;33mloss{0.1357}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1357\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m855.28 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m719.78 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m135.51 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [74] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m75\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 444)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 445/450\n",
      "256/256 [==============================] - 120s 452ms/step - loss: 0.1429 - accuracy: 0.9497 - val_loss: 0.1452 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 446/450\n",
      "256/256 [==============================] - 117s 456ms/step - loss: 0.1360 - accuracy: 0.9524 - val_loss: 0.1439 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 447/450\n",
      "256/256 [==============================] - 113s 441ms/step - loss: 0.1238 - accuracy: 0.9573 - val_loss: 0.1608 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 448/450\n",
      "256/256 [==============================] - 118s 460ms/step - loss: 0.1203 - accuracy: 0.9578 - val_loss: 0.1628 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 449/450\n",
      "256/256 [==============================] - 122s 477ms/step - loss: 0.1206 - accuracy: 0.9595 - val_loss: 0.1459 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 450/450\n",
      "256/256 [==============================] - 120s 467ms/step - loss: 0.1194 - accuracy: 0.9578 - val_loss: 0.1419 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9471}, \u001b[0m\u001b[0;33mloss{0.1419}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1419\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m843.63 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m710.39 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m133.25 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [75] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m76\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 450)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 451/456\n",
      "256/256 [==============================] - 116s 439ms/step - loss: 0.1256 - accuracy: 0.9541 - val_loss: 0.1506 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 452/456\n",
      "256/256 [==============================] - 116s 452ms/step - loss: 0.1230 - accuracy: 0.9592 - val_loss: 0.1328 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 453/456\n",
      "256/256 [==============================] - 116s 454ms/step - loss: 0.1093 - accuracy: 0.9619 - val_loss: 0.1442 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 454/456\n",
      "256/256 [==============================] - 122s 477ms/step - loss: 0.1092 - accuracy: 0.9646 - val_loss: 0.1379 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 455/456\n",
      "256/256 [==============================] - 121s 474ms/step - loss: 0.1032 - accuracy: 0.9658 - val_loss: 0.1522 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 456/456\n",
      "256/256 [==============================] - 121s 472ms/step - loss: 0.1008 - accuracy: 0.9670 - val_loss: 0.1402 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9471}, \u001b[0m\u001b[0;33mloss{0.1328}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1402\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m853.16 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m713.94 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m139.22 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [76] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m77\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 456)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 457/462\n",
      "256/256 [==============================] - 116s 436ms/step - loss: 0.1157 - accuracy: 0.9624 - val_loss: 0.1307 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 458/462\n",
      "256/256 [==============================] - 114s 446ms/step - loss: 0.1127 - accuracy: 0.9644 - val_loss: 0.1267 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 459/462\n",
      "256/256 [==============================] - 115s 449ms/step - loss: 0.1058 - accuracy: 0.9656 - val_loss: 0.1634 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 460/462\n",
      "256/256 [==============================] - 116s 452ms/step - loss: 0.1052 - accuracy: 0.9631 - val_loss: 0.1347 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 461/462\n",
      "256/256 [==============================] - 113s 443ms/step - loss: 0.0994 - accuracy: 0.9670 - val_loss: 0.1402 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 462/462\n",
      "256/256 [==============================] - 114s 445ms/step - loss: 0.1066 - accuracy: 0.9663 - val_loss: 0.1337 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1267}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9487\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1337\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m823.68 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m689.16 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m134.52 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [77] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m78\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 462)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 463/468\n",
      "256/256 [==============================] - 121s 455ms/step - loss: 0.1259 - accuracy: 0.9561 - val_loss: 0.1316 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 464/468\n",
      "256/256 [==============================] - 113s 442ms/step - loss: 0.1182 - accuracy: 0.9575 - val_loss: 0.1337 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 465/468\n",
      "256/256 [==============================] - 111s 435ms/step - loss: 0.1069 - accuracy: 0.9646 - val_loss: 0.1417 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 466/468\n",
      "256/256 [==============================] - 112s 436ms/step - loss: 0.1070 - accuracy: 0.9634 - val_loss: 0.1371 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 467/468\n",
      "256/256 [==============================] - 120s 471ms/step - loss: 0.1033 - accuracy: 0.9656 - val_loss: 0.1398 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 468/468\n",
      "256/256 [==============================] - 113s 440ms/step - loss: 0.1005 - accuracy: 0.9675 - val_loss: 0.1384 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9471}, \u001b[0m\u001b[0;33mloss{0.1316}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1384\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m830.84 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m691.17 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m139.66 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [78] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m79\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 468)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 469/474\n",
      "256/256 [==============================] - 116s 437ms/step - loss: 0.1162 - accuracy: 0.9600 - val_loss: 0.1399 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 470/474\n",
      "256/256 [==============================] - 115s 449ms/step - loss: 0.1116 - accuracy: 0.9609 - val_loss: 0.1474 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 471/474\n",
      "256/256 [==============================] - 117s 457ms/step - loss: 0.1055 - accuracy: 0.9675 - val_loss: 0.1533 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 472/474\n",
      "256/256 [==============================] - 123s 480ms/step - loss: 0.1009 - accuracy: 0.9683 - val_loss: 0.1440 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 473/474\n",
      "256/256 [==============================] - 124s 484ms/step - loss: 0.0955 - accuracy: 0.9678 - val_loss: 0.1496 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 474/474\n",
      "256/256 [==============================] - 120s 470ms/step - loss: 0.0932 - accuracy: 0.9661 - val_loss: 0.1365 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9503}, \u001b[0m\u001b[0;33mloss{0.1365}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1365\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m854.95 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m716.30 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m138.64 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [79] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m80\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 474)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 475/480\n",
      "256/256 [==============================] - 114s 428ms/step - loss: 0.1309 - accuracy: 0.9556 - val_loss: 0.1307 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 476/480\n",
      "256/256 [==============================] - 118s 460ms/step - loss: 0.1273 - accuracy: 0.9512 - val_loss: 0.1481 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 477/480\n",
      "256/256 [==============================] - 112s 437ms/step - loss: 0.1189 - accuracy: 0.9563 - val_loss: 0.1338 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 478/480\n",
      "256/256 [==============================] - 120s 468ms/step - loss: 0.1220 - accuracy: 0.9575 - val_loss: 0.1338 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 479/480\n",
      "256/256 [==============================] - 118s 462ms/step - loss: 0.1020 - accuracy: 0.9617 - val_loss: 0.1388 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 480/480\n",
      "256/256 [==============================] - 117s 455ms/step - loss: 0.1107 - accuracy: 0.9619 - val_loss: 0.1324 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1307}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9471\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1324\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m838.44 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m699.03 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m139.41 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [80] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m81\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 480)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 481/486\n",
      "256/256 [==============================] - 117s 439ms/step - loss: 0.1326 - accuracy: 0.9497 - val_loss: 0.1386 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 482/486\n",
      "256/256 [==============================] - 120s 467ms/step - loss: 0.1234 - accuracy: 0.9563 - val_loss: 0.1297 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 483/486\n",
      "256/256 [==============================] - 123s 480ms/step - loss: 0.1239 - accuracy: 0.9563 - val_loss: 0.1299 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 484/486\n",
      "256/256 [==============================] - 120s 470ms/step - loss: 0.1150 - accuracy: 0.9583 - val_loss: 0.1614 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 485/486\n",
      "256/256 [==============================] - 113s 442ms/step - loss: 0.1101 - accuracy: 0.9580 - val_loss: 0.1347 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 486/486\n",
      "256/256 [==============================] - 112s 437ms/step - loss: 0.1027 - accuracy: 0.9666 - val_loss: 0.1494 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1297}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9439\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1494\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m843.55 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m705.75 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m137.80 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [81] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m82\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 486)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 487/492\n",
      "256/256 [==============================] - 125s 472ms/step - loss: 0.1278 - accuracy: 0.9536 - val_loss: 0.1490 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 488/492\n",
      "256/256 [==============================] - 118s 462ms/step - loss: 0.1233 - accuracy: 0.9570 - val_loss: 0.1421 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 489/492\n",
      "256/256 [==============================] - 117s 458ms/step - loss: 0.1143 - accuracy: 0.9592 - val_loss: 0.1458 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 490/492\n",
      "256/256 [==============================] - 123s 481ms/step - loss: 0.1093 - accuracy: 0.9644 - val_loss: 0.1414 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 491/492\n",
      "256/256 [==============================] - 123s 482ms/step - loss: 0.1024 - accuracy: 0.9644 - val_loss: 0.1393 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 492/492\n",
      "256/256 [==============================] - 123s 479ms/step - loss: 0.0969 - accuracy: 0.9688 - val_loss: 0.1520 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9455}, \u001b[0m\u001b[0;33mloss{0.1393}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1521\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m869.79 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m730.91 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m138.89 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [82] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m83\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 492)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 493/498\n",
      "256/256 [==============================] - 119s 449ms/step - loss: 0.1207 - accuracy: 0.9590 - val_loss: 0.1584 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 494/498\n",
      "256/256 [==============================] - 115s 447ms/step - loss: 0.1118 - accuracy: 0.9636 - val_loss: 0.1564 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 495/498\n",
      "256/256 [==============================] - 118s 459ms/step - loss: 0.1105 - accuracy: 0.9624 - val_loss: 0.1402 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 496/498\n",
      "256/256 [==============================] - 124s 485ms/step - loss: 0.1010 - accuracy: 0.9663 - val_loss: 0.1544 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 497/498\n",
      "256/256 [==============================] - 124s 485ms/step - loss: 0.1028 - accuracy: 0.9634 - val_loss: 0.1415 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 498/498\n",
      "256/256 [==============================] - 114s 444ms/step - loss: 0.0972 - accuracy: 0.9680 - val_loss: 0.1623 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9519}, \u001b[0m\u001b[0;33mloss{0.1402}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9519\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1623\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m851.68 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m714.70 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m136.98 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [83] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m84\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 498)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;31m- Debug DP Sample dir: \u001b[0m\u001b[0;32mSamples/TSR_SUB_400_y2024_m02_d18-h16_m42_s58\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 499/504\n",
      "256/256 [==============================] - 114s 431ms/step - loss: 0.1149 - accuracy: 0.9636 - val_loss: 0.1627 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 500/504\n",
      "256/256 [==============================] - 121s 474ms/step - loss: 0.1087 - accuracy: 0.9617 - val_loss: 0.1481 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 501/504\n",
      "256/256 [==============================] - 115s 450ms/step - loss: 0.1034 - accuracy: 0.9663 - val_loss: 0.1449 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 502/504\n",
      "256/256 [==============================] - 120s 469ms/step - loss: 0.0959 - accuracy: 0.9685 - val_loss: 0.1414 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 503/504\n",
      "256/256 [==============================] - 123s 481ms/step - loss: 0.0944 - accuracy: 0.9705 - val_loss: 0.1654 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 504/504\n",
      "256/256 [==============================] - 120s 468ms/step - loss: 0.0950 - accuracy: 0.9705 - val_loss: 0.1441 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9503}, \u001b[0m\u001b[0;33mloss{0.1414}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9439\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1441\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m864.61 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m715.23 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m149.38 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [84] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m85\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 504)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 505/510\n",
      "256/256 [==============================] - 119s 447ms/step - loss: 0.1198 - accuracy: 0.9604 - val_loss: 0.1418 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 506/510\n",
      "256/256 [==============================] - 119s 463ms/step - loss: 0.1087 - accuracy: 0.9631 - val_loss: 0.1449 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 507/510\n",
      "256/256 [==============================] - 116s 455ms/step - loss: 0.1135 - accuracy: 0.9626 - val_loss: 0.1355 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 508/510\n",
      "256/256 [==============================] - 124s 485ms/step - loss: 0.1021 - accuracy: 0.9644 - val_loss: 0.1490 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 509/510\n",
      "256/256 [==============================] - 126s 492ms/step - loss: 0.1006 - accuracy: 0.9648 - val_loss: 0.1492 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 510/510\n",
      "256/256 [==============================] - 126s 491ms/step - loss: 0.0989 - accuracy: 0.9644 - val_loss: 0.1517 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9503}, \u001b[0m\u001b[0;33mloss{0.1355}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9503\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1517\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m870.72 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m730.86 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m139.86 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [85] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m86\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 510)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 511/516\n",
      "256/256 [==============================] - 116s 436ms/step - loss: 0.1263 - accuracy: 0.9524 - val_loss: 0.1381 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 512/516\n",
      "256/256 [==============================] - 121s 473ms/step - loss: 0.1297 - accuracy: 0.9531 - val_loss: 0.1368 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 513/516\n",
      "256/256 [==============================] - 114s 446ms/step - loss: 0.1135 - accuracy: 0.9570 - val_loss: 0.1370 - val_accuracy: 0.9439 - lr: 5.0000e-04\n",
      "Epoch 514/516\n",
      "256/256 [==============================] - 117s 456ms/step - loss: 0.1095 - accuracy: 0.9602 - val_loss: 0.1555 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 515/516\n",
      "256/256 [==============================] - 122s 475ms/step - loss: 0.1114 - accuracy: 0.9602 - val_loss: 0.1403 - val_accuracy: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 516/516\n",
      "256/256 [==============================] - 126s 491ms/step - loss: 0.1059 - accuracy: 0.9634 - val_loss: 0.1528 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9487}, \u001b[0m\u001b[0;33mloss{0.1368}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9407\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1529\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m857.96 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m716.28 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m141.68 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [86] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m87\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 516)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 517/522\n",
      "256/256 [==============================] - 117s 440ms/step - loss: 0.1361 - accuracy: 0.9529 - val_loss: 0.1480 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 518/522\n",
      "256/256 [==============================] - 115s 447ms/step - loss: 0.1249 - accuracy: 0.9575 - val_loss: 0.1787 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 519/522\n",
      "256/256 [==============================] - 118s 459ms/step - loss: 0.1238 - accuracy: 0.9551 - val_loss: 0.1444 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 520/522\n",
      "256/256 [==============================] - 130s 508ms/step - loss: 0.1196 - accuracy: 0.9600 - val_loss: 0.1674 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 521/522\n",
      "256/256 [==============================] - 126s 494ms/step - loss: 0.1199 - accuracy: 0.9604 - val_loss: 0.1564 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "Epoch 522/522\n",
      "256/256 [==============================] - 127s 495ms/step - loss: 0.1047 - accuracy: 0.9634 - val_loss: 0.1868 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9535}, \u001b[0m\u001b[0;33mloss{0.1444}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9455\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1869\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m874.34 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m733.72 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m140.62 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [87] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m88\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 522)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 523/528\n",
      "256/256 [==============================] - 123s 463ms/step - loss: 0.1287 - accuracy: 0.9548 - val_loss: 0.1584 - val_accuracy: 0.9455 - lr: 5.0000e-04\n",
      "Epoch 524/528\n",
      "256/256 [==============================] - 126s 493ms/step - loss: 0.1342 - accuracy: 0.9536 - val_loss: 0.1393 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 525/528\n",
      "256/256 [==============================] - 121s 473ms/step - loss: 0.1142 - accuracy: 0.9585 - val_loss: 0.1498 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 526/528\n",
      "256/256 [==============================] - 124s 484ms/step - loss: 0.1131 - accuracy: 0.9597 - val_loss: 0.1935 - val_accuracy: 0.9423 - lr: 5.0000e-04\n",
      "Epoch 527/528\n",
      "256/256 [==============================] - 125s 488ms/step - loss: 0.1063 - accuracy: 0.9636 - val_loss: 0.1469 - val_accuracy: 0.9487 - lr: 5.0000e-04\n",
      "Epoch 528/528\n",
      "256/256 [==============================] - 127s 496ms/step - loss: 0.1000 - accuracy: 0.9656 - val_loss: 0.1559 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mNot loading weights\u001b[0m\u001b[0;32m[\u001b[0m\u001b[0;94mBSR:\u001b[0m\u001b[0;33macc{0.9535}, \u001b[0m\u001b[0;33mloss{0.1393}\u001b[0m\u001b[0;95m|\u001b[0m\u001b[0;94mBTR:\u001b[0m\u001b[0;32macc{0.9583}, loss{0.1259}]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test acc: \u001b[0m\u001b[0;32m0.9535\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mModel Test loss: \u001b[0m\u001b[0;32m0.1559\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel accuracy did not improve from 0.9583333135. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;91mModel loss did not improve from 0.1259101629. Not saving model.\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(FULL): \u001b[0m\u001b[0;32m901.71 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(SUBo): \u001b[0m\u001b[0;32m748.01 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTime taken for epoch(OTHERo): \u001b[0m\u001b[0;32m153.70 \u001b[0m\u001b[0;36msec\u001b[0m\n",
      "\u001b[0;36m<---------------------------------------|Epoch [88] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m89\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m489 (TSEC: 528)\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[|4096|AdvSubset:True]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mPreparing train data...\u001b[0m\n",
      "\u001b[0;33m- Augmenting Image Data...\u001b[0m\n",
      "\u001b[0;33m- Normalizing Image Data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting training subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 529/534\n",
      "256/256 [==============================] - 119s 448ms/step - loss: 0.1090 - accuracy: 0.9636 - val_loss: 0.1516 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 530/534\n",
      "256/256 [==============================] - 115s 449ms/step - loss: 0.0971 - accuracy: 0.9697 - val_loss: 0.1533 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 531/534\n",
      "256/256 [==============================] - 120s 467ms/step - loss: 0.0914 - accuracy: 0.9719 - val_loss: 0.1656 - val_accuracy: 0.9535 - lr: 5.0000e-04\n",
      "Epoch 532/534\n",
      "203/256 [======================>.......] - ETA: 25s - loss: 0.0931 - accuracy: 0.9704"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "# CONF <-------------------------------------------------------------------------->\n",
    "# Hyperparameters for training the model:\n",
    "max_epoch = 489 # max_epoch: Maximum number of epochs to train for. Use >=256 for full fine-tuning of large models.\n",
    "subset_epoch = 6 # subset_epoch: Number of epochs to train each subset.\n",
    "subset_epoch_FT = 6 # subset_epoch_FT: subset_epoch after pre-training epochs.\n",
    "PL_epoch = 26 # PL_epoch: Number of pre-training epochs. Use >=24 for large models or 0/1 for fine-tuning only.\n",
    "subset_size = 4096 # subset_size: Size of each training subset. Common values: 512, 1024, 2048, 3200, 4096, 8192.\n",
    "Conf_batch_size_REV2 = 16 # Conf_batch_size_REV2: Batch size.\n",
    "RES_Train = False # RES_Train: Resume training if True.\n",
    "MAX_LR = 0.01 # MAX_LR: Maximum learning rate.\n",
    "DEC_LR = 0.00006 # DEC_LR: Learning rate decay.\n",
    "MIN_LR = 0.0005 # MIN_LR: Minimum learning rate.\n",
    "RES_LR = 0.006 # RES_LR: Resuming learning rate.\n",
    "Use_OneCycleLr = False # Use_OneCycleLr: Use OneCycleLr if True. if false, use ReduceLROnPlateau.\n",
    "OneCycleLr_UFTS = False # OneCycleLr_UFTS: Set the OneCycleLr max epochs to the estimated full training SUB epochs. (DEC_LR and MIN_LR dont have any effect if True)\n",
    "Debug_OUTPUT_DPS = True # Debug_OUTPUT_DPS: Output debug image samples if True.\n",
    "Debug_OUTPUT_DPS_freq = 42 # Debug_OUTPUT_DPS_freq: Debug image output frequency(epoch).\n",
    "TerminateOnHighTemp_M = True # TerminateOnHighTemp_M: Terminate training on high GPU temp to prevent damage.\n",
    "SAVE_FULLM = True # SAVE_FULLM: Save full model if True.\n",
    "AdvSubsetC = True  # AdvSubsetC: Use advanced subset sampling to prevent overfitting if True.\n",
    "AdvSubsetC_SHR = 32 # AdvSubsetC_SHR: Parameter for advanced subset sampling (shuffling data after n epochs).\n",
    "load_SUB_BRW = True # load_SUB_BRW: Load previous subset weights to speed up training if True. May reduce max accuracy.\n",
    "load_SUB_BRW_MODE = 'val_accuracy' # load_SUB_BRW_MODE: Previous subset weights loading mode - 'val_accuracy' or 'val_loss'.\n",
    "load_SUB_BRW_LMODE = 0 # load_SUB_BRW_LMODE: Previous subset weights loading mode parameter (1 for only on imp and !1 for normal mode (for subset_epoch > 6 normal mode is better)).\n",
    "load_SUB_BRW_LMODE_FN = True # load_SUB_BRW_LMODE_FN: Set load_SUB_BRW_LMODE=1 during fine-tuning if True.\n",
    "ModelCheckpoint_mode = 'auto' # ModelCheckpoint_mode: 'auto', 'min', or 'max' - how to monitor ModelCheckpoint.\n",
    "ModelCheckpoint_Reset_TO = 0.6251 # ModelCheckpoint_Reset_TO: Reset ModelCheckpoint monitor to this value, e.g. 0 or float('inf').\n",
    "Auto_clear_cache = True # Auto_clear_cache: Clear cache during training if True to reduce memory usage.\n",
    "Use_ES_ONSUBT = False # Use_ES_ONSUBT: Early stopping per subset (‚ö†Ô∏èdeprecated‚ö†Ô∏è).\n",
    "EarlyStopping_P = 5 # EarlyStopping_P: Early stopping patience (‚ö†Ô∏èdeprecated‚ö†Ô∏è).\n",
    "Use_tensorboard_profiler = False # Use_tensorboard_profiler: Enable tensorboard profiler.\n",
    "Use_extended_tensorboard = False # Use_extended_tensorboard: Enable extended tensorboard (Some funcs may not work).\n",
    "Use_tensorBoard_img = False # Use_tensorBoard_img: Enable tensorboard image logging.\n",
    "Use_noise_func_TRLRev2 = True # Use_noise_func_TRLRev2: Use noise function for IDG if True.\n",
    "Show_confusion_matrix_tensorBoard = False # Show_confusion_matrix_tensorBoard: Show confusion matrix on tensorboard.\n",
    "BEST_RSN = 'PAI_model_T' # Best model save name prefix. (Uses a lot of memory and storage).\n",
    "ALWAYS_REFIT_IDG = 1 # ALWAYS_REFIT_IDG: if 0/False - do not always refit IDG. if 1 - always refit IDG (In Start). if 2 - always refit IDG (After each epoch) (slow).\n",
    "IDG_FitP_PATH = 'Data\\\\image_SUB_generator.pkl'\n",
    "# CONF END <---------------------------------------------------------------------->\n",
    "#Prep\n",
    "if RES_Train:\n",
    "    MAX_LR = RES_LR\n",
    "    PL_epoch = 1\n",
    "#VAR\n",
    "Total_SUB_epoch_C = 0 # TO FIX TensorBoard\n",
    "CU_LR = MAX_LR\n",
    "all_histories = []\n",
    "chosen_indices = []\n",
    "subset_sizes = []\n",
    "best_acc = 0\n",
    "best_loss = float('inf')\n",
    "#Funcs\n",
    "def normalize_TO_RANGE(arr, min_val, max_val):\n",
    "  arr = arr.astype('float32')\n",
    "  arr = (arr - arr.min()) / (arr.max() - arr.min())\n",
    "  arr = arr * (max_val - min_val) + min_val\n",
    "  return arr\n",
    "\n",
    "def Z_SCORE_normalize(arr):\n",
    "   arr = arr.astype('float32')\n",
    "   mean = np.mean(arr)\n",
    "   std_dev = np.std(arr)\n",
    "   arr = (arr - mean) / std_dev\n",
    "   return arr\n",
    "\n",
    "def add_image_grain_TRLRev2(image, intensity = 0.01):\n",
    "    # Generate random noise array\n",
    "    noise = (np.random.randint(-255, 255, size=image.shape, dtype=np.int16) \\\n",
    "          + np.random.randint(-255, 255, size=image.shape, dtype=np.int16)) / 2\n",
    "\n",
    "    # Scale the noise array\n",
    "    scaled_noise = (noise * intensity).astype(np.float32)\n",
    "    # Add the noise to the image\n",
    "    noisy_image = cv2.add(image, scaled_noise)\n",
    "\n",
    "    return noisy_image\n",
    "# noise_func_TRLRev2 ([REV1 OLD])\n",
    "def noise_func_TRLRev2(image): \n",
    "    noise_type = np.random.choice(['L1', 'L2', 'L3', 'none'])\n",
    "    new_image = np.copy(image)\n",
    "    \n",
    "    if noise_type == 'L3':\n",
    "        intensityL2 = random.uniform(-0.08, 0.08)\n",
    "        intensityL1 = random.uniform(-0.05, 0.05)\n",
    "    else:\n",
    "        intensityL2 = random.uniform(-0.09, 0.09)\n",
    "        intensityL1 = random.uniform(-0.06, 0.06)\n",
    "        \n",
    "    block_size_L1 = random.randint(16, 32)\n",
    "    block_size_L2 = random.randint(32, 112)\n",
    "    \n",
    "    if noise_type == 'L2' or noise_type == 'L3':\n",
    "        for i in range(0, image.shape[0], block_size_L2):\n",
    "            for j in range(0, image.shape[1], block_size_L2):\n",
    "                block = image[i:i+block_size_L2, j:j+block_size_L2]\n",
    "                block = (np.random.rand() * intensityL2 + 1) * block\n",
    "                new_image[i:i+block_size_L2, j:j+block_size_L2] = block\n",
    "        image = new_image      \n",
    "        \n",
    "    if noise_type == 'L1' or noise_type == 'L3': \n",
    "        for i in range(0, image.shape[0], block_size_L1):\n",
    "            for j in range(0, image.shape[1], block_size_L1):\n",
    "                block = image[i:i+block_size_L1, j:j+block_size_L1]\n",
    "                block = (np.random.rand() * intensityL1 + 1) * block\n",
    "                new_image[i:i+block_size_L1, j:j+block_size_L1] = block\n",
    "    \n",
    "    if add_img_grain:\n",
    "        intensity = random.uniform(0, 0.07)  # Random intensity \n",
    "        new_image = add_image_grain_TRLRev2(new_image, intensity=intensity)\n",
    "    return new_image\n",
    "#CONST\n",
    "train_SUB_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=179,\n",
    "        zoom_range=0.18, \n",
    "        shear_range=0.18,\n",
    "        width_shift_range=0.18,\n",
    "        brightness_range=(0.82, 1.18),\n",
    "        height_shift_range=0.18,\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        zca_whitening=False,\n",
    "        interpolation_order=2,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=noise_func_TRLRev2 if Use_noise_func_TRLRev2 else None\n",
    "    )\n",
    "class TerminateOnHighTemp(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, active=True, check_every_n_batches=2, high_temp=75, low_temp=60, pause_time=60):\n",
    "        super().__init__()\n",
    "        self.active = active\n",
    "        self.check_every_n_batches = check_every_n_batches\n",
    "        self.high_temp = high_temp\n",
    "        self.low_temp = low_temp\n",
    "        self.pause_time = pause_time\n",
    "        self.batch_counter = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if not self.active:\n",
    "            return\n",
    "        self.batch_counter += 1\n",
    "        if self.batch_counter % self.check_every_n_batches == 0:\n",
    "            temperature = gpu_control.get_temperature()\n",
    "            if temperature > self.high_temp:\n",
    "                print_Color(f'\\nPausing training due to high GPU temperature! (for [{self.pause_time}]sec)', ['red'], advanced_mode=False)\n",
    "                time.sleep(self.pause_time) \n",
    "                while gpu_control.get_temperature() > self.low_temp:\n",
    "                    time.sleep(4)\n",
    "                print_Color('Resuming training...', ['yellow'])\n",
    "class ExtendedTensorBoard(TensorBoard):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        logs['momentum'] = self.model.optimizer.momentum  \n",
    "        super().on_epoch_end(epoch, logs)\n",
    "class DummyCallback(Callback):\n",
    "    pass\n",
    "def DummyFunc(*Dummy_args, **Dummy_kwargs):\n",
    "    pass\n",
    "# Define a function to plot the confusion matrix\n",
    "def plot_confusion_matrix_TensorBoard(epoch, logs):\n",
    "    # Use the model to predict the values from the test dataset.\n",
    "    test_pred_raw = model.predict(x_test, verbose=0)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)  # Convert predictions from one-hot encoded to binary\n",
    "\n",
    "    # Convert true labels from one-hot encoded to binary\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate the confusion matrix.\n",
    "    cm = confusion_matrix(y_true, test_pred)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=plt.cm.Blues)\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    # Add image summary\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", image, step=epoch)\n",
    "steps_per_epoch_train_SUB = subset_size // Conf_batch_size_REV2\n",
    "#callbacks>>>\n",
    "# EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                               patience=EarlyStopping_P,\n",
    "                               verbose=1, restore_best_weights=True,\n",
    "                               mode='max'\n",
    "                               ) if Use_ES_ONSUBT else DummyCallback()\n",
    "# ModelCheckpoint \n",
    "checkpoint_SUB = ModelCheckpoint(f'cache\\\\model_SUB_checkpoint-{{epoch:03d}}-{{{load_SUB_BRW_MODE}:.4f}}.h5', # f'cache\\\\model_SUB_checkpoint-{{epoch:03d}}-{{{load_SUB_BRW_MODE}:.4f}}.h5', \n",
    "                                 monitor=load_SUB_BRW_MODE,\n",
    "                                 save_best_only=True, mode=ModelCheckpoint_mode,\n",
    "                                 save_weights_only = True\n",
    "                                 ) if load_SUB_BRW else DummyCallback()\n",
    "checkpoint_SUB.best = ModelCheckpoint_Reset_TO\n",
    "# TerminateOnHighTemp\n",
    "TerminateOnHighTemp_CB = TerminateOnHighTemp(active=TerminateOnHighTemp_M,\n",
    "                                             check_every_n_batches=6,\n",
    "                                             high_temp=73,\n",
    "                                             low_temp=58,\n",
    "                                             pause_time=60)\n",
    "# confusion_matrix_callback\n",
    "confusion_matrix_callback = LambdaCallback(on_epoch_end=plot_confusion_matrix_TensorBoard) if Show_confusion_matrix_tensorBoard else DummyCallback()\n",
    "# TensorBoard\n",
    "log_dir = 'logs/fit/' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')\n",
    "if Show_confusion_matrix_tensorBoard:\n",
    "    file_writer = tf.summary.create_file_writer(log_dir)\n",
    "if Use_extended_tensorboard:\n",
    "    tensorboard_callback = ExtendedTensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        write_images=Use_tensorBoard_img,  \n",
    "        histogram_freq=1,\n",
    "        update_freq='epoch',\n",
    "        write_grads=True,\n",
    "        profile_batch='256,512' if Use_tensorboard_profiler else 0\n",
    "    )\n",
    "else:\n",
    "    tensorboard_callback = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        write_images=Use_tensorBoard_img, \n",
    "        histogram_freq=1,\n",
    "        update_freq='epoch',\n",
    "        write_grads=True,\n",
    "        profile_batch='256,512' if Use_tensorboard_profiler else 0\n",
    "    )\n",
    "# OneCycleLr\n",
    "if OneCycleLr_UFTS and Use_OneCycleLr:    \n",
    "    learning_rate_schedule_SUB = OneCycleLr(max_lr=MAX_LR,\n",
    "                                            steps_per_epoch=steps_per_epoch_train_SUB,\n",
    "                                            epochs=(PL_epoch * subset_epoch) + ((max_epoch - PL_epoch) * subset_epoch_FT))    \n",
    "# ReduceLROnPlateau\n",
    "if not Use_OneCycleLr:\n",
    "    learning_rate_schedule_SUB = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                                   factor=0.1,\n",
    "                                                   patience=subset_epoch * 6,\n",
    "                                                   min_lr=MIN_LR,\n",
    "                                                   verbose=1)\n",
    "    learning_rate_schedule_SUB.on_train_begin = DummyFunc # Remove on_train_begin to make it work with subset training.\n",
    "#PRES\n",
    "# ...\n",
    "#MAIN\n",
    "print('Training the model...')\n",
    "# INFOp\n",
    "print_Color('\\nSetup Verbose:', ['yellow'])\n",
    "print_Color(f'~*Setting TensorBoard Log dir to ~*[{log_dir}]~*...', ['cyan', 'green', 'cyan'], advanced_mode=True)\n",
    "print_Color(f'~*Use_extended_tensorboard ~*[{Use_extended_tensorboard}]~*.', ['cyan', 'green', 'cyan'], advanced_mode=True)\n",
    "print_Color(f'~*Debug_OUTPUT_DPS ~*[{Debug_OUTPUT_DPS}]~*.', ['cyan', 'green', 'cyan'], advanced_mode=True)\n",
    "print_Color(f'~*Use_OneCycleLr ~*[{Use_OneCycleLr}]~*.', ['cyan', 'green', 'cyan'], advanced_mode=True)\n",
    "print_Color(f'~*OneCycleLr_UFTS ~*[{OneCycleLr_UFTS}]~*.', ['cyan', 'green', 'cyan'], advanced_mode=True)\n",
    "#warnings\n",
    "P_warning('RES_Train is True.') if RES_Train else None\n",
    "print_Color('Setup Verbose END.', ['yellow'])\n",
    "# MAIN LOOP\n",
    "try:\n",
    "    for epoch in range(1, max_epoch):\n",
    "        # Start Epoch\n",
    "        STG = 'Learning the patterns' if epoch < PL_epoch else 'Fine tuning'\n",
    "        C_subset_epoch = subset_epoch if epoch < PL_epoch else subset_epoch_FT\n",
    "        if epoch > PL_epoch and load_SUB_BRW_LMODE_FN: load_SUB_BRW_LMODE = 1\n",
    "        start_FULL_time = time.time()\n",
    "        if Auto_clear_cache:\n",
    "            subprocess.run([\"Cache_clear.cmd\"], shell=True)\n",
    "        # TSEC: Total-Subset-Epoch-Count\n",
    "        print_Color(f'\\n~*Epoch: ~*{epoch}~*/~*{max_epoch} (TSEC: {Total_SUB_epoch_C})~* | ~*[{STG}]', ['normal', 'cyan', 'normal', 'green', 'blue', 'green'], advanced_mode=True)\n",
    "        # DP\n",
    "        if not AdvSubsetC:\n",
    "            print_Color('Shuffling data...', ['yellow'])\n",
    "            x_train, y_train = shuffle_data(x_train, y_train)\n",
    "        print_Color(f'~*Taking a subset of ~*[|{subset_size}|AdvSubset:{AdvSubsetC}]~*...', ['yellow', 'green', 'yellow'], advanced_mode=True)\n",
    "        if AdvSubsetC:\n",
    "            if AdvSubsetC_SHR > 0 and epoch % AdvSubsetC_SHR == 0:\n",
    "                print_Color('‚îî‚îÄ‚îÄ‚îÄShuffling data...', ['yellow'])\n",
    "                x_train, y_train = shuffle_data(x_train, y_train)\n",
    "                chosen_indices = []  # Reset chosen_indices\n",
    "\n",
    "            available_indices = list(set(range(x_train.shape[0])) - set(chosen_indices))\n",
    "            \n",
    "            if len(available_indices) < subset_size:\n",
    "                #DEBUG\n",
    "                # print('[DEBUG]-[AdvSubset]: Not enough available indices using the indices that were chosen the longest time ago.')\n",
    "                # If there are not enough available indices, choose from the indices that were chosen the longest time ago\n",
    "                old_indices = chosen_indices[:subset_size - len(available_indices)]\n",
    "                subset_indices = old_indices + list(np.random.choice(available_indices, len(available_indices), replace=False))\n",
    "                \n",
    "                # Update the list of chosen indices and their sizes\n",
    "                chosen_indices = chosen_indices[len(old_indices):] + subset_indices\n",
    "                subset_sizes = subset_sizes[len(old_indices):] + [subset_size] * len(subset_indices)\n",
    "            else:\n",
    "                subset_indices = list(np.random.choice(available_indices, subset_size, replace=False))\n",
    "                \n",
    "                # Add the chosen indices to the list of already chosen indices\n",
    "                chosen_indices += subset_indices\n",
    "                subset_sizes += [subset_size] * len(subset_indices)\n",
    "        else:\n",
    "            subset_indices = np.random.choice(x_train.shape[0], subset_size, replace=False)\n",
    "        # Taking the subset\n",
    "        x_SUB_train = x_train[subset_indices]\n",
    "        y_SUB_train = y_train[subset_indices]\n",
    "        x_SUB_train, y_SUB_train = shuffle_data(x_SUB_train, y_SUB_train)\n",
    "        assert len(x_SUB_train) == subset_size, f'Expected subset size of {subset_size}, but got {len(x_SUB_train)}'\n",
    "        print_Color('Preparing train data...', ['yellow']) \n",
    "        # if epoch == 1: # OLD\n",
    "        #     print_Color('- ImageDataGenerator fit...', ['yellow']) \n",
    "        #     train_SUB_datagen.fit(x_SUB_train * 255, augment=True, rounds=6)\n",
    "        #     print_Color('- ImageDataGenerator fit done.', ['yellow'])\n",
    "        if epoch == 1 or ALWAYS_REFIT_IDG == 2:\n",
    "            if os.path.exists(IDG_FitP_PATH) and not ALWAYS_REFIT_IDG:\n",
    "                print_Color('- Loading fitted ImageDataGenerator...', ['yellow'])\n",
    "                train_SUB_datagen = pickle.load(open(IDG_FitP_PATH, 'rb')) \n",
    "            else:\n",
    "                print_Color('- Fitting ImageDataGenerator...', ['yellow'])\n",
    "                IDG_FIT_rc = 3 if ALWAYS_REFIT_IDG == 2 else 12\n",
    "                train_SUB_datagen.fit(x_SUB_train * 255, augment=True, rounds=6)\n",
    "                pickle.dump(train_SUB_datagen, open(IDG_FitP_PATH, 'wb'))\n",
    "            print_Color('- ImageDataGenerator fit done.', ['yellow']) \n",
    "\n",
    "        print_Color('- Augmenting Image Data...', ['yellow'])    \n",
    "        train_SUB_augmented_images = train_SUB_datagen.flow(x_SUB_train * 255,\n",
    "                                                            y_SUB_train,\n",
    "                                                            shuffle=False,\n",
    "                                                            batch_size=len(x_SUB_train)\n",
    "                                                            ).next()\n",
    "        print_Color('- Normalizing Image Data...', ['yellow'])\n",
    "        x_SUB_train = normalize_TO_RANGE(train_SUB_augmented_images[0], 0, 255)\n",
    "        x_SUB_train = apply_clahe_rgb_array(x_SUB_train, 0.5) / 255\n",
    "        # x_SUB_train = x_SUB_train / 255\n",
    "        x_SUB_train = normalize_TO_RANGE(Z_SCORE_normalize(x_SUB_train), 0, 1)\n",
    "        y_SUB_train = train_SUB_augmented_images[1]\n",
    "        # DEBUG\n",
    "        if Debug_OUTPUT_DPS and (epoch % Debug_OUTPUT_DPS_freq == 0 or epoch == 1):\n",
    "            SITD = np.random.choice(subset_size, size=400, replace=False)\n",
    "            S_dir = 'Samples/TSR_SUB_400_' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')\n",
    "            print_Color(f'~*- Debug DP Sample dir: ~*{S_dir}', ['red', 'green'], advanced_mode=True)\n",
    "            save_images_to_dir(np.clip(x_SUB_train[SITD], 0, 1), y_SUB_train[SITD], S_dir)\n",
    "        # learning_rate_schedule_SUB\n",
    "        if PL_epoch == 0:\n",
    "            CU_LR = MIN_LR\n",
    "        elif epoch >= PL_epoch and CU_LR > MIN_LR:\n",
    "            if (CU_LR - DEC_LR) < MIN_LR:\n",
    "                CU_LR = MIN_LR\n",
    "            else:\n",
    "                CU_LR -= DEC_LR\n",
    "        if (not OneCycleLr_UFTS) and Use_OneCycleLr:    \n",
    "            learning_rate_schedule_SUB = OneCycleLr(max_lr=CU_LR,\n",
    "                                                    steps_per_epoch=steps_per_epoch_train_SUB,\n",
    "                                                    epochs=C_subset_epoch)\n",
    "        #FV\n",
    "        if Use_OneCycleLr:\n",
    "            print_Color(f'~*Setting training OneCycleLr::maxlr to ~*[{(str(round(CU_LR, 8)) + \"~*~*\") if not OneCycleLr_UFTS else \"~*OneCycleLr_UFTS Is ON~*\"}]~*...',\n",
    "                        ['yellow', 'green', 'red', 'green', 'yellow'], advanced_mode=True)\n",
    "        print_Color(f'~*Setting training subset epoch.c to ~*[{C_subset_epoch}]~*...', ['yellow', 'green', 'yellow'], advanced_mode=True)\n",
    "        # Train\n",
    "        print_Color('Training on subset...', ['green'])\n",
    "        start_SUBO_time = time.time()\n",
    "        SUB_history = model.fit(x_SUB_train,\n",
    "                            y_SUB_train,\n",
    "                            epochs=C_subset_epoch + Total_SUB_epoch_C, # TO FIX TensorBoard (Total_SUB_epoch_C)\n",
    "                            batch_size=Conf_batch_size_REV2,\n",
    "                            validation_data=(x_test, y_test),\n",
    "                            verbose='auto',\n",
    "                            initial_epoch=Total_SUB_epoch_C, # TO FIX TensorBoard\n",
    "                            callbacks=[\n",
    "                                        learning_rate_schedule_SUB,\n",
    "                                        TerminateOnHighTemp_CB,\n",
    "                                        checkpoint_SUB,\n",
    "                                        early_stopping,\n",
    "                                        tensorboard_callback,\n",
    "                                        confusion_matrix_callback\n",
    "                                        ]\n",
    "        )\n",
    "        end_SUBO_time = time.time()\n",
    "        print_Color('Subset training done.', ['green'])\n",
    "        if load_SUB_BRW_LMODE == 1:\n",
    "            if max(SUB_history.history['val_accuracy']) > best_acc: \n",
    "                load_weights = True \n",
    "            elif min(SUB_history.history['val_loss']) < best_loss:\n",
    "                load_weights = True \n",
    "            else:\n",
    "                load_weights = False    \n",
    "        else: \n",
    "            load_weights = True \n",
    "        \n",
    "        if load_SUB_BRW and load_weights:\n",
    "            print_Color('Loading the best weights...', ['yellow'])\n",
    "            # Get the filename of the best weights file\n",
    "            list_of_files = glob.glob('cache\\\\*.h5') \n",
    "            try:\n",
    "                best_weights_filename = max(list_of_files, key=os.path.getctime)\n",
    "                print_Color(f'Loading weights from file {best_weights_filename}...', ['yellow'])\n",
    "                model.load_weights(best_weights_filename)\n",
    "            except Exception as Err:\n",
    "                print_Color(f'ERROR: Failed to load weights. Error: {Err}', ['red'])\n",
    "        elif load_SUB_BRW and (not load_weights):\n",
    "            print_Color_V2(f'<light_red>Not loading weights<green>[<light_blue>BSR:<yellow>acc{{{max(SUB_history.history[\"val_accuracy\"]):.4f}}}, <yellow>loss{{{min(SUB_history.history[\"val_loss\"]):.4f}}}<light_magenta>|<light_blue>BTR:<green>acc{{{best_acc:.4f}}}, loss{{{best_loss:.4f}}}]')\n",
    "        all_histories.append(SUB_history.history)\n",
    "        checkpoint_SUB.best = ModelCheckpoint_Reset_TO\n",
    "        # Garbage Collection (memory)\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()   \n",
    "        # Evaluate the model on the test data\n",
    "        evaluation = model.evaluate(x_test, y_test, verbose=0)\n",
    "        \n",
    "        # Extract the loss and accuracy from the evaluation results\n",
    "        loss = evaluation[0]\n",
    "        acc = evaluation[1]\n",
    "        print_Color(f'~*Model Test acc: ~*{acc:.4f}', ['yellow', 'green'], advanced_mode=True)\n",
    "        print_Color(f'~*Model Test loss: ~*{loss:.4f}', ['yellow', 'green'], advanced_mode=True)\n",
    "        # If the accuracy is higher than the best_acc\n",
    "        if acc > best_acc:\n",
    "            print_Color_V2(f'<yellow>Improved model accuracy from <green>{best_acc:10f} <yellow>to <green>{acc:10f}<yellow>. <light_cyan>Saving model.')\n",
    "            # Update the best_acc\n",
    "            best_acc = acc\n",
    "            if SAVE_FULLM:\n",
    "                # Save the model\n",
    "                if SAVE_TYPE == 'TF':\n",
    "                    print_Color_V2(f'<cyan>Saving full model tf format...')\n",
    "                    model.save(BEST_RSN, save_format='tf')\n",
    "                else:\n",
    "                    print_Color_V2(f'<cyan>Saving full model H5 format...')\n",
    "                    model.save(f'{BEST_RSN}.h5')\n",
    "            model.save_weights('PAI_model_weights.h5')\n",
    "        else:\n",
    "            print_Color_V2(f'<light_red>Model accuracy did not improve from {best_acc:.10f}. Not saving model.')\n",
    "            \n",
    "        # If the loss is higher than the best_loss\n",
    "        if loss < best_loss:\n",
    "            print_Color_V2(f'<yellow>Improved model loss from <green>{best_loss:.10f} <yellow>to <green>{loss:.10f}<yellow>. <light_cyan>Saving model.')\n",
    "            \n",
    "            # Update the best_acc\n",
    "            best_loss = loss\n",
    "            \n",
    "            if SAVE_FULLM:\n",
    "                # Save the model\n",
    "                if SAVE_TYPE == 'TF':\n",
    "                    print_Color_V2(f'<cyan>Saving full model tf format...')\n",
    "                    model.save(BEST_RSN + '_BL', save_format='tf')\n",
    "                else:\n",
    "                    print_Color_V2(f'<cyan>Saving full model H5 format...')\n",
    "                    model.save(f'{BEST_RSN}_BL.h5')\n",
    "            model.save_weights('PAI_model_weights_BL.h5')\n",
    "        else:\n",
    "            print_Color_V2(f'<light_red>Model loss did not improve from {best_loss:.10f}. Not saving model.') \n",
    "        # Garbage Collection (memory)\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()   \n",
    "        # Epoch end\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_FULL_time\n",
    "        print_Color_V2(f'<yellow>Time taken for epoch(FULL): <green>{epoch_time:.2f} <cyan>sec')\n",
    "        epoch_SUB_time = end_SUBO_time - start_SUBO_time\n",
    "        print_Color_V2(f'<yellow>Time taken for epoch(SUBo): <green>{epoch_SUB_time:.2f} <cyan>sec')\n",
    "        epoch_OTHERO_time = epoch_time - epoch_SUB_time\n",
    "        print_Color_V2(f'<yellow>Time taken for epoch(OTHERo): <green>{epoch_OTHERO_time:.2f} <cyan>sec')\n",
    "        print_Color(f'<---------------------------------------|Epoch [{epoch}] END|--------------------------------------->', ['cyan'])\n",
    "        Total_SUB_epoch_C += C_subset_epoch # TO FIX TensorBoard\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nKeyboardInterrupt. (Training stopped)')\n",
    "# End\n",
    "try:\n",
    "    history = {}\n",
    "    for key in all_histories[0].keys():\n",
    "        # For each metric, concatenate the values from all histories\n",
    "        history[key] = np.concatenate([h[key] for h in all_histories])\n",
    "except Exception as Err:\n",
    "    print(f'Failed to make model `history` var.\\nERROR: {Err}')\n",
    "    \n",
    "print('Training done.\\n')\n",
    "# del vars\n",
    "try:\n",
    "    del train_SUB_datagen\n",
    "    del train_SUB_augmented_images\n",
    "    del x_SUB_train\n",
    "    del y_SUB_train\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rev1 (‚ö†Ô∏èdeprecated‚ö†Ô∏è)\n",
    "```\n",
    "Working: ‚úÖ\n",
    "Other:\n",
    " + Tensorboard works.\n",
    " - Can cause overfitting.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "#CONF\n",
    "Conf_batch_size = 8 \n",
    "OneCycleLr_epoch = 20\n",
    "Learning_rate_conf = 3 # 1 and 2 for custom learning_rate_fn and 3 for OneCycleLr (Better for full training)\n",
    "#TensorBoard conf\n",
    "TensorBoard_UF = 1 # 1 for Slow 2 for fast (very slow tarining)\n",
    "# Learning rate configuration\n",
    "Learning_rate_conf_SET2C = 3 # 1 for SGD and 2 for Adam and... for lower lr 3 for very high lr\n",
    "MAX_LR = 0.0174\n",
    "# First time\n",
    "if Learning_rate_conf == 1:\n",
    "    learning_rate_start = 8e-04\n",
    "    learning_rate_max = 5e-03\n",
    "    learning_rate_min = 5e-05\n",
    "    learning_rate_rampup_epochs = 5\n",
    "    learning_rate_sustain_epochs = 1\n",
    "    learning_rate_exp_decay = .3\n",
    "    #TEMP\n",
    "    # learning_rate_start = 8e-04\n",
    "    # learning_rate_max = 1e-02\n",
    "    # learning_rate_min = 8e-04\n",
    "    # learning_rate_rampup_epochs = 5\n",
    "    # learning_rate_sustain_epochs = 3\n",
    "    # learning_rate_exp_decay = .45\n",
    "# 2th time\n",
    "if Learning_rate_conf == 2:\n",
    "    if Learning_rate_conf_SET2C == 1:\n",
    "        learning_rate_start = 4.10e-06\n",
    "        learning_rate_max = 4.10e-06\n",
    "        learning_rate_min = 4.10e-06\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = .1\n",
    "        \n",
    "    elif Learning_rate_conf_SET2C == 2:\n",
    "        learning_rate_start = 4e-07\n",
    "        learning_rate_max = 4e-07\n",
    "        learning_rate_min = 4e-07\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = .1\n",
    "    \n",
    "    elif Learning_rate_conf_SET2C == 3:\n",
    "        learning_rate_start = 5e-04\n",
    "        learning_rate_max = 5e-04\n",
    "        learning_rate_min = 5e-04\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = .1\n",
    "# Function to build learning rate schedule\n",
    "if Learning_rate_conf in [1,2]:\n",
    "    def build_learning_rate_fn(lr_start=learning_rate_start,\n",
    "                            lr_max=learning_rate_max,\n",
    "                            lr_min=learning_rate_min,\n",
    "                            lr_rampup_epochs=learning_rate_rampup_epochs,\n",
    "                            lr_sustain_epochs=learning_rate_sustain_epochs,\n",
    "                            lr_exp_decay=learning_rate_exp_decay):    \n",
    "        lr_max = lr_max * tf.distribute.get_strategy().num_replicas_in_sync\n",
    "        def learning_rate_fn(epoch):\n",
    "            if epoch < lr_rampup_epochs:\n",
    "                lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "            elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "                lr = lr_max\n",
    "            else:\n",
    "                lr = (lr_max - lr_min) *\\\n",
    "                    lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "            return lr\n",
    "        return learning_rate_fn\n",
    "    \n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch_train = len(x_train) // Conf_batch_size\n",
    "\n",
    "# Set up callbacks\n",
    "class EpochEndMON(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        optimizer = self.model.optimizer\n",
    "        if hasattr(optimizer, 'lr'):\n",
    "            lr = tf.keras.backend.get_value(optimizer.lr)\n",
    "            print(f'\\nLearning rate for epoch {epoch+1} is {lr}')\n",
    "        if hasattr(optimizer, 'momentum'):\n",
    "            momentum = tf.keras.backend.get_value(optimizer.momentum)\n",
    "            print(f'Momentum for epoch {epoch+1} is {momentum}')\n",
    "        if logs:\n",
    "            val_loss = logs.get('val_loss')\n",
    "            val_acc = logs.get('val_accuracy')\n",
    "            print(f'Validation loss for epoch {epoch+1} is {val_loss}')\n",
    "            print(f'Validation accuracy for epoch {epoch+1} is {val_acc}')\n",
    "\n",
    "        print_Color_V2(f'`red`<!--------------------------------------|Epoch`yellow` [{epoch+1}]`red` End|--------------------------------------!> `green`PBE‚Üì', start_char='`', end_char='`')\n",
    "\n",
    "# Instantiate the callback\n",
    "EpochEndMON_callback = EpochEndMON()\n",
    "if Learning_rate_conf in [1,2]:\n",
    "    learning_rate_fn = build_learning_rate_fn()\n",
    "    learning_rate_schedule = LearningRateScheduler(learning_rate_fn, verbose=1)\n",
    "else:\n",
    "    learning_rate_schedule = OneCycleLr(max_lr=MAX_LR, steps_per_epoch=steps_per_epoch_train, epochs=OneCycleLr_epoch)\n",
    "if SAVE_TYPE == 'TF':\n",
    "    checkpoint_BVAC = ModelCheckpoint('models\\\\Temp\\\\bestVAC_model', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "    checkpoint_BVL = ModelCheckpoint('models\\\\Temp\\\\bestVL_model', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "else:\n",
    "    checkpoint_BVAC = ModelCheckpoint('models\\\\Temp\\\\bestVAC_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "    checkpoint_BVL = ModelCheckpoint('models\\\\Temp\\\\bestVL_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1, restore_best_weights=True)\n",
    "log_dir = 'logs/fit/' + datetime.datetime.now().strftime('y%Y_m%m_d%d-h%H_m%M_s%S')\n",
    "TensorBoard_update_freq = 'batch' if TensorBoard_UF == 2 else 'epoch'\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, write_images=True, histogram_freq=1, update_freq=TensorBoard_update_freq, write_grads=True)\n",
    "\n",
    "# Train the model\n",
    "print('Log dir:', log_dir)\n",
    "#MInfo\n",
    "print('Input Shape:', model.input_shape)\n",
    "print('Output Shape:', model.output_shape)\n",
    "print('Loss Function:', model.loss)\n",
    "print('Training the model...\\n')\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=256,\n",
    "                    batch_size=Conf_batch_size,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose='auto',\n",
    "                    callbacks=[early_stopping,\n",
    "                            tensorboard_callback,\n",
    "                            learning_rate_schedule,\n",
    "                            checkpoint_BVAC,\n",
    "                            checkpoint_BVL,\n",
    "                            EpochEndMON_callback])\n",
    "print('Training done.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "Extra_EXT = '_T'\n",
    "# Save the weights\n",
    "print('Saving weights...')\n",
    "model.save_weights('PAI_model_weights.h5')\n",
    "print('Saving full model...')\n",
    "if SAVE_TYPE == 'TF':\n",
    "    print('Saving full model tf format...')\n",
    "    model.save(f'PAI_model{Extra_EXT}', save_format='tf')\n",
    "else:\n",
    "    try:\n",
    "        model.save(f'PAI_model{Extra_EXT}.h5')\n",
    "    except ValueError:\n",
    "        print('failed to save in .h5 format!')\n",
    "        print('Saving full model in tf format...')\n",
    "        model.save(f'PAI_model{Extra_EXT}', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage Collection (memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse model Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "save_list(history, 'history\\\\model_history.pkl.gz', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load history\n",
    "history = load_list('history\\\\model_history.pkl.gz', compressed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T07:04:52.565658900Z",
     "start_time": "2023-12-28T07:04:51.032425100Z"
    }
   },
   "outputs": [],
   "source": [
    "from turtle import left\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Chunk size for 3D plot\n",
    "chunk_size = 6  # Change this to your desired chunk size\n",
    "    \n",
    "def convert_history(history):\n",
    "    if isinstance(history, tf.keras.callbacks.History):\n",
    "        return history.history\n",
    "    else:\n",
    "        return history\n",
    "    \n",
    "def chunked_data(data, chunk_size):\n",
    "    return [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "\n",
    "try:\n",
    "    EPM = 'Epoch(Subset)' if not isinstance(history, tf.keras.callbacks.History) else 'Epoch'    \n",
    "    history = convert_history(history)\n",
    "\n",
    "    # Calculate deltas\n",
    "    delta_loss = np.diff(history['loss'])\n",
    "    delta_accuracy = np.diff(history['accuracy'])\n",
    "\n",
    "    try:\n",
    "        delta_val_loss = np.diff(history['val_loss'])\n",
    "        delta_val_accuracy = np.diff(history['val_accuracy'])\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load val_loss or val_accuracy for delta calculation.')\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    # Loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history['loss'], label='loss')\n",
    "    try:\n",
    "        plt.plot(history['val_loss'], label='val_loss', color='orange')\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load val_loss.')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel(EPM)\n",
    "    plt.ylim(top=max(history['val_loss'][10:]), bottom=0) # (max(history['val_loss'][8:]) + min(history['val_loss'])) / 2\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Density plot for loss\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hist(history['loss'], label='loss density', color='blue', alpha=0.5, bins=100)\n",
    "    try:\n",
    "        plt.hist(history['val_loss'], label='val_loss density', color='orange', alpha=0.5, bins=100)\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load val_loss (density plot).')\n",
    "    plt.title('Density Plot for Loss')\n",
    "    plt.xlabel('Loss')\n",
    "    plt.xlim(right=max(history['val_loss'][10:]), left=0) # (max(history['val_loss'][8:]) + min(history['val_loss'])) / 2\n",
    "    plt.grid(True)\n",
    "    \n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history['accuracy'], label='accuracy')\n",
    "    try:\n",
    "        plt.plot(history['val_accuracy'], label='val_accuracy', color='orange')\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load val_accuracy.')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Density plot for accuracy\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.hist(history['accuracy'], label='accuracy density', color='blue', alpha=0.5, bins=40)\n",
    "    try:\n",
    "        plt.hist(history['val_accuracy'], label='val_accuracy density', color='orange', alpha=0.5, bins=40)\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load val_accuracy (density plot).')\n",
    "    plt.title('Density Plot for Accuracy')\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Delta Loss\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(delta_loss, label='delta_loss')\n",
    "    try:\n",
    "        plt.plot(delta_val_loss, label='delta_val_loss', color='orange')\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load delta_val_loss.')\n",
    "    plt.title('Delta Model Loss')\n",
    "    plt.ylabel('Delta Loss')\n",
    "    plt.ylim(top=1.5, bottom=-1.5) \n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "    # Delta Accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(delta_accuracy, label='delta_accuracy')\n",
    "    try:\n",
    "        plt.plot(delta_val_accuracy, label='delta_val_accuracy', color='orange')\n",
    "    except (ValueError, NameError):\n",
    "        print('\\033[91mfailed to load delta_val_accuracy.')\n",
    "    plt.title('Delta Model Accuracy')\n",
    "    plt.ylabel('Delta Accuracy')\n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Calculate chunked data\n",
    "    chunked_loss = chunked_data(history['val_loss'], chunk_size)\n",
    "    chunked_accuracy = chunked_data(history['val_accuracy'], chunk_size)\n",
    "\n",
    "    # Clip the loss values to a maximum of max(history['val_loss'][10:])\n",
    "    max_loss = max(history['val_loss'][10:])\n",
    "    chunked_loss = np.clip(chunked_loss, a_min=None, a_max=max_loss)\n",
    "\n",
    "    # Create 3D surface plots for each chunk\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    ax = fig.add_subplot(121, projection='3d')\n",
    "    X = np.arange(len(chunked_loss))\n",
    "    Y = np.arange(chunk_size)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = np.array(chunked_loss).T  # Transpose the array to match the shape of X and Y\n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    ax.set_title('3D Surface Plot of Chunked Loss')\n",
    "    ax.set_xlabel('Chunk Index')\n",
    "    ax.set_ylabel('Epoch')\n",
    "    ax.set_zlabel('Loss')\n",
    "\n",
    "    ax = fig.add_subplot(122, projection='3d')\n",
    "    X = np.arange(len(chunked_accuracy))\n",
    "    Y = np.arange(chunk_size)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = np.array(chunked_accuracy).T  # Transpose the array to match the shape of X and Y\n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    ax.set_title('3D Surface Plot of Chunked Accuracy')\n",
    "    ax.set_xlabel('Chunk Index')\n",
    "    ax.set_ylabel('Epoch')\n",
    "    ax.set_zlabel('Accuracy')\n",
    "\n",
    "        # Function to calculate the average of chunks\n",
    "    def chunked_average(values, chunk_size):\n",
    "        return [np.mean(values[i:i + chunk_size]) for i in range(0, len(values), chunk_size)]\n",
    "\n",
    "    avg_accuracy_chunks = chunked_average(history['val_accuracy'], chunk_size)\n",
    "    avg_loss_chunks = chunked_average(history['val_loss'], chunk_size)\n",
    "\n",
    "    # Find the chunk with the highest average accuracy\n",
    "    max_acc_chunk_index = np.argmax(avg_accuracy_chunks)\n",
    "    max_acc_value = avg_accuracy_chunks[max_acc_chunk_index]\n",
    "\n",
    "    # Create a pile plot for accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(avg_accuracy_chunks)), avg_accuracy_chunks, label='Average Accuracy')\n",
    "    plt.bar(max_acc_chunk_index, max_acc_value, color='red', label='Highest Average Accuracy')\n",
    "    plt.xlabel('Chunk')\n",
    "    plt.ylabel('Average Accuracy')\n",
    "    plt.title('Average Validation Accuracy per Chunk')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create a pile plot for loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(avg_loss_chunks)), avg_loss_chunks, color='green', label='Average Loss')\n",
    "    plt.xlabel('Chunk')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title('Average Validation Loss per Chunk')\n",
    "    plt.legend()\n",
    "\n",
    "    # Function to calculate the average of each epoch across chunks, ignoring the first chunk\n",
    "    def average_across_chunks(values, chunk_size):\n",
    "        num_chunks = len(values) // chunk_size\n",
    "        avg_values = []\n",
    "        for epoch in range(chunk_size):\n",
    "            epoch_values = [values[chunk * chunk_size + epoch] for chunk in range(1, num_chunks)]\n",
    "            avg_values.append(np.mean(epoch_values))\n",
    "        return avg_values\n",
    "\n",
    "    # Calculate the average accuracy and loss for each epoch across chunks, ignoring the first chunk\n",
    "    avg_accuracy_epochs = average_across_chunks(history['val_accuracy'], chunk_size)\n",
    "    avg_loss_epochs = average_across_chunks(history['val_loss'], chunk_size)\n",
    "\n",
    "    # Create a bar plot for average accuracy and loss of each epoch across chunks\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create an index for each epoch\n",
    "    epoch_indices = np.arange(len(avg_accuracy_epochs))\n",
    "\n",
    "    # Plot accuracy and loss as bars\n",
    "    plt.bar(epoch_indices - 0.2, avg_accuracy_epochs, width=0.4, label='Average Accuracy', color='blue', alpha=0.6)\n",
    "    plt.bar(epoch_indices + 0.2, avg_loss_epochs, width=0.4, label='Average Loss', color='orange', alpha=0.6)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Epoch (within chunk)')\n",
    "    plt.ylabel('Average Value')\n",
    "    plt.title('Average Validation Accuracy and Loss for Each Epoch Across Chunks (Ignoring First Chunk)')\n",
    "    plt.xticks(epoch_indices, [f'Epoch {i+1}' for i in epoch_indices])  # Set x-tick labels to epoch numbers\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except (ValueError, NameError) as E:\n",
    "    print(f'\\033[91mFailed to load model history.\\nError: {E}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse model Predicting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from scipy.stats import binom\n",
    "from tqdm import tqdm\n",
    "import efficientnet.tfkeras\n",
    "import cv2\n",
    "import gc\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "\n",
    "Extra_EXT = '_T' # _T or _T_BL\n",
    "Train_data_test = False\n",
    "if SAVE_TYPE == 'TF':\n",
    "    # Load the pre-trained model\n",
    "    model = load_model(f'PAI_model{Extra_EXT}')\n",
    "else:\n",
    "    # Load the pre-trained model\n",
    "    model = load_model(f'PAI_model{Extra_EXT}.h5')\n",
    "\n",
    "# Ensure the model's input_shape matches your data\n",
    "assert model.input_shape[1:] == (img_res[0], img_res[1], img_res[2]), 'Models input shape doesnt match data.'\n",
    "\n",
    "# Make predictions on validation data\n",
    "val_predictions = model.predict(x_val)\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = model.predict(x_test)\n",
    "\n",
    "# Print acc\n",
    "print('Val data acc:')\n",
    "evaluate_model_full(y_val, val_predictions)\n",
    "print('Test data acc:')\n",
    "evaluate_model_full(y_test, test_predictions)\n",
    "\n",
    "# format data\n",
    "val_predictions = np.argmax(val_predictions, axis=1)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "y_val_original = np.argmax(y_val, axis=1)\n",
    "y_test_original = np.argmax(y_test, axis=1)\n",
    "# Visualize the predictions on validation data as a grid of squares\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_val[i])\n",
    "    plt.title(f'True: {y_val_original[i]}\\nPredicted: {val_predictions[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#Heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    img = x_val[i]\n",
    "    heatmap = make_gradcam_heatmap(img[np.newaxis, ...], model, 'top_activation', second_last_conv_layer_name = 'top_conv', sensitivity_map = 2) \n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    # Apply Adaptive Histogram Equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=1, tileGridSize=(8,8))  # Create CLAHE object\n",
    "    heatmap = clahe.apply(heatmap)\n",
    "    heatmap = cv2.applyColorMap(np.max(heatmap) - heatmap, cv2.COLORMAP_JET)\n",
    "    if RANGE_NOM:\n",
    "        superimposed_img = (heatmap / 255) * 0.4 + img \n",
    "    else:\n",
    "        superimposed_img = (heatmap / 255) * 0.4 + (img / 255)\n",
    "    #clip\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 1)  # ensure the values are in the range [0, 1]\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.title(f'True: {y_val_original[i]}\\nPredicted: {val_predictions[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define the list of labels\n",
    "labels = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "# Create a confusion matrix for validation data\n",
    "val_cm = confusion_matrix(y_val_original, val_predictions)\n",
    "\n",
    "# Create a confusion matrix for test data\n",
    "test_cm = confusion_matrix(y_test_original, test_predictions)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap for validation data\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(val_cm, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix - Validation Data')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Plot the confusion matrix as a heatmap for test data\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(test_cm, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix - Test Data')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Define the range of test data sizes to use\n",
    "data_sizes = range(1, len(x_test), 4)  \n",
    "\n",
    "# Create a list to store the number of incorrect predictions for each test data size\n",
    "incorrect_predictions = []\n",
    "\n",
    "# Generate predictions and track incorrect predictions for each data size\n",
    "for size in tqdm(data_sizes, desc='Predicting', unit='dpb'):\n",
    "    # Garbage Collection (memory)\n",
    "    gc.collect()\n",
    "    # Randomly select a subset of test data\n",
    "    indices = np.random.choice(len(x_test), size, replace=False)\n",
    "    x_test_subset = x_test[indices]\n",
    "    y_test_subset = y_test[indices]\n",
    "\n",
    "    # Make predictions on the subset of test data\n",
    "    test_predictions = model.predict(x_test_subset, batch_size=1, verbose=0, max_queue_size=120, workers=1, use_multiprocessing=False)\n",
    "    test_predictions = np.argmax(test_predictions, axis=1)\n",
    "    y_test_original_subset = np.argmax(y_test_subset, axis=1)\n",
    "\n",
    "    # Calculate the number of incorrect predictions\n",
    "    incorrect_preds = np.sum(test_predictions != y_test_original_subset)\n",
    "    incorrect_predictions.append(incorrect_preds)\n",
    "    \n",
    "# Plot the number of incorrect predictions vs. the number of data points\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_sizes, incorrect_predictions)\n",
    "plt.xlabel('Number of Data Points')\n",
    "plt.ylabel('Number of Incorrect Predictions')\n",
    "# Add gridlines for the x and y axes\n",
    "plt.grid(True)\n",
    "\n",
    "# Change the tick spacing for the x and y axes\n",
    "plt.xticks(np.arange(min(data_sizes), max(data_sizes)+1, 50))\n",
    "plt.yticks(np.arange(0, max(incorrect_predictions) + 5, 3))\n",
    "\n",
    "plt.title('Number of Incorrect Predictions vs. Number of Data Points')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
