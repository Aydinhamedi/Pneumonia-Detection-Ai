{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pylibs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "import gpu_control\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Input, GlobalAveragePooling2D, CuDNNLSTM, concatenate, Reshape\n",
    "\n",
    "# Utils\n",
    "from Utils.one_cycle import OneCycleLr\n",
    "from Utils.lr_find import LrFinder\n",
    "from Utils.print_color_V2_NEW import print_Color_V2\n",
    "from Utils.print_color_V1_OLD import print_Color\n",
    "\n",
    "# Other\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "for gpu_instance in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "train_dir = \"Data_set/train\"\n",
    "test_dir = \"Data_set/test\"\n",
    "validation_dir = \"Data_set/val\"\n",
    "img_res = [224, 224, 3]\n",
    "# img_res = [224, 224, 3]\n",
    "# img_res = [384, 384, 3] # Very slow needs >=24Gb Vram for batch size of 1 (NR!)\n",
    "interpolation_order_IFG = 2\n",
    "categorical_IMP = True\n",
    "Make_EV_DATA = False\n",
    "R_fill_mode = True\n",
    "add_img_grain = True\n",
    "Save_TS = True\n",
    "ADBD = 1\n",
    "OP_HDC = False\n",
    "SL_EX = \"_V1\"  # _NONOM_V1 | _V1 | _SDNP_V1\n",
    "LNTS = 0\n",
    "adjust_brightness_Mode = True\n",
    "RANGE_NOM = True  # False for 0 to 255 True for 0 to 1 >> use False for models like ConvNeXtXLarge\n",
    "scale_data_NP_M = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_TYPE = \"H5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33mUsing Def IDG...\u001b[0m\n",
      "Found 8818 images belonging to 2 classes.\n",
      "\u001b[0;33mLoading all images and labels into memory...\u001b[0m\n",
      "\u001b[0;33mMaking categorical data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mGenerating augmented data \u001b[0m\u001b[0;36m[\u001b[0m\u001b[0;32mADBD: \u001b[0m\u001b[0;31m1\u001b[0m\u001b[0;36m]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      ">   Generating ADB[1/1]...\n",
      ">   â”œâ”€â”€â”€Applying adaptive histogram equalization...\n",
      ">   â”œâ”€â”€â”€Adaptive histogram equalization clip limit = 1.6\n",
      ">   â””â”€â”€â”€Adding the Generated ADB...\n",
      "\u001b[0;33mNormalizing image data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mGrayscale range: \u001b[0m\u001b[0;34mMin = 0.0\u001b[0m\u001b[0m | \u001b[0m\u001b[0;31mMax = 1.0\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mData type: \u001b[0m\u001b[0;32mfloat32\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mLabel ratio: \u001b[0m\u001b[0;31m44.62% PNEUMONIA \u001b[0m\u001b[0;35m| \u001b[0m\u001b[0;32m55.38% NORMAL\u001b[0m\n",
      "\u001b[0;33mSetting LNTS...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mOriginal num_samples: \u001b[0m\u001b[0;32m17636\u001b[0m\n",
      "\u001b[0;33mshuffling data...\u001b[0m\n",
      "\u001b[0;33mSaving TS...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0mSample dir: \u001b[0m\u001b[0;32mSamples/TSR400_y2023_m11_d13-h20_m09_s53\u001b[0m\n",
      "\u001b[0;32mDone.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# scale_data\n",
    "def scale_data_NP(data):\n",
    "    if scale_data_NP_M:\n",
    "        data = data.astype(\"float32\")\n",
    "        data = (data - 127.5) / 127.5\n",
    "        return data\n",
    "    else:\n",
    "        return data / 255\n",
    "\n",
    "\n",
    "# add_image_grain\n",
    "def add_image_grain(image, intensity=0.01):\n",
    "    # Generate random noise array\n",
    "    noise = np.random.randint(0, 255, size=image.shape, dtype=np.uint8)\n",
    "\n",
    "    # Scale the noise array\n",
    "    scaled_noise = (noise * intensity).astype(np.float32)\n",
    "    # Add the noise to the image\n",
    "    noisy_image = cv2.add(image, scaled_noise)\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "# adjust_brightness\n",
    "# V1\n",
    "def adjust_brightness(images, target_average):\n",
    "    # Calculate the average pixel value of all the images\n",
    "    overall_average = np.mean(images)\n",
    "\n",
    "    # Iterate over each image in the array\n",
    "    for i in range(len(images)):\n",
    "        # Calculate the average pixel value of the current image\n",
    "        image_average = np.mean(images[i])\n",
    "\n",
    "        # Compare the image average with the overall average\n",
    "        if image_average > overall_average + 10:\n",
    "            # Increase brightness by adding a constant value\n",
    "            images[i] = np.clip(images[i] - random.randint(6, 25), 0, 255)\n",
    "        elif image_average < overall_average - 10:\n",
    "            # Decrease brightness by subtracting a constant value\n",
    "            images[i] = np.clip(images[i] + random.randint(6, 25), 0, 255)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "# V2 (Very slow NOT Recommended)\n",
    "# def adjust_brightness(images, target_average):\n",
    "#     # Calculate the average pixel value of all the images\n",
    "#     overall_average = np.mean(images)\n",
    "\n",
    "#     # Initialize a variable to keep track of the number of deleted images\n",
    "#     deleted_images = 0\n",
    "\n",
    "#     # Create a progress bar\n",
    "#     pbar = tqdm(total=len(images), desc='Processing images')\n",
    "\n",
    "#     # Iterate over each image in the array\n",
    "#     for i in range(len(images)):\n",
    "#         # Adjust the index to account for deleted images\n",
    "#         adjusted_index = i - deleted_images\n",
    "\n",
    "#         # Calculate the average pixel value of the current image\n",
    "#         image_average = np.mean(images[adjusted_index])\n",
    "\n",
    "#         # Compare the image average with the overall average\n",
    "#         if image_average > overall_average + 50 or image_average < overall_average - 60:\n",
    "#             # If the image brightness is 45 units higher than the overall average, delete the image\n",
    "#             images = np.delete(images, adjusted_index, axis=0)\n",
    "#             # Increment the count of deleted images\n",
    "#             deleted_images += 1\n",
    "#         elif image_average > overall_average + 10:\n",
    "#             # Increase brightness by adding a random value between 6 and 25\n",
    "#             images[adjusted_index] = np.clip(images[adjusted_index] - random.randint(6, 25), 0, 255)\n",
    "#         elif image_average < overall_average - 10:\n",
    "#             # Decrease brightness by subtracting a random value between 6 and 25\n",
    "#             images[adjusted_index] = np.clip(images[adjusted_index] + random.randint(6, 25), 0, 255)\n",
    "\n",
    "#         # Update the progress bar\n",
    "#         pbar.update(1)\n",
    "\n",
    "#     # Close the progress bar\n",
    "#     pbar.close()\n",
    "\n",
    "\n",
    "#     print(f'deleted_images: {deleted_images}')\n",
    "#     return images\n",
    "# apply_clahe_rgb_array\n",
    "def apply_clahe_rgb_array(images, clip_limit=1.8, tile_grid_size=(8, 8)):\n",
    "    # Create a CLAHE object\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "\n",
    "    # Iterate over each image in the array\n",
    "    for i in range(len(images)):\n",
    "        # Split the image into color channels\n",
    "        b, g, r = cv2.split(images[i])\n",
    "\n",
    "        # Convert the channels to the appropriate format\n",
    "        b = cv2.convertScaleAbs(b)\n",
    "        g = cv2.convertScaleAbs(g)\n",
    "        r = cv2.convertScaleAbs(r)\n",
    "\n",
    "        # Apply adaptive histogram equalization to each channel\n",
    "        equalized_b = clahe.apply(b)\n",
    "        equalized_g = clahe.apply(g)\n",
    "        equalized_r = clahe.apply(r)\n",
    "\n",
    "        # Merge the equalized channels back into an image\n",
    "        equalized_image = cv2.merge((equalized_b, equalized_g, equalized_r))\n",
    "\n",
    "        # Replace the original image with the equalized image in the array\n",
    "        images[i] = equalized_image\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "# noise_func\n",
    "def noise_func(image):\n",
    "    noise_type = np.random.choice([\"L1\", \"L2\", \"L3\", \"none\"])\n",
    "    new_image = np.copy(image)\n",
    "\n",
    "    if noise_type == \"L3\":\n",
    "        intensityL2 = random.uniform(0.001, 0.024)\n",
    "        intensityL1 = random.uniform(0.005, 0.026)\n",
    "    else:\n",
    "        intensityL2 = random.uniform(0.001, 0.037)\n",
    "        intensityL1 = random.uniform(0.001, 0.037)\n",
    "\n",
    "    block_size_L1 = random.randint(16, 32)\n",
    "    block_size_L2 = random.randint(32, 64)\n",
    "\n",
    "    if noise_type == \"L2\" or noise_type == \"L3\":\n",
    "        for i in range(0, image.shape[0], block_size_L2):\n",
    "            for j in range(0, image.shape[1], block_size_L2):\n",
    "                block = image[i : i + block_size_L2, j : j + block_size_L2]\n",
    "                block = (np.random.rand() * intensityL2 + 1) * block\n",
    "                new_image[i : i + block_size_L2, j : j + block_size_L2] = block\n",
    "        image = new_image\n",
    "\n",
    "    if noise_type == \"L1\" or noise_type == \"L3\":\n",
    "        for i in range(0, image.shape[0], block_size_L1):\n",
    "            for j in range(0, image.shape[1], block_size_L1):\n",
    "                block = image[i : i + block_size_L1, j : j + block_size_L1]\n",
    "                block = (np.random.rand() * intensityL1 + 1) * block\n",
    "                new_image[i : i + block_size_L1, j : j + block_size_L1] = block\n",
    "\n",
    "    if add_img_grain:\n",
    "        intensity = random.uniform(0, 0.026)  # Random intensity between 0 and 0.026\n",
    "        new_image = add_image_grain(new_image, intensity=intensity)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "# shuffle_data\n",
    "def shuffle_data(x, y):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# save_images_to_dir\n",
    "def save_images_to_dir(images, labels, dir_path):\n",
    "    # create the directory if it doesn't exist\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    # iterate over the images and labels\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        # get the class label\n",
    "        class_label = np.argmax(label)\n",
    "        # create the file path\n",
    "        file_path = os.path.join(dir_path, f\"image_{i}_class_{class_label}.png\")\n",
    "        # save the image to the file path\n",
    "        plt.imsave(file_path, image.squeeze())\n",
    "\n",
    "\n",
    "# Create an ImageDataGenerator for the training set\n",
    "if OP_HDC:\n",
    "    print_Color(\"Using OP_HDC IDG...\", [\"yellow\"])\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=179,\n",
    "        zoom_range=0.24,\n",
    "        shear_range=0.22,\n",
    "        width_shift_range=0.21,\n",
    "        brightness_range=(0.86, 1.13),\n",
    "        height_shift_range=0.21,\n",
    "        channel_shift_range=100,\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        fill_mode=\"nearest\",  # constant\n",
    "        preprocessing_function=noise_func,\n",
    "    )\n",
    "else:\n",
    "    print_Color(\"Using Def IDG...\", [\"yellow\"])\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=179,\n",
    "        zoom_range=0.26,\n",
    "        shear_range=0.25,\n",
    "        width_shift_range=0.25,\n",
    "        brightness_range=(0.8, 1.2),\n",
    "        height_shift_range=0.25,\n",
    "        channel_shift_range=100,\n",
    "        featurewise_center=False,\n",
    "        interpolation_order=interpolation_order_IFG,\n",
    "        featurewise_std_normalization=False,\n",
    "        fill_mode=\"nearest\",  # constant\n",
    "        preprocessing_function=noise_func,\n",
    "    )\n",
    "train_datagen_SM = ImageDataGenerator(\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.07,\n",
    "    shear_range=0.07,\n",
    "    width_shift_range=0.07,\n",
    "    brightness_range=(0.99, 1.01),\n",
    "    height_shift_range=0.07,\n",
    "    channel_shift_range=0,\n",
    "    featurewise_center=False,\n",
    "    interpolation_order=interpolation_order_IFG,\n",
    "    featurewise_std_normalization=False,\n",
    ")\n",
    "# Create an iterator for the training set\n",
    "train_generator_SM = train_datagen_SM.flow_from_directory(\n",
    "    train_dir, target_size=(img_res[0], img_res[1]), batch_size=sum([len(files) for r, d, files in os.walk(train_dir)]), class_mode=\"binary\"\n",
    ")\n",
    "# Create an ImageDataGenerator for the validation set (OP)\n",
    "if Make_EV_DATA:\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=False, zoom_range=0.01, width_shift_range=0.01, interpolation_order=interpolation_order_IFG, height_shift_range=0.01\n",
    "    )\n",
    "\n",
    "    # Create an iterator for the validation set\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_res[0], img_res[1]),\n",
    "        batch_size=sum([len(files) for r, d, files in os.walk(validation_dir)]),\n",
    "        class_mode=\"binary\",\n",
    "        color_mode=\"rgb\",\n",
    "    )\n",
    "\n",
    "    # Create an ImageDataGenerator for the test set\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        horizontal_flip=False, zoom_range=0.01, width_shift_range=0.01, interpolation_order=interpolation_order_IFG, height_shift_range=0.01\n",
    "    )\n",
    "\n",
    "    # Create an iterator for the test set\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_res[0], img_res[1]),\n",
    "        batch_size=sum([len(files) for r, d, files in os.walk(test_dir)]),\n",
    "        class_mode=\"binary\",\n",
    "        color_mode=\"rgb\",\n",
    "    )\n",
    "# Load all images and labels into memory\n",
    "print_Color(\"Loading all images and labels into memory...\", [\"yellow\"])\n",
    "x_train, y_train = next(iter(train_generator_SM))\n",
    "if Make_EV_DATA:\n",
    "    x_val, y_val = next(iter(val_generator))\n",
    "    x_test, y_test = next(iter(test_generator))\n",
    "# fit parameters from data\n",
    "# train_datagen.fit(x_train)\n",
    "# to_categorical (TEMP)\n",
    "if categorical_IMP:\n",
    "    print_Color(\"Making categorical data...\", [\"yellow\"])\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    if Make_EV_DATA:\n",
    "        y_val = to_categorical(y_val, num_classes=2)\n",
    "        y_test = to_categorical(y_test, num_classes=2)\n",
    "print_Color(\n",
    "    f\"~*Generating augmented data ~*[~*ADBD: ~*{str(ADBD)}~*]~*...\",\n",
    "    [\"yellow\", \"cyan\", \"green\", \"red\", \"cyan\", \"yellow\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "if ADBD > 0:\n",
    "    for i in range(ADBD):\n",
    "        # ADB_clip_limit Scheduler>>>\n",
    "        if i == 0:\n",
    "            ADB_clip_limit = 1.6\n",
    "        else:\n",
    "            # V1>>>\n",
    "            CL_SLM = 2.4\n",
    "            ADB_clip_limit = max(2 / (i + 1) ** CL_SLM, 0.05)\n",
    "            # Try it in win graphing calculator copy and paste:\n",
    "            #  â”Œ-------------â”¬--â”¬---------------â”\n",
    "            #  â”‚ ð‘¦=2/(ð‘¥+1)^ð‘§ â”œORâ”¤ ð‘¦=2/(ð‘¥+1)^2.4 â”‚\n",
    "            #  â””-------------â”´--â”´---------------â”˜\n",
    "            # V2>>>\n",
    "            # CL_SLM_2 = 1.4\n",
    "            # CL_SLM_Start_2 = 2\n",
    "            # ADB_clip_limit = CL_SLM_Start_2/(i+1)**(i+CL_SLM_2)\n",
    "            # Try it in win graphing calculator copy and paste:\n",
    "            #  â”Œ-----------------â”¬--â”¬-------------------â”\n",
    "            #  â”‚ ð‘¦=2/(ð‘¥+1)^(ð‘¥+ð‘‰) â”œORâ”¤ ð‘¦=2/(ð‘¥+1)^(ð‘¥+1.4) â”‚\n",
    "            #  â””-----------------â”´--â”´-------------------â”˜\n",
    "        print(f\">   Generating ADB[{i + 1}/{ADBD}]...\")\n",
    "        # prepare an iterators to scale images\n",
    "        train_iterator = train_datagen.flow(x_train, y_train, batch_size=len(x_train))\n",
    "\n",
    "        # get augmented data\n",
    "        x_train_augmented, y_train_augmented = train_iterator.next()\n",
    "        print(\">   â”œâ”€â”€â”€Applying adaptive histogram equalization...\")\n",
    "        print(f\">   â”œâ”€â”€â”€Adaptive histogram equalization clip limit = {round(ADB_clip_limit, 2)}\")\n",
    "        x_train_augmented = np.clip(x_train_augmented, 0, 255)\n",
    "        # print_Color(f'~*>   |---Grayscale range: ~*Min = {np.min(x_train_augmented)}~* | ~*Max = {np.max(x_train_augmented)}', ['normal', 'blue', 'normal', 'red'], advanced_mode=True)\n",
    "        x_train_augmented = apply_clahe_rgb_array(x_train_augmented, clip_limit=ADB_clip_limit)  # compensating the image info loss\n",
    "        print(\">   â””â”€â”€â”€Adding the Generated ADB...\")\n",
    "        # append augmented data to original data\n",
    "        x_train = np.concatenate([x_train, x_train_augmented])\n",
    "        y_train = np.concatenate([y_train, y_train_augmented])\n",
    "        # free up memory\n",
    "        del y_train_augmented\n",
    "        del x_train_augmented\n",
    "# normalizing\n",
    "print_Color(\"Normalizing image data...\", [\"yellow\"])\n",
    "if adjust_brightness_Mode:\n",
    "    x_train = adjust_brightness(x_train, np.mean(x_train))\n",
    "x_train = np.clip(x_train, 0, 255)\n",
    "if RANGE_NOM:\n",
    "    x_train = scale_data_NP(x_train)\n",
    "y_train = np.array(y_train)\n",
    "if Make_EV_DATA:\n",
    "    x_test = np.clip(x_test, 0, 255)\n",
    "    x_val = np.clip(x_val, 0, 255)\n",
    "    if RANGE_NOM:\n",
    "        x_val = scale_data_NP(x_val)\n",
    "    y_val = np.array(y_val)\n",
    "    if RANGE_NOM:\n",
    "        x_test = scale_data_NP(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "# Check the range of image data\n",
    "print_Color(\n",
    "    f\"~*Grayscale range: ~*Min = {np.min(x_train)}~* | ~*Max = {np.max(x_train)}\", [\"normal\", \"blue\", \"normal\", \"red\"], advanced_mode=True\n",
    ")\n",
    "# Check the data type of image data\n",
    "print_Color(f\"~*Data type: ~*{x_train.dtype}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "# Calculate the ratio of two labels\n",
    "if categorical_IMP:\n",
    "    label_ratio = np.sum(y_train[:, 0]) / (np.sum(y_train[:, 1]) + 1e-10)\n",
    "else:\n",
    "    label_ratio = np.sum(y_train == 0) / (np.sum(y_train == 1) + 1e-10)\n",
    "label_ratio_percentage = label_ratio * 100\n",
    "print_Color(\n",
    "    f\"~*Label ratio: ~*{100 - label_ratio_percentage:.2f}% PNEUMONIA ~*| ~*{label_ratio_percentage:.2f}% NORMAL\",\n",
    "    [\"normal\", \"red\", \"magenta\", \"green\"],\n",
    "    advanced_mode=True,\n",
    ")\n",
    "print_Color(\"Setting LNTS...\", [\"yellow\"])\n",
    "# Get the total number of samples in the arrays\n",
    "num_samples = x_train.shape[0]\n",
    "print_Color(f\"~*Original num_samples: ~*{num_samples}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "if LNTS != 0:\n",
    "    print_Color(f\"~*Applying LNTS of: ~*{LNTS}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "    print_Color(f\"~*SNC: ~*{num_samples - LNTS}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "    # Generate random indices to select LNTS samples\n",
    "    indices = np.random.choice(num_samples, size=LNTS, replace=False)\n",
    "    # Select the samples using the generated indices\n",
    "    x_selected = x_train[indices]\n",
    "    y_selected = y_train[indices]\n",
    "    x_train = x_selected\n",
    "    y_train = y_selected\n",
    "    # free up memory\n",
    "    del x_selected\n",
    "    del y_selected\n",
    "    del indices\n",
    "    # Debug\n",
    "    num_samples = x_train.shape[0]\n",
    "    print_Color(f\"~*New num_samples: ~*{num_samples}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "# Shuffle the training data\n",
    "print_Color(\"shuffling data...\", [\"yellow\"])\n",
    "x_train, y_train = shuffle_data(x_train, y_train)\n",
    "# save_images_to_dir\n",
    "if Save_TS:\n",
    "    print_Color(\"Saving TS...\", [\"yellow\"])\n",
    "    SITD = np.random.choice(num_samples, size=400, replace=False)\n",
    "    S_dir = \"Samples/TSR400_\" + datetime.datetime.now().strftime(\"y%Y_m%m_d%d-h%H_m%M_s%S\")\n",
    "    print_Color(f\"~*Sample dir: ~*{S_dir}\", [\"normal\", \"green\"], advanced_mode=True)\n",
    "    if RANGE_NOM:\n",
    "        if scale_data_NP_M:\n",
    "            save_images_to_dir((x_train[SITD] + 1) / 2.0, y_train[SITD], S_dir)\n",
    "        else:\n",
    "            save_images_to_dir(x_train[SITD], y_train[SITD], S_dir)\n",
    "    else:\n",
    "        save_images_to_dir(x_train[SITD] / 255, y_train[SITD], S_dir)\n",
    "print_Color(\"Done.\", [\"green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save EV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"Database\\\\x_val{SL_EX}.npy\", x_val)\n",
    "np.save(f\"Database\\\\y_val{SL_EX}.npy\", y_val)\n",
    "np.save(f\"Database\\\\x_test{SL_EX}.npy\", x_test)\n",
    "np.save(f\"Database\\\\y_test{SL_EX}.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load EV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "x_val = np.load(f\"Database\\\\x_val{SL_EX}.npy\")\n",
    "y_val = np.load(f\"Database\\\\y_val{SL_EX}.npy\")\n",
    "x_test = np.load(f\"Database\\\\x_test{SL_EX}.npy\")\n",
    "y_test = np.load(f\"Database\\\\y_test{SL_EX}.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1\n",
    "```\n",
    "statuses: Ready\n",
    "Working: âœ…\n",
    "Max fine tuned acc: â‰…95.1\n",
    "Max fine tuned acc TLRev2: N/A\n",
    "type: transfer learning>>>(EfficientNetB7)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling_1 (Rescaling)        (None, 224, 224, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 224, 224, 3)  7          ['rescaling_1[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stem_conv_pad (ZeroPadding2D)  (None, 225, 225, 3)  0           ['normalization_1[0][0]']        \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 112, 112, 64  1728        ['stem_conv_pad[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 64  256         ['stem_conv[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, 112, 112, 64  0           ['stem_bn[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 64  576        ['stem_activation[0][0]']        \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 64  256        ['block1a_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_activation (Activation  (None, 112, 112, 64  0          ['block1a_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (GlobalAver  (None, 64)          0           ['block1a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 64)     0           ['block1a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 16)     1040        ['block1a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 64)     1088        ['block1a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 64  0           ['block1a_activation[0][0]',     \n",
      "                                )                                 'block1a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 32  2048        ['block1a_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1a_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block1b_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1a_project_bn[0][0]']     \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1b_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1b_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1b_activation (Activation  (None, 112, 112, 32  0          ['block1b_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1b_se_squeeze (GlobalAver  (None, 32)          0           ['block1b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1b_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1b_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1b_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1b_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1b_activation[0][0]',     \n",
      "                                )                                 'block1b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1b_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1b_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1b_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1b_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block1b_drop (Dropout)         (None, 112, 112, 32  0           ['block1b_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1b_add (Add)              (None, 112, 112, 32  0           ['block1b_drop[0][0]',           \n",
      "                                )                                 'block1a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block1c_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1b_add[0][0]']            \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1c_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1c_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1c_activation (Activation  (None, 112, 112, 32  0          ['block1c_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1c_se_squeeze (GlobalAver  (None, 32)          0           ['block1c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1c_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1c_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1c_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1c_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1c_activation[0][0]',     \n",
      "                                )                                 'block1c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1c_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1c_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1c_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1c_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block1c_drop (Dropout)         (None, 112, 112, 32  0           ['block1c_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1c_add (Add)              (None, 112, 112, 32  0           ['block1c_drop[0][0]',           \n",
      "                                )                                 'block1b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block1d_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1c_add[0][0]']            \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1d_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1d_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1d_activation (Activation  (None, 112, 112, 32  0          ['block1d_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1d_se_squeeze (GlobalAver  (None, 32)          0           ['block1d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1d_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1d_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1d_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1d_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1d_activation[0][0]',     \n",
      "                                )                                 'block1d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1d_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1d_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1d_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1d_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block1d_drop (Dropout)         (None, 112, 112, 32  0           ['block1d_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1d_add (Add)              (None, 112, 112, 32  0           ['block1d_drop[0][0]',           \n",
      "                                )                                 'block1c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 19  6144        ['block1d_add[0][0]']            \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 19  768        ['block2a_expand_conv[0][0]']    \n",
      " ization)                       2)                                                                \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, 112, 112, 19  0          ['block2a_expand_bn[0][0]']      \n",
      " ivation)                       2)                                                                \n",
      "                                                                                                  \n",
      " block2a_dwconv_pad (ZeroPaddin  (None, 113, 113, 19  0          ['block2a_expand_activation[0][0]\n",
      " g2D)                           2)                               ']                               \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 192)  1728       ['block2a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 192)  768        ['block2a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_activation (Activation  (None, 56, 56, 192)  0          ['block2a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (GlobalAver  (None, 192)         0           ['block2a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 192)  0           ['block2a_activation[0][0]',     \n",
      "                                                                  'block2a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 48)   9216        ['block2a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, 56, 56, 288)  0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_activation (Activation  (None, 56, 56, 288)  0          ['block2b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (GlobalAver  (None, 288)         0           ['block2b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2b_activation[0][0]',     \n",
      "                                                                  'block2b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)         (None, 56, 56, 48)   0           ['block2b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, 56, 56, 48)   0           ['block2b_drop[0][0]',           \n",
      "                                                                  'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2c_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2c_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2c_expand_activation (Act  (None, 56, 56, 288)  0          ['block2c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2c_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2c_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2c_activation (Activation  (None, 56, 56, 288)  0          ['block2c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2c_se_squeeze (GlobalAver  (None, 288)         0           ['block2c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2c_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2c_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2c_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2c_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2c_activation[0][0]',     \n",
      "                                                                  'block2c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2c_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2c_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2c_drop (Dropout)         (None, 56, 56, 48)   0           ['block2c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2c_add (Add)              (None, 56, 56, 48)   0           ['block2c_drop[0][0]',           \n",
      "                                                                  'block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2d_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2d_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2d_expand_activation (Act  (None, 56, 56, 288)  0          ['block2d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2d_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2d_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2d_activation (Activation  (None, 56, 56, 288)  0          ['block2d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2d_se_squeeze (GlobalAver  (None, 288)         0           ['block2d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2d_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2d_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2d_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2d_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2d_activation[0][0]',     \n",
      "                                                                  'block2d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2d_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2d_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2d_drop (Dropout)         (None, 56, 56, 48)   0           ['block2d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2d_add (Add)              (None, 56, 56, 48)   0           ['block2d_drop[0][0]',           \n",
      "                                                                  'block2c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2e_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2e_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2e_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2e_expand_activation (Act  (None, 56, 56, 288)  0          ['block2e_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2e_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2e_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2e_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2e_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2e_activation (Activation  (None, 56, 56, 288)  0          ['block2e_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2e_se_squeeze (GlobalAver  (None, 288)         0           ['block2e_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2e_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2e_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2e_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2e_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2e_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2e_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2e_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2e_activation[0][0]',     \n",
      "                                                                  'block2e_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2e_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2e_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2e_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2e_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2e_drop (Dropout)         (None, 56, 56, 48)   0           ['block2e_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2e_add (Add)              (None, 56, 56, 48)   0           ['block2e_drop[0][0]',           \n",
      "                                                                  'block2d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2f_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2f_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2f_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2f_expand_activation (Act  (None, 56, 56, 288)  0          ['block2f_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2f_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2f_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2f_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2f_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2f_activation (Activation  (None, 56, 56, 288)  0          ['block2f_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2f_se_squeeze (GlobalAver  (None, 288)         0           ['block2f_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2f_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2f_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2f_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2f_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2f_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2f_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2f_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2f_activation[0][0]',     \n",
      "                                                                  'block2f_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2f_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2f_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2f_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2f_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2f_drop (Dropout)         (None, 56, 56, 48)   0           ['block2f_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2f_add (Add)              (None, 56, 56, 48)   0           ['block2f_drop[0][0]',           \n",
      "                                                                  'block2e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2g_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2f_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2g_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2g_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2g_expand_activation (Act  (None, 56, 56, 288)  0          ['block2g_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2g_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2g_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2g_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2g_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2g_activation (Activation  (None, 56, 56, 288)  0          ['block2g_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2g_se_squeeze (GlobalAver  (None, 288)         0           ['block2g_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2g_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2g_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2g_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2g_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2g_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2g_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2g_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2g_activation[0][0]',     \n",
      "                                                                  'block2g_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2g_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2g_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2g_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2g_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2g_drop (Dropout)         (None, 56, 56, 48)   0           ['block2g_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2g_add (Add)              (None, 56, 56, 48)   0           ['block2g_drop[0][0]',           \n",
      "                                                                  'block2f_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2g_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block3a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, 56, 56, 288)  0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_dwconv_pad (ZeroPaddin  (None, 59, 59, 288)  0          ['block3a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 288)  7200       ['block3a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 288)  1152       ['block3a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_activation (Activation  (None, 28, 28, 288)  0          ['block3a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (GlobalAver  (None, 288)         0           ['block3a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block3a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block3a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block3a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 288)  0           ['block3a_activation[0][0]',     \n",
      "                                                                  'block3a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 80)   23040       ['block3a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, 28, 28, 480)  0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_activation (Activation  (None, 28, 28, 480)  0          ['block3b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (GlobalAver  (None, 480)         0           ['block3b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3b_activation[0][0]',     \n",
      "                                                                  'block3b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)         (None, 28, 28, 80)   0           ['block3b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, 28, 28, 80)   0           ['block3b_drop[0][0]',           \n",
      "                                                                  'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3c_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3c_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3c_expand_activation (Act  (None, 28, 28, 480)  0          ['block3c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3c_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3c_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3c_activation (Activation  (None, 28, 28, 480)  0          ['block3c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3c_se_squeeze (GlobalAver  (None, 480)         0           ['block3c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3c_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3c_activation[0][0]',     \n",
      "                                                                  'block3c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3c_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3c_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3c_drop (Dropout)         (None, 28, 28, 80)   0           ['block3c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3c_add (Add)              (None, 28, 28, 80)   0           ['block3c_drop[0][0]',           \n",
      "                                                                  'block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3d_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3d_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3d_expand_activation (Act  (None, 28, 28, 480)  0          ['block3d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3d_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3d_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3d_activation (Activation  (None, 28, 28, 480)  0          ['block3d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3d_se_squeeze (GlobalAver  (None, 480)         0           ['block3d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3d_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3d_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3d_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3d_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3d_activation[0][0]',     \n",
      "                                                                  'block3d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3d_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3d_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3d_drop (Dropout)         (None, 28, 28, 80)   0           ['block3d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3d_add (Add)              (None, 28, 28, 80)   0           ['block3d_drop[0][0]',           \n",
      "                                                                  'block3c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3e_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3e_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3e_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3e_expand_activation (Act  (None, 28, 28, 480)  0          ['block3e_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3e_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3e_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3e_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3e_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3e_activation (Activation  (None, 28, 28, 480)  0          ['block3e_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3e_se_squeeze (GlobalAver  (None, 480)         0           ['block3e_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3e_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3e_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3e_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3e_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3e_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3e_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3e_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3e_activation[0][0]',     \n",
      "                                                                  'block3e_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3e_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3e_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3e_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3e_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3e_drop (Dropout)         (None, 28, 28, 80)   0           ['block3e_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3e_add (Add)              (None, 28, 28, 80)   0           ['block3e_drop[0][0]',           \n",
      "                                                                  'block3d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3f_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3f_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3f_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3f_expand_activation (Act  (None, 28, 28, 480)  0          ['block3f_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3f_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3f_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3f_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3f_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3f_activation (Activation  (None, 28, 28, 480)  0          ['block3f_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3f_se_squeeze (GlobalAver  (None, 480)         0           ['block3f_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3f_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3f_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3f_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3f_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3f_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3f_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3f_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3f_activation[0][0]',     \n",
      "                                                                  'block3f_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3f_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3f_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3f_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3f_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3f_drop (Dropout)         (None, 28, 28, 80)   0           ['block3f_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3f_add (Add)              (None, 28, 28, 80)   0           ['block3f_drop[0][0]',           \n",
      "                                                                  'block3e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3g_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3f_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3g_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3g_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3g_expand_activation (Act  (None, 28, 28, 480)  0          ['block3g_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3g_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3g_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3g_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3g_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3g_activation (Activation  (None, 28, 28, 480)  0          ['block3g_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3g_se_squeeze (GlobalAver  (None, 480)         0           ['block3g_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3g_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3g_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3g_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3g_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3g_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3g_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3g_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3g_activation[0][0]',     \n",
      "                                                                  'block3g_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3g_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3g_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3g_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3g_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3g_drop (Dropout)         (None, 28, 28, 80)   0           ['block3g_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3g_add (Add)              (None, 28, 28, 80)   0           ['block3g_drop[0][0]',           \n",
      "                                                                  'block3f_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3g_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block4a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, 28, 28, 480)  0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_dwconv_pad (ZeroPaddin  (None, 29, 29, 480)  0          ['block4a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_activation (Activation  (None, 14, 14, 480)  0          ['block4a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 480)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4a_activation[0][0]',     \n",
      "                                                                  'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 160)  76800       ['block4a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, 14, 14, 960)  0          ['block4b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, 14, 14, 960)  0          ['block4b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 960)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4b_activation[0][0]',     \n",
      "                                                                  'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)         (None, 14, 14, 160)  0           ['block4b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, 14, 14, 160)  0           ['block4b_drop[0][0]',           \n",
      "                                                                  'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, 14, 14, 960)  0          ['block4c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, 14, 14, 960)  0          ['block4c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 960)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4c_activation[0][0]',     \n",
      "                                                                  'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)         (None, 14, 14, 160)  0           ['block4c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, 14, 14, 160)  0           ['block4c_drop[0][0]',           \n",
      "                                                                  'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4d_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4d_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4d_expand_activation (Act  (None, 14, 14, 960)  0          ['block4d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4d_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4d_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4d_activation (Activation  (None, 14, 14, 960)  0          ['block4d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4d_se_squeeze (GlobalAver  (None, 960)         0           ['block4d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4d_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4d_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4d_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4d_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4d_activation[0][0]',     \n",
      "                                                                  'block4d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4d_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4d_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4d_drop (Dropout)         (None, 14, 14, 160)  0           ['block4d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4d_add (Add)              (None, 14, 14, 160)  0           ['block4d_drop[0][0]',           \n",
      "                                                                  'block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4e_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4e_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4e_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4e_expand_activation (Act  (None, 14, 14, 960)  0          ['block4e_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4e_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4e_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4e_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4e_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4e_activation (Activation  (None, 14, 14, 960)  0          ['block4e_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4e_se_squeeze (GlobalAver  (None, 960)         0           ['block4e_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4e_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4e_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4e_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4e_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4e_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4e_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4e_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4e_activation[0][0]',     \n",
      "                                                                  'block4e_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4e_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4e_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4e_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4e_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4e_drop (Dropout)         (None, 14, 14, 160)  0           ['block4e_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4e_add (Add)              (None, 14, 14, 160)  0           ['block4e_drop[0][0]',           \n",
      "                                                                  'block4d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4f_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4f_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4f_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4f_expand_activation (Act  (None, 14, 14, 960)  0          ['block4f_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4f_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4f_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4f_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4f_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4f_activation (Activation  (None, 14, 14, 960)  0          ['block4f_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4f_se_squeeze (GlobalAver  (None, 960)         0           ['block4f_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4f_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4f_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4f_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4f_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4f_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4f_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4f_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4f_activation[0][0]',     \n",
      "                                                                  'block4f_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4f_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4f_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4f_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4f_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4f_drop (Dropout)         (None, 14, 14, 160)  0           ['block4f_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4f_add (Add)              (None, 14, 14, 160)  0           ['block4f_drop[0][0]',           \n",
      "                                                                  'block4e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4g_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4f_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4g_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4g_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4g_expand_activation (Act  (None, 14, 14, 960)  0          ['block4g_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4g_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4g_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4g_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4g_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4g_activation (Activation  (None, 14, 14, 960)  0          ['block4g_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4g_se_squeeze (GlobalAver  (None, 960)         0           ['block4g_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4g_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4g_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4g_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4g_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4g_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4g_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4g_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4g_activation[0][0]',     \n",
      "                                                                  'block4g_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4g_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4g_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4g_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4g_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4g_drop (Dropout)         (None, 14, 14, 160)  0           ['block4g_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4g_add (Add)              (None, 14, 14, 160)  0           ['block4g_drop[0][0]',           \n",
      "                                                                  'block4f_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4h_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4g_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4h_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4h_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4h_expand_activation (Act  (None, 14, 14, 960)  0          ['block4h_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4h_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4h_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4h_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4h_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4h_activation (Activation  (None, 14, 14, 960)  0          ['block4h_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4h_se_squeeze (GlobalAver  (None, 960)         0           ['block4h_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4h_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4h_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4h_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4h_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4h_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4h_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4h_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4h_activation[0][0]',     \n",
      "                                                                  'block4h_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4h_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4h_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4h_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4h_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4h_drop (Dropout)         (None, 14, 14, 160)  0           ['block4h_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4h_add (Add)              (None, 14, 14, 160)  0           ['block4h_drop[0][0]',           \n",
      "                                                                  'block4g_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4i_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4h_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4i_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4i_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4i_expand_activation (Act  (None, 14, 14, 960)  0          ['block4i_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4i_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4i_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4i_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4i_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4i_activation (Activation  (None, 14, 14, 960)  0          ['block4i_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4i_se_squeeze (GlobalAver  (None, 960)         0           ['block4i_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4i_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4i_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4i_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4i_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4i_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4i_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4i_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4i_activation[0][0]',     \n",
      "                                                                  'block4i_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4i_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4i_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4i_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4i_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4i_drop (Dropout)         (None, 14, 14, 160)  0           ['block4i_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4i_add (Add)              (None, 14, 14, 160)  0           ['block4i_drop[0][0]',           \n",
      "                                                                  'block4h_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4j_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4i_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4j_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4j_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4j_expand_activation (Act  (None, 14, 14, 960)  0          ['block4j_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4j_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4j_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4j_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4j_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4j_activation (Activation  (None, 14, 14, 960)  0          ['block4j_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4j_se_squeeze (GlobalAver  (None, 960)         0           ['block4j_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4j_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4j_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4j_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4j_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4j_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4j_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4j_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4j_activation[0][0]',     \n",
      "                                                                  'block4j_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4j_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4j_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4j_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4j_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4j_drop (Dropout)         (None, 14, 14, 160)  0           ['block4j_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4j_add (Add)              (None, 14, 14, 160)  0           ['block4j_drop[0][0]',           \n",
      "                                                                  'block4i_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4j_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block5a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, 14, 14, 960)  0          ['block5a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 960)  24000      ['block5a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block5a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, 14, 14, 960)  0          ['block5a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 960)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block5a_activation[0][0]',     \n",
      "                                                                  'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 224)  215040      ['block5a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5a_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5b_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, 14, 14, 1344  0          ['block5b_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5b_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5b_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, 14, 14, 1344  0          ['block5b_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 1344)        0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5b_activation[0][0]',     \n",
      "                                )                                 'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)         (None, 14, 14, 224)  0           ['block5b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, 14, 14, 224)  0           ['block5b_drop[0][0]',           \n",
      "                                                                  'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5b_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5c_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, 14, 14, 1344  0          ['block5c_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5c_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5c_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, 14, 14, 1344  0          ['block5c_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 1344)        0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5c_activation[0][0]',     \n",
      "                                )                                 'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)         (None, 14, 14, 224)  0           ['block5c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, 14, 14, 224)  0           ['block5c_drop[0][0]',           \n",
      "                                                                  'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5d_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5c_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block5d_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5d_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5d_expand_activation (Act  (None, 14, 14, 1344  0          ['block5d_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5d_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5d_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block5d_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5d_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5d_activation (Activation  (None, 14, 14, 1344  0          ['block5d_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5d_se_squeeze (GlobalAver  (None, 1344)        0           ['block5d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5d_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5d_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5d_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5d_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5d_activation[0][0]',     \n",
      "                                )                                 'block5d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5d_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5d_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5d_drop (Dropout)         (None, 14, 14, 224)  0           ['block5d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5d_add (Add)              (None, 14, 14, 224)  0           ['block5d_drop[0][0]',           \n",
      "                                                                  'block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5e_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5d_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block5e_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5e_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5e_expand_activation (Act  (None, 14, 14, 1344  0          ['block5e_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5e_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5e_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block5e_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5e_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5e_activation (Activation  (None, 14, 14, 1344  0          ['block5e_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5e_se_squeeze (GlobalAver  (None, 1344)        0           ['block5e_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5e_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5e_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5e_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5e_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5e_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5e_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5e_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5e_activation[0][0]',     \n",
      "                                )                                 'block5e_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5e_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5e_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5e_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5e_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5e_drop (Dropout)         (None, 14, 14, 224)  0           ['block5e_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5e_add (Add)              (None, 14, 14, 224)  0           ['block5e_drop[0][0]',           \n",
      "                                                                  'block5d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5f_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5e_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block5f_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5f_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5f_expand_activation (Act  (None, 14, 14, 1344  0          ['block5f_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5f_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5f_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block5f_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5f_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5f_activation (Activation  (None, 14, 14, 1344  0          ['block5f_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5f_se_squeeze (GlobalAver  (None, 1344)        0           ['block5f_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5f_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5f_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5f_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5f_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5f_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5f_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5f_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5f_activation[0][0]',     \n",
      "                                )                                 'block5f_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5f_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5f_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5f_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5f_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5f_drop (Dropout)         (None, 14, 14, 224)  0           ['block5f_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5f_add (Add)              (None, 14, 14, 224)  0           ['block5f_drop[0][0]',           \n",
      "                                                                  'block5e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5g_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5f_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block5g_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5g_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5g_expand_activation (Act  (None, 14, 14, 1344  0          ['block5g_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5g_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5g_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block5g_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5g_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5g_activation (Activation  (None, 14, 14, 1344  0          ['block5g_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5g_se_squeeze (GlobalAver  (None, 1344)        0           ['block5g_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5g_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5g_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5g_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5g_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5g_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5g_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5g_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5g_activation[0][0]',     \n",
      "                                )                                 'block5g_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5g_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5g_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5g_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5g_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5g_drop (Dropout)         (None, 14, 14, 224)  0           ['block5g_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5g_add (Add)              (None, 14, 14, 224)  0           ['block5g_drop[0][0]',           \n",
      "                                                                  'block5f_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5h_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5g_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block5h_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5h_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5h_expand_activation (Act  (None, 14, 14, 1344  0          ['block5h_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5h_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5h_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block5h_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5h_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5h_activation (Activation  (None, 14, 14, 1344  0          ['block5h_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5h_se_squeeze (GlobalAver  (None, 1344)        0           ['block5h_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5h_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5h_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5h_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5h_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5h_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5h_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5h_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5h_activation[0][0]',     \n",
      "                                )                                 'block5h_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5h_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5h_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5h_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5h_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5h_drop (Dropout)         (None, 14, 14, 224)  0           ['block5h_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5h_add (Add)              (None, 14, 14, 224)  0           ['block5h_drop[0][0]',           \n",
      "                                                                  'block5g_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5i_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5h_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block5i_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5i_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5i_expand_activation (Act  (None, 14, 14, 1344  0          ['block5i_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5i_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5i_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block5i_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5i_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5i_activation (Activation  (None, 14, 14, 1344  0          ['block5i_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5i_se_squeeze (GlobalAver  (None, 1344)        0           ['block5i_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5i_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5i_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5i_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5i_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5i_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5i_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5i_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5i_activation[0][0]',     \n",
      "                                )                                 'block5i_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5i_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5i_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5i_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5i_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5i_drop (Dropout)         (None, 14, 14, 224)  0           ['block5i_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5i_add (Add)              (None, 14, 14, 224)  0           ['block5i_drop[0][0]',           \n",
      "                                                                  'block5h_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5j_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5i_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block5j_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5j_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5j_expand_activation (Act  (None, 14, 14, 1344  0          ['block5j_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block5j_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5j_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block5j_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5j_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5j_activation (Activation  (None, 14, 14, 1344  0          ['block5j_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block5j_se_squeeze (GlobalAver  (None, 1344)        0           ['block5j_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5j_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5j_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5j_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5j_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5j_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5j_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5j_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5j_activation[0][0]',     \n",
      "                                )                                 'block5j_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5j_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5j_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5j_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5j_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5j_drop (Dropout)         (None, 14, 14, 224)  0           ['block5j_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5j_add (Add)              (None, 14, 14, 224)  0           ['block5j_drop[0][0]',           \n",
      "                                                                  'block5i_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5j_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block6a_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, 14, 14, 1344  0          ['block6a_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6a_dwconv_pad (ZeroPaddin  (None, 17, 17, 1344  0          ['block6a_expand_activation[0][0]\n",
      " g2D)                           )                                ']                               \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 1344)  33600       ['block6a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 1344)  5376        ['block6a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, 7, 7, 1344)  0           ['block6a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 1344)        0           ['block6a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 1344)   0           ['block6a_activation[0][0]',     \n",
      "                                                                  'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 384)    516096      ['block6a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, 7, 7, 2304)  0           ['block6b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 2304)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6b_activation[0][0]',     \n",
      "                                                                  'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)         (None, 7, 7, 384)    0           ['block6b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, 7, 7, 384)    0           ['block6b_drop[0][0]',           \n",
      "                                                                  'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, 7, 7, 2304)  0           ['block6c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 2304)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6c_activation[0][0]',     \n",
      "                                                                  'block6c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)         (None, 7, 7, 384)    0           ['block6c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, 7, 7, 384)    0           ['block6c_drop[0][0]',           \n",
      "                                                                  'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_activation (Activation  (None, 7, 7, 2304)  0           ['block6d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 2304)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6d_activation[0][0]',     \n",
      "                                                                  'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)         (None, 7, 7, 384)    0           ['block6d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, 7, 7, 384)    0           ['block6d_drop[0][0]',           \n",
      "                                                                  'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6e_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6e_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6e_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6e_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6e_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6e_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6e_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6e_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6e_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6e_activation (Activation  (None, 7, 7, 2304)  0           ['block6e_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6e_se_squeeze (GlobalAver  (None, 2304)        0           ['block6e_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6e_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6e_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6e_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6e_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6e_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6e_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6e_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6e_activation[0][0]',     \n",
      "                                                                  'block6e_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6e_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6e_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6e_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6e_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6e_drop (Dropout)         (None, 7, 7, 384)    0           ['block6e_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6e_add (Add)              (None, 7, 7, 384)    0           ['block6e_drop[0][0]',           \n",
      "                                                                  'block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6f_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6f_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6f_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6f_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6f_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6f_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6f_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6f_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6f_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6f_activation (Activation  (None, 7, 7, 2304)  0           ['block6f_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6f_se_squeeze (GlobalAver  (None, 2304)        0           ['block6f_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6f_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6f_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6f_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6f_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6f_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6f_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6f_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6f_activation[0][0]',     \n",
      "                                                                  'block6f_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6f_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6f_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6f_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6f_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6f_drop (Dropout)         (None, 7, 7, 384)    0           ['block6f_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6f_add (Add)              (None, 7, 7, 384)    0           ['block6f_drop[0][0]',           \n",
      "                                                                  'block6e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6g_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6f_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6g_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6g_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6g_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6g_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6g_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6g_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6g_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6g_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6g_activation (Activation  (None, 7, 7, 2304)  0           ['block6g_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6g_se_squeeze (GlobalAver  (None, 2304)        0           ['block6g_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6g_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6g_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6g_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6g_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6g_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6g_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6g_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6g_activation[0][0]',     \n",
      "                                                                  'block6g_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6g_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6g_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6g_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6g_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6g_drop (Dropout)         (None, 7, 7, 384)    0           ['block6g_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6g_add (Add)              (None, 7, 7, 384)    0           ['block6g_drop[0][0]',           \n",
      "                                                                  'block6f_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6h_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6g_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6h_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6h_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6h_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6h_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6h_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6h_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6h_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6h_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6h_activation (Activation  (None, 7, 7, 2304)  0           ['block6h_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6h_se_squeeze (GlobalAver  (None, 2304)        0           ['block6h_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6h_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6h_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6h_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6h_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6h_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6h_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6h_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6h_activation[0][0]',     \n",
      "                                                                  'block6h_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6h_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6h_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6h_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6h_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6h_drop (Dropout)         (None, 7, 7, 384)    0           ['block6h_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6h_add (Add)              (None, 7, 7, 384)    0           ['block6h_drop[0][0]',           \n",
      "                                                                  'block6g_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6i_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6h_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6i_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6i_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6i_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6i_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6i_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6i_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6i_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6i_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6i_activation (Activation  (None, 7, 7, 2304)  0           ['block6i_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6i_se_squeeze (GlobalAver  (None, 2304)        0           ['block6i_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6i_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6i_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6i_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6i_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6i_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6i_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6i_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6i_activation[0][0]',     \n",
      "                                                                  'block6i_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6i_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6i_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6i_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6i_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6i_drop (Dropout)         (None, 7, 7, 384)    0           ['block6i_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6i_add (Add)              (None, 7, 7, 384)    0           ['block6i_drop[0][0]',           \n",
      "                                                                  'block6h_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6j_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6i_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6j_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6j_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6j_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6j_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6j_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6j_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6j_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6j_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6j_activation (Activation  (None, 7, 7, 2304)  0           ['block6j_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6j_se_squeeze (GlobalAver  (None, 2304)        0           ['block6j_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6j_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6j_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6j_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6j_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6j_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6j_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6j_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6j_activation[0][0]',     \n",
      "                                                                  'block6j_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6j_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6j_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6j_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6j_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6j_drop (Dropout)         (None, 7, 7, 384)    0           ['block6j_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6j_add (Add)              (None, 7, 7, 384)    0           ['block6j_drop[0][0]',           \n",
      "                                                                  'block6i_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6k_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6j_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6k_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6k_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6k_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6k_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6k_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6k_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6k_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6k_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6k_activation (Activation  (None, 7, 7, 2304)  0           ['block6k_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6k_se_squeeze (GlobalAver  (None, 2304)        0           ['block6k_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6k_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6k_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6k_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6k_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6k_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6k_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6k_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6k_activation[0][0]',     \n",
      "                                                                  'block6k_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6k_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6k_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6k_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6k_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6k_drop (Dropout)         (None, 7, 7, 384)    0           ['block6k_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6k_add (Add)              (None, 7, 7, 384)    0           ['block6k_drop[0][0]',           \n",
      "                                                                  'block6j_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6l_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6k_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6l_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6l_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6l_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6l_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6l_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6l_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6l_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6l_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6l_activation (Activation  (None, 7, 7, 2304)  0           ['block6l_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6l_se_squeeze (GlobalAver  (None, 2304)        0           ['block6l_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6l_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6l_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6l_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6l_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6l_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6l_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6l_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6l_activation[0][0]',     \n",
      "                                                                  'block6l_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6l_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6l_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6l_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6l_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6l_drop (Dropout)         (None, 7, 7, 384)    0           ['block6l_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6l_add (Add)              (None, 7, 7, 384)    0           ['block6l_drop[0][0]',           \n",
      "                                                                  'block6k_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6m_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6l_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6m_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6m_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6m_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6m_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6m_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6m_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6m_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6m_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6m_activation (Activation  (None, 7, 7, 2304)  0           ['block6m_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6m_se_squeeze (GlobalAver  (None, 2304)        0           ['block6m_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6m_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6m_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6m_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6m_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6m_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6m_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6m_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6m_activation[0][0]',     \n",
      "                                                                  'block6m_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6m_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6m_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6m_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6m_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6m_drop (Dropout)         (None, 7, 7, 384)    0           ['block6m_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6m_add (Add)              (None, 7, 7, 384)    0           ['block6m_drop[0][0]',           \n",
      "                                                                  'block6l_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6m_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block7a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_expand_activation (Act  (None, 7, 7, 2304)  0           ['block7a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  20736       ['block7a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block7a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_activation (Activation  (None, 7, 7, 2304)  0           ['block7a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (GlobalAver  (None, 2304)        0           ['block7a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block7a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block7a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block7a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block7a_activation[0][0]',     \n",
      "                                                                  'block7a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 640)    1474560     ['block7a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7b_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block7b_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7b_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7b_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7b_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7b_activation (Activation  (None, 7, 7, 3840)  0           ['block7b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7b_se_squeeze (GlobalAver  (None, 3840)        0           ['block7b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7b_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7b_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7b_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7b_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7b_activation[0][0]',     \n",
      "                                                                  'block7b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7b_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7b_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7b_drop (Dropout)         (None, 7, 7, 640)    0           ['block7b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block7b_add (Add)              (None, 7, 7, 640)    0           ['block7b_drop[0][0]',           \n",
      "                                                                  'block7a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block7c_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7c_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7c_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7c_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7c_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7c_activation (Activation  (None, 7, 7, 3840)  0           ['block7c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7c_se_squeeze (GlobalAver  (None, 3840)        0           ['block7c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7c_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7c_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7c_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7c_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7c_activation[0][0]',     \n",
      "                                                                  'block7c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7c_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7c_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7c_drop (Dropout)         (None, 7, 7, 640)    0           ['block7c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block7c_add (Add)              (None, 7, 7, 640)    0           ['block7c_drop[0][0]',           \n",
      "                                                                  'block7b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7d_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7d_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7d_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7d_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7d_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7d_activation (Activation  (None, 7, 7, 3840)  0           ['block7d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7d_se_squeeze (GlobalAver  (None, 3840)        0           ['block7d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7d_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7d_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7d_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7d_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7d_activation[0][0]',     \n",
      "                                                                  'block7d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7d_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7d_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7d_drop (Dropout)         (None, 7, 7, 640)    0           ['block7d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block7d_add (Add)              (None, 7, 7, 640)    0           ['block7d_drop[0][0]',           \n",
      "                                                                  'block7c_add[0][0]']            \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, 7, 7, 2560)   1638400     ['block7d_add[0][0]']            \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 2560)   10240       ['top_conv[0][0]']               \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, 7, 7, 2560)   0           ['top_bn[0][0]']                 \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2560)        0           ['top_activation[0][0]']         \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " top_dropout (Dropout)          (None, 2560)         0           ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 2)            5122        ['top_dropout[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64,102,809\n",
      "Trainable params: 63,792,082\n",
      "Non-trainable params: 310,727\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import EfficientNetB7\n",
    "\n",
    "EfficientNet_M = EfficientNetB7(\n",
    "    include_top=True, input_shape=(img_res[0], img_res[1], img_res[2]), weights=None, classes=2, classifier_activation=\"softmax\"\n",
    ")\n",
    "# define new model\n",
    "model = Model(inputs=EfficientNet_M.inputs, outputs=EfficientNet_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)\n",
    "# opt = SGD(learning_rate=0.008, momentum=0.85, decay=0.001)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.1\n",
    "```\n",
    "statuses: S.Ready (can improve)\n",
    "Working: âœ…\n",
    "Max fine tuned acc: â‰…93.2\n",
    "Max fine tuned acc TLRev2: N/A\n",
    "type: transfer learning>>>(ConvNeXtLarge)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " convnext_large_prestem_normali  (None, 224, 224, 3)  0          ['input_1[0][0]']                \n",
      " zation (Normalization)                                                                           \n",
      "                                                                                                  \n",
      " convnext_large_stem (Sequentia  (None, 56, 56, 192)  9792       ['convnext_large_prestem_normaliz\n",
      " l)                                                              ation[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_0  (None, 56, 56, 192)  9600       ['convnext_large_stem[0][0]']    \n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_0  (None, 56, 56, 192)  384        ['convnext_large_stage_0_block_0_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_0  (None, 56, 56, 768)  148224     ['convnext_large_stage_0_block_0_\n",
      " _pointwise_conv_1 (Dense)                                       layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_0  (None, 56, 56, 768)  0          ['convnext_large_stage_0_block_0_\n",
      " _gelu (Activation)                                              pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_0  (None, 56, 56, 192)  147648     ['convnext_large_stage_0_block_0_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_0  (None, 56, 56, 192)  192        ['convnext_large_stage_0_block_0_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_0  (None, 56, 56, 192)  0          ['convnext_large_stage_0_block_0_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 56, 56, 192)  0          ['convnext_large_stem[0][0]',    \n",
      " da)                                                              'convnext_large_stage_0_block_0_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_1  (None, 56, 56, 192)  9600       ['tf.__operators__.add[0][0]']   \n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_1  (None, 56, 56, 192)  384        ['convnext_large_stage_0_block_1_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_1  (None, 56, 56, 768)  148224     ['convnext_large_stage_0_block_1_\n",
      " _pointwise_conv_1 (Dense)                                       layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_1  (None, 56, 56, 768)  0          ['convnext_large_stage_0_block_1_\n",
      " _gelu (Activation)                                              pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_1  (None, 56, 56, 192)  147648     ['convnext_large_stage_0_block_1_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_1  (None, 56, 56, 192)  192        ['convnext_large_stage_0_block_1_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_1  (None, 56, 56, 192)  0          ['convnext_large_stage_0_block_1_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 56, 56, 192)  0          ['tf.__operators__.add[0][0]',   \n",
      " mbda)                                                            'convnext_large_stage_0_block_1_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_2  (None, 56, 56, 192)  9600       ['tf.__operators__.add_1[0][0]'] \n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_2  (None, 56, 56, 192)  384        ['convnext_large_stage_0_block_2_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_2  (None, 56, 56, 768)  148224     ['convnext_large_stage_0_block_2_\n",
      " _pointwise_conv_1 (Dense)                                       layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_2  (None, 56, 56, 768)  0          ['convnext_large_stage_0_block_2_\n",
      " _gelu (Activation)                                              pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_2  (None, 56, 56, 192)  147648     ['convnext_large_stage_0_block_2_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_2  (None, 56, 56, 192)  192        ['convnext_large_stage_0_block_2_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_0_block_2  (None, 56, 56, 192)  0          ['convnext_large_stage_0_block_2_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 56, 56, 192)  0          ['tf.__operators__.add_1[0][0]', \n",
      " mbda)                                                            'convnext_large_stage_0_block_2_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_downsampling_bl  (None, 28, 28, 384)  295680     ['tf.__operators__.add_2[0][0]'] \n",
      " ock_0 (Sequential)                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_0  (None, 28, 28, 384)  19200      ['convnext_large_downsampling_blo\n",
      " _depthwise_conv (Conv2D)                                        ck_0[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_0  (None, 28, 28, 384)  768        ['convnext_large_stage_1_block_0_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_0  (None, 28, 28, 1536  591360     ['convnext_large_stage_1_block_0_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_0  (None, 28, 28, 1536  0          ['convnext_large_stage_1_block_0_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_0  (None, 28, 28, 384)  590208     ['convnext_large_stage_1_block_0_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_0  (None, 28, 28, 384)  384        ['convnext_large_stage_1_block_0_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_0  (None, 28, 28, 384)  0          ['convnext_large_stage_1_block_0_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 28, 28, 384)  0          ['convnext_large_downsampling_blo\n",
      " mbda)                                                           ck_0[0][0]',                     \n",
      "                                                                  'convnext_large_stage_1_block_0_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_1  (None, 28, 28, 384)  19200      ['tf.__operators__.add_3[0][0]'] \n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_1  (None, 28, 28, 384)  768        ['convnext_large_stage_1_block_1_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_1  (None, 28, 28, 1536  591360     ['convnext_large_stage_1_block_1_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_1  (None, 28, 28, 1536  0          ['convnext_large_stage_1_block_1_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_1  (None, 28, 28, 384)  590208     ['convnext_large_stage_1_block_1_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_1  (None, 28, 28, 384)  384        ['convnext_large_stage_1_block_1_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_1  (None, 28, 28, 384)  0          ['convnext_large_stage_1_block_1_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 28, 28, 384)  0          ['tf.__operators__.add_3[0][0]', \n",
      " mbda)                                                            'convnext_large_stage_1_block_1_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_2  (None, 28, 28, 384)  19200      ['tf.__operators__.add_4[0][0]'] \n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_2  (None, 28, 28, 384)  768        ['convnext_large_stage_1_block_2_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_2  (None, 28, 28, 1536  591360     ['convnext_large_stage_1_block_2_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_2  (None, 28, 28, 1536  0          ['convnext_large_stage_1_block_2_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_2  (None, 28, 28, 384)  590208     ['convnext_large_stage_1_block_2_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_2  (None, 28, 28, 384)  384        ['convnext_large_stage_1_block_2_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_1_block_2  (None, 28, 28, 384)  0          ['convnext_large_stage_1_block_2_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 28, 28, 384)  0          ['tf.__operators__.add_4[0][0]', \n",
      " mbda)                                                            'convnext_large_stage_1_block_2_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_downsampling_bl  (None, 14, 14, 768)  1181184    ['tf.__operators__.add_5[0][0]'] \n",
      " ock_1 (Sequential)                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_0  (None, 14, 14, 768)  38400      ['convnext_large_downsampling_blo\n",
      " _depthwise_conv (Conv2D)                                        ck_1[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_0  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_0_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_0  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_0_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_0  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_0_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_0  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_0_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_0  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_0_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_0  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_0_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 14, 14, 768)  0          ['convnext_large_downsampling_blo\n",
      " mbda)                                                           ck_1[0][0]',                     \n",
      "                                                                  'convnext_large_stage_2_block_0_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_6[0][0]'] \n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_1_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_1_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_1_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_1_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_1_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_1_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 14, 14, 768)  0          ['tf.__operators__.add_6[0][0]', \n",
      " mbda)                                                            'convnext_large_stage_2_block_1_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  38400      ['tf.__operators__.add_7[0][0]'] \n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_2_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_2_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_2_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_2_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_2_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_2_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 14, 14, 768)  0          ['tf.__operators__.add_7[0][0]', \n",
      " mbda)                                                            'convnext_large_stage_2_block_2_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_3  (None, 14, 14, 768)  38400      ['tf.__operators__.add_8[0][0]'] \n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_3  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_3_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_3  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_3_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_3  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_3_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_3  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_3_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_3  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_3_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_3  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_3_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 14, 14, 768)  0          ['tf.__operators__.add_8[0][0]', \n",
      " mbda)                                                            'convnext_large_stage_2_block_3_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_4  (None, 14, 14, 768)  38400      ['tf.__operators__.add_9[0][0]'] \n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_4  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_4_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_4  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_4_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_4  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_4_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_4  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_4_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_4  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_4_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_4  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_4_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_9[0][0]', \n",
      " ambda)                                                           'convnext_large_stage_2_block_4_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_5  (None, 14, 14, 768)  38400      ['tf.__operators__.add_10[0][0]']\n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_5  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_5_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_5  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_5_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_5  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_5_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_5  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_5_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_5  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_5_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_5  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_5_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_10[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_5_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_6  (None, 14, 14, 768)  38400      ['tf.__operators__.add_11[0][0]']\n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_6  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_6_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_6  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_6_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_6  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_6_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_6  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_6_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_6  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_6_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_6  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_6_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_11[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_6_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_7  (None, 14, 14, 768)  38400      ['tf.__operators__.add_12[0][0]']\n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_7  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_7_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_7  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_7_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_7  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_7_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_7  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_7_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_7  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_7_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_7  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_7_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_12[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_7_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_8  (None, 14, 14, 768)  38400      ['tf.__operators__.add_13[0][0]']\n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_8  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_8_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_8  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_8_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_8  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_8_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_8  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_8_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_8  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_8_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_8  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_8_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_13[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_8_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_9  (None, 14, 14, 768)  38400      ['tf.__operators__.add_14[0][0]']\n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_9  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_9_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_9  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_9_\n",
      " _pointwise_conv_1 (Dense)      )                                layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_9  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_9_\n",
      " _gelu (Activation)             )                                pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_9  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_9_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_9  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_9_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_9  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_9_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_14[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_9_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_15[0][0]']\n",
      " 0_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_10\n",
      " 0_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_10\n",
      " 0_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_10\n",
      " 0_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_10\n",
      " 0_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_10\n",
      " 0_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_10\n",
      " 0_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_15[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_10\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_16[0][0]']\n",
      " 1_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_11\n",
      " 1_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_11\n",
      " 1_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_11\n",
      " 1_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_11\n",
      " 1_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_11\n",
      " 1_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_11\n",
      " 1_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_16[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_11\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_17[0][0]']\n",
      " 2_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_12\n",
      " 2_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_12\n",
      " 2_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_12\n",
      " 2_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_12\n",
      " 2_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_12\n",
      " 2_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_12\n",
      " 2_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_17[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_12\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_18[0][0]']\n",
      " 3_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_13\n",
      " 3_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_13\n",
      " 3_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_13\n",
      " 3_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_13\n",
      " 3_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_13\n",
      " 3_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_13\n",
      " 3_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_18[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_13\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_19[0][0]']\n",
      " 4_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_14\n",
      " 4_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_14\n",
      " 4_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_14\n",
      " 4_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_14\n",
      " 4_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_14\n",
      " 4_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_14\n",
      " 4_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_19[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_14\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_20[0][0]']\n",
      " 5_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_15\n",
      " 5_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_15\n",
      " 5_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_15\n",
      " 5_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_15\n",
      " 5_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_15\n",
      " 5_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_15\n",
      " 5_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_20[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_15\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_21[0][0]']\n",
      " 6_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_16\n",
      " 6_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_16\n",
      " 6_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_16\n",
      " 6_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_16\n",
      " 6_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_16\n",
      " 6_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_16\n",
      " 6_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_21[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_16\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_22[0][0]']\n",
      " 7_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_17\n",
      " 7_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_17\n",
      " 7_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_17\n",
      " 7_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_17\n",
      " 7_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_17\n",
      " 7_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_17\n",
      " 7_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_22[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_17\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_23[0][0]']\n",
      " 8_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_18\n",
      " 8_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_18\n",
      " 8_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_18\n",
      " 8_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_18\n",
      " 8_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_18\n",
      " 8_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_18\n",
      " 8_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_23[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_18\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  38400      ['tf.__operators__.add_24[0][0]']\n",
      " 9_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_19\n",
      " 9_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_19\n",
      " 9_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_19\n",
      " 9_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_19\n",
      " 9_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_19\n",
      " 9_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_1  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_19\n",
      " 9_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_24[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_19\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  38400      ['tf.__operators__.add_25[0][0]']\n",
      " 0_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_20\n",
      " 0_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_20\n",
      " 0_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_20\n",
      " 0_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_20\n",
      " 0_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_20\n",
      " 0_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_20\n",
      " 0_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_25[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_20\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  38400      ['tf.__operators__.add_26[0][0]']\n",
      " 1_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_21\n",
      " 1_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_21\n",
      " 1_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_21\n",
      " 1_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_21\n",
      " 1_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_21\n",
      " 1_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_21\n",
      " 1_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_26[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_21\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  38400      ['tf.__operators__.add_27[0][0]']\n",
      " 2_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_22\n",
      " 2_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_22\n",
      " 2_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_22\n",
      " 2_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_22\n",
      " 2_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_22\n",
      " 2_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_22\n",
      " 2_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_27[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_22\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  38400      ['tf.__operators__.add_28[0][0]']\n",
      " 3_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_23\n",
      " 3_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_23\n",
      " 3_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_23\n",
      " 3_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_23\n",
      " 3_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_23\n",
      " 3_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_23\n",
      " 3_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_28[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_23\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  38400      ['tf.__operators__.add_29[0][0]']\n",
      " 4_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_24\n",
      " 4_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_24\n",
      " 4_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_24\n",
      " 4_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_24\n",
      " 4_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_24\n",
      " 4_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_24\n",
      " 4_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_29[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_24\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  38400      ['tf.__operators__.add_30[0][0]']\n",
      " 5_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_25\n",
      " 5_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_25\n",
      " 5_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_25\n",
      " 5_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_25\n",
      " 5_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_25\n",
      " 5_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_25\n",
      " 5_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_30[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_25\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  38400      ['tf.__operators__.add_31[0][0]']\n",
      " 6_depthwise_conv (Conv2D)                                                                        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  1536       ['convnext_large_stage_2_block_26\n",
      " 6_layernorm (LayerNormalizatio                                  _depthwise_conv[0][0]']          \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  2362368    ['convnext_large_stage_2_block_26\n",
      " 6_pointwise_conv_1 (Dense)     )                                _layernorm[0][0]']               \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 3072  0          ['convnext_large_stage_2_block_26\n",
      " 6_gelu (Activation)            )                                _pointwise_conv_1[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  2360064    ['convnext_large_stage_2_block_26\n",
      " 6_pointwise_conv_2 (Dense)                                      _gelu[0][0]']                    \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  768        ['convnext_large_stage_2_block_26\n",
      " 6_layer_scale (LayerScale)                                      _pointwise_conv_2[0][0]']        \n",
      "                                                                                                  \n",
      " convnext_large_stage_2_block_2  (None, 14, 14, 768)  0          ['convnext_large_stage_2_block_26\n",
      " 6_identity (Activation)                                         _layer_scale[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, 14, 14, 768)  0          ['tf.__operators__.add_31[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_2_block_26\n",
      "                                                                 _identity[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_downsampling_bl  (None, 7, 7, 1536)  4721664     ['tf.__operators__.add_32[0][0]']\n",
      " ock_2 (Sequential)                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_0  (None, 7, 7, 1536)  76800       ['convnext_large_downsampling_blo\n",
      " _depthwise_conv (Conv2D)                                        ck_2[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_0  (None, 7, 7, 1536)  3072        ['convnext_large_stage_3_block_0_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_0  (None, 7, 7, 6144)  9443328     ['convnext_large_stage_3_block_0_\n",
      " _pointwise_conv_1 (Dense)                                       layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_0  (None, 7, 7, 6144)  0           ['convnext_large_stage_3_block_0_\n",
      " _gelu (Activation)                                              pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_0  (None, 7, 7, 1536)  9438720     ['convnext_large_stage_3_block_0_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_0  (None, 7, 7, 1536)  1536        ['convnext_large_stage_3_block_0_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_0  (None, 7, 7, 1536)  0           ['convnext_large_stage_3_block_0_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, 7, 7, 1536)  0           ['convnext_large_downsampling_blo\n",
      " ambda)                                                          ck_2[0][0]',                     \n",
      "                                                                  'convnext_large_stage_3_block_0_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_1  (None, 7, 7, 1536)  76800       ['tf.__operators__.add_33[0][0]']\n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_1  (None, 7, 7, 1536)  3072        ['convnext_large_stage_3_block_1_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_1  (None, 7, 7, 6144)  9443328     ['convnext_large_stage_3_block_1_\n",
      " _pointwise_conv_1 (Dense)                                       layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_1  (None, 7, 7, 6144)  0           ['convnext_large_stage_3_block_1_\n",
      " _gelu (Activation)                                              pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_1  (None, 7, 7, 1536)  9438720     ['convnext_large_stage_3_block_1_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_1  (None, 7, 7, 1536)  1536        ['convnext_large_stage_3_block_1_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_1  (None, 7, 7, 1536)  0           ['convnext_large_stage_3_block_1_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, 7, 7, 1536)  0           ['tf.__operators__.add_33[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_3_block_1_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_2  (None, 7, 7, 1536)  76800       ['tf.__operators__.add_34[0][0]']\n",
      " _depthwise_conv (Conv2D)                                                                         \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_2  (None, 7, 7, 1536)  3072        ['convnext_large_stage_3_block_2_\n",
      " _layernorm (LayerNormalization                                  depthwise_conv[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_2  (None, 7, 7, 6144)  9443328     ['convnext_large_stage_3_block_2_\n",
      " _pointwise_conv_1 (Dense)                                       layernorm[0][0]']                \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_2  (None, 7, 7, 6144)  0           ['convnext_large_stage_3_block_2_\n",
      " _gelu (Activation)                                              pointwise_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_2  (None, 7, 7, 1536)  9438720     ['convnext_large_stage_3_block_2_\n",
      " _pointwise_conv_2 (Dense)                                       gelu[0][0]']                     \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_2  (None, 7, 7, 1536)  1536        ['convnext_large_stage_3_block_2_\n",
      " _layer_scale (LayerScale)                                       pointwise_conv_2[0][0]']         \n",
      "                                                                                                  \n",
      " convnext_large_stage_3_block_2  (None, 7, 7, 1536)  0           ['convnext_large_stage_3_block_2_\n",
      " _identity (Activation)                                          layer_scale[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (None, 7, 7, 1536)  0           ['tf.__operators__.add_34[0][0]',\n",
      " ambda)                                                           'convnext_large_stage_3_block_2_\n",
      "                                                                 identity[0][0]']                 \n",
      "                                                                                                  \n",
      " convnext_large_head_gap (Globa  (None, 1536)        0           ['tf.__operators__.add_35[0][0]']\n",
      " lAveragePooling2D)                                                                               \n",
      "                                                                                                  \n",
      " convnext_large_head_layernorm   (None, 1536)        3072        ['convnext_large_head_gap[0][0]']\n",
      " (LayerNormalization)                                                                             \n",
      "                                                                                                  \n",
      " convnext_large_head_dense (Den  (None, 2)           3074        ['convnext_large_head_layernorm[0\n",
      " se)                                                             ][0]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 196,233,410\n",
      "Trainable params: 196,233,410\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ConvNeXtLarge\n",
    "\n",
    "ConvNeXtLarge_M = ConvNeXtLarge(\n",
    "    include_top=True, input_shape=(img_res[0], img_res[1], img_res[2]), weights=None, classes=2, classifier_activation=\"softmax\"\n",
    ")\n",
    "# define new model\n",
    "model = Model(inputs=ConvNeXtLarge_M.inputs, outputs=ConvNeXtLarge_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(learning_rate=0.008, momentum=0.85, decay=0.001)\n",
    "# opt = SGD(learning_rate=0.008, momentum=0.85, decay=0.001)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"binary_accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "### Rev1.2\n",
    "```\n",
    "statuses: Ready\n",
    "Working: âœ…\n",
    "Max fine tuned acc: 95.3\n",
    "Max fine tuned acc TLRev2: 96.96\n",
    "type: transfer learning>>>(EfficientNetB7::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Total layers in the base model:  806\n",
      "Freezing 0 layers in the base model...\n",
      "Percentage of the base model that is frozen: 0.00%\n",
      "Total model layers:  814\n",
      "Model: \"model_10\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     Trainable  \n",
      "=============================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               Y          \n",
      "                                )]                                                                           \n",
      "                                                                                                             \n",
      " stem_conv (Conv2D)             (None, 112, 112, 64  1728        ['input_1[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 64  256         ['stem_conv[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_activation (Activation)   (None, 112, 112, 64  0           ['stem_bn[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 64  576        ['stem_activation[0][0]']        Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 64  256        ['block1a_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_activation (Activation  (None, 112, 112, 64  0          ['block1a_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_se_squeeze (GlobalAver  (None, 64)          0           ['block1a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 64)     0           ['block1a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 16)     1040        ['block1a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 64)     1088        ['block1a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 64  0           ['block1a_activation[0][0]',     Y          \n",
      "                                )                                 'block1a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 32  2048        ['block1a_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1a_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1b_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1a_project_bn[0][0]']     Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1b_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1b_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1b_activation (Activation  (None, 112, 112, 32  0          ['block1b_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1b_se_squeeze (GlobalAver  (None, 32)          0           ['block1b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1b_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1b_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1b_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1b_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1b_activation[0][0]',     Y          \n",
      "                                )                                 'block1b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1b_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1b_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1b_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1b_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1b_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1b_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1b_add (Add)              (None, 112, 112, 32  0           ['block1b_drop[0][0]',           Y          \n",
      "                                )                                 'block1a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block1c_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1b_add[0][0]']            Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1c_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1c_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1c_activation (Activation  (None, 112, 112, 32  0          ['block1c_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1c_se_squeeze (GlobalAver  (None, 32)          0           ['block1c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1c_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1c_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1c_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1c_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1c_activation[0][0]',     Y          \n",
      "                                )                                 'block1c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1c_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1c_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1c_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1c_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1c_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1c_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1c_add (Add)              (None, 112, 112, 32  0           ['block1c_drop[0][0]',           Y          \n",
      "                                )                                 'block1b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block1d_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1c_add[0][0]']            Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1d_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1d_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1d_activation (Activation  (None, 112, 112, 32  0          ['block1d_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1d_se_squeeze (GlobalAver  (None, 32)          0           ['block1d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1d_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1d_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1d_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1d_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1d_activation[0][0]',     Y          \n",
      "                                )                                 'block1d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1d_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1d_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1d_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1d_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1d_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1d_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1d_add (Add)              (None, 112, 112, 32  0           ['block1d_drop[0][0]',           Y          \n",
      "                                )                                 'block1c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 19  6144        ['block1d_add[0][0]']            Y          \n",
      "                                2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 19  768        ['block2a_expand_conv[0][0]']    Y          \n",
      " ization)                       2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_expand_activation (Act  (None, 112, 112, 19  0          ['block2a_expand_bn[0][0]']      Y          \n",
      " ivation)                       2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 192)  1728       ['block2a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 192)  768        ['block2a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_activation (Activation  (None, 56, 56, 192)  0          ['block2a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_se_squeeze (GlobalAver  (None, 192)         0           ['block2a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 192)  0           ['block2a_activation[0][0]',     Y          \n",
      "                                                                  'block2a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 48)   9216        ['block2a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_expand_activation (Act  (None, 56, 56, 288)  0          ['block2b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_activation (Activation  (None, 56, 56, 288)  0          ['block2b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_se_squeeze (GlobalAver  (None, 288)         0           ['block2b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2b_activation[0][0]',     Y          \n",
      "                                                                  'block2b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_add (Add)              (None, 56, 56, 48)   0           ['block2b_drop[0][0]',           Y          \n",
      "                                                                  'block2a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block2c_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2c_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2c_expand_activation (Act  (None, 56, 56, 288)  0          ['block2c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2c_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2c_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2c_activation (Activation  (None, 56, 56, 288)  0          ['block2c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2c_se_squeeze (GlobalAver  (None, 288)         0           ['block2c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2c_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2c_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2c_activation[0][0]',     Y          \n",
      "                                                                  'block2c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2c_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2c_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2c_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_add (Add)              (None, 56, 56, 48)   0           ['block2c_drop[0][0]',           Y          \n",
      "                                                                  'block2b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2d_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2d_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2d_expand_activation (Act  (None, 56, 56, 288)  0          ['block2d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2d_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2d_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2d_activation (Activation  (None, 56, 56, 288)  0          ['block2d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2d_se_squeeze (GlobalAver  (None, 288)         0           ['block2d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2d_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2d_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2d_activation[0][0]',     Y          \n",
      "                                                                  'block2d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2d_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2d_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2d_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_add (Add)              (None, 56, 56, 48)   0           ['block2d_drop[0][0]',           Y          \n",
      "                                                                  'block2c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2e_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2e_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2e_expand_activation (Act  (None, 56, 56, 288)  0          ['block2e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2e_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2e_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2e_activation (Activation  (None, 56, 56, 288)  0          ['block2e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2e_se_squeeze (GlobalAver  (None, 288)         0           ['block2e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2e_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2e_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2e_activation[0][0]',     Y          \n",
      "                                                                  'block2e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2e_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2e_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2e_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_add (Add)              (None, 56, 56, 48)   0           ['block2e_drop[0][0]',           Y          \n",
      "                                                                  'block2d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2f_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2f_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2f_expand_activation (Act  (None, 56, 56, 288)  0          ['block2f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2f_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2f_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2f_activation (Activation  (None, 56, 56, 288)  0          ['block2f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2f_se_squeeze (GlobalAver  (None, 288)         0           ['block2f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2f_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2f_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2f_activation[0][0]',     Y          \n",
      "                                                                  'block2f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2f_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2f_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2f_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_add (Add)              (None, 56, 56, 48)   0           ['block2f_drop[0][0]',           Y          \n",
      "                                                                  'block2e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2g_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2g_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2g_expand_activation (Act  (None, 56, 56, 288)  0          ['block2g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2g_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2g_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2g_activation (Activation  (None, 56, 56, 288)  0          ['block2g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2g_se_squeeze (GlobalAver  (None, 288)         0           ['block2g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2g_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2g_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2g_activation[0][0]',     Y          \n",
      "                                                                  'block2g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2g_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2g_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2g_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_add (Add)              (None, 56, 56, 48)   0           ['block2g_drop[0][0]',           Y          \n",
      "                                                                  'block2f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block3a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_expand_activation (Act  (None, 56, 56, 288)  0          ['block3a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 288)  7200       ['block3a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 288)  1152       ['block3a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_activation (Activation  (None, 28, 28, 288)  0          ['block3a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_se_squeeze (GlobalAver  (None, 288)         0           ['block3a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block3a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block3a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block3a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 288)  0           ['block3a_activation[0][0]',     Y          \n",
      "                                                                  'block3a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 80)   23040       ['block3a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_expand_activation (Act  (None, 28, 28, 480)  0          ['block3b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_activation (Activation  (None, 28, 28, 480)  0          ['block3b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_se_squeeze (GlobalAver  (None, 480)         0           ['block3b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3b_activation[0][0]',     Y          \n",
      "                                                                  'block3b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_add (Add)              (None, 28, 28, 80)   0           ['block3b_drop[0][0]',           Y          \n",
      "                                                                  'block3a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block3c_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3c_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3c_expand_activation (Act  (None, 28, 28, 480)  0          ['block3c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3c_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3c_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3c_activation (Activation  (None, 28, 28, 480)  0          ['block3c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3c_se_squeeze (GlobalAver  (None, 480)         0           ['block3c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3c_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3c_activation[0][0]',     Y          \n",
      "                                                                  'block3c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3c_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3c_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3c_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_add (Add)              (None, 28, 28, 80)   0           ['block3c_drop[0][0]',           Y          \n",
      "                                                                  'block3b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3d_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3d_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3d_expand_activation (Act  (None, 28, 28, 480)  0          ['block3d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3d_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3d_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3d_activation (Activation  (None, 28, 28, 480)  0          ['block3d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3d_se_squeeze (GlobalAver  (None, 480)         0           ['block3d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3d_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3d_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3d_activation[0][0]',     Y          \n",
      "                                                                  'block3d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3d_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3d_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3d_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_add (Add)              (None, 28, 28, 80)   0           ['block3d_drop[0][0]',           Y          \n",
      "                                                                  'block3c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3e_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3e_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3e_expand_activation (Act  (None, 28, 28, 480)  0          ['block3e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3e_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3e_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3e_activation (Activation  (None, 28, 28, 480)  0          ['block3e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3e_se_squeeze (GlobalAver  (None, 480)         0           ['block3e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3e_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3e_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3e_activation[0][0]',     Y          \n",
      "                                                                  'block3e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3e_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3e_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3e_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_add (Add)              (None, 28, 28, 80)   0           ['block3e_drop[0][0]',           Y          \n",
      "                                                                  'block3d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3f_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3f_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3f_expand_activation (Act  (None, 28, 28, 480)  0          ['block3f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3f_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3f_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3f_activation (Activation  (None, 28, 28, 480)  0          ['block3f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3f_se_squeeze (GlobalAver  (None, 480)         0           ['block3f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3f_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3f_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3f_activation[0][0]',     Y          \n",
      "                                                                  'block3f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3f_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3f_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3f_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_add (Add)              (None, 28, 28, 80)   0           ['block3f_drop[0][0]',           Y          \n",
      "                                                                  'block3e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3g_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3g_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3g_expand_activation (Act  (None, 28, 28, 480)  0          ['block3g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3g_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3g_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3g_activation (Activation  (None, 28, 28, 480)  0          ['block3g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3g_se_squeeze (GlobalAver  (None, 480)         0           ['block3g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3g_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3g_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3g_activation[0][0]',     Y          \n",
      "                                                                  'block3g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3g_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3g_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3g_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_add (Add)              (None, 28, 28, 80)   0           ['block3g_drop[0][0]',           Y          \n",
      "                                                                  'block3f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block4a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_expand_activation (Act  (None, 28, 28, 480)  0          ['block4a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_activation (Activation  (None, 14, 14, 480)  0          ['block4a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_se_squeeze (GlobalAver  (None, 480)         0           ['block4a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4a_activation[0][0]',     Y          \n",
      "                                                                  'block4a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 160)  76800       ['block4a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_expand_activation (Act  (None, 14, 14, 960)  0          ['block4b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_activation (Activation  (None, 14, 14, 960)  0          ['block4b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_se_squeeze (GlobalAver  (None, 960)         0           ['block4b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4b_activation[0][0]',     Y          \n",
      "                                                                  'block4b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_add (Add)              (None, 14, 14, 160)  0           ['block4b_drop[0][0]',           Y          \n",
      "                                                                  'block4a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_expand_activation (Act  (None, 14, 14, 960)  0          ['block4c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_activation (Activation  (None, 14, 14, 960)  0          ['block4c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_se_squeeze (GlobalAver  (None, 960)         0           ['block4c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4c_activation[0][0]',     Y          \n",
      "                                                                  'block4c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4c_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_add (Add)              (None, 14, 14, 160)  0           ['block4c_drop[0][0]',           Y          \n",
      "                                                                  'block4b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4d_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4d_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4d_expand_activation (Act  (None, 14, 14, 960)  0          ['block4d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4d_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4d_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4d_activation (Activation  (None, 14, 14, 960)  0          ['block4d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4d_se_squeeze (GlobalAver  (None, 960)         0           ['block4d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4d_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4d_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4d_activation[0][0]',     Y          \n",
      "                                                                  'block4d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4d_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4d_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4d_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_add (Add)              (None, 14, 14, 160)  0           ['block4d_drop[0][0]',           Y          \n",
      "                                                                  'block4c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4e_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4e_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4e_expand_activation (Act  (None, 14, 14, 960)  0          ['block4e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4e_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4e_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4e_activation (Activation  (None, 14, 14, 960)  0          ['block4e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4e_se_squeeze (GlobalAver  (None, 960)         0           ['block4e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4e_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4e_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4e_activation[0][0]',     Y          \n",
      "                                                                  'block4e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4e_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4e_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4e_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_add (Add)              (None, 14, 14, 160)  0           ['block4e_drop[0][0]',           Y          \n",
      "                                                                  'block4d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4f_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4f_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4f_expand_activation (Act  (None, 14, 14, 960)  0          ['block4f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4f_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4f_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4f_activation (Activation  (None, 14, 14, 960)  0          ['block4f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4f_se_squeeze (GlobalAver  (None, 960)         0           ['block4f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4f_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4f_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4f_activation[0][0]',     Y          \n",
      "                                                                  'block4f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4f_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4f_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4f_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_add (Add)              (None, 14, 14, 160)  0           ['block4f_drop[0][0]',           Y          \n",
      "                                                                  'block4e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4g_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4g_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4g_expand_activation (Act  (None, 14, 14, 960)  0          ['block4g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4g_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4g_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4g_activation (Activation  (None, 14, 14, 960)  0          ['block4g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4g_se_squeeze (GlobalAver  (None, 960)         0           ['block4g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4g_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4g_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4g_activation[0][0]',     Y          \n",
      "                                                                  'block4g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4g_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4g_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4g_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_add (Add)              (None, 14, 14, 160)  0           ['block4g_drop[0][0]',           Y          \n",
      "                                                                  'block4f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4h_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4h_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4h_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4h_expand_activation (Act  (None, 14, 14, 960)  0          ['block4h_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4h_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4h_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4h_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4h_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4h_activation (Activation  (None, 14, 14, 960)  0          ['block4h_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4h_se_squeeze (GlobalAver  (None, 960)         0           ['block4h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4h_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4h_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4h_activation[0][0]',     Y          \n",
      "                                                                  'block4h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4h_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4h_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4h_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_add (Add)              (None, 14, 14, 160)  0           ['block4h_drop[0][0]',           Y          \n",
      "                                                                  'block4g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4i_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4h_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4i_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4i_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4i_expand_activation (Act  (None, 14, 14, 960)  0          ['block4i_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4i_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4i_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4i_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4i_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4i_activation (Activation  (None, 14, 14, 960)  0          ['block4i_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4i_se_squeeze (GlobalAver  (None, 960)         0           ['block4i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4i_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4i_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4i_activation[0][0]',     Y          \n",
      "                                                                  'block4i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4i_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4i_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4i_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_add (Add)              (None, 14, 14, 160)  0           ['block4i_drop[0][0]',           Y          \n",
      "                                                                  'block4h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4j_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4i_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4j_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4j_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4j_expand_activation (Act  (None, 14, 14, 960)  0          ['block4j_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4j_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4j_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4j_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4j_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4j_activation (Activation  (None, 14, 14, 960)  0          ['block4j_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4j_se_squeeze (GlobalAver  (None, 960)         0           ['block4j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4j_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4j_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4j_activation[0][0]',     Y          \n",
      "                                                                  'block4j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4j_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4j_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4j_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_add (Add)              (None, 14, 14, 160)  0           ['block4j_drop[0][0]',           Y          \n",
      "                                                                  'block4i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4j_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block5a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_expand_activation (Act  (None, 14, 14, 960)  0          ['block5a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 960)  24000      ['block5a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block5a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_activation (Activation  (None, 14, 14, 960)  0          ['block5a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_se_squeeze (GlobalAver  (None, 960)         0           ['block5a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block5a_activation[0][0]',     Y          \n",
      "                                                                  'block5a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 224)  215040      ['block5a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5a_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5b_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5b_expand_activation (Act  (None, 14, 14, 1344  0          ['block5b_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5b_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5b_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5b_activation (Activation  (None, 14, 14, 1344  0          ['block5b_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5b_se_squeeze (GlobalAver  (None, 1344)        0           ['block5b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5b_activation[0][0]',     Y          \n",
      "                                )                                 'block5b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_add (Add)              (None, 14, 14, 224)  0           ['block5b_drop[0][0]',           Y          \n",
      "                                                                  'block5a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5b_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5c_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5c_expand_activation (Act  (None, 14, 14, 1344  0          ['block5c_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5c_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5c_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5c_activation (Activation  (None, 14, 14, 1344  0          ['block5c_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5c_se_squeeze (GlobalAver  (None, 1344)        0           ['block5c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5c_activation[0][0]',     Y          \n",
      "                                )                                 'block5c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5c_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_add (Add)              (None, 14, 14, 224)  0           ['block5c_drop[0][0]',           Y          \n",
      "                                                                  'block5b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5d_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5c_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5d_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5d_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5d_expand_activation (Act  (None, 14, 14, 1344  0          ['block5d_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5d_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5d_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5d_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5d_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5d_activation (Activation  (None, 14, 14, 1344  0          ['block5d_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5d_se_squeeze (GlobalAver  (None, 1344)        0           ['block5d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5d_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5d_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5d_activation[0][0]',     Y          \n",
      "                                )                                 'block5d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5d_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5d_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5d_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_add (Add)              (None, 14, 14, 224)  0           ['block5d_drop[0][0]',           Y          \n",
      "                                                                  'block5c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5e_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5d_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5e_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5e_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5e_expand_activation (Act  (None, 14, 14, 1344  0          ['block5e_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5e_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5e_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5e_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5e_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5e_activation (Activation  (None, 14, 14, 1344  0          ['block5e_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5e_se_squeeze (GlobalAver  (None, 1344)        0           ['block5e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5e_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5e_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5e_activation[0][0]',     Y          \n",
      "                                )                                 'block5e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5e_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5e_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5e_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_add (Add)              (None, 14, 14, 224)  0           ['block5e_drop[0][0]',           Y          \n",
      "                                                                  'block5d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5f_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5e_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5f_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5f_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5f_expand_activation (Act  (None, 14, 14, 1344  0          ['block5f_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5f_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5f_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5f_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5f_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5f_activation (Activation  (None, 14, 14, 1344  0          ['block5f_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5f_se_squeeze (GlobalAver  (None, 1344)        0           ['block5f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5f_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5f_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5f_activation[0][0]',     Y          \n",
      "                                )                                 'block5f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5f_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5f_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5f_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_add (Add)              (None, 14, 14, 224)  0           ['block5f_drop[0][0]',           Y          \n",
      "                                                                  'block5e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5g_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5f_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5g_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5g_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5g_expand_activation (Act  (None, 14, 14, 1344  0          ['block5g_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5g_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5g_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5g_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5g_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5g_activation (Activation  (None, 14, 14, 1344  0          ['block5g_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5g_se_squeeze (GlobalAver  (None, 1344)        0           ['block5g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5g_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5g_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5g_activation[0][0]',     Y          \n",
      "                                )                                 'block5g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5g_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5g_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5g_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_add (Add)              (None, 14, 14, 224)  0           ['block5g_drop[0][0]',           Y          \n",
      "                                                                  'block5f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5h_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5g_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5h_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5h_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5h_expand_activation (Act  (None, 14, 14, 1344  0          ['block5h_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5h_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5h_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5h_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5h_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5h_activation (Activation  (None, 14, 14, 1344  0          ['block5h_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5h_se_squeeze (GlobalAver  (None, 1344)        0           ['block5h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5h_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5h_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5h_activation[0][0]',     Y          \n",
      "                                )                                 'block5h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5h_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5h_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5h_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_add (Add)              (None, 14, 14, 224)  0           ['block5h_drop[0][0]',           Y          \n",
      "                                                                  'block5g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5i_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5h_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5i_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5i_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5i_expand_activation (Act  (None, 14, 14, 1344  0          ['block5i_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5i_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5i_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5i_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5i_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5i_activation (Activation  (None, 14, 14, 1344  0          ['block5i_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5i_se_squeeze (GlobalAver  (None, 1344)        0           ['block5i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5i_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5i_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5i_activation[0][0]',     Y          \n",
      "                                )                                 'block5i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5i_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5i_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5i_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_add (Add)              (None, 14, 14, 224)  0           ['block5i_drop[0][0]',           Y          \n",
      "                                                                  'block5h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5j_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5i_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5j_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5j_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5j_expand_activation (Act  (None, 14, 14, 1344  0          ['block5j_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5j_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5j_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5j_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5j_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5j_activation (Activation  (None, 14, 14, 1344  0          ['block5j_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5j_se_squeeze (GlobalAver  (None, 1344)        0           ['block5j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5j_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5j_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5j_activation[0][0]',     Y          \n",
      "                                )                                 'block5j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5j_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5j_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5j_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_add (Add)              (None, 14, 14, 224)  0           ['block5j_drop[0][0]',           Y          \n",
      "                                                                  'block5i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5j_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block6a_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block6a_expand_activation (Act  (None, 14, 14, 1344  0          ['block6a_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 1344)  33600       ['block6a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 1344)  5376        ['block6a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_activation (Activation  (None, 7, 7, 1344)  0           ['block6a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_se_squeeze (GlobalAver  (None, 1344)        0           ['block6a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block6a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block6a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block6a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 1344)   0           ['block6a_activation[0][0]',     Y          \n",
      "                                                                  'block6a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 384)    516096      ['block6a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_activation (Activation  (None, 7, 7, 2304)  0           ['block6b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_se_squeeze (GlobalAver  (None, 2304)        0           ['block6b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6b_activation[0][0]',     Y          \n",
      "                                                                  'block6b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_add (Add)              (None, 7, 7, 384)    0           ['block6b_drop[0][0]',           Y          \n",
      "                                                                  'block6a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_activation (Activation  (None, 7, 7, 2304)  0           ['block6c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_se_squeeze (GlobalAver  (None, 2304)        0           ['block6c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6c_activation[0][0]',     Y          \n",
      "                                                                  'block6c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6c_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_add (Add)              (None, 7, 7, 384)    0           ['block6c_drop[0][0]',           Y          \n",
      "                                                                  'block6b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_activation (Activation  (None, 7, 7, 2304)  0           ['block6d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_se_squeeze (GlobalAver  (None, 2304)        0           ['block6d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6d_activation[0][0]',     Y          \n",
      "                                                                  'block6d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6d_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_add (Add)              (None, 7, 7, 384)    0           ['block6d_drop[0][0]',           Y          \n",
      "                                                                  'block6c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6e_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6e_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6e_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6e_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6e_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6e_activation (Activation  (None, 7, 7, 2304)  0           ['block6e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6e_se_squeeze (GlobalAver  (None, 2304)        0           ['block6e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6e_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6e_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6e_activation[0][0]',     Y          \n",
      "                                                                  'block6e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6e_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6e_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6e_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_add (Add)              (None, 7, 7, 384)    0           ['block6e_drop[0][0]',           Y          \n",
      "                                                                  'block6d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6f_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6f_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6f_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6f_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6f_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6f_activation (Activation  (None, 7, 7, 2304)  0           ['block6f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6f_se_squeeze (GlobalAver  (None, 2304)        0           ['block6f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6f_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6f_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6f_activation[0][0]',     Y          \n",
      "                                                                  'block6f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6f_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6f_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6f_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_add (Add)              (None, 7, 7, 384)    0           ['block6f_drop[0][0]',           Y          \n",
      "                                                                  'block6e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6g_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6g_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6g_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6g_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6g_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6g_activation (Activation  (None, 7, 7, 2304)  0           ['block6g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6g_se_squeeze (GlobalAver  (None, 2304)        0           ['block6g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6g_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6g_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6g_activation[0][0]',     Y          \n",
      "                                                                  'block6g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6g_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6g_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6g_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_add (Add)              (None, 7, 7, 384)    0           ['block6g_drop[0][0]',           Y          \n",
      "                                                                  'block6f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6h_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6h_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6h_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6h_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6h_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6h_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6h_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6h_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6h_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6h_activation (Activation  (None, 7, 7, 2304)  0           ['block6h_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6h_se_squeeze (GlobalAver  (None, 2304)        0           ['block6h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6h_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6h_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6h_activation[0][0]',     Y          \n",
      "                                                                  'block6h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6h_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6h_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6h_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_add (Add)              (None, 7, 7, 384)    0           ['block6h_drop[0][0]',           Y          \n",
      "                                                                  'block6g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6i_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6h_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6i_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6i_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6i_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6i_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6i_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6i_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6i_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6i_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6i_activation (Activation  (None, 7, 7, 2304)  0           ['block6i_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6i_se_squeeze (GlobalAver  (None, 2304)        0           ['block6i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6i_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6i_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6i_activation[0][0]',     Y          \n",
      "                                                                  'block6i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6i_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6i_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6i_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_add (Add)              (None, 7, 7, 384)    0           ['block6i_drop[0][0]',           Y          \n",
      "                                                                  'block6h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6j_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6i_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6j_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6j_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6j_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6j_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6j_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6j_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6j_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6j_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6j_activation (Activation  (None, 7, 7, 2304)  0           ['block6j_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6j_se_squeeze (GlobalAver  (None, 2304)        0           ['block6j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6j_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6j_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6j_activation[0][0]',     Y          \n",
      "                                                                  'block6j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6j_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6j_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6j_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_add (Add)              (None, 7, 7, 384)    0           ['block6j_drop[0][0]',           Y          \n",
      "                                                                  'block6i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6k_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6j_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6k_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6k_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6k_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6k_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6k_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6k_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6k_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6k_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6k_activation (Activation  (None, 7, 7, 2304)  0           ['block6k_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6k_se_squeeze (GlobalAver  (None, 2304)        0           ['block6k_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6k_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6k_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6k_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6k_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6k_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6k_activation[0][0]',     Y          \n",
      "                                                                  'block6k_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6k_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6k_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6k_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6k_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6k_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6k_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_add (Add)              (None, 7, 7, 384)    0           ['block6k_drop[0][0]',           Y          \n",
      "                                                                  'block6j_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6l_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6k_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6l_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6l_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6l_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6l_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6l_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6l_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6l_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6l_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6l_activation (Activation  (None, 7, 7, 2304)  0           ['block6l_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6l_se_squeeze (GlobalAver  (None, 2304)        0           ['block6l_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6l_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6l_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6l_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6l_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6l_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6l_activation[0][0]',     Y          \n",
      "                                                                  'block6l_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6l_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6l_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6l_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6l_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6l_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6l_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_add (Add)              (None, 7, 7, 384)    0           ['block6l_drop[0][0]',           Y          \n",
      "                                                                  'block6k_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6m_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6l_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6m_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6m_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6m_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6m_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6m_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6m_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6m_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6m_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6m_activation (Activation  (None, 7, 7, 2304)  0           ['block6m_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6m_se_squeeze (GlobalAver  (None, 2304)        0           ['block6m_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6m_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6m_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6m_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6m_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6m_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6m_activation[0][0]',     Y          \n",
      "                                                                  'block6m_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6m_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6m_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6m_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6m_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6m_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6m_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_add (Add)              (None, 7, 7, 384)    0           ['block6m_drop[0][0]',           Y          \n",
      "                                                                  'block6l_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6m_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block7a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_expand_activation (Act  (None, 7, 7, 2304)  0           ['block7a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  20736       ['block7a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block7a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_activation (Activation  (None, 7, 7, 2304)  0           ['block7a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_se_squeeze (GlobalAver  (None, 2304)        0           ['block7a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block7a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block7a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block7a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block7a_activation[0][0]',     Y          \n",
      "                                                                  'block7a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 640)    1474560     ['block7a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7b_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7b_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7b_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7b_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7b_activation (Activation  (None, 7, 7, 3840)  0           ['block7b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7b_se_squeeze (GlobalAver  (None, 3840)        0           ['block7b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7b_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7b_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7b_activation[0][0]',     Y          \n",
      "                                                                  'block7b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7b_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7b_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7b_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_add (Add)              (None, 7, 7, 640)    0           ['block7b_drop[0][0]',           Y          \n",
      "                                                                  'block7a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block7c_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7c_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7c_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7c_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7c_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7c_activation (Activation  (None, 7, 7, 3840)  0           ['block7c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7c_se_squeeze (GlobalAver  (None, 3840)        0           ['block7c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7c_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7c_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7c_activation[0][0]',     Y          \n",
      "                                                                  'block7c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7c_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7c_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7c_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_add (Add)              (None, 7, 7, 640)    0           ['block7c_drop[0][0]',           Y          \n",
      "                                                                  'block7b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7d_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7d_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7d_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7d_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7d_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7d_activation (Activation  (None, 7, 7, 3840)  0           ['block7d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7d_se_squeeze (GlobalAver  (None, 3840)        0           ['block7d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7d_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7d_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7d_activation[0][0]',     Y          \n",
      "                                                                  'block7d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7d_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7d_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7d_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_add (Add)              (None, 7, 7, 640)    0           ['block7d_drop[0][0]',           Y          \n",
      "                                                                  'block7c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " top_conv (Conv2D)              (None, 7, 7, 2560)   1638400     ['block7d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 2560)   10240       ['top_conv[0][0]']               Y          \n",
      "                                                                                                             \n",
      " top_activation (Activation)    (None, 7, 7, 2560)   0           ['top_bn[0][0]']                 Y          \n",
      "                                                                                                             \n",
      " global_average_pooling2d (Glob  (None, 2560)        0           ['top_activation[0][0]']         Y          \n",
      " alAveragePooling2D)                                                                                         \n",
      "                                                                                                             \n",
      " dense (Dense)                  (None, 512)          1311232     ['global_average_pooling2d[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  Y          \n",
      "                                                                                                             \n",
      " batch_normalization (BatchNorm  (None, 512)         2048        ['dropout[0][0]']                Y          \n",
      " alization)                                                                                                  \n",
      "                                                                                                             \n",
      " dense_1 (Dense)                (None, 512)          262656      ['batch_normalization[0][0]']    Y          \n",
      "                                                                                                             \n",
      " batch_normalization_1 (BatchNo  (None, 512)         2048        ['dense_1[0][0]']                Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " dense_2 (Dense)                (None, 128)          65664       ['batch_normalization_1[0][0]']  Y          \n",
      "                                                                                                             \n",
      " dense_3 (Dense)                (None, 2)            258         ['dense_2[0][0]']                Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 65,741,586\n",
      "Trainable params: 65,428,818\n",
      "Non-trainable params: 312,768\n",
      "_____________________________________________________________________________________________________________\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from efficientnet.keras import EfficientNetB7 as KENB7\n",
    "\n",
    "\n",
    "# FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENB7(input_shape=(img_res[0], img_res[1], img_res[2]), weights=\"noisy-student\", include_top=False)\n",
    "    print(\"Total layers in the base model: \", len(base_model.layers))\n",
    "    print(f\"Freezing {freeze_layers} layers in the base model...\")\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) / len(base_model.layers)) * 100\n",
    "    print(f\"Percentage of the base model that is frozen: {frozen_percentage:.2f}%\")\n",
    "    # adding CDL\n",
    "    base_model_FT = GlobalAveragePooling2D()(base_model.output)\n",
    "    Dense_L1 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.02))(base_model_FT)\n",
    "    Dropout_L1 = Dropout(0.1)(Dense_L1)\n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.01))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation=\"relu\")(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\")(Dense_L3)\n",
    "\n",
    "    model_EfficientNetB7_NS = Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.3\n",
    "```\n",
    "statuses: Test\n",
    "Working: âœ…\n",
    "Max fine tuned acc: âš ï¸\n",
    "Max fine tuned acc TLRev2: âš ï¸\n",
    "type: transfer learning>>>(EfficientNetB7|Xception::CCL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Total base_model1 layers:  806\n",
      "Total base_model2 layers:  132\n",
      "Total model layers:  12\n",
      "Model: \"model_1\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     Trainable  \n",
      "=============================================================================================================\n",
      " input_2 (InputLayer)           [(None, 384, 384, 3  0           []                               Y          \n",
      "                                )]                                                                           \n",
      "                                                                                                             \n",
      " efficientnet-b7 (Functional)   (None, 12, 12, 2560  64097680    ['input_2[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "|Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯|\n",
      "| input_3 (InputLayer)         [(None, 384, 384, 3  0           []                               Y          |\n",
      "|                              )]                                                                           |\n",
      "|                                                                                                           |\n",
      "| stem_conv (Conv2D)           (None, 192, 192, 64  1728        []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| stem_bn (BatchNormalization)  (None, 192, 192, 64  256        []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| stem_activation (Activation)  (None, 192, 192, 64  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1a_dwconv (DepthwiseConv2  (None, 192, 192, 64  576      []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1a_bn (BatchNormalization  (None, 192, 192, 64  256      []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1a_activation (Activation  (None, 192, 192, 64  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1a_se_squeeze (GlobalAver  (None, 64)        0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block1a_se_reshape (Reshape)  (None, 1, 1, 64)    0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1a_se_reduce (Conv2D)   (None, 1, 1, 16)     1040        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1a_se_expand (Conv2D)   (None, 1, 1, 64)     1088        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1a_se_excite (Multiply)  (None, 192, 192, 64  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1a_project_conv (Conv2D)  (None, 192, 192, 32  2048      []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1a_project_bn (BatchNorma  (None, 192, 192, 32  128      []                               Y          |\n",
      "| lization)                    )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1b_dwconv (DepthwiseConv2  (None, 192, 192, 32  288      []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1b_bn (BatchNormalization  (None, 192, 192, 32  128      []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1b_activation (Activation  (None, 192, 192, 32  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1b_se_squeeze (GlobalAver  (None, 32)        0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block1b_se_reshape (Reshape)  (None, 1, 1, 32)    0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1b_se_reduce (Conv2D)   (None, 1, 1, 8)      264         []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1b_se_expand (Conv2D)   (None, 1, 1, 32)     288         []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1b_se_excite (Multiply)  (None, 192, 192, 32  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1b_project_conv (Conv2D)  (None, 192, 192, 32  1024      []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1b_project_bn (BatchNorma  (None, 192, 192, 32  128      []                               Y          |\n",
      "| lization)                    )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1b_drop (FixedDropout)  (None, 192, 192, 32  0           []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1b_add (Add)            (None, 192, 192, 32  0           []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1c_dwconv (DepthwiseConv2  (None, 192, 192, 32  288      []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1c_bn (BatchNormalization  (None, 192, 192, 32  128      []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1c_activation (Activation  (None, 192, 192, 32  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1c_se_squeeze (GlobalAver  (None, 32)        0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block1c_se_reshape (Reshape)  (None, 1, 1, 32)    0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1c_se_reduce (Conv2D)   (None, 1, 1, 8)      264         []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1c_se_expand (Conv2D)   (None, 1, 1, 32)     288         []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1c_se_excite (Multiply)  (None, 192, 192, 32  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1c_project_conv (Conv2D)  (None, 192, 192, 32  1024      []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1c_project_bn (BatchNorma  (None, 192, 192, 32  128      []                               Y          |\n",
      "| lization)                    )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1c_drop (FixedDropout)  (None, 192, 192, 32  0           []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1c_add (Add)            (None, 192, 192, 32  0           []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1d_dwconv (DepthwiseConv2  (None, 192, 192, 32  288      []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1d_bn (BatchNormalization  (None, 192, 192, 32  128      []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1d_activation (Activation  (None, 192, 192, 32  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1d_se_squeeze (GlobalAver  (None, 32)        0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block1d_se_reshape (Reshape)  (None, 1, 1, 32)    0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1d_se_reduce (Conv2D)   (None, 1, 1, 8)      264         []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1d_se_expand (Conv2D)   (None, 1, 1, 32)     288         []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block1d_se_excite (Multiply)  (None, 192, 192, 32  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1d_project_conv (Conv2D)  (None, 192, 192, 32  1024      []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1d_project_bn (BatchNorma  (None, 192, 192, 32  128      []                               Y          |\n",
      "| lization)                    )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1d_drop (FixedDropout)  (None, 192, 192, 32  0           []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1d_add (Add)            (None, 192, 192, 32  0           []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block2a_expand_conv (Conv2D)  (None, 192, 192, 19  6144       []                               Y          |\n",
      "|                              2)                                                                           |\n",
      "|                                                                                                           |\n",
      "| block2a_expand_bn (BatchNormal  (None, 192, 192, 19  768      []                               Y          |\n",
      "| ization)                     2)                                                                           |\n",
      "|                                                                                                           |\n",
      "| block2a_expand_activation (Act  (None, 192, 192, 19  0        []                               Y          |\n",
      "| ivation)                     2)                                                                           |\n",
      "|                                                                                                           |\n",
      "| block2a_dwconv (DepthwiseConv2  (None, 96, 96, 192)  1728     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block2a_bn (BatchNormalization  (None, 96, 96, 192)  768      []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2a_activation (Activation  (None, 96, 96, 192)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2a_se_squeeze (GlobalAver  (None, 192)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block2a_se_reshape (Reshape)  (None, 1, 1, 192)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2a_se_reduce (Conv2D)   (None, 1, 1, 8)      1544        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2a_se_expand (Conv2D)   (None, 1, 1, 192)    1728        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2a_se_excite (Multiply)  (None, 96, 96, 192)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2a_project_conv (Conv2D)  (None, 96, 96, 48)  9216       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2a_project_bn (BatchNorma  (None, 96, 96, 48)  192       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block2b_expand_conv (Conv2D)  (None, 96, 96, 288)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2b_expand_bn (BatchNormal  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2b_expand_activation (Act  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2b_dwconv (DepthwiseConv2  (None, 96, 96, 288)  2592     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block2b_bn (BatchNormalization  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2b_activation (Activation  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2b_se_squeeze (GlobalAver  (None, 288)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block2b_se_reshape (Reshape)  (None, 1, 1, 288)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2b_se_reduce (Conv2D)   (None, 1, 1, 12)     3468        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2b_se_expand (Conv2D)   (None, 1, 1, 288)    3744        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2b_se_excite (Multiply)  (None, 96, 96, 288)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2b_project_conv (Conv2D)  (None, 96, 96, 48)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2b_project_bn (BatchNorma  (None, 96, 96, 48)  192       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block2b_drop (FixedDropout)  (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2b_add (Add)            (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2c_expand_conv (Conv2D)  (None, 96, 96, 288)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2c_expand_bn (BatchNormal  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2c_expand_activation (Act  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2c_dwconv (DepthwiseConv2  (None, 96, 96, 288)  2592     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block2c_bn (BatchNormalization  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2c_activation (Activation  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2c_se_squeeze (GlobalAver  (None, 288)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block2c_se_reshape (Reshape)  (None, 1, 1, 288)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2c_se_reduce (Conv2D)   (None, 1, 1, 12)     3468        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2c_se_expand (Conv2D)   (None, 1, 1, 288)    3744        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2c_se_excite (Multiply)  (None, 96, 96, 288)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2c_project_conv (Conv2D)  (None, 96, 96, 48)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2c_project_bn (BatchNorma  (None, 96, 96, 48)  192       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block2c_drop (FixedDropout)  (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2c_add (Add)            (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2d_expand_conv (Conv2D)  (None, 96, 96, 288)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2d_expand_bn (BatchNormal  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2d_expand_activation (Act  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2d_dwconv (DepthwiseConv2  (None, 96, 96, 288)  2592     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block2d_bn (BatchNormalization  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2d_activation (Activation  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2d_se_squeeze (GlobalAver  (None, 288)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block2d_se_reshape (Reshape)  (None, 1, 1, 288)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2d_se_reduce (Conv2D)   (None, 1, 1, 12)     3468        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2d_se_expand (Conv2D)   (None, 1, 1, 288)    3744        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2d_se_excite (Multiply)  (None, 96, 96, 288)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2d_project_conv (Conv2D)  (None, 96, 96, 48)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2d_project_bn (BatchNorma  (None, 96, 96, 48)  192       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block2d_drop (FixedDropout)  (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2d_add (Add)            (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2e_expand_conv (Conv2D)  (None, 96, 96, 288)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2e_expand_bn (BatchNormal  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2e_expand_activation (Act  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2e_dwconv (DepthwiseConv2  (None, 96, 96, 288)  2592     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block2e_bn (BatchNormalization  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2e_activation (Activation  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2e_se_squeeze (GlobalAver  (None, 288)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block2e_se_reshape (Reshape)  (None, 1, 1, 288)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2e_se_reduce (Conv2D)   (None, 1, 1, 12)     3468        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2e_se_expand (Conv2D)   (None, 1, 1, 288)    3744        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2e_se_excite (Multiply)  (None, 96, 96, 288)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2e_project_conv (Conv2D)  (None, 96, 96, 48)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2e_project_bn (BatchNorma  (None, 96, 96, 48)  192       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block2e_drop (FixedDropout)  (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2e_add (Add)            (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2f_expand_conv (Conv2D)  (None, 96, 96, 288)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2f_expand_bn (BatchNormal  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2f_expand_activation (Act  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2f_dwconv (DepthwiseConv2  (None, 96, 96, 288)  2592     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block2f_bn (BatchNormalization  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2f_activation (Activation  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2f_se_squeeze (GlobalAver  (None, 288)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block2f_se_reshape (Reshape)  (None, 1, 1, 288)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2f_se_reduce (Conv2D)   (None, 1, 1, 12)     3468        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2f_se_expand (Conv2D)   (None, 1, 1, 288)    3744        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2f_se_excite (Multiply)  (None, 96, 96, 288)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2f_project_conv (Conv2D)  (None, 96, 96, 48)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2f_project_bn (BatchNorma  (None, 96, 96, 48)  192       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block2f_drop (FixedDropout)  (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2f_add (Add)            (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2g_expand_conv (Conv2D)  (None, 96, 96, 288)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2g_expand_bn (BatchNormal  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2g_expand_activation (Act  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block2g_dwconv (DepthwiseConv2  (None, 96, 96, 288)  2592     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block2g_bn (BatchNormalization  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2g_activation (Activation  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block2g_se_squeeze (GlobalAver  (None, 288)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block2g_se_reshape (Reshape)  (None, 1, 1, 288)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2g_se_reduce (Conv2D)   (None, 1, 1, 12)     3468        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2g_se_expand (Conv2D)   (None, 1, 1, 288)    3744        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2g_se_excite (Multiply)  (None, 96, 96, 288)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2g_project_conv (Conv2D)  (None, 96, 96, 48)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2g_project_bn (BatchNorma  (None, 96, 96, 48)  192       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block2g_drop (FixedDropout)  (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2g_add (Add)            (None, 96, 96, 48)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3a_expand_conv (Conv2D)  (None, 96, 96, 288)  13824      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3a_expand_bn (BatchNormal  (None, 96, 96, 288)  1152     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3a_expand_activation (Act  (None, 96, 96, 288)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3a_dwconv (DepthwiseConv2  (None, 48, 48, 288)  7200     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block3a_bn (BatchNormalization  (None, 48, 48, 288)  1152     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3a_activation (Activation  (None, 48, 48, 288)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3a_se_squeeze (GlobalAver  (None, 288)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block3a_se_reshape (Reshape)  (None, 1, 1, 288)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3a_se_reduce (Conv2D)   (None, 1, 1, 12)     3468        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3a_se_expand (Conv2D)   (None, 1, 1, 288)    3744        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3a_se_excite (Multiply)  (None, 48, 48, 288)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3a_project_conv (Conv2D)  (None, 48, 48, 80)  23040      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3a_project_bn (BatchNorma  (None, 48, 48, 80)  320       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block3b_expand_conv (Conv2D)  (None, 48, 48, 480)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3b_expand_bn (BatchNormal  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3b_expand_activation (Act  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3b_dwconv (DepthwiseConv2  (None, 48, 48, 480)  12000    []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block3b_bn (BatchNormalization  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3b_activation (Activation  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3b_se_squeeze (GlobalAver  (None, 480)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block3b_se_reshape (Reshape)  (None, 1, 1, 480)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3b_se_reduce (Conv2D)   (None, 1, 1, 20)     9620        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3b_se_expand (Conv2D)   (None, 1, 1, 480)    10080       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3b_se_excite (Multiply)  (None, 48, 48, 480)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3b_project_conv (Conv2D)  (None, 48, 48, 80)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3b_project_bn (BatchNorma  (None, 48, 48, 80)  320       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block3b_drop (FixedDropout)  (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3b_add (Add)            (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3c_expand_conv (Conv2D)  (None, 48, 48, 480)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3c_expand_bn (BatchNormal  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3c_expand_activation (Act  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3c_dwconv (DepthwiseConv2  (None, 48, 48, 480)  12000    []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block3c_bn (BatchNormalization  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3c_activation (Activation  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3c_se_squeeze (GlobalAver  (None, 480)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block3c_se_reshape (Reshape)  (None, 1, 1, 480)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3c_se_reduce (Conv2D)   (None, 1, 1, 20)     9620        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3c_se_expand (Conv2D)   (None, 1, 1, 480)    10080       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3c_se_excite (Multiply)  (None, 48, 48, 480)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3c_project_conv (Conv2D)  (None, 48, 48, 80)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3c_project_bn (BatchNorma  (None, 48, 48, 80)  320       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block3c_drop (FixedDropout)  (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3c_add (Add)            (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3d_expand_conv (Conv2D)  (None, 48, 48, 480)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3d_expand_bn (BatchNormal  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3d_expand_activation (Act  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3d_dwconv (DepthwiseConv2  (None, 48, 48, 480)  12000    []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block3d_bn (BatchNormalization  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3d_activation (Activation  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3d_se_squeeze (GlobalAver  (None, 480)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block3d_se_reshape (Reshape)  (None, 1, 1, 480)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3d_se_reduce (Conv2D)   (None, 1, 1, 20)     9620        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3d_se_expand (Conv2D)   (None, 1, 1, 480)    10080       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3d_se_excite (Multiply)  (None, 48, 48, 480)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3d_project_conv (Conv2D)  (None, 48, 48, 80)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3d_project_bn (BatchNorma  (None, 48, 48, 80)  320       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block3d_drop (FixedDropout)  (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3d_add (Add)            (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3e_expand_conv (Conv2D)  (None, 48, 48, 480)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3e_expand_bn (BatchNormal  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3e_expand_activation (Act  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3e_dwconv (DepthwiseConv2  (None, 48, 48, 480)  12000    []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block3e_bn (BatchNormalization  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3e_activation (Activation  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3e_se_squeeze (GlobalAver  (None, 480)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block3e_se_reshape (Reshape)  (None, 1, 1, 480)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3e_se_reduce (Conv2D)   (None, 1, 1, 20)     9620        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3e_se_expand (Conv2D)   (None, 1, 1, 480)    10080       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3e_se_excite (Multiply)  (None, 48, 48, 480)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3e_project_conv (Conv2D)  (None, 48, 48, 80)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3e_project_bn (BatchNorma  (None, 48, 48, 80)  320       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block3e_drop (FixedDropout)  (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3e_add (Add)            (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3f_expand_conv (Conv2D)  (None, 48, 48, 480)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3f_expand_bn (BatchNormal  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3f_expand_activation (Act  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3f_dwconv (DepthwiseConv2  (None, 48, 48, 480)  12000    []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block3f_bn (BatchNormalization  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3f_activation (Activation  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3f_se_squeeze (GlobalAver  (None, 480)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block3f_se_reshape (Reshape)  (None, 1, 1, 480)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3f_se_reduce (Conv2D)   (None, 1, 1, 20)     9620        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3f_se_expand (Conv2D)   (None, 1, 1, 480)    10080       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3f_se_excite (Multiply)  (None, 48, 48, 480)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3f_project_conv (Conv2D)  (None, 48, 48, 80)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3f_project_bn (BatchNorma  (None, 48, 48, 80)  320       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block3f_drop (FixedDropout)  (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3f_add (Add)            (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3g_expand_conv (Conv2D)  (None, 48, 48, 480)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3g_expand_bn (BatchNormal  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3g_expand_activation (Act  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block3g_dwconv (DepthwiseConv2  (None, 48, 48, 480)  12000    []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block3g_bn (BatchNormalization  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3g_activation (Activation  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block3g_se_squeeze (GlobalAver  (None, 480)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block3g_se_reshape (Reshape)  (None, 1, 1, 480)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3g_se_reduce (Conv2D)   (None, 1, 1, 20)     9620        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3g_se_expand (Conv2D)   (None, 1, 1, 480)    10080       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3g_se_excite (Multiply)  (None, 48, 48, 480)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3g_project_conv (Conv2D)  (None, 48, 48, 80)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3g_project_bn (BatchNorma  (None, 48, 48, 80)  320       []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block3g_drop (FixedDropout)  (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3g_add (Add)            (None, 48, 48, 80)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4a_expand_conv (Conv2D)  (None, 48, 48, 480)  38400      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4a_expand_bn (BatchNormal  (None, 48, 48, 480)  1920     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4a_expand_activation (Act  (None, 48, 48, 480)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4a_dwconv (DepthwiseConv2  (None, 24, 24, 480)  4320     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4a_bn (BatchNormalization  (None, 24, 24, 480)  1920     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4a_activation (Activation  (None, 24, 24, 480)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4a_se_squeeze (GlobalAver  (None, 480)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block4a_se_reshape (Reshape)  (None, 1, 1, 480)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4a_se_reduce (Conv2D)   (None, 1, 1, 20)     9620        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4a_se_expand (Conv2D)   (None, 1, 1, 480)    10080       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4a_se_excite (Multiply)  (None, 24, 24, 480)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4a_project_conv (Conv2D)  (None, 24, 24, 160)  76800     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4a_project_bn (BatchNorma  (None, 24, 24, 160)  640      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4b_expand_conv (Conv2D)  (None, 24, 24, 960)  153600     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4b_expand_bn (BatchNormal  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4b_expand_activation (Act  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4b_dwconv (DepthwiseConv2  (None, 24, 24, 960)  8640     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4b_bn (BatchNormalization  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4b_activation (Activation  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4b_se_squeeze (GlobalAver  (None, 960)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block4b_se_reshape (Reshape)  (None, 1, 1, 960)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4b_se_reduce (Conv2D)   (None, 1, 1, 40)     38440       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4b_se_expand (Conv2D)   (None, 1, 1, 960)    39360       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4b_se_excite (Multiply)  (None, 24, 24, 960)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4b_project_conv (Conv2D)  (None, 24, 24, 160)  153600    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4b_project_bn (BatchNorma  (None, 24, 24, 160)  640      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4b_drop (FixedDropout)  (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4b_add (Add)            (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4c_expand_conv (Conv2D)  (None, 24, 24, 960)  153600     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4c_expand_bn (BatchNormal  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4c_expand_activation (Act  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4c_dwconv (DepthwiseConv2  (None, 24, 24, 960)  8640     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4c_bn (BatchNormalization  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4c_activation (Activation  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4c_se_squeeze (GlobalAver  (None, 960)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block4c_se_reshape (Reshape)  (None, 1, 1, 960)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4c_se_reduce (Conv2D)   (None, 1, 1, 40)     38440       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4c_se_expand (Conv2D)   (None, 1, 1, 960)    39360       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4c_se_excite (Multiply)  (None, 24, 24, 960)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4c_project_conv (Conv2D)  (None, 24, 24, 160)  153600    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4c_project_bn (BatchNorma  (None, 24, 24, 160)  640      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4c_drop (FixedDropout)  (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4c_add (Add)            (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4d_expand_conv (Conv2D)  (None, 24, 24, 960)  153600     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4d_expand_bn (BatchNormal  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4d_expand_activation (Act  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4d_dwconv (DepthwiseConv2  (None, 24, 24, 960)  8640     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4d_bn (BatchNormalization  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4d_activation (Activation  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4d_se_squeeze (GlobalAver  (None, 960)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block4d_se_reshape (Reshape)  (None, 1, 1, 960)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4d_se_reduce (Conv2D)   (None, 1, 1, 40)     38440       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4d_se_expand (Conv2D)   (None, 1, 1, 960)    39360       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4d_se_excite (Multiply)  (None, 24, 24, 960)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4d_project_conv (Conv2D)  (None, 24, 24, 160)  153600    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4d_project_bn (BatchNorma  (None, 24, 24, 160)  640      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4d_drop (FixedDropout)  (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4d_add (Add)            (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4e_expand_conv (Conv2D)  (None, 24, 24, 960)  153600     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4e_expand_bn (BatchNormal  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4e_expand_activation (Act  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4e_dwconv (DepthwiseConv2  (None, 24, 24, 960)  8640     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4e_bn (BatchNormalization  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4e_activation (Activation  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4e_se_squeeze (GlobalAver  (None, 960)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block4e_se_reshape (Reshape)  (None, 1, 1, 960)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4e_se_reduce (Conv2D)   (None, 1, 1, 40)     38440       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4e_se_expand (Conv2D)   (None, 1, 1, 960)    39360       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4e_se_excite (Multiply)  (None, 24, 24, 960)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4e_project_conv (Conv2D)  (None, 24, 24, 160)  153600    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4e_project_bn (BatchNorma  (None, 24, 24, 160)  640      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4e_drop (FixedDropout)  (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4e_add (Add)            (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4f_expand_conv (Conv2D)  (None, 24, 24, 960)  153600     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4f_expand_bn (BatchNormal  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4f_expand_activation (Act  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4f_dwconv (DepthwiseConv2  (None, 24, 24, 960)  8640     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4f_bn (BatchNormalization  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4f_activation (Activation  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4f_se_squeeze (GlobalAver  (None, 960)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block4f_se_reshape (Reshape)  (None, 1, 1, 960)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4f_se_reduce (Conv2D)   (None, 1, 1, 40)     38440       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4f_se_expand (Conv2D)   (None, 1, 1, 960)    39360       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4f_se_excite (Multiply)  (None, 24, 24, 960)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4f_project_conv (Conv2D)  (None, 24, 24, 160)  153600    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4f_project_bn (BatchNorma  (None, 24, 24, 160)  640      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4f_drop (FixedDropout)  (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4f_add (Add)            (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4g_expand_conv (Conv2D)  (None, 24, 24, 960)  153600     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4g_expand_bn (BatchNormal  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4g_expand_activation (Act  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4g_dwconv (DepthwiseConv2  (None, 24, 24, 960)  8640     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4g_bn (BatchNormalization  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4g_activation (Activation  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4g_se_squeeze (GlobalAver  (None, 960)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block4g_se_reshape (Reshape)  (None, 1, 1, 960)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4g_se_reduce (Conv2D)   (None, 1, 1, 40)     38440       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4g_se_expand (Conv2D)   (None, 1, 1, 960)    39360       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4g_se_excite (Multiply)  (None, 24, 24, 960)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4g_project_conv (Conv2D)  (None, 24, 24, 160)  153600    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4g_project_bn (BatchNorma  (None, 24, 24, 160)  640      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4g_drop (FixedDropout)  (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4g_add (Add)            (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4h_expand_conv (Conv2D)  (None, 24, 24, 960)  153600     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4h_expand_bn (BatchNormal  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4h_expand_activation (Act  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4h_dwconv (DepthwiseConv2  (None, 24, 24, 960)  8640     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4h_bn (BatchNormalization  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4h_activation (Activation  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4h_se_squeeze (GlobalAver  (None, 960)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block4h_se_reshape (Reshape)  (None, 1, 1, 960)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4h_se_reduce (Conv2D)   (None, 1, 1, 40)     38440       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4h_se_expand (Conv2D)   (None, 1, 1, 960)    39360       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4h_se_excite (Multiply)  (None, 24, 24, 960)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4h_project_conv (Conv2D)  (None, 24, 24, 160)  153600    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4h_project_bn (BatchNorma  (None, 24, 24, 160)  640      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4h_drop (FixedDropout)  (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4h_add (Add)            (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4i_expand_conv (Conv2D)  (None, 24, 24, 960)  153600     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4i_expand_bn (BatchNormal  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4i_expand_activation (Act  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4i_dwconv (DepthwiseConv2  (None, 24, 24, 960)  8640     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4i_bn (BatchNormalization  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4i_activation (Activation  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4i_se_squeeze (GlobalAver  (None, 960)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block4i_se_reshape (Reshape)  (None, 1, 1, 960)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4i_se_reduce (Conv2D)   (None, 1, 1, 40)     38440       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4i_se_expand (Conv2D)   (None, 1, 1, 960)    39360       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4i_se_excite (Multiply)  (None, 24, 24, 960)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4i_project_conv (Conv2D)  (None, 24, 24, 160)  153600    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4i_project_bn (BatchNorma  (None, 24, 24, 160)  640      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4i_drop (FixedDropout)  (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4i_add (Add)            (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4j_expand_conv (Conv2D)  (None, 24, 24, 960)  153600     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4j_expand_bn (BatchNormal  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4j_expand_activation (Act  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block4j_dwconv (DepthwiseConv2  (None, 24, 24, 960)  8640     []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4j_bn (BatchNormalization  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4j_activation (Activation  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block4j_se_squeeze (GlobalAver  (None, 960)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block4j_se_reshape (Reshape)  (None, 1, 1, 960)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4j_se_reduce (Conv2D)   (None, 1, 1, 40)     38440       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4j_se_expand (Conv2D)   (None, 1, 1, 960)    39360       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4j_se_excite (Multiply)  (None, 24, 24, 960)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4j_project_conv (Conv2D)  (None, 24, 24, 160)  153600    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4j_project_bn (BatchNorma  (None, 24, 24, 160)  640      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4j_drop (FixedDropout)  (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4j_add (Add)            (None, 24, 24, 160)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5a_expand_conv (Conv2D)  (None, 24, 24, 960)  153600     []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5a_expand_bn (BatchNormal  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| ization)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block5a_expand_activation (Act  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| ivation)                                                                                                  |\n",
      "|                                                                                                           |\n",
      "| block5a_dwconv (DepthwiseConv2  (None, 24, 24, 960)  24000    []                               Y          |\n",
      "| D)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block5a_bn (BatchNormalization  (None, 24, 24, 960)  3840     []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block5a_activation (Activation  (None, 24, 24, 960)  0        []                               Y          |\n",
      "| )                                                                                                         |\n",
      "|                                                                                                           |\n",
      "| block5a_se_squeeze (GlobalAver  (None, 960)       0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block5a_se_reshape (Reshape)  (None, 1, 1, 960)   0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5a_se_reduce (Conv2D)   (None, 1, 1, 40)     38440       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5a_se_expand (Conv2D)   (None, 1, 1, 960)    39360       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5a_se_excite (Multiply)  (None, 24, 24, 960)  0          []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5a_project_conv (Conv2D)  (None, 24, 24, 224)  215040    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5a_project_bn (BatchNorma  (None, 24, 24, 224)  896      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5b_expand_conv (Conv2D)  (None, 24, 24, 1344  301056     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5b_expand_bn (BatchNormal  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5b_expand_activation (Act  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5b_dwconv (DepthwiseConv2  (None, 24, 24, 1344  33600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5b_bn (BatchNormalization  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5b_activation (Activation  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5b_se_squeeze (GlobalAver  (None, 1344)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block5b_se_reshape (Reshape)  (None, 1, 1, 1344)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5b_se_reduce (Conv2D)   (None, 1, 1, 56)     75320       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5b_se_expand (Conv2D)   (None, 1, 1, 1344)   76608       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5b_se_excite (Multiply)  (None, 24, 24, 1344  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5b_project_conv (Conv2D)  (None, 24, 24, 224)  301056    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5b_project_bn (BatchNorma  (None, 24, 24, 224)  896      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5b_drop (FixedDropout)  (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5b_add (Add)            (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5c_expand_conv (Conv2D)  (None, 24, 24, 1344  301056     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5c_expand_bn (BatchNormal  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5c_expand_activation (Act  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5c_dwconv (DepthwiseConv2  (None, 24, 24, 1344  33600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5c_bn (BatchNormalization  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5c_activation (Activation  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5c_se_squeeze (GlobalAver  (None, 1344)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block5c_se_reshape (Reshape)  (None, 1, 1, 1344)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5c_se_reduce (Conv2D)   (None, 1, 1, 56)     75320       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5c_se_expand (Conv2D)   (None, 1, 1, 1344)   76608       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5c_se_excite (Multiply)  (None, 24, 24, 1344  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5c_project_conv (Conv2D)  (None, 24, 24, 224)  301056    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5c_project_bn (BatchNorma  (None, 24, 24, 224)  896      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5c_drop (FixedDropout)  (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5c_add (Add)            (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5d_expand_conv (Conv2D)  (None, 24, 24, 1344  301056     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5d_expand_bn (BatchNormal  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5d_expand_activation (Act  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5d_dwconv (DepthwiseConv2  (None, 24, 24, 1344  33600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5d_bn (BatchNormalization  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5d_activation (Activation  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5d_se_squeeze (GlobalAver  (None, 1344)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block5d_se_reshape (Reshape)  (None, 1, 1, 1344)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5d_se_reduce (Conv2D)   (None, 1, 1, 56)     75320       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5d_se_expand (Conv2D)   (None, 1, 1, 1344)   76608       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5d_se_excite (Multiply)  (None, 24, 24, 1344  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5d_project_conv (Conv2D)  (None, 24, 24, 224)  301056    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5d_project_bn (BatchNorma  (None, 24, 24, 224)  896      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5d_drop (FixedDropout)  (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5d_add (Add)            (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5e_expand_conv (Conv2D)  (None, 24, 24, 1344  301056     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5e_expand_bn (BatchNormal  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5e_expand_activation (Act  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5e_dwconv (DepthwiseConv2  (None, 24, 24, 1344  33600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5e_bn (BatchNormalization  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5e_activation (Activation  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5e_se_squeeze (GlobalAver  (None, 1344)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block5e_se_reshape (Reshape)  (None, 1, 1, 1344)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5e_se_reduce (Conv2D)   (None, 1, 1, 56)     75320       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5e_se_expand (Conv2D)   (None, 1, 1, 1344)   76608       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5e_se_excite (Multiply)  (None, 24, 24, 1344  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5e_project_conv (Conv2D)  (None, 24, 24, 224)  301056    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5e_project_bn (BatchNorma  (None, 24, 24, 224)  896      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5e_drop (FixedDropout)  (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5e_add (Add)            (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5f_expand_conv (Conv2D)  (None, 24, 24, 1344  301056     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5f_expand_bn (BatchNormal  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5f_expand_activation (Act  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5f_dwconv (DepthwiseConv2  (None, 24, 24, 1344  33600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5f_bn (BatchNormalization  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5f_activation (Activation  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5f_se_squeeze (GlobalAver  (None, 1344)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block5f_se_reshape (Reshape)  (None, 1, 1, 1344)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5f_se_reduce (Conv2D)   (None, 1, 1, 56)     75320       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5f_se_expand (Conv2D)   (None, 1, 1, 1344)   76608       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5f_se_excite (Multiply)  (None, 24, 24, 1344  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5f_project_conv (Conv2D)  (None, 24, 24, 224)  301056    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5f_project_bn (BatchNorma  (None, 24, 24, 224)  896      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5f_drop (FixedDropout)  (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5f_add (Add)            (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5g_expand_conv (Conv2D)  (None, 24, 24, 1344  301056     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5g_expand_bn (BatchNormal  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5g_expand_activation (Act  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5g_dwconv (DepthwiseConv2  (None, 24, 24, 1344  33600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5g_bn (BatchNormalization  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5g_activation (Activation  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5g_se_squeeze (GlobalAver  (None, 1344)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block5g_se_reshape (Reshape)  (None, 1, 1, 1344)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5g_se_reduce (Conv2D)   (None, 1, 1, 56)     75320       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5g_se_expand (Conv2D)   (None, 1, 1, 1344)   76608       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5g_se_excite (Multiply)  (None, 24, 24, 1344  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5g_project_conv (Conv2D)  (None, 24, 24, 224)  301056    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5g_project_bn (BatchNorma  (None, 24, 24, 224)  896      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5g_drop (FixedDropout)  (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5g_add (Add)            (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5h_expand_conv (Conv2D)  (None, 24, 24, 1344  301056     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5h_expand_bn (BatchNormal  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5h_expand_activation (Act  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5h_dwconv (DepthwiseConv2  (None, 24, 24, 1344  33600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5h_bn (BatchNormalization  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5h_activation (Activation  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5h_se_squeeze (GlobalAver  (None, 1344)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block5h_se_reshape (Reshape)  (None, 1, 1, 1344)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5h_se_reduce (Conv2D)   (None, 1, 1, 56)     75320       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5h_se_expand (Conv2D)   (None, 1, 1, 1344)   76608       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5h_se_excite (Multiply)  (None, 24, 24, 1344  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5h_project_conv (Conv2D)  (None, 24, 24, 224)  301056    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5h_project_bn (BatchNorma  (None, 24, 24, 224)  896      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5h_drop (FixedDropout)  (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5h_add (Add)            (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5i_expand_conv (Conv2D)  (None, 24, 24, 1344  301056     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5i_expand_bn (BatchNormal  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5i_expand_activation (Act  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5i_dwconv (DepthwiseConv2  (None, 24, 24, 1344  33600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5i_bn (BatchNormalization  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5i_activation (Activation  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5i_se_squeeze (GlobalAver  (None, 1344)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block5i_se_reshape (Reshape)  (None, 1, 1, 1344)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5i_se_reduce (Conv2D)   (None, 1, 1, 56)     75320       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5i_se_expand (Conv2D)   (None, 1, 1, 1344)   76608       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5i_se_excite (Multiply)  (None, 24, 24, 1344  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5i_project_conv (Conv2D)  (None, 24, 24, 224)  301056    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5i_project_bn (BatchNorma  (None, 24, 24, 224)  896      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5i_drop (FixedDropout)  (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5i_add (Add)            (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5j_expand_conv (Conv2D)  (None, 24, 24, 1344  301056     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5j_expand_bn (BatchNormal  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5j_expand_activation (Act  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5j_dwconv (DepthwiseConv2  (None, 24, 24, 1344  33600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5j_bn (BatchNormalization  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5j_activation (Activation  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5j_se_squeeze (GlobalAver  (None, 1344)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block5j_se_reshape (Reshape)  (None, 1, 1, 1344)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5j_se_reduce (Conv2D)   (None, 1, 1, 56)     75320       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5j_se_expand (Conv2D)   (None, 1, 1, 1344)   76608       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5j_se_excite (Multiply)  (None, 24, 24, 1344  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block5j_project_conv (Conv2D)  (None, 24, 24, 224)  301056    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5j_project_bn (BatchNorma  (None, 24, 24, 224)  896      []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5j_drop (FixedDropout)  (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5j_add (Add)            (None, 24, 24, 224)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6a_expand_conv (Conv2D)  (None, 24, 24, 1344  301056     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6a_expand_bn (BatchNormal  (None, 24, 24, 1344  5376     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6a_expand_activation (Act  (None, 24, 24, 1344  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6a_dwconv (DepthwiseConv2  (None, 12, 12, 1344  33600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6a_bn (BatchNormalization  (None, 12, 12, 1344  5376     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6a_activation (Activation  (None, 12, 12, 1344  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6a_se_squeeze (GlobalAver  (None, 1344)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6a_se_reshape (Reshape)  (None, 1, 1, 1344)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6a_se_reduce (Conv2D)   (None, 1, 1, 56)     75320       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6a_se_expand (Conv2D)   (None, 1, 1, 1344)   76608       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6a_se_excite (Multiply)  (None, 12, 12, 1344  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6a_project_conv (Conv2D)  (None, 12, 12, 384)  516096    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6a_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6b_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6b_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6b_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6b_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6b_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6b_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6b_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6b_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6b_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6b_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6b_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6b_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6b_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6b_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6b_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6c_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6c_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6c_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6c_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6c_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6c_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6c_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6c_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6c_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6c_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6c_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6c_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6c_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6c_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6c_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6d_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6d_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6d_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6d_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6d_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6d_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6d_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6d_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6d_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6d_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6d_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6d_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6d_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6d_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6d_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6e_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6e_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6e_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6e_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6e_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6e_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6e_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6e_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6e_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6e_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6e_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6e_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6e_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6e_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6e_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6f_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6f_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6f_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6f_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6f_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6f_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6f_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6f_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6f_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6f_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6f_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6f_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6f_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6f_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6f_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6g_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6g_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6g_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6g_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6g_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6g_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6g_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6g_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6g_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6g_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6g_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6g_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6g_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6g_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6g_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6h_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6h_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6h_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6h_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6h_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6h_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6h_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6h_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6h_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6h_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6h_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6h_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6h_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6h_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6h_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6i_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6i_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6i_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6i_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6i_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6i_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6i_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6i_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6i_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6i_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6i_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6i_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6i_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6i_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6i_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6j_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6j_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6j_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6j_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6j_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6j_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6j_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6j_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6j_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6j_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6j_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6j_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6j_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6j_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6j_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6k_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6k_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6k_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6k_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6k_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6k_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6k_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6k_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6k_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6k_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6k_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6k_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6k_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6k_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6k_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6l_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6l_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6l_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6l_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6l_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6l_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6l_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6l_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6l_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6l_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6l_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6l_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6l_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6l_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6l_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6m_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6m_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6m_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6m_dwconv (DepthwiseConv2  (None, 12, 12, 2304  57600    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6m_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6m_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6m_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block6m_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6m_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6m_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6m_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block6m_project_conv (Conv2D)  (None, 12, 12, 384)  884736    []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6m_project_bn (BatchNorma  (None, 12, 12, 384)  1536     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6m_drop (FixedDropout)  (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6m_add (Add)            (None, 12, 12, 384)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7a_expand_conv (Conv2D)  (None, 12, 12, 2304  884736     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7a_expand_bn (BatchNormal  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7a_expand_activation (Act  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7a_dwconv (DepthwiseConv2  (None, 12, 12, 2304  20736    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7a_bn (BatchNormalization  (None, 12, 12, 2304  9216     []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7a_activation (Activation  (None, 12, 12, 2304  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7a_se_squeeze (GlobalAver  (None, 2304)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block7a_se_reshape (Reshape)  (None, 1, 1, 2304)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7a_se_reduce (Conv2D)   (None, 1, 1, 96)     221280      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7a_se_expand (Conv2D)   (None, 1, 1, 2304)   223488      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7a_se_excite (Multiply)  (None, 12, 12, 2304  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7a_project_conv (Conv2D)  (None, 12, 12, 640)  1474560   []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7a_project_bn (BatchNorma  (None, 12, 12, 640)  2560     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block7b_expand_conv (Conv2D)  (None, 12, 12, 3840  2457600    []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7b_expand_bn (BatchNormal  (None, 12, 12, 3840  15360    []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7b_expand_activation (Act  (None, 12, 12, 3840  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7b_dwconv (DepthwiseConv2  (None, 12, 12, 3840  34560    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7b_bn (BatchNormalization  (None, 12, 12, 3840  15360    []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7b_activation (Activation  (None, 12, 12, 3840  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7b_se_squeeze (GlobalAver  (None, 3840)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block7b_se_reshape (Reshape)  (None, 1, 1, 3840)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7b_se_reduce (Conv2D)   (None, 1, 1, 160)    614560      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7b_se_expand (Conv2D)   (None, 1, 1, 3840)   618240      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7b_se_excite (Multiply)  (None, 12, 12, 3840  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7b_project_conv (Conv2D)  (None, 12, 12, 640)  2457600   []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7b_project_bn (BatchNorma  (None, 12, 12, 640)  2560     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block7b_drop (FixedDropout)  (None, 12, 12, 640)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7b_add (Add)            (None, 12, 12, 640)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7c_expand_conv (Conv2D)  (None, 12, 12, 3840  2457600    []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7c_expand_bn (BatchNormal  (None, 12, 12, 3840  15360    []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7c_expand_activation (Act  (None, 12, 12, 3840  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7c_dwconv (DepthwiseConv2  (None, 12, 12, 3840  34560    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7c_bn (BatchNormalization  (None, 12, 12, 3840  15360    []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7c_activation (Activation  (None, 12, 12, 3840  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7c_se_squeeze (GlobalAver  (None, 3840)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block7c_se_reshape (Reshape)  (None, 1, 1, 3840)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7c_se_reduce (Conv2D)   (None, 1, 1, 160)    614560      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7c_se_expand (Conv2D)   (None, 1, 1, 3840)   618240      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7c_se_excite (Multiply)  (None, 12, 12, 3840  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7c_project_conv (Conv2D)  (None, 12, 12, 640)  2457600   []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7c_project_bn (BatchNorma  (None, 12, 12, 640)  2560     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block7c_drop (FixedDropout)  (None, 12, 12, 640)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7c_add (Add)            (None, 12, 12, 640)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7d_expand_conv (Conv2D)  (None, 12, 12, 3840  2457600    []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7d_expand_bn (BatchNormal  (None, 12, 12, 3840  15360    []                               Y          |\n",
      "| ization)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7d_expand_activation (Act  (None, 12, 12, 3840  0        []                               Y          |\n",
      "| ivation)                     )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7d_dwconv (DepthwiseConv2  (None, 12, 12, 3840  34560    []                               Y          |\n",
      "| D)                           )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7d_bn (BatchNormalization  (None, 12, 12, 3840  15360    []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7d_activation (Activation  (None, 12, 12, 3840  0        []                               Y          |\n",
      "| )                            )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7d_se_squeeze (GlobalAver  (None, 3840)      0           []                               Y          |\n",
      "| agePooling2D)                                                                                             |\n",
      "|                                                                                                           |\n",
      "| block7d_se_reshape (Reshape)  (None, 1, 1, 3840)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7d_se_reduce (Conv2D)   (None, 1, 1, 160)    614560      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7d_se_expand (Conv2D)   (None, 1, 1, 3840)   618240      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7d_se_excite (Multiply)  (None, 12, 12, 3840  0          []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block7d_project_conv (Conv2D)  (None, 12, 12, 640)  2457600   []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7d_project_bn (BatchNorma  (None, 12, 12, 640)  2560     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block7d_drop (FixedDropout)  (None, 12, 12, 640)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7d_add (Add)            (None, 12, 12, 640)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| top_conv (Conv2D)            (None, 12, 12, 2560  1638400     []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| top_bn (BatchNormalization)  (None, 12, 12, 2560  10240       []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| top_activation (Activation)  (None, 12, 12, 2560  0           []                               Y          |\n",
      "|                              )                                                                            |\n",
      "Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯\n",
      " xception (Functional)          (None, 12, 12, 2048  20861480    ['input_2[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "|Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯|\n",
      "| input_4 (InputLayer)         [(None, 384, 384, 3  0           []                               Y          |\n",
      "|                              )]                                                                           |\n",
      "|                                                                                                           |\n",
      "| block1_conv1 (Conv2D)        (None, 191, 191, 32  864         []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1_conv1_bn (BatchNormaliz  (None, 191, 191, 32  128      []                               Y          |\n",
      "| ation)                       )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1_conv1_act (Activation)  (None, 191, 191, 32  0         []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1_conv2 (Conv2D)        (None, 189, 189, 64  18432       []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1_conv2_bn (BatchNormaliz  (None, 189, 189, 64  256      []                               Y          |\n",
      "| ation)                       )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block1_conv2_act (Activation)  (None, 189, 189, 64  0         []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block2_sepconv1 (SeparableConv  (None, 189, 189, 12  8768     []                               Y          |\n",
      "| 2D)                          8)                                                                           |\n",
      "|                                                                                                           |\n",
      "| block2_sepconv1_bn (BatchNorma  (None, 189, 189, 12  512      []                               Y          |\n",
      "| lization)                    8)                                                                           |\n",
      "|                                                                                                           |\n",
      "| block2_sepconv2_act (Activatio  (None, 189, 189, 12  0        []                               Y          |\n",
      "| n)                           8)                                                                           |\n",
      "|                                                                                                           |\n",
      "| block2_sepconv2 (SeparableConv  (None, 189, 189, 12  17536    []                               Y          |\n",
      "| 2D)                          8)                                                                           |\n",
      "|                                                                                                           |\n",
      "| block2_sepconv2_bn (BatchNorma  (None, 189, 189, 12  512      []                               Y          |\n",
      "| lization)                    8)                                                                           |\n",
      "|                                                                                                           |\n",
      "| conv2d (Conv2D)              (None, 95, 95, 128)  8192        []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block2_pool (MaxPooling2D)   (None, 95, 95, 128)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| batch_normalization_2 (BatchNo  (None, 95, 95, 128)  512      []                               Y          |\n",
      "| rmalization)                                                                                              |\n",
      "|                                                                                                           |\n",
      "| add (Add)                    (None, 95, 95, 128)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3_sepconv1_act (Activatio  (None, 95, 95, 128)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block3_sepconv1 (SeparableConv  (None, 95, 95, 256)  33920    []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block3_sepconv1_bn (BatchNorma  (None, 95, 95, 256)  1024     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block3_sepconv2_act (Activatio  (None, 95, 95, 256)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block3_sepconv2 (SeparableConv  (None, 95, 95, 256)  67840    []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block3_sepconv2_bn (BatchNorma  (None, 95, 95, 256)  1024     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| conv2d_1 (Conv2D)            (None, 48, 48, 256)  32768       []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block3_pool (MaxPooling2D)   (None, 48, 48, 256)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| batch_normalization_3 (BatchNo  (None, 48, 48, 256)  1024     []                               Y          |\n",
      "| rmalization)                                                                                              |\n",
      "|                                                                                                           |\n",
      "| add_1 (Add)                  (None, 48, 48, 256)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4_sepconv1_act (Activatio  (None, 48, 48, 256)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4_sepconv1 (SeparableConv  (None, 48, 48, 728)  188672   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block4_sepconv1_bn (BatchNorma  (None, 48, 48, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block4_sepconv2_act (Activatio  (None, 48, 48, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block4_sepconv2 (SeparableConv  (None, 48, 48, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block4_sepconv2_bn (BatchNorma  (None, 48, 48, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| conv2d_2 (Conv2D)            (None, 24, 24, 728)  186368      []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block4_pool (MaxPooling2D)   (None, 24, 24, 728)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| batch_normalization_4 (BatchNo  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| rmalization)                                                                                              |\n",
      "|                                                                                                           |\n",
      "| add_2 (Add)                  (None, 24, 24, 728)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block5_sepconv1_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block5_sepconv1 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block5_sepconv1_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5_sepconv2_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block5_sepconv2 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block5_sepconv2_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block5_sepconv3_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block5_sepconv3 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block5_sepconv3_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| add_3 (Add)                  (None, 24, 24, 728)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block6_sepconv1_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block6_sepconv1 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block6_sepconv1_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6_sepconv2_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block6_sepconv2 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block6_sepconv2_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block6_sepconv3_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block6_sepconv3 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block6_sepconv3_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| add_4 (Add)                  (None, 24, 24, 728)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block7_sepconv1_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block7_sepconv1 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block7_sepconv1_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block7_sepconv2_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block7_sepconv2 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block7_sepconv2_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block7_sepconv3_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block7_sepconv3 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block7_sepconv3_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| add_5 (Add)                  (None, 24, 24, 728)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block8_sepconv1_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block8_sepconv1 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block8_sepconv1_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block8_sepconv2_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block8_sepconv2 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block8_sepconv2_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block8_sepconv3_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block8_sepconv3 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block8_sepconv3_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| add_6 (Add)                  (None, 24, 24, 728)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block9_sepconv1_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block9_sepconv1 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block9_sepconv1_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block9_sepconv2_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block9_sepconv2 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block9_sepconv2_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| block9_sepconv3_act (Activatio  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| n)                                                                                                        |\n",
      "|                                                                                                           |\n",
      "| block9_sepconv3 (SeparableConv  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| 2D)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block9_sepconv3_bn (BatchNorma  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| lization)                                                                                                 |\n",
      "|                                                                                                           |\n",
      "| add_7 (Add)                  (None, 24, 24, 728)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block10_sepconv1_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block10_sepconv1 (SeparableCon  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| v2D)                                                                                                      |\n",
      "|                                                                                                           |\n",
      "| block10_sepconv1_bn (BatchNorm  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| alization)                                                                                                |\n",
      "|                                                                                                           |\n",
      "| block10_sepconv2_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block10_sepconv2 (SeparableCon  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| v2D)                                                                                                      |\n",
      "|                                                                                                           |\n",
      "| block10_sepconv2_bn (BatchNorm  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| alization)                                                                                                |\n",
      "|                                                                                                           |\n",
      "| block10_sepconv3_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block10_sepconv3 (SeparableCon  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| v2D)                                                                                                      |\n",
      "|                                                                                                           |\n",
      "| block10_sepconv3_bn (BatchNorm  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| alization)                                                                                                |\n",
      "|                                                                                                           |\n",
      "| add_8 (Add)                  (None, 24, 24, 728)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block11_sepconv1_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block11_sepconv1 (SeparableCon  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| v2D)                                                                                                      |\n",
      "|                                                                                                           |\n",
      "| block11_sepconv1_bn (BatchNorm  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| alization)                                                                                                |\n",
      "|                                                                                                           |\n",
      "| block11_sepconv2_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block11_sepconv2 (SeparableCon  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| v2D)                                                                                                      |\n",
      "|                                                                                                           |\n",
      "| block11_sepconv2_bn (BatchNorm  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| alization)                                                                                                |\n",
      "|                                                                                                           |\n",
      "| block11_sepconv3_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block11_sepconv3 (SeparableCon  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| v2D)                                                                                                      |\n",
      "|                                                                                                           |\n",
      "| block11_sepconv3_bn (BatchNorm  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| alization)                                                                                                |\n",
      "|                                                                                                           |\n",
      "| add_9 (Add)                  (None, 24, 24, 728)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block12_sepconv1_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block12_sepconv1 (SeparableCon  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| v2D)                                                                                                      |\n",
      "|                                                                                                           |\n",
      "| block12_sepconv1_bn (BatchNorm  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| alization)                                                                                                |\n",
      "|                                                                                                           |\n",
      "| block12_sepconv2_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block12_sepconv2 (SeparableCon  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| v2D)                                                                                                      |\n",
      "|                                                                                                           |\n",
      "| block12_sepconv2_bn (BatchNorm  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| alization)                                                                                                |\n",
      "|                                                                                                           |\n",
      "| block12_sepconv3_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block12_sepconv3 (SeparableCon  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| v2D)                                                                                                      |\n",
      "|                                                                                                           |\n",
      "| block12_sepconv3_bn (BatchNorm  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| alization)                                                                                                |\n",
      "|                                                                                                           |\n",
      "| add_10 (Add)                 (None, 24, 24, 728)  0           []                               Y          |\n",
      "|                                                                                                           |\n",
      "| block13_sepconv1_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block13_sepconv1 (SeparableCon  (None, 24, 24, 728)  536536   []                               Y          |\n",
      "| v2D)                                                                                                      |\n",
      "|                                                                                                           |\n",
      "| block13_sepconv1_bn (BatchNorm  (None, 24, 24, 728)  2912     []                               Y          |\n",
      "| alization)                                                                                                |\n",
      "|                                                                                                           |\n",
      "| block13_sepconv2_act (Activati  (None, 24, 24, 728)  0        []                               Y          |\n",
      "| on)                                                                                                       |\n",
      "|                                                                                                           |\n",
      "| block13_sepconv2 (SeparableCon  (None, 24, 24, 1024  752024   []                               Y          |\n",
      "| v2D)                         )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block13_sepconv2_bn (BatchNorm  (None, 24, 24, 1024  4096     []                               Y          |\n",
      "| alization)                   )                                                                            |\n",
      "|                                                                                                           |\n",
      "| conv2d_3 (Conv2D)            (None, 12, 12, 1024  745472      []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block13_pool (MaxPooling2D)  (None, 12, 12, 1024  0           []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| batch_normalization_5 (BatchNo  (None, 12, 12, 1024  4096     []                               Y          |\n",
      "| rmalization)                 )                                                                            |\n",
      "|                                                                                                           |\n",
      "| add_11 (Add)                 (None, 12, 12, 1024  0           []                               Y          |\n",
      "|                              )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block14_sepconv1 (SeparableCon  (None, 12, 12, 1536  1582080  []                               Y          |\n",
      "| v2D)                         )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block14_sepconv1_bn (BatchNorm  (None, 12, 12, 1536  6144     []                               Y          |\n",
      "| alization)                   )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block14_sepconv1_act (Activati  (None, 12, 12, 1536  0        []                               Y          |\n",
      "| on)                          )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block14_sepconv2 (SeparableCon  (None, 12, 12, 2048  3159552  []                               Y          |\n",
      "| v2D)                         )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block14_sepconv2_bn (BatchNorm  (None, 12, 12, 2048  8192     []                               Y          |\n",
      "| alization)                   )                                                                            |\n",
      "|                                                                                                           |\n",
      "| block14_sepconv2_act (Activati  (None, 12, 12, 2048  0        []                               Y          |\n",
      "| on)                          )                                                                            |\n",
      "Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯\n",
      " concatenate (Concatenate)      (None, 12, 12, 4608  0           ['efficientnet-b7[0][0]',        Y          \n",
      "                                )                                 'xception[0][0]']                          \n",
      "                                                                                                             \n",
      " global_average_pooling2d_1 (Gl  (None, 4608)        0           ['concatenate[0][0]']            Y          \n",
      " obalAveragePooling2D)                                                                                       \n",
      "                                                                                                             \n",
      " dense_4 (Dense)                (None, 2048)         9439232     ['global_average_pooling2d_1[0]  Y          \n",
      "                                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " dropout_1 (Dropout)            (None, 2048)         0           ['dense_4[0][0]']                Y          \n",
      "                                                                                                             \n",
      " batch_normalization_6 (BatchNo  (None, 2048)        8192        ['dropout_1[0][0]']              Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " dense_5 (Dense)                (None, 512)          1049088     ['batch_normalization_6[0][0]']  Y          \n",
      "                                                                                                             \n",
      " batch_normalization_7 (BatchNo  (None, 512)         2048        ['dense_5[0][0]']                Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " dense_6 (Dense)                (None, 128)          65664       ['batch_normalization_7[0][0]']  Y          \n",
      "                                                                                                             \n",
      " dense_7 (Dense)                (None, 2)            258         ['dense_6[0][0]']                Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 95,523,642\n",
      "Trainable params: 95,153,274\n",
      "Non-trainable params: 370,368\n",
      "_____________________________________________________________________________________________________________\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "\n",
    "\n",
    "# FUNC\n",
    "def Combo_Model(freeze_layers1, freeze_layers2):\n",
    "    # Define a common input\n",
    "    common_input = Input(shape=(img_res[0], img_res[1], img_res[2]))\n",
    "\n",
    "    # Base model 1\n",
    "    base_model1 = KENB7(input_shape=(img_res[0], img_res[1], img_res[2]), weights=None, include_top=False)\n",
    "    # base_model1.load_weights('models\\Ready\\Other\\EfficientNetB7_PRET.h5', by_name=True, skip_mismatch=True)\n",
    "    base_model1_out = base_model1(common_input)\n",
    "\n",
    "    # Base model 2\n",
    "    base_model2 = Xception(input_shape=(img_res[0], img_res[1], img_res[2]), weights=None, include_top=False)\n",
    "    # base_model1.load_weights('models\\Ready\\Other\\Xception_PRET.h5', by_name=True, skip_mismatch=True)\n",
    "    base_model2_out = base_model2(common_input)\n",
    "\n",
    "    print(\"Total base_model1 layers: \", len(base_model1.layers))\n",
    "    print(\"Total base_model2 layers: \", len(base_model2.layers))\n",
    "\n",
    "    # Freeze the specified number of layers in both models\n",
    "    for layer in base_model1.layers[:freeze_layers1]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model2.layers[:freeze_layers2]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest in both models\n",
    "    for layer in base_model1.layers[freeze_layers1:]:\n",
    "        layer.trainable = True\n",
    "    for layer in base_model2.layers[freeze_layers2:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Combine the output of the two base models\n",
    "    combined = concatenate([base_model1_out, base_model2_out])\n",
    "\n",
    "    # adding CDL\n",
    "    base_model_FT = GlobalAveragePooling2D()(combined)\n",
    "    Dense_L1 = Dense(2048, activation=\"relu\", kernel_regularizer=l2(0.04))(base_model_FT)\n",
    "    Dropout_L1 = Dropout(0.4)(Dense_L1)\n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.02))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation=\"relu\")(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\")(Dense_L3)\n",
    "\n",
    "    combo_model = Model(inputs=common_input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(combo_model.layers))\n",
    "\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9)\n",
    "    combo_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return combo_model\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers_1 = 0\n",
    "freeze_layers_2 = 0\n",
    "model = Combo_Model(freeze_layers_1, freeze_layers_2)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev1.4\n",
    "```\n",
    "statuses: Test\n",
    "Working: âœ…\n",
    "Max fine tuned acc: âš ï¸\n",
    "Max fine tuned acc TLRev2: â‰…95.64\n",
    "type: transfer learning>>>(EfficientNetV2XL)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Load pretrained from: C:\\Users\\aydin\\.keras\\models/efficientnetv2\\efficientnetv2-xl-21k-ft1k.h5\n",
      "Model: \"model\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     Trainable  \n",
      "=============================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               Y          \n",
      "                                )]                                                                           \n",
      "                                                                                                             \n",
      " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['input_1[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_swish (Activation)        (None, 112, 112, 32  0           ['stem_bn[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stack_0_block0_fu_conv (Conv2D  (None, 112, 112, 32  9216       ['stem_swish[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " stack_0_block0_fu_bn (BatchNor  (None, 112, 112, 32  128        ['stack_0_block0_fu_conv[0][0]'  Y          \n",
      " malization)                    )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_0_block0_fu_swish (Activ  (None, 112, 112, 32  0          ['stack_0_block0_fu_bn[0][0]']   Y          \n",
      " ation)                         )                                                                            \n",
      "                                                                                                             \n",
      " add (Add)                      (None, 112, 112, 32  0           ['stem_swish[0][0]',             Y          \n",
      "                                )                                 'stack_0_block0_fu_swish[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_0_block1_fu_conv (Conv2D  (None, 112, 112, 32  9216       ['add[0][0]']                    Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " stack_0_block1_fu_bn (BatchNor  (None, 112, 112, 32  128        ['stack_0_block1_fu_conv[0][0]'  Y          \n",
      " malization)                    )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_0_block1_fu_swish (Activ  (None, 112, 112, 32  0          ['stack_0_block1_fu_bn[0][0]']   Y          \n",
      " ation)                         )                                                                            \n",
      "                                                                                                             \n",
      " add_1 (Add)                    (None, 112, 112, 32  0           ['add[0][0]',                    Y          \n",
      "                                )                                 'stack_0_block1_fu_swish[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_0_block2_fu_conv (Conv2D  (None, 112, 112, 32  9216       ['add_1[0][0]']                  Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " stack_0_block2_fu_bn (BatchNor  (None, 112, 112, 32  128        ['stack_0_block2_fu_conv[0][0]'  Y          \n",
      " malization)                    )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_0_block2_fu_swish (Activ  (None, 112, 112, 32  0          ['stack_0_block2_fu_bn[0][0]']   Y          \n",
      " ation)                         )                                                                            \n",
      "                                                                                                             \n",
      " add_2 (Add)                    (None, 112, 112, 32  0           ['add_1[0][0]',                  Y          \n",
      "                                )                                 'stack_0_block2_fu_swish[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_0_block3_fu_conv (Conv2D  (None, 112, 112, 32  9216       ['add_2[0][0]']                  Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " stack_0_block3_fu_bn (BatchNor  (None, 112, 112, 32  128        ['stack_0_block3_fu_conv[0][0]'  Y          \n",
      " malization)                    )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_0_block3_fu_swish (Activ  (None, 112, 112, 32  0          ['stack_0_block3_fu_bn[0][0]']   Y          \n",
      " ation)                         )                                                                            \n",
      "                                                                                                             \n",
      " add_3 (Add)                    (None, 112, 112, 32  0           ['add_2[0][0]',                  Y          \n",
      "                                )                                 'stack_0_block3_fu_swish[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_1_block0_sortcut_conv (C  (None, 56, 56, 128)  36864      ['add_3[0][0]']                  Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_1_block0_sortcut_bn (Bat  (None, 56, 56, 128)  512        ['stack_1_block0_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_1_block0_sortcut_swish (  (None, 56, 56, 128)  0          ['stack_1_block0_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_1_block0_MB_pw_conv (Con  (None, 56, 56, 64)  8192        ['stack_1_block0_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_1_block0_MB_pw_bn (Batch  (None, 56, 56, 64)  256         ['stack_1_block0_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " stack_1_block1_sortcut_conv (C  (None, 56, 56, 256)  147456     ['stack_1_block0_MB_pw_bn[0][0]  Y          \n",
      " onv2D)                                                          ']                                          \n",
      "                                                                                                             \n",
      " stack_1_block1_sortcut_bn (Bat  (None, 56, 56, 256)  1024       ['stack_1_block1_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_1_block1_sortcut_swish (  (None, 56, 56, 256)  0          ['stack_1_block1_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_1_block1_MB_pw_conv (Con  (None, 56, 56, 64)  16384       ['stack_1_block1_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_1_block1_MB_pw_bn (Batch  (None, 56, 56, 64)  256         ['stack_1_block1_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_4 (Add)                    (None, 56, 56, 64)   0           ['stack_1_block0_MB_pw_bn[0][0]  Y          \n",
      "                                                                 ',                                          \n",
      "                                                                  'stack_1_block1_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_1_block2_sortcut_conv (C  (None, 56, 56, 256)  147456     ['add_4[0][0]']                  Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_1_block2_sortcut_bn (Bat  (None, 56, 56, 256)  1024       ['stack_1_block2_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_1_block2_sortcut_swish (  (None, 56, 56, 256)  0          ['stack_1_block2_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_1_block2_MB_pw_conv (Con  (None, 56, 56, 64)  16384       ['stack_1_block2_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_1_block2_MB_pw_bn (Batch  (None, 56, 56, 64)  256         ['stack_1_block2_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_5 (Add)                    (None, 56, 56, 64)   0           ['add_4[0][0]',                  Y          \n",
      "                                                                  'stack_1_block2_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_1_block3_sortcut_conv (C  (None, 56, 56, 256)  147456     ['add_5[0][0]']                  Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_1_block3_sortcut_bn (Bat  (None, 56, 56, 256)  1024       ['stack_1_block3_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_1_block3_sortcut_swish (  (None, 56, 56, 256)  0          ['stack_1_block3_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_1_block3_MB_pw_conv (Con  (None, 56, 56, 64)  16384       ['stack_1_block3_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_1_block3_MB_pw_bn (Batch  (None, 56, 56, 64)  256         ['stack_1_block3_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_6 (Add)                    (None, 56, 56, 64)   0           ['add_5[0][0]',                  Y          \n",
      "                                                                  'stack_1_block3_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_1_block4_sortcut_conv (C  (None, 56, 56, 256)  147456     ['add_6[0][0]']                  Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_1_block4_sortcut_bn (Bat  (None, 56, 56, 256)  1024       ['stack_1_block4_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_1_block4_sortcut_swish (  (None, 56, 56, 256)  0          ['stack_1_block4_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_1_block4_MB_pw_conv (Con  (None, 56, 56, 64)  16384       ['stack_1_block4_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_1_block4_MB_pw_bn (Batch  (None, 56, 56, 64)  256         ['stack_1_block4_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_7 (Add)                    (None, 56, 56, 64)   0           ['add_6[0][0]',                  Y          \n",
      "                                                                  'stack_1_block4_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_1_block5_sortcut_conv (C  (None, 56, 56, 256)  147456     ['add_7[0][0]']                  Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_1_block5_sortcut_bn (Bat  (None, 56, 56, 256)  1024       ['stack_1_block5_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_1_block5_sortcut_swish (  (None, 56, 56, 256)  0          ['stack_1_block5_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_1_block5_MB_pw_conv (Con  (None, 56, 56, 64)  16384       ['stack_1_block5_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_1_block5_MB_pw_bn (Batch  (None, 56, 56, 64)  256         ['stack_1_block5_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_8 (Add)                    (None, 56, 56, 64)   0           ['add_7[0][0]',                  Y          \n",
      "                                                                  'stack_1_block5_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_1_block6_sortcut_conv (C  (None, 56, 56, 256)  147456     ['add_8[0][0]']                  Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_1_block6_sortcut_bn (Bat  (None, 56, 56, 256)  1024       ['stack_1_block6_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_1_block6_sortcut_swish (  (None, 56, 56, 256)  0          ['stack_1_block6_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_1_block6_MB_pw_conv (Con  (None, 56, 56, 64)  16384       ['stack_1_block6_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_1_block6_MB_pw_bn (Batch  (None, 56, 56, 64)  256         ['stack_1_block6_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_9 (Add)                    (None, 56, 56, 64)   0           ['add_8[0][0]',                  Y          \n",
      "                                                                  'stack_1_block6_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_1_block7_sortcut_conv (C  (None, 56, 56, 256)  147456     ['add_9[0][0]']                  Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_1_block7_sortcut_bn (Bat  (None, 56, 56, 256)  1024       ['stack_1_block7_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_1_block7_sortcut_swish (  (None, 56, 56, 256)  0          ['stack_1_block7_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_1_block7_MB_pw_conv (Con  (None, 56, 56, 64)  16384       ['stack_1_block7_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_1_block7_MB_pw_bn (Batch  (None, 56, 56, 64)  256         ['stack_1_block7_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_10 (Add)                   (None, 56, 56, 64)   0           ['add_9[0][0]',                  Y          \n",
      "                                                                  'stack_1_block7_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_2_block0_sortcut_conv (C  (None, 28, 28, 256)  147456     ['add_10[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_2_block0_sortcut_bn (Bat  (None, 28, 28, 256)  1024       ['stack_2_block0_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_2_block0_sortcut_swish (  (None, 28, 28, 256)  0          ['stack_2_block0_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_2_block0_MB_pw_conv (Con  (None, 28, 28, 96)  24576       ['stack_2_block0_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_2_block0_MB_pw_bn (Batch  (None, 28, 28, 96)  384         ['stack_2_block0_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " stack_2_block1_sortcut_conv (C  (None, 28, 28, 384)  331776     ['stack_2_block0_MB_pw_bn[0][0]  Y          \n",
      " onv2D)                                                          ']                                          \n",
      "                                                                                                             \n",
      " stack_2_block1_sortcut_bn (Bat  (None, 28, 28, 384)  1536       ['stack_2_block1_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_2_block1_sortcut_swish (  (None, 28, 28, 384)  0          ['stack_2_block1_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_2_block1_MB_pw_conv (Con  (None, 28, 28, 96)  36864       ['stack_2_block1_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_2_block1_MB_pw_bn (Batch  (None, 28, 28, 96)  384         ['stack_2_block1_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_11 (Add)                   (None, 28, 28, 96)   0           ['stack_2_block0_MB_pw_bn[0][0]  Y          \n",
      "                                                                 ',                                          \n",
      "                                                                  'stack_2_block1_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_2_block2_sortcut_conv (C  (None, 28, 28, 384)  331776     ['add_11[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_2_block2_sortcut_bn (Bat  (None, 28, 28, 384)  1536       ['stack_2_block2_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_2_block2_sortcut_swish (  (None, 28, 28, 384)  0          ['stack_2_block2_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_2_block2_MB_pw_conv (Con  (None, 28, 28, 96)  36864       ['stack_2_block2_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_2_block2_MB_pw_bn (Batch  (None, 28, 28, 96)  384         ['stack_2_block2_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_12 (Add)                   (None, 28, 28, 96)   0           ['add_11[0][0]',                 Y          \n",
      "                                                                  'stack_2_block2_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_2_block3_sortcut_conv (C  (None, 28, 28, 384)  331776     ['add_12[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_2_block3_sortcut_bn (Bat  (None, 28, 28, 384)  1536       ['stack_2_block3_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_2_block3_sortcut_swish (  (None, 28, 28, 384)  0          ['stack_2_block3_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_2_block3_MB_pw_conv (Con  (None, 28, 28, 96)  36864       ['stack_2_block3_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_2_block3_MB_pw_bn (Batch  (None, 28, 28, 96)  384         ['stack_2_block3_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_13 (Add)                   (None, 28, 28, 96)   0           ['add_12[0][0]',                 Y          \n",
      "                                                                  'stack_2_block3_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_2_block4_sortcut_conv (C  (None, 28, 28, 384)  331776     ['add_13[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_2_block4_sortcut_bn (Bat  (None, 28, 28, 384)  1536       ['stack_2_block4_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_2_block4_sortcut_swish (  (None, 28, 28, 384)  0          ['stack_2_block4_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_2_block4_MB_pw_conv (Con  (None, 28, 28, 96)  36864       ['stack_2_block4_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_2_block4_MB_pw_bn (Batch  (None, 28, 28, 96)  384         ['stack_2_block4_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_14 (Add)                   (None, 28, 28, 96)   0           ['add_13[0][0]',                 Y          \n",
      "                                                                  'stack_2_block4_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_2_block5_sortcut_conv (C  (None, 28, 28, 384)  331776     ['add_14[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_2_block5_sortcut_bn (Bat  (None, 28, 28, 384)  1536       ['stack_2_block5_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_2_block5_sortcut_swish (  (None, 28, 28, 384)  0          ['stack_2_block5_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_2_block5_MB_pw_conv (Con  (None, 28, 28, 96)  36864       ['stack_2_block5_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_2_block5_MB_pw_bn (Batch  (None, 28, 28, 96)  384         ['stack_2_block5_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_15 (Add)                   (None, 28, 28, 96)   0           ['add_14[0][0]',                 Y          \n",
      "                                                                  'stack_2_block5_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_2_block6_sortcut_conv (C  (None, 28, 28, 384)  331776     ['add_15[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_2_block6_sortcut_bn (Bat  (None, 28, 28, 384)  1536       ['stack_2_block6_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_2_block6_sortcut_swish (  (None, 28, 28, 384)  0          ['stack_2_block6_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_2_block6_MB_pw_conv (Con  (None, 28, 28, 96)  36864       ['stack_2_block6_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_2_block6_MB_pw_bn (Batch  (None, 28, 28, 96)  384         ['stack_2_block6_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_16 (Add)                   (None, 28, 28, 96)   0           ['add_15[0][0]',                 Y          \n",
      "                                                                  'stack_2_block6_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_2_block7_sortcut_conv (C  (None, 28, 28, 384)  331776     ['add_16[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_2_block7_sortcut_bn (Bat  (None, 28, 28, 384)  1536       ['stack_2_block7_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_2_block7_sortcut_swish (  (None, 28, 28, 384)  0          ['stack_2_block7_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_2_block7_MB_pw_conv (Con  (None, 28, 28, 96)  36864       ['stack_2_block7_sortcut_swish[  Y          \n",
      " v2D)                                                            0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_2_block7_MB_pw_bn (Batch  (None, 28, 28, 96)  384         ['stack_2_block7_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_17 (Add)                   (None, 28, 28, 96)   0           ['add_16[0][0]',                 Y          \n",
      "                                                                  'stack_2_block7_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block0_sortcut_conv (C  (None, 28, 28, 384)  36864      ['add_17[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_3_block0_sortcut_bn (Bat  (None, 28, 28, 384)  1536       ['stack_3_block0_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block0_sortcut_swish (  (None, 28, 28, 384)  0          ['stack_3_block0_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block0_MB_dw_ (Depthwi  (None, 14, 14, 384)  3456       ['stack_3_block0_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block0_MB_dw_bn (Batch  (None, 14, 14, 384)  1536       ['stack_3_block0_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_3_block0_MB_dw_swish (Ac  (None, 14, 14, 384)  0          ['stack_3_block0_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 1, 1, 384)   0           ['stack_3_block0_MB_dw_swish[0]  Y          \n",
      " a)                                                              [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block0_se_1_conv (Conv  (None, 1, 1, 24)    9240        ['tf.math.reduce_mean[0][0]']    Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation (Activation)        (None, 1, 1, 24)     0           ['stack_3_block0_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block0_se_2_conv (Conv  (None, 1, 1, 384)   9600        ['activation[0][0]']             Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_1 (Activation)      (None, 1, 1, 384)    0           ['stack_3_block0_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply (Multiply)            (None, 14, 14, 384)  0           ['stack_3_block0_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_1[0][0]']                      \n",
      "                                                                                                             \n",
      " stack_3_block0_MB_pw_conv (Con  (None, 14, 14, 192)  73728      ['multiply[0][0]']               Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_3_block0_MB_pw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block0_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block1_sortcut_conv (C  (None, 14, 14, 768)  147456     ['stack_3_block0_MB_pw_bn[0][0]  Y          \n",
      " onv2D)                                                          ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block1_sortcut_bn (Bat  (None, 14, 14, 768)  3072       ['stack_3_block1_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block1_sortcut_swish (  (None, 14, 14, 768)  0          ['stack_3_block1_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block1_MB_dw_ (Depthwi  (None, 14, 14, 768)  6912       ['stack_3_block1_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block1_MB_dw_bn (Batch  (None, 14, 14, 768)  3072       ['stack_3_block1_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_3_block1_MB_dw_swish (Ac  (None, 14, 14, 768)  0          ['stack_3_block1_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_1 (TFOpLam  (None, 1, 1, 768)   0           ['stack_3_block1_MB_dw_swish[0]  Y          \n",
      " bda)                                                            [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block1_se_1_conv (Conv  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_1[0][0]']  Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_2 (Activation)      (None, 1, 1, 48)     0           ['stack_3_block1_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block1_se_2_conv (Conv  (None, 1, 1, 768)   37632       ['activation_2[0][0]']           Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_3 (Activation)      (None, 1, 1, 768)    0           ['stack_3_block1_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_1 (Multiply)          (None, 14, 14, 768)  0           ['stack_3_block1_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_3[0][0]']                      \n",
      "                                                                                                             \n",
      " stack_3_block1_MB_pw_conv (Con  (None, 14, 14, 192)  147456     ['multiply_1[0][0]']             Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_3_block1_MB_pw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block1_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_18 (Add)                   (None, 14, 14, 192)  0           ['stack_3_block0_MB_pw_bn[0][0]  Y          \n",
      "                                                                 ',                                          \n",
      "                                                                  'stack_3_block1_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block2_sortcut_conv (C  (None, 14, 14, 768)  147456     ['add_18[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_3_block2_sortcut_bn (Bat  (None, 14, 14, 768)  3072       ['stack_3_block2_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block2_sortcut_swish (  (None, 14, 14, 768)  0          ['stack_3_block2_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block2_MB_dw_ (Depthwi  (None, 14, 14, 768)  6912       ['stack_3_block2_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block2_MB_dw_bn (Batch  (None, 14, 14, 768)  3072       ['stack_3_block2_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_3_block2_MB_dw_swish (Ac  (None, 14, 14, 768)  0          ['stack_3_block2_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 1, 1, 768)   0           ['stack_3_block2_MB_dw_swish[0]  Y          \n",
      " bda)                                                            [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block2_se_1_conv (Conv  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_2[0][0]']  Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_4 (Activation)      (None, 1, 1, 48)     0           ['stack_3_block2_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block2_se_2_conv (Conv  (None, 1, 1, 768)   37632       ['activation_4[0][0]']           Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_5 (Activation)      (None, 1, 1, 768)    0           ['stack_3_block2_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_2 (Multiply)          (None, 14, 14, 768)  0           ['stack_3_block2_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_5[0][0]']                      \n",
      "                                                                                                             \n",
      " stack_3_block2_MB_pw_conv (Con  (None, 14, 14, 192)  147456     ['multiply_2[0][0]']             Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_3_block2_MB_pw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block2_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_19 (Add)                   (None, 14, 14, 192)  0           ['add_18[0][0]',                 Y          \n",
      "                                                                  'stack_3_block2_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block3_sortcut_conv (C  (None, 14, 14, 768)  147456     ['add_19[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_3_block3_sortcut_bn (Bat  (None, 14, 14, 768)  3072       ['stack_3_block3_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block3_sortcut_swish (  (None, 14, 14, 768)  0          ['stack_3_block3_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block3_MB_dw_ (Depthwi  (None, 14, 14, 768)  6912       ['stack_3_block3_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block3_MB_dw_bn (Batch  (None, 14, 14, 768)  3072       ['stack_3_block3_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_3_block3_MB_dw_swish (Ac  (None, 14, 14, 768)  0          ['stack_3_block3_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_3 (TFOpLam  (None, 1, 1, 768)   0           ['stack_3_block3_MB_dw_swish[0]  Y          \n",
      " bda)                                                            [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block3_se_1_conv (Conv  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_3[0][0]']  Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_6 (Activation)      (None, 1, 1, 48)     0           ['stack_3_block3_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block3_se_2_conv (Conv  (None, 1, 1, 768)   37632       ['activation_6[0][0]']           Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_7 (Activation)      (None, 1, 1, 768)    0           ['stack_3_block3_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_3 (Multiply)          (None, 14, 14, 768)  0           ['stack_3_block3_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_7[0][0]']                      \n",
      "                                                                                                             \n",
      " stack_3_block3_MB_pw_conv (Con  (None, 14, 14, 192)  147456     ['multiply_3[0][0]']             Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_3_block3_MB_pw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block3_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_20 (Add)                   (None, 14, 14, 192)  0           ['add_19[0][0]',                 Y          \n",
      "                                                                  'stack_3_block3_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block4_sortcut_conv (C  (None, 14, 14, 768)  147456     ['add_20[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_3_block4_sortcut_bn (Bat  (None, 14, 14, 768)  3072       ['stack_3_block4_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block4_sortcut_swish (  (None, 14, 14, 768)  0          ['stack_3_block4_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block4_MB_dw_ (Depthwi  (None, 14, 14, 768)  6912       ['stack_3_block4_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block4_MB_dw_bn (Batch  (None, 14, 14, 768)  3072       ['stack_3_block4_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_3_block4_MB_dw_swish (Ac  (None, 14, 14, 768)  0          ['stack_3_block4_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_4 (TFOpLam  (None, 1, 1, 768)   0           ['stack_3_block4_MB_dw_swish[0]  Y          \n",
      " bda)                                                            [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block4_se_1_conv (Conv  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_4[0][0]']  Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_8 (Activation)      (None, 1, 1, 48)     0           ['stack_3_block4_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block4_se_2_conv (Conv  (None, 1, 1, 768)   37632       ['activation_8[0][0]']           Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_9 (Activation)      (None, 1, 1, 768)    0           ['stack_3_block4_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_4 (Multiply)          (None, 14, 14, 768)  0           ['stack_3_block4_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_9[0][0]']                      \n",
      "                                                                                                             \n",
      " stack_3_block4_MB_pw_conv (Con  (None, 14, 14, 192)  147456     ['multiply_4[0][0]']             Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_3_block4_MB_pw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block4_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_21 (Add)                   (None, 14, 14, 192)  0           ['add_20[0][0]',                 Y          \n",
      "                                                                  'stack_3_block4_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block5_sortcut_conv (C  (None, 14, 14, 768)  147456     ['add_21[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_3_block5_sortcut_bn (Bat  (None, 14, 14, 768)  3072       ['stack_3_block5_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block5_sortcut_swish (  (None, 14, 14, 768)  0          ['stack_3_block5_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block5_MB_dw_ (Depthwi  (None, 14, 14, 768)  6912       ['stack_3_block5_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block5_MB_dw_bn (Batch  (None, 14, 14, 768)  3072       ['stack_3_block5_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_3_block5_MB_dw_swish (Ac  (None, 14, 14, 768)  0          ['stack_3_block5_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_5 (TFOpLam  (None, 1, 1, 768)   0           ['stack_3_block5_MB_dw_swish[0]  Y          \n",
      " bda)                                                            [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block5_se_1_conv (Conv  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_5[0][0]']  Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_10 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block5_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block5_se_2_conv (Conv  (None, 1, 1, 768)   37632       ['activation_10[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_11 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block5_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_5 (Multiply)          (None, 14, 14, 768)  0           ['stack_3_block5_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_11[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block5_MB_pw_conv (Con  (None, 14, 14, 192)  147456     ['multiply_5[0][0]']             Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_3_block5_MB_pw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block5_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_22 (Add)                   (None, 14, 14, 192)  0           ['add_21[0][0]',                 Y          \n",
      "                                                                  'stack_3_block5_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block6_sortcut_conv (C  (None, 14, 14, 768)  147456     ['add_22[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_3_block6_sortcut_bn (Bat  (None, 14, 14, 768)  3072       ['stack_3_block6_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block6_sortcut_swish (  (None, 14, 14, 768)  0          ['stack_3_block6_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block6_MB_dw_ (Depthwi  (None, 14, 14, 768)  6912       ['stack_3_block6_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block6_MB_dw_bn (Batch  (None, 14, 14, 768)  3072       ['stack_3_block6_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_3_block6_MB_dw_swish (Ac  (None, 14, 14, 768)  0          ['stack_3_block6_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_6 (TFOpLam  (None, 1, 1, 768)   0           ['stack_3_block6_MB_dw_swish[0]  Y          \n",
      " bda)                                                            [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block6_se_1_conv (Conv  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_6[0][0]']  Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_12 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block6_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block6_se_2_conv (Conv  (None, 1, 1, 768)   37632       ['activation_12[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_13 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block6_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_6 (Multiply)          (None, 14, 14, 768)  0           ['stack_3_block6_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_13[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block6_MB_pw_conv (Con  (None, 14, 14, 192)  147456     ['multiply_6[0][0]']             Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_3_block6_MB_pw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block6_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_23 (Add)                   (None, 14, 14, 192)  0           ['add_22[0][0]',                 Y          \n",
      "                                                                  'stack_3_block6_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block7_sortcut_conv (C  (None, 14, 14, 768)  147456     ['add_23[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_3_block7_sortcut_bn (Bat  (None, 14, 14, 768)  3072       ['stack_3_block7_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block7_sortcut_swish (  (None, 14, 14, 768)  0          ['stack_3_block7_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block7_MB_dw_ (Depthwi  (None, 14, 14, 768)  6912       ['stack_3_block7_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block7_MB_dw_bn (Batch  (None, 14, 14, 768)  3072       ['stack_3_block7_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_3_block7_MB_dw_swish (Ac  (None, 14, 14, 768)  0          ['stack_3_block7_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_7 (TFOpLam  (None, 1, 1, 768)   0           ['stack_3_block7_MB_dw_swish[0]  Y          \n",
      " bda)                                                            [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block7_se_1_conv (Conv  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_7[0][0]']  Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_14 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block7_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block7_se_2_conv (Conv  (None, 1, 1, 768)   37632       ['activation_14[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_15 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block7_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_7 (Multiply)          (None, 14, 14, 768)  0           ['stack_3_block7_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_15[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block7_MB_pw_conv (Con  (None, 14, 14, 192)  147456     ['multiply_7[0][0]']             Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_3_block7_MB_pw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block7_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_24 (Add)                   (None, 14, 14, 192)  0           ['add_23[0][0]',                 Y          \n",
      "                                                                  'stack_3_block7_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block8_sortcut_conv (C  (None, 14, 14, 768)  147456     ['add_24[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_3_block8_sortcut_bn (Bat  (None, 14, 14, 768)  3072       ['stack_3_block8_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block8_sortcut_swish (  (None, 14, 14, 768)  0          ['stack_3_block8_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block8_MB_dw_ (Depthwi  (None, 14, 14, 768)  6912       ['stack_3_block8_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block8_MB_dw_bn (Batch  (None, 14, 14, 768)  3072       ['stack_3_block8_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_3_block8_MB_dw_swish (Ac  (None, 14, 14, 768)  0          ['stack_3_block8_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_8 (TFOpLam  (None, 1, 1, 768)   0           ['stack_3_block8_MB_dw_swish[0]  Y          \n",
      " bda)                                                            [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block8_se_1_conv (Conv  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_8[0][0]']  Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_16 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block8_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block8_se_2_conv (Conv  (None, 1, 1, 768)   37632       ['activation_16[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_17 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block8_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_8 (Multiply)          (None, 14, 14, 768)  0           ['stack_3_block8_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_17[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block8_MB_pw_conv (Con  (None, 14, 14, 192)  147456     ['multiply_8[0][0]']             Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_3_block8_MB_pw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block8_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_25 (Add)                   (None, 14, 14, 192)  0           ['add_24[0][0]',                 Y          \n",
      "                                                                  'stack_3_block8_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block9_sortcut_conv (C  (None, 14, 14, 768)  147456     ['add_25[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_3_block9_sortcut_bn (Bat  (None, 14, 14, 768)  3072       ['stack_3_block9_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block9_sortcut_swish (  (None, 14, 14, 768)  0          ['stack_3_block9_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block9_MB_dw_ (Depthwi  (None, 14, 14, 768)  6912       ['stack_3_block9_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block9_MB_dw_bn (Batch  (None, 14, 14, 768)  3072       ['stack_3_block9_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_3_block9_MB_dw_swish (Ac  (None, 14, 14, 768)  0          ['stack_3_block9_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_9 (TFOpLam  (None, 1, 1, 768)   0           ['stack_3_block9_MB_dw_swish[0]  Y          \n",
      " bda)                                                            [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block9_se_1_conv (Conv  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_9[0][0]']  Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_18 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block9_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block9_se_2_conv (Conv  (None, 1, 1, 768)   37632       ['activation_18[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_19 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block9_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_9 (Multiply)          (None, 14, 14, 768)  0           ['stack_3_block9_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_19[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block9_MB_pw_conv (Con  (None, 14, 14, 192)  147456     ['multiply_9[0][0]']             Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_3_block9_MB_pw_bn (Batch  (None, 14, 14, 192)  768        ['stack_3_block9_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_26 (Add)                   (None, 14, 14, 192)  0           ['add_25[0][0]',                 Y          \n",
      "                                                                  'stack_3_block9_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_3_block10_sortcut_conv (  (None, 14, 14, 768)  147456     ['add_26[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_3_block10_sortcut_bn (Ba  (None, 14, 14, 768)  3072       ['stack_3_block10_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block10_sortcut_swish   (None, 14, 14, 768)  0          ['stack_3_block10_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block10_MB_dw_ (Depthw  (None, 14, 14, 768)  6912       ['stack_3_block10_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_3_block10_MB_dw_bn (Batc  (None, 14, 14, 768)  3072       ['stack_3_block10_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_3_block10_MB_dw_swish (A  (None, 14, 14, 768)  0          ['stack_3_block10_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_10 (TFOpLa  (None, 1, 1, 768)   0           ['stack_3_block10_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block10_se_1_conv (Con  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_10[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_20 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block10_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block10_se_2_conv (Con  (None, 1, 1, 768)   37632       ['activation_20[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_21 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block10_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_10 (Multiply)         (None, 14, 14, 768)  0           ['stack_3_block10_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_21[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block10_MB_pw_conv (Co  (None, 14, 14, 192)  147456     ['multiply_10[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_3_block10_MB_pw_bn (Batc  (None, 14, 14, 192)  768        ['stack_3_block10_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_27 (Add)                   (None, 14, 14, 192)  0           ['add_26[0][0]',                 Y          \n",
      "                                                                  'stack_3_block10_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block11_sortcut_conv (  (None, 14, 14, 768)  147456     ['add_27[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_3_block11_sortcut_bn (Ba  (None, 14, 14, 768)  3072       ['stack_3_block11_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block11_sortcut_swish   (None, 14, 14, 768)  0          ['stack_3_block11_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block11_MB_dw_ (Depthw  (None, 14, 14, 768)  6912       ['stack_3_block11_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_3_block11_MB_dw_bn (Batc  (None, 14, 14, 768)  3072       ['stack_3_block11_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_3_block11_MB_dw_swish (A  (None, 14, 14, 768)  0          ['stack_3_block11_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_11 (TFOpLa  (None, 1, 1, 768)   0           ['stack_3_block11_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block11_se_1_conv (Con  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_11[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_22 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block11_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block11_se_2_conv (Con  (None, 1, 1, 768)   37632       ['activation_22[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_23 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block11_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_11 (Multiply)         (None, 14, 14, 768)  0           ['stack_3_block11_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_23[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block11_MB_pw_conv (Co  (None, 14, 14, 192)  147456     ['multiply_11[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_3_block11_MB_pw_bn (Batc  (None, 14, 14, 192)  768        ['stack_3_block11_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_28 (Add)                   (None, 14, 14, 192)  0           ['add_27[0][0]',                 Y          \n",
      "                                                                  'stack_3_block11_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block12_sortcut_conv (  (None, 14, 14, 768)  147456     ['add_28[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_3_block12_sortcut_bn (Ba  (None, 14, 14, 768)  3072       ['stack_3_block12_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block12_sortcut_swish   (None, 14, 14, 768)  0          ['stack_3_block12_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block12_MB_dw_ (Depthw  (None, 14, 14, 768)  6912       ['stack_3_block12_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_3_block12_MB_dw_bn (Batc  (None, 14, 14, 768)  3072       ['stack_3_block12_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_3_block12_MB_dw_swish (A  (None, 14, 14, 768)  0          ['stack_3_block12_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_12 (TFOpLa  (None, 1, 1, 768)   0           ['stack_3_block12_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block12_se_1_conv (Con  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_12[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_24 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block12_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block12_se_2_conv (Con  (None, 1, 1, 768)   37632       ['activation_24[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_25 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block12_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_12 (Multiply)         (None, 14, 14, 768)  0           ['stack_3_block12_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_25[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block12_MB_pw_conv (Co  (None, 14, 14, 192)  147456     ['multiply_12[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_3_block12_MB_pw_bn (Batc  (None, 14, 14, 192)  768        ['stack_3_block12_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_29 (Add)                   (None, 14, 14, 192)  0           ['add_28[0][0]',                 Y          \n",
      "                                                                  'stack_3_block12_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block13_sortcut_conv (  (None, 14, 14, 768)  147456     ['add_29[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_3_block13_sortcut_bn (Ba  (None, 14, 14, 768)  3072       ['stack_3_block13_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block13_sortcut_swish   (None, 14, 14, 768)  0          ['stack_3_block13_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block13_MB_dw_ (Depthw  (None, 14, 14, 768)  6912       ['stack_3_block13_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_3_block13_MB_dw_bn (Batc  (None, 14, 14, 768)  3072       ['stack_3_block13_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_3_block13_MB_dw_swish (A  (None, 14, 14, 768)  0          ['stack_3_block13_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_13 (TFOpLa  (None, 1, 1, 768)   0           ['stack_3_block13_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block13_se_1_conv (Con  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_13[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_26 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block13_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block13_se_2_conv (Con  (None, 1, 1, 768)   37632       ['activation_26[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_27 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block13_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_13 (Multiply)         (None, 14, 14, 768)  0           ['stack_3_block13_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_27[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block13_MB_pw_conv (Co  (None, 14, 14, 192)  147456     ['multiply_13[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_3_block13_MB_pw_bn (Batc  (None, 14, 14, 192)  768        ['stack_3_block13_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_30 (Add)                   (None, 14, 14, 192)  0           ['add_29[0][0]',                 Y          \n",
      "                                                                  'stack_3_block13_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block14_sortcut_conv (  (None, 14, 14, 768)  147456     ['add_30[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_3_block14_sortcut_bn (Ba  (None, 14, 14, 768)  3072       ['stack_3_block14_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block14_sortcut_swish   (None, 14, 14, 768)  0          ['stack_3_block14_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block14_MB_dw_ (Depthw  (None, 14, 14, 768)  6912       ['stack_3_block14_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_3_block14_MB_dw_bn (Batc  (None, 14, 14, 768)  3072       ['stack_3_block14_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_3_block14_MB_dw_swish (A  (None, 14, 14, 768)  0          ['stack_3_block14_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_14 (TFOpLa  (None, 1, 1, 768)   0           ['stack_3_block14_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block14_se_1_conv (Con  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_14[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_28 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block14_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block14_se_2_conv (Con  (None, 1, 1, 768)   37632       ['activation_28[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_29 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block14_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_14 (Multiply)         (None, 14, 14, 768)  0           ['stack_3_block14_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_29[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block14_MB_pw_conv (Co  (None, 14, 14, 192)  147456     ['multiply_14[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_3_block14_MB_pw_bn (Batc  (None, 14, 14, 192)  768        ['stack_3_block14_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_31 (Add)                   (None, 14, 14, 192)  0           ['add_30[0][0]',                 Y          \n",
      "                                                                  'stack_3_block14_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_3_block15_sortcut_conv (  (None, 14, 14, 768)  147456     ['add_31[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_3_block15_sortcut_bn (Ba  (None, 14, 14, 768)  3072       ['stack_3_block15_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_3_block15_sortcut_swish   (None, 14, 14, 768)  0          ['stack_3_block15_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_3_block15_MB_dw_ (Depthw  (None, 14, 14, 768)  6912       ['stack_3_block15_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_3_block15_MB_dw_bn (Batc  (None, 14, 14, 768)  3072       ['stack_3_block15_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_3_block15_MB_dw_swish (A  (None, 14, 14, 768)  0          ['stack_3_block15_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_15 (TFOpLa  (None, 1, 1, 768)   0           ['stack_3_block15_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_3_block15_se_1_conv (Con  (None, 1, 1, 48)    36912       ['tf.math.reduce_mean_15[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_30 (Activation)     (None, 1, 1, 48)     0           ['stack_3_block15_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_3_block15_se_2_conv (Con  (None, 1, 1, 768)   37632       ['activation_30[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_31 (Activation)     (None, 1, 1, 768)    0           ['stack_3_block15_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_15 (Multiply)         (None, 14, 14, 768)  0           ['stack_3_block15_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_31[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_3_block15_MB_pw_conv (Co  (None, 14, 14, 192)  147456     ['multiply_15[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_3_block15_MB_pw_bn (Batc  (None, 14, 14, 192)  768        ['stack_3_block15_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_32 (Add)                   (None, 14, 14, 192)  0           ['add_31[0][0]',                 Y          \n",
      "                                                                  'stack_3_block15_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block0_sortcut_conv (C  (None, 14, 14, 1152  221184     ['add_32[0][0]']                 Y          \n",
      " onv2D)                         )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block0_sortcut_bn (Bat  (None, 14, 14, 1152  4608       ['stack_4_block0_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block0_sortcut_swish (  (None, 14, 14, 1152  0          ['stack_4_block0_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block0_MB_dw_ (Depthwi  (None, 14, 14, 1152  10368      ['stack_4_block0_sortcut_swish[  Y          \n",
      " seConv2D)                      )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block0_MB_dw_bn (Batch  (None, 14, 14, 1152  4608       ['stack_4_block0_MB_dw_[0][0]']  Y          \n",
      " Normalization)                 )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block0_MB_dw_swish (Ac  (None, 14, 14, 1152  0          ['stack_4_block0_MB_dw_bn[0][0]  Y          \n",
      " tivation)                      )                                ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_16 (TFOpLa  (None, 1, 1, 1152)  0           ['stack_4_block0_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block0_se_1_conv (Conv  (None, 1, 1, 48)    55344       ['tf.math.reduce_mean_16[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_32 (Activation)     (None, 1, 1, 48)     0           ['stack_4_block0_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block0_se_2_conv (Conv  (None, 1, 1, 1152)  56448       ['activation_32[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_33 (Activation)     (None, 1, 1, 1152)   0           ['stack_4_block0_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_16 (Multiply)         (None, 14, 14, 1152  0           ['stack_4_block0_MB_dw_swish[0]  Y          \n",
      "                                )                                [0]',                                       \n",
      "                                                                  'activation_33[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block0_MB_pw_conv (Con  (None, 14, 14, 256)  294912     ['multiply_16[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_4_block0_MB_pw_bn (Batch  (None, 14, 14, 256)  1024       ['stack_4_block0_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block1_sortcut_conv (C  (None, 14, 14, 1536  393216     ['stack_4_block0_MB_pw_bn[0][0]  Y          \n",
      " onv2D)                         )                                ']                                          \n",
      "                                                                                                             \n",
      " stack_4_block1_sortcut_bn (Bat  (None, 14, 14, 1536  6144       ['stack_4_block1_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block1_sortcut_swish (  (None, 14, 14, 1536  0          ['stack_4_block1_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block1_MB_dw_ (Depthwi  (None, 14, 14, 1536  13824      ['stack_4_block1_sortcut_swish[  Y          \n",
      " seConv2D)                      )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block1_MB_dw_bn (Batch  (None, 14, 14, 1536  6144       ['stack_4_block1_MB_dw_[0][0]']  Y          \n",
      " Normalization)                 )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block1_MB_dw_swish (Ac  (None, 14, 14, 1536  0          ['stack_4_block1_MB_dw_bn[0][0]  Y          \n",
      " tivation)                      )                                ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_17 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block1_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block1_se_1_conv (Conv  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_17[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_34 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block1_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block1_se_2_conv (Conv  (None, 1, 1, 1536)  99840       ['activation_34[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_35 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block1_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_17 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block1_MB_dw_swish[0]  Y          \n",
      "                                )                                [0]',                                       \n",
      "                                                                  'activation_35[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block1_MB_pw_conv (Con  (None, 14, 14, 256)  393216     ['multiply_17[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_4_block1_MB_pw_bn (Batch  (None, 14, 14, 256)  1024       ['stack_4_block1_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_33 (Add)                   (None, 14, 14, 256)  0           ['stack_4_block0_MB_pw_bn[0][0]  Y          \n",
      "                                                                 ',                                          \n",
      "                                                                  'stack_4_block1_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_4_block2_sortcut_conv (C  (None, 14, 14, 1536  393216     ['add_33[0][0]']                 Y          \n",
      " onv2D)                         )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block2_sortcut_bn (Bat  (None, 14, 14, 1536  6144       ['stack_4_block2_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block2_sortcut_swish (  (None, 14, 14, 1536  0          ['stack_4_block2_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block2_MB_dw_ (Depthwi  (None, 14, 14, 1536  13824      ['stack_4_block2_sortcut_swish[  Y          \n",
      " seConv2D)                      )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block2_MB_dw_bn (Batch  (None, 14, 14, 1536  6144       ['stack_4_block2_MB_dw_[0][0]']  Y          \n",
      " Normalization)                 )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block2_MB_dw_swish (Ac  (None, 14, 14, 1536  0          ['stack_4_block2_MB_dw_bn[0][0]  Y          \n",
      " tivation)                      )                                ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_18 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block2_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block2_se_1_conv (Conv  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_18[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_36 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block2_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block2_se_2_conv (Conv  (None, 1, 1, 1536)  99840       ['activation_36[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_37 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block2_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_18 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block2_MB_dw_swish[0]  Y          \n",
      "                                )                                [0]',                                       \n",
      "                                                                  'activation_37[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block2_MB_pw_conv (Con  (None, 14, 14, 256)  393216     ['multiply_18[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_4_block2_MB_pw_bn (Batch  (None, 14, 14, 256)  1024       ['stack_4_block2_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_34 (Add)                   (None, 14, 14, 256)  0           ['add_33[0][0]',                 Y          \n",
      "                                                                  'stack_4_block2_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_4_block3_sortcut_conv (C  (None, 14, 14, 1536  393216     ['add_34[0][0]']                 Y          \n",
      " onv2D)                         )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block3_sortcut_bn (Bat  (None, 14, 14, 1536  6144       ['stack_4_block3_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block3_sortcut_swish (  (None, 14, 14, 1536  0          ['stack_4_block3_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block3_MB_dw_ (Depthwi  (None, 14, 14, 1536  13824      ['stack_4_block3_sortcut_swish[  Y          \n",
      " seConv2D)                      )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block3_MB_dw_bn (Batch  (None, 14, 14, 1536  6144       ['stack_4_block3_MB_dw_[0][0]']  Y          \n",
      " Normalization)                 )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block3_MB_dw_swish (Ac  (None, 14, 14, 1536  0          ['stack_4_block3_MB_dw_bn[0][0]  Y          \n",
      " tivation)                      )                                ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_19 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block3_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block3_se_1_conv (Conv  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_19[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_38 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block3_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block3_se_2_conv (Conv  (None, 1, 1, 1536)  99840       ['activation_38[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_39 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block3_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_19 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block3_MB_dw_swish[0]  Y          \n",
      "                                )                                [0]',                                       \n",
      "                                                                  'activation_39[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block3_MB_pw_conv (Con  (None, 14, 14, 256)  393216     ['multiply_19[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_4_block3_MB_pw_bn (Batch  (None, 14, 14, 256)  1024       ['stack_4_block3_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_35 (Add)                   (None, 14, 14, 256)  0           ['add_34[0][0]',                 Y          \n",
      "                                                                  'stack_4_block3_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_4_block4_sortcut_conv (C  (None, 14, 14, 1536  393216     ['add_35[0][0]']                 Y          \n",
      " onv2D)                         )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block4_sortcut_bn (Bat  (None, 14, 14, 1536  6144       ['stack_4_block4_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block4_sortcut_swish (  (None, 14, 14, 1536  0          ['stack_4_block4_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block4_MB_dw_ (Depthwi  (None, 14, 14, 1536  13824      ['stack_4_block4_sortcut_swish[  Y          \n",
      " seConv2D)                      )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block4_MB_dw_bn (Batch  (None, 14, 14, 1536  6144       ['stack_4_block4_MB_dw_[0][0]']  Y          \n",
      " Normalization)                 )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block4_MB_dw_swish (Ac  (None, 14, 14, 1536  0          ['stack_4_block4_MB_dw_bn[0][0]  Y          \n",
      " tivation)                      )                                ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_20 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block4_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block4_se_1_conv (Conv  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_20[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_40 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block4_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block4_se_2_conv (Conv  (None, 1, 1, 1536)  99840       ['activation_40[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_41 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block4_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_20 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block4_MB_dw_swish[0]  Y          \n",
      "                                )                                [0]',                                       \n",
      "                                                                  'activation_41[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block4_MB_pw_conv (Con  (None, 14, 14, 256)  393216     ['multiply_20[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_4_block4_MB_pw_bn (Batch  (None, 14, 14, 256)  1024       ['stack_4_block4_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_36 (Add)                   (None, 14, 14, 256)  0           ['add_35[0][0]',                 Y          \n",
      "                                                                  'stack_4_block4_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_4_block5_sortcut_conv (C  (None, 14, 14, 1536  393216     ['add_36[0][0]']                 Y          \n",
      " onv2D)                         )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block5_sortcut_bn (Bat  (None, 14, 14, 1536  6144       ['stack_4_block5_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block5_sortcut_swish (  (None, 14, 14, 1536  0          ['stack_4_block5_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block5_MB_dw_ (Depthwi  (None, 14, 14, 1536  13824      ['stack_4_block5_sortcut_swish[  Y          \n",
      " seConv2D)                      )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block5_MB_dw_bn (Batch  (None, 14, 14, 1536  6144       ['stack_4_block5_MB_dw_[0][0]']  Y          \n",
      " Normalization)                 )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block5_MB_dw_swish (Ac  (None, 14, 14, 1536  0          ['stack_4_block5_MB_dw_bn[0][0]  Y          \n",
      " tivation)                      )                                ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_21 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block5_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block5_se_1_conv (Conv  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_21[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_42 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block5_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block5_se_2_conv (Conv  (None, 1, 1, 1536)  99840       ['activation_42[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_43 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block5_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_21 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block5_MB_dw_swish[0]  Y          \n",
      "                                )                                [0]',                                       \n",
      "                                                                  'activation_43[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block5_MB_pw_conv (Con  (None, 14, 14, 256)  393216     ['multiply_21[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_4_block5_MB_pw_bn (Batch  (None, 14, 14, 256)  1024       ['stack_4_block5_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_37 (Add)                   (None, 14, 14, 256)  0           ['add_36[0][0]',                 Y          \n",
      "                                                                  'stack_4_block5_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_4_block6_sortcut_conv (C  (None, 14, 14, 1536  393216     ['add_37[0][0]']                 Y          \n",
      " onv2D)                         )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block6_sortcut_bn (Bat  (None, 14, 14, 1536  6144       ['stack_4_block6_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block6_sortcut_swish (  (None, 14, 14, 1536  0          ['stack_4_block6_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block6_MB_dw_ (Depthwi  (None, 14, 14, 1536  13824      ['stack_4_block6_sortcut_swish[  Y          \n",
      " seConv2D)                      )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block6_MB_dw_bn (Batch  (None, 14, 14, 1536  6144       ['stack_4_block6_MB_dw_[0][0]']  Y          \n",
      " Normalization)                 )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block6_MB_dw_swish (Ac  (None, 14, 14, 1536  0          ['stack_4_block6_MB_dw_bn[0][0]  Y          \n",
      " tivation)                      )                                ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_22 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block6_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block6_se_1_conv (Conv  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_22[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_44 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block6_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block6_se_2_conv (Conv  (None, 1, 1, 1536)  99840       ['activation_44[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_45 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block6_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_22 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block6_MB_dw_swish[0]  Y          \n",
      "                                )                                [0]',                                       \n",
      "                                                                  'activation_45[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block6_MB_pw_conv (Con  (None, 14, 14, 256)  393216     ['multiply_22[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_4_block6_MB_pw_bn (Batch  (None, 14, 14, 256)  1024       ['stack_4_block6_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_38 (Add)                   (None, 14, 14, 256)  0           ['add_37[0][0]',                 Y          \n",
      "                                                                  'stack_4_block6_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_4_block7_sortcut_conv (C  (None, 14, 14, 1536  393216     ['add_38[0][0]']                 Y          \n",
      " onv2D)                         )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block7_sortcut_bn (Bat  (None, 14, 14, 1536  6144       ['stack_4_block7_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block7_sortcut_swish (  (None, 14, 14, 1536  0          ['stack_4_block7_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block7_MB_dw_ (Depthwi  (None, 14, 14, 1536  13824      ['stack_4_block7_sortcut_swish[  Y          \n",
      " seConv2D)                      )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block7_MB_dw_bn (Batch  (None, 14, 14, 1536  6144       ['stack_4_block7_MB_dw_[0][0]']  Y          \n",
      " Normalization)                 )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block7_MB_dw_swish (Ac  (None, 14, 14, 1536  0          ['stack_4_block7_MB_dw_bn[0][0]  Y          \n",
      " tivation)                      )                                ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_23 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block7_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block7_se_1_conv (Conv  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_23[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_46 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block7_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block7_se_2_conv (Conv  (None, 1, 1, 1536)  99840       ['activation_46[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_47 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block7_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_23 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block7_MB_dw_swish[0]  Y          \n",
      "                                )                                [0]',                                       \n",
      "                                                                  'activation_47[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block7_MB_pw_conv (Con  (None, 14, 14, 256)  393216     ['multiply_23[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_4_block7_MB_pw_bn (Batch  (None, 14, 14, 256)  1024       ['stack_4_block7_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_39 (Add)                   (None, 14, 14, 256)  0           ['add_38[0][0]',                 Y          \n",
      "                                                                  'stack_4_block7_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_4_block8_sortcut_conv (C  (None, 14, 14, 1536  393216     ['add_39[0][0]']                 Y          \n",
      " onv2D)                         )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block8_sortcut_bn (Bat  (None, 14, 14, 1536  6144       ['stack_4_block8_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block8_sortcut_swish (  (None, 14, 14, 1536  0          ['stack_4_block8_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block8_MB_dw_ (Depthwi  (None, 14, 14, 1536  13824      ['stack_4_block8_sortcut_swish[  Y          \n",
      " seConv2D)                      )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block8_MB_dw_bn (Batch  (None, 14, 14, 1536  6144       ['stack_4_block8_MB_dw_[0][0]']  Y          \n",
      " Normalization)                 )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block8_MB_dw_swish (Ac  (None, 14, 14, 1536  0          ['stack_4_block8_MB_dw_bn[0][0]  Y          \n",
      " tivation)                      )                                ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_24 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block8_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block8_se_1_conv (Conv  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_24[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_48 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block8_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block8_se_2_conv (Conv  (None, 1, 1, 1536)  99840       ['activation_48[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_49 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block8_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_24 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block8_MB_dw_swish[0]  Y          \n",
      "                                )                                [0]',                                       \n",
      "                                                                  'activation_49[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block8_MB_pw_conv (Con  (None, 14, 14, 256)  393216     ['multiply_24[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_4_block8_MB_pw_bn (Batch  (None, 14, 14, 256)  1024       ['stack_4_block8_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_40 (Add)                   (None, 14, 14, 256)  0           ['add_39[0][0]',                 Y          \n",
      "                                                                  'stack_4_block8_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_4_block9_sortcut_conv (C  (None, 14, 14, 1536  393216     ['add_40[0][0]']                 Y          \n",
      " onv2D)                         )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block9_sortcut_bn (Bat  (None, 14, 14, 1536  6144       ['stack_4_block9_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block9_sortcut_swish (  (None, 14, 14, 1536  0          ['stack_4_block9_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block9_MB_dw_ (Depthwi  (None, 14, 14, 1536  13824      ['stack_4_block9_sortcut_swish[  Y          \n",
      " seConv2D)                      )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block9_MB_dw_bn (Batch  (None, 14, 14, 1536  6144       ['stack_4_block9_MB_dw_[0][0]']  Y          \n",
      " Normalization)                 )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block9_MB_dw_swish (Ac  (None, 14, 14, 1536  0          ['stack_4_block9_MB_dw_bn[0][0]  Y          \n",
      " tivation)                      )                                ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_25 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block9_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block9_se_1_conv (Conv  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_25[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_50 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block9_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block9_se_2_conv (Conv  (None, 1, 1, 1536)  99840       ['activation_50[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_51 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block9_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_25 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block9_MB_dw_swish[0]  Y          \n",
      "                                )                                [0]',                                       \n",
      "                                                                  'activation_51[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block9_MB_pw_conv (Con  (None, 14, 14, 256)  393216     ['multiply_25[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_4_block9_MB_pw_bn (Batch  (None, 14, 14, 256)  1024       ['stack_4_block9_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_41 (Add)                   (None, 14, 14, 256)  0           ['add_40[0][0]',                 Y          \n",
      "                                                                  'stack_4_block9_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_4_block10_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_41[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block10_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block10_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block10_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block10_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block10_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block10_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block10_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block10_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block10_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block10_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_26 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block10_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block10_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_26[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_52 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block10_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block10_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_52[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_53 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block10_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_26 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block10_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_53[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block10_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_26[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block10_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block10_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_42 (Add)                   (None, 14, 14, 256)  0           ['add_41[0][0]',                 Y          \n",
      "                                                                  'stack_4_block10_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block11_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_42[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block11_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block11_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block11_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block11_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block11_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block11_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block11_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block11_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block11_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block11_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_27 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block11_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block11_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_27[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_54 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block11_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block11_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_54[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_55 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block11_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_27 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block11_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_55[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block11_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_27[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block11_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block11_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_43 (Add)                   (None, 14, 14, 256)  0           ['add_42[0][0]',                 Y          \n",
      "                                                                  'stack_4_block11_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block12_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_43[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block12_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block12_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block12_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block12_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block12_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block12_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block12_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block12_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block12_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block12_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_28 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block12_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block12_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_28[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_56 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block12_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block12_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_56[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_57 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block12_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_28 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block12_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_57[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block12_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_28[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block12_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block12_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_44 (Add)                   (None, 14, 14, 256)  0           ['add_43[0][0]',                 Y          \n",
      "                                                                  'stack_4_block12_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block13_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_44[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block13_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block13_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block13_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block13_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block13_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block13_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block13_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block13_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block13_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block13_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_29 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block13_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block13_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_29[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_58 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block13_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block13_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_58[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_59 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block13_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_29 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block13_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_59[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block13_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_29[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block13_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block13_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_45 (Add)                   (None, 14, 14, 256)  0           ['add_44[0][0]',                 Y          \n",
      "                                                                  'stack_4_block13_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block14_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_45[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block14_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block14_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block14_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block14_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block14_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block14_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block14_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block14_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block14_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block14_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_30 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block14_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block14_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_30[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_60 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block14_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block14_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_60[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_61 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block14_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_30 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block14_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_61[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block14_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_30[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block14_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block14_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_46 (Add)                   (None, 14, 14, 256)  0           ['add_45[0][0]',                 Y          \n",
      "                                                                  'stack_4_block14_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block15_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_46[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block15_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block15_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block15_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block15_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block15_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block15_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block15_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block15_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block15_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block15_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_31 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block15_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block15_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_31[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_62 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block15_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block15_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_62[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_63 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block15_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_31 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block15_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_63[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block15_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_31[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block15_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block15_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_47 (Add)                   (None, 14, 14, 256)  0           ['add_46[0][0]',                 Y          \n",
      "                                                                  'stack_4_block15_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block16_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_47[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block16_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block16_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block16_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block16_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block16_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block16_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block16_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block16_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block16_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block16_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_32 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block16_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block16_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_32[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_64 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block16_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block16_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_64[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_65 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block16_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_32 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block16_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_65[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block16_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_32[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block16_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block16_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_48 (Add)                   (None, 14, 14, 256)  0           ['add_47[0][0]',                 Y          \n",
      "                                                                  'stack_4_block16_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block17_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_48[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block17_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block17_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block17_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block17_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block17_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block17_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block17_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block17_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block17_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block17_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_33 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block17_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block17_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_33[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_66 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block17_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block17_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_66[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_67 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block17_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_33 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block17_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_67[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block17_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_33[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block17_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block17_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_49 (Add)                   (None, 14, 14, 256)  0           ['add_48[0][0]',                 Y          \n",
      "                                                                  'stack_4_block17_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block18_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_49[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block18_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block18_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block18_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block18_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block18_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block18_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block18_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block18_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block18_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block18_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_34 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block18_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block18_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_34[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_68 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block18_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block18_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_68[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_69 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block18_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_34 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block18_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_69[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block18_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_34[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block18_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block18_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_50 (Add)                   (None, 14, 14, 256)  0           ['add_49[0][0]',                 Y          \n",
      "                                                                  'stack_4_block18_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block19_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_50[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block19_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block19_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block19_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block19_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block19_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block19_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block19_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block19_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block19_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block19_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_35 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block19_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block19_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_35[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_70 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block19_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block19_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_70[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_71 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block19_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_35 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block19_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_71[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block19_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_35[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block19_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block19_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_51 (Add)                   (None, 14, 14, 256)  0           ['add_50[0][0]',                 Y          \n",
      "                                                                  'stack_4_block19_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block20_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_51[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block20_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block20_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block20_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block20_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block20_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block20_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block20_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block20_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block20_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block20_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_36 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block20_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block20_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_36[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_72 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block20_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block20_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_72[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_73 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block20_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_36 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block20_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_73[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block20_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_36[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block20_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block20_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_52 (Add)                   (None, 14, 14, 256)  0           ['add_51[0][0]',                 Y          \n",
      "                                                                  'stack_4_block20_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block21_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_52[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block21_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block21_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block21_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block21_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block21_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block21_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block21_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block21_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block21_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block21_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_37 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block21_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block21_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_37[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_74 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block21_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block21_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_74[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_75 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block21_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_37 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block21_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_75[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block21_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_37[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block21_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block21_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_53 (Add)                   (None, 14, 14, 256)  0           ['add_52[0][0]',                 Y          \n",
      "                                                                  'stack_4_block21_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block22_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_53[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block22_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block22_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block22_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block22_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block22_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block22_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block22_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block22_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block22_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block22_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_38 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block22_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block22_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_38[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_76 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block22_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block22_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_76[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_77 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block22_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_38 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block22_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_77[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block22_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_38[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block22_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block22_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_54 (Add)                   (None, 14, 14, 256)  0           ['add_53[0][0]',                 Y          \n",
      "                                                                  'stack_4_block22_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_4_block23_sortcut_conv (  (None, 14, 14, 1536  393216     ['add_54[0][0]']                 Y          \n",
      " Conv2D)                        )                                                                            \n",
      "                                                                                                             \n",
      " stack_4_block23_sortcut_bn (Ba  (None, 14, 14, 1536  6144       ['stack_4_block23_sortcut_conv[  Y          \n",
      " tchNormalization)              )                                0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_4_block23_sortcut_swish   (None, 14, 14, 1536  0          ['stack_4_block23_sortcut_bn[0]  Y          \n",
      " (Activation)                   )                                [0]']                                       \n",
      "                                                                                                             \n",
      " stack_4_block23_MB_dw_ (Depthw  (None, 14, 14, 1536  13824      ['stack_4_block23_sortcut_swish  Y          \n",
      " iseConv2D)                     )                                [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_4_block23_MB_dw_bn (Batc  (None, 14, 14, 1536  6144       ['stack_4_block23_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                )                                ]                                           \n",
      "                                                                                                             \n",
      " stack_4_block23_MB_dw_swish (A  (None, 14, 14, 1536  0          ['stack_4_block23_MB_dw_bn[0][0  Y          \n",
      " ctivation)                     )                                ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_39 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_4_block23_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_4_block23_se_1_conv (Con  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_39[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_78 (Activation)     (None, 1, 1, 64)     0           ['stack_4_block23_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_4_block23_se_2_conv (Con  (None, 1, 1, 1536)  99840       ['activation_78[0][0]']          Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_79 (Activation)     (None, 1, 1, 1536)   0           ['stack_4_block23_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_39 (Multiply)         (None, 14, 14, 1536  0           ['stack_4_block23_MB_dw_swish[0  Y          \n",
      "                                )                                ][0]',                                      \n",
      "                                                                  'activation_79[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_4_block23_MB_pw_conv (Co  (None, 14, 14, 256)  393216     ['multiply_39[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_4_block23_MB_pw_bn (Batc  (None, 14, 14, 256)  1024       ['stack_4_block23_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_55 (Add)                   (None, 14, 14, 256)  0           ['add_54[0][0]',                 Y          \n",
      "                                                                  'stack_4_block23_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block0_sortcut_conv (C  (None, 14, 14, 1536  393216     ['add_55[0][0]']                 Y          \n",
      " onv2D)                         )                                                                            \n",
      "                                                                                                             \n",
      " stack_5_block0_sortcut_bn (Bat  (None, 14, 14, 1536  6144       ['stack_5_block0_sortcut_conv[0  Y          \n",
      " chNormalization)               )                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block0_sortcut_swish (  (None, 14, 14, 1536  0          ['stack_5_block0_sortcut_bn[0][  Y          \n",
      " Activation)                    )                                0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block0_MB_dw_ (Depthwi  (None, 7, 7, 1536)  13824       ['stack_5_block0_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block0_MB_dw_bn (Batch  (None, 7, 7, 1536)  6144        ['stack_5_block0_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_5_block0_MB_dw_swish (Ac  (None, 7, 7, 1536)  0           ['stack_5_block0_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_40 (TFOpLa  (None, 1, 1, 1536)  0           ['stack_5_block0_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block0_se_1_conv (Conv  (None, 1, 1, 64)    98368       ['tf.math.reduce_mean_40[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_80 (Activation)     (None, 1, 1, 64)     0           ['stack_5_block0_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block0_se_2_conv (Conv  (None, 1, 1, 1536)  99840       ['activation_80[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_81 (Activation)     (None, 1, 1, 1536)   0           ['stack_5_block0_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_40 (Multiply)         (None, 7, 7, 1536)   0           ['stack_5_block0_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_81[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_5_block0_MB_pw_conv (Con  (None, 7, 7, 512)   786432      ['multiply_40[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_5_block0_MB_pw_bn (Batch  (None, 7, 7, 512)   2048        ['stack_5_block0_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block1_sortcut_conv (C  (None, 7, 7, 3072)  1572864     ['stack_5_block0_MB_pw_bn[0][0]  Y          \n",
      " onv2D)                                                          ']                                          \n",
      "                                                                                                             \n",
      " stack_5_block1_sortcut_bn (Bat  (None, 7, 7, 3072)  12288       ['stack_5_block1_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block1_sortcut_swish (  (None, 7, 7, 3072)  0           ['stack_5_block1_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block1_MB_dw_ (Depthwi  (None, 7, 7, 3072)  27648       ['stack_5_block1_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block1_MB_dw_bn (Batch  (None, 7, 7, 3072)  12288       ['stack_5_block1_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_5_block1_MB_dw_swish (Ac  (None, 7, 7, 3072)  0           ['stack_5_block1_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_41 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block1_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block1_se_1_conv (Conv  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_41[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_82 (Activation)     (None, 1, 1, 128)    0           ['stack_5_block1_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block1_se_2_conv (Conv  (None, 1, 1, 3072)  396288      ['activation_82[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_83 (Activation)     (None, 1, 1, 3072)   0           ['stack_5_block1_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_41 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block1_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_83[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_5_block1_MB_pw_conv (Con  (None, 7, 7, 512)   1572864     ['multiply_41[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_5_block1_MB_pw_bn (Batch  (None, 7, 7, 512)   2048        ['stack_5_block1_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_56 (Add)                   (None, 7, 7, 512)    0           ['stack_5_block0_MB_pw_bn[0][0]  Y          \n",
      "                                                                 ',                                          \n",
      "                                                                  'stack_5_block1_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_5_block2_sortcut_conv (C  (None, 7, 7, 3072)  1572864     ['add_56[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_5_block2_sortcut_bn (Bat  (None, 7, 7, 3072)  12288       ['stack_5_block2_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block2_sortcut_swish (  (None, 7, 7, 3072)  0           ['stack_5_block2_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block2_MB_dw_ (Depthwi  (None, 7, 7, 3072)  27648       ['stack_5_block2_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block2_MB_dw_bn (Batch  (None, 7, 7, 3072)  12288       ['stack_5_block2_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_5_block2_MB_dw_swish (Ac  (None, 7, 7, 3072)  0           ['stack_5_block2_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_42 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block2_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block2_se_1_conv (Conv  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_42[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_84 (Activation)     (None, 1, 1, 128)    0           ['stack_5_block2_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block2_se_2_conv (Conv  (None, 1, 1, 3072)  396288      ['activation_84[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_85 (Activation)     (None, 1, 1, 3072)   0           ['stack_5_block2_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_42 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block2_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_85[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_5_block2_MB_pw_conv (Con  (None, 7, 7, 512)   1572864     ['multiply_42[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_5_block2_MB_pw_bn (Batch  (None, 7, 7, 512)   2048        ['stack_5_block2_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_57 (Add)                   (None, 7, 7, 512)    0           ['add_56[0][0]',                 Y          \n",
      "                                                                  'stack_5_block2_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_5_block3_sortcut_conv (C  (None, 7, 7, 3072)  1572864     ['add_57[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_5_block3_sortcut_bn (Bat  (None, 7, 7, 3072)  12288       ['stack_5_block3_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block3_sortcut_swish (  (None, 7, 7, 3072)  0           ['stack_5_block3_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block3_MB_dw_ (Depthwi  (None, 7, 7, 3072)  27648       ['stack_5_block3_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block3_MB_dw_bn (Batch  (None, 7, 7, 3072)  12288       ['stack_5_block3_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_5_block3_MB_dw_swish (Ac  (None, 7, 7, 3072)  0           ['stack_5_block3_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_43 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block3_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block3_se_1_conv (Conv  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_43[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_86 (Activation)     (None, 1, 1, 128)    0           ['stack_5_block3_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block3_se_2_conv (Conv  (None, 1, 1, 3072)  396288      ['activation_86[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_87 (Activation)     (None, 1, 1, 3072)   0           ['stack_5_block3_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_43 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block3_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_87[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_5_block3_MB_pw_conv (Con  (None, 7, 7, 512)   1572864     ['multiply_43[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_5_block3_MB_pw_bn (Batch  (None, 7, 7, 512)   2048        ['stack_5_block3_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_58 (Add)                   (None, 7, 7, 512)    0           ['add_57[0][0]',                 Y          \n",
      "                                                                  'stack_5_block3_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_5_block4_sortcut_conv (C  (None, 7, 7, 3072)  1572864     ['add_58[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_5_block4_sortcut_bn (Bat  (None, 7, 7, 3072)  12288       ['stack_5_block4_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block4_sortcut_swish (  (None, 7, 7, 3072)  0           ['stack_5_block4_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block4_MB_dw_ (Depthwi  (None, 7, 7, 3072)  27648       ['stack_5_block4_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block4_MB_dw_bn (Batch  (None, 7, 7, 3072)  12288       ['stack_5_block4_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_5_block4_MB_dw_swish (Ac  (None, 7, 7, 3072)  0           ['stack_5_block4_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_44 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block4_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block4_se_1_conv (Conv  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_44[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_88 (Activation)     (None, 1, 1, 128)    0           ['stack_5_block4_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block4_se_2_conv (Conv  (None, 1, 1, 3072)  396288      ['activation_88[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_89 (Activation)     (None, 1, 1, 3072)   0           ['stack_5_block4_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_44 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block4_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_89[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_5_block4_MB_pw_conv (Con  (None, 7, 7, 512)   1572864     ['multiply_44[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_5_block4_MB_pw_bn (Batch  (None, 7, 7, 512)   2048        ['stack_5_block4_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_59 (Add)                   (None, 7, 7, 512)    0           ['add_58[0][0]',                 Y          \n",
      "                                                                  'stack_5_block4_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_5_block5_sortcut_conv (C  (None, 7, 7, 3072)  1572864     ['add_59[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_5_block5_sortcut_bn (Bat  (None, 7, 7, 3072)  12288       ['stack_5_block5_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block5_sortcut_swish (  (None, 7, 7, 3072)  0           ['stack_5_block5_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block5_MB_dw_ (Depthwi  (None, 7, 7, 3072)  27648       ['stack_5_block5_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block5_MB_dw_bn (Batch  (None, 7, 7, 3072)  12288       ['stack_5_block5_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_5_block5_MB_dw_swish (Ac  (None, 7, 7, 3072)  0           ['stack_5_block5_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_45 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block5_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block5_se_1_conv (Conv  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_45[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_90 (Activation)     (None, 1, 1, 128)    0           ['stack_5_block5_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block5_se_2_conv (Conv  (None, 1, 1, 3072)  396288      ['activation_90[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_91 (Activation)     (None, 1, 1, 3072)   0           ['stack_5_block5_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_45 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block5_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_91[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_5_block5_MB_pw_conv (Con  (None, 7, 7, 512)   1572864     ['multiply_45[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_5_block5_MB_pw_bn (Batch  (None, 7, 7, 512)   2048        ['stack_5_block5_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_60 (Add)                   (None, 7, 7, 512)    0           ['add_59[0][0]',                 Y          \n",
      "                                                                  'stack_5_block5_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_5_block6_sortcut_conv (C  (None, 7, 7, 3072)  1572864     ['add_60[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_5_block6_sortcut_bn (Bat  (None, 7, 7, 3072)  12288       ['stack_5_block6_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block6_sortcut_swish (  (None, 7, 7, 3072)  0           ['stack_5_block6_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block6_MB_dw_ (Depthwi  (None, 7, 7, 3072)  27648       ['stack_5_block6_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block6_MB_dw_bn (Batch  (None, 7, 7, 3072)  12288       ['stack_5_block6_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_5_block6_MB_dw_swish (Ac  (None, 7, 7, 3072)  0           ['stack_5_block6_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_46 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block6_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block6_se_1_conv (Conv  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_46[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_92 (Activation)     (None, 1, 1, 128)    0           ['stack_5_block6_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block6_se_2_conv (Conv  (None, 1, 1, 3072)  396288      ['activation_92[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_93 (Activation)     (None, 1, 1, 3072)   0           ['stack_5_block6_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_46 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block6_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_93[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_5_block6_MB_pw_conv (Con  (None, 7, 7, 512)   1572864     ['multiply_46[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_5_block6_MB_pw_bn (Batch  (None, 7, 7, 512)   2048        ['stack_5_block6_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_61 (Add)                   (None, 7, 7, 512)    0           ['add_60[0][0]',                 Y          \n",
      "                                                                  'stack_5_block6_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_5_block7_sortcut_conv (C  (None, 7, 7, 3072)  1572864     ['add_61[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_5_block7_sortcut_bn (Bat  (None, 7, 7, 3072)  12288       ['stack_5_block7_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block7_sortcut_swish (  (None, 7, 7, 3072)  0           ['stack_5_block7_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block7_MB_dw_ (Depthwi  (None, 7, 7, 3072)  27648       ['stack_5_block7_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block7_MB_dw_bn (Batch  (None, 7, 7, 3072)  12288       ['stack_5_block7_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_5_block7_MB_dw_swish (Ac  (None, 7, 7, 3072)  0           ['stack_5_block7_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_47 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block7_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block7_se_1_conv (Conv  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_47[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_94 (Activation)     (None, 1, 1, 128)    0           ['stack_5_block7_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block7_se_2_conv (Conv  (None, 1, 1, 3072)  396288      ['activation_94[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_95 (Activation)     (None, 1, 1, 3072)   0           ['stack_5_block7_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_47 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block7_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_95[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_5_block7_MB_pw_conv (Con  (None, 7, 7, 512)   1572864     ['multiply_47[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_5_block7_MB_pw_bn (Batch  (None, 7, 7, 512)   2048        ['stack_5_block7_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_62 (Add)                   (None, 7, 7, 512)    0           ['add_61[0][0]',                 Y          \n",
      "                                                                  'stack_5_block7_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_5_block8_sortcut_conv (C  (None, 7, 7, 3072)  1572864     ['add_62[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_5_block8_sortcut_bn (Bat  (None, 7, 7, 3072)  12288       ['stack_5_block8_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block8_sortcut_swish (  (None, 7, 7, 3072)  0           ['stack_5_block8_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block8_MB_dw_ (Depthwi  (None, 7, 7, 3072)  27648       ['stack_5_block8_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block8_MB_dw_bn (Batch  (None, 7, 7, 3072)  12288       ['stack_5_block8_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_5_block8_MB_dw_swish (Ac  (None, 7, 7, 3072)  0           ['stack_5_block8_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_48 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block8_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block8_se_1_conv (Conv  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_48[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_96 (Activation)     (None, 1, 1, 128)    0           ['stack_5_block8_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block8_se_2_conv (Conv  (None, 1, 1, 3072)  396288      ['activation_96[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_97 (Activation)     (None, 1, 1, 3072)   0           ['stack_5_block8_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_48 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block8_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_97[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_5_block8_MB_pw_conv (Con  (None, 7, 7, 512)   1572864     ['multiply_48[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_5_block8_MB_pw_bn (Batch  (None, 7, 7, 512)   2048        ['stack_5_block8_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_63 (Add)                   (None, 7, 7, 512)    0           ['add_62[0][0]',                 Y          \n",
      "                                                                  'stack_5_block8_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_5_block9_sortcut_conv (C  (None, 7, 7, 3072)  1572864     ['add_63[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_5_block9_sortcut_bn (Bat  (None, 7, 7, 3072)  12288       ['stack_5_block9_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block9_sortcut_swish (  (None, 7, 7, 3072)  0           ['stack_5_block9_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block9_MB_dw_ (Depthwi  (None, 7, 7, 3072)  27648       ['stack_5_block9_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block9_MB_dw_bn (Batch  (None, 7, 7, 3072)  12288       ['stack_5_block9_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_5_block9_MB_dw_swish (Ac  (None, 7, 7, 3072)  0           ['stack_5_block9_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_49 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block9_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block9_se_1_conv (Conv  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_49[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_98 (Activation)     (None, 1, 1, 128)    0           ['stack_5_block9_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block9_se_2_conv (Conv  (None, 1, 1, 3072)  396288      ['activation_98[0][0]']          Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_99 (Activation)     (None, 1, 1, 3072)   0           ['stack_5_block9_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_49 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block9_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_99[0][0]']                     \n",
      "                                                                                                             \n",
      " stack_5_block9_MB_pw_conv (Con  (None, 7, 7, 512)   1572864     ['multiply_49[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_5_block9_MB_pw_bn (Batch  (None, 7, 7, 512)   2048        ['stack_5_block9_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_64 (Add)                   (None, 7, 7, 512)    0           ['add_63[0][0]',                 Y          \n",
      "                                                                  'stack_5_block9_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_5_block10_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_64[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block10_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block10_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block10_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block10_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block10_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block10_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block10_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block10_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block10_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block10_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_50 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block10_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block10_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_50[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_100 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block10_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block10_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_100[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_101 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block10_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_50 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block10_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_101[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block10_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_50[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block10_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block10_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_65 (Add)                   (None, 7, 7, 512)    0           ['add_64[0][0]',                 Y          \n",
      "                                                                  'stack_5_block10_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block11_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_65[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block11_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block11_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block11_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block11_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block11_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block11_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block11_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block11_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block11_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block11_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_51 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block11_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block11_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_51[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_102 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block11_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block11_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_102[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_103 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block11_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_51 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block11_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_103[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block11_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_51[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block11_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block11_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_66 (Add)                   (None, 7, 7, 512)    0           ['add_65[0][0]',                 Y          \n",
      "                                                                  'stack_5_block11_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block12_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_66[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block12_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block12_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block12_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block12_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block12_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block12_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block12_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block12_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block12_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block12_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_52 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block12_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block12_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_52[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_104 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block12_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block12_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_104[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_105 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block12_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_52 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block12_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_105[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block12_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_52[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block12_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block12_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_67 (Add)                   (None, 7, 7, 512)    0           ['add_66[0][0]',                 Y          \n",
      "                                                                  'stack_5_block12_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block13_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_67[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block13_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block13_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block13_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block13_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block13_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block13_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block13_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block13_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block13_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block13_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_53 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block13_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block13_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_53[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_106 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block13_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block13_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_106[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_107 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block13_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_53 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block13_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_107[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block13_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_53[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block13_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block13_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_68 (Add)                   (None, 7, 7, 512)    0           ['add_67[0][0]',                 Y          \n",
      "                                                                  'stack_5_block13_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block14_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_68[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block14_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block14_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block14_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block14_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block14_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block14_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block14_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block14_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block14_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block14_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_54 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block14_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block14_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_54[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_108 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block14_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block14_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_108[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_109 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block14_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_54 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block14_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_109[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block14_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_54[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block14_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block14_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_69 (Add)                   (None, 7, 7, 512)    0           ['add_68[0][0]',                 Y          \n",
      "                                                                  'stack_5_block14_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block15_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_69[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block15_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block15_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block15_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block15_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block15_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block15_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block15_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block15_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block15_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block15_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_55 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block15_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block15_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_55[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_110 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block15_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block15_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_110[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_111 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block15_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_55 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block15_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_111[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block15_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_55[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block15_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block15_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_70 (Add)                   (None, 7, 7, 512)    0           ['add_69[0][0]',                 Y          \n",
      "                                                                  'stack_5_block15_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block16_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_70[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block16_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block16_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block16_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block16_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block16_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block16_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block16_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block16_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block16_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block16_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_56 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block16_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block16_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_56[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_112 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block16_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block16_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_112[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_113 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block16_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_56 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block16_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_113[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block16_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_56[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block16_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block16_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_71 (Add)                   (None, 7, 7, 512)    0           ['add_70[0][0]',                 Y          \n",
      "                                                                  'stack_5_block16_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block17_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_71[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block17_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block17_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block17_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block17_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block17_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block17_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block17_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block17_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block17_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block17_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_57 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block17_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block17_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_57[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_114 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block17_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block17_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_114[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_115 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block17_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_57 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block17_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_115[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block17_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_57[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block17_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block17_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_72 (Add)                   (None, 7, 7, 512)    0           ['add_71[0][0]',                 Y          \n",
      "                                                                  'stack_5_block17_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block18_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_72[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block18_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block18_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block18_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block18_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block18_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block18_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block18_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block18_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block18_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block18_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_58 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block18_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block18_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_58[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_116 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block18_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block18_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_116[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_117 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block18_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_58 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block18_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_117[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block18_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_58[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block18_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block18_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_73 (Add)                   (None, 7, 7, 512)    0           ['add_72[0][0]',                 Y          \n",
      "                                                                  'stack_5_block18_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block19_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_73[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block19_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block19_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block19_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block19_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block19_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block19_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block19_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block19_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block19_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block19_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_59 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block19_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block19_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_59[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_118 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block19_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block19_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_118[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_119 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block19_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_59 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block19_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_119[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block19_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_59[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block19_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block19_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_74 (Add)                   (None, 7, 7, 512)    0           ['add_73[0][0]',                 Y          \n",
      "                                                                  'stack_5_block19_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block20_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_74[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block20_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block20_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block20_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block20_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block20_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block20_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block20_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block20_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block20_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block20_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_60 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block20_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block20_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_60[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_120 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block20_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block20_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_120[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_121 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block20_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_60 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block20_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_121[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block20_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_60[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block20_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block20_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_75 (Add)                   (None, 7, 7, 512)    0           ['add_74[0][0]',                 Y          \n",
      "                                                                  'stack_5_block20_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block21_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_75[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block21_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block21_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block21_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block21_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block21_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block21_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block21_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block21_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block21_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block21_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_61 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block21_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block21_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_61[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_122 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block21_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block21_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_122[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_123 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block21_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_61 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block21_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_123[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block21_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_61[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block21_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block21_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_76 (Add)                   (None, 7, 7, 512)    0           ['add_75[0][0]',                 Y          \n",
      "                                                                  'stack_5_block21_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block22_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_76[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block22_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block22_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block22_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block22_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block22_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block22_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block22_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block22_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block22_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block22_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_62 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block22_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block22_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_62[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_124 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block22_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block22_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_124[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_125 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block22_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_62 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block22_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_125[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block22_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_62[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block22_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block22_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_77 (Add)                   (None, 7, 7, 512)    0           ['add_76[0][0]',                 Y          \n",
      "                                                                  'stack_5_block22_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block23_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_77[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block23_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block23_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block23_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block23_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block23_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block23_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block23_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block23_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block23_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block23_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_63 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block23_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block23_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_63[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_126 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block23_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block23_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_126[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_127 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block23_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_63 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block23_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_127[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block23_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_63[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block23_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block23_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_78 (Add)                   (None, 7, 7, 512)    0           ['add_77[0][0]',                 Y          \n",
      "                                                                  'stack_5_block23_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block24_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_78[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block24_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block24_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block24_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block24_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block24_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block24_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block24_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block24_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block24_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block24_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_64 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block24_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block24_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_64[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_128 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block24_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block24_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_128[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_129 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block24_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_64 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block24_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_129[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block24_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_64[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block24_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block24_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_79 (Add)                   (None, 7, 7, 512)    0           ['add_78[0][0]',                 Y          \n",
      "                                                                  'stack_5_block24_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block25_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_79[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block25_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block25_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block25_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block25_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block25_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block25_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block25_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block25_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block25_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block25_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_65 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block25_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block25_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_65[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_130 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block25_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block25_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_130[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_131 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block25_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_65 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block25_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_131[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block25_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_65[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block25_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block25_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_80 (Add)                   (None, 7, 7, 512)    0           ['add_79[0][0]',                 Y          \n",
      "                                                                  'stack_5_block25_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block26_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_80[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block26_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block26_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block26_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block26_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block26_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block26_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block26_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block26_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block26_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block26_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_66 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block26_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block26_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_66[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_132 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block26_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block26_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_132[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_133 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block26_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_66 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block26_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_133[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block26_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_66[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block26_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block26_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_81 (Add)                   (None, 7, 7, 512)    0           ['add_80[0][0]',                 Y          \n",
      "                                                                  'stack_5_block26_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block27_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_81[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block27_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block27_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block27_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block27_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block27_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block27_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block27_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block27_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block27_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block27_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_67 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block27_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block27_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_67[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_134 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block27_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block27_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_134[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_135 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block27_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_67 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block27_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_135[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block27_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_67[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block27_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block27_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_82 (Add)                   (None, 7, 7, 512)    0           ['add_81[0][0]',                 Y          \n",
      "                                                                  'stack_5_block27_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block28_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_82[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block28_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block28_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block28_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block28_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block28_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block28_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block28_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block28_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block28_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block28_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_68 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block28_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block28_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_68[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_136 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block28_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block28_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_136[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_137 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block28_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_68 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block28_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_137[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block28_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_68[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block28_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block28_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_83 (Add)                   (None, 7, 7, 512)    0           ['add_82[0][0]',                 Y          \n",
      "                                                                  'stack_5_block28_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block29_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_83[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block29_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block29_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block29_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block29_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block29_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block29_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block29_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block29_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block29_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block29_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_69 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block29_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block29_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_69[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_138 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block29_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block29_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_138[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_139 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block29_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_69 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block29_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_139[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block29_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_69[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block29_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block29_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_84 (Add)                   (None, 7, 7, 512)    0           ['add_83[0][0]',                 Y          \n",
      "                                                                  'stack_5_block29_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block30_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_84[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block30_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block30_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block30_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block30_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block30_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block30_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block30_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block30_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block30_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block30_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_70 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block30_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block30_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_70[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_140 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block30_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block30_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_140[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_141 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block30_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_70 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block30_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_141[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block30_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_70[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block30_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block30_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_85 (Add)                   (None, 7, 7, 512)    0           ['add_84[0][0]',                 Y          \n",
      "                                                                  'stack_5_block30_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_5_block31_sortcut_conv (  (None, 7, 7, 3072)  1572864     ['add_85[0][0]']                 Y          \n",
      " Conv2D)                                                                                                     \n",
      "                                                                                                             \n",
      " stack_5_block31_sortcut_bn (Ba  (None, 7, 7, 3072)  12288       ['stack_5_block31_sortcut_conv[  Y          \n",
      " tchNormalization)                                               0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_5_block31_sortcut_swish   (None, 7, 7, 3072)  0           ['stack_5_block31_sortcut_bn[0]  Y          \n",
      " (Activation)                                                    [0]']                                       \n",
      "                                                                                                             \n",
      " stack_5_block31_MB_dw_ (Depthw  (None, 7, 7, 3072)  27648       ['stack_5_block31_sortcut_swish  Y          \n",
      " iseConv2D)                                                      [0][0]']                                    \n",
      "                                                                                                             \n",
      " stack_5_block31_MB_dw_bn (Batc  (None, 7, 7, 3072)  12288       ['stack_5_block31_MB_dw_[0][0]'  Y          \n",
      " hNormalization)                                                 ]                                           \n",
      "                                                                                                             \n",
      " stack_5_block31_MB_dw_swish (A  (None, 7, 7, 3072)  0           ['stack_5_block31_MB_dw_bn[0][0  Y          \n",
      " ctivation)                                                      ]']                                         \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_71 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_5_block31_MB_dw_swish[0  Y          \n",
      " mbda)                                                           ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_5_block31_se_1_conv (Con  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_71[0][0]'  Y          \n",
      " v2D)                                                            ]                                           \n",
      "                                                                                                             \n",
      " activation_142 (Activation)    (None, 1, 1, 128)    0           ['stack_5_block31_se_1_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " stack_5_block31_se_2_conv (Con  (None, 1, 1, 3072)  396288      ['activation_142[0][0]']         Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " activation_143 (Activation)    (None, 1, 1, 3072)   0           ['stack_5_block31_se_2_conv[0][  Y          \n",
      "                                                                 0]']                                        \n",
      "                                                                                                             \n",
      " multiply_71 (Multiply)         (None, 7, 7, 3072)   0           ['stack_5_block31_MB_dw_swish[0  Y          \n",
      "                                                                 ][0]',                                      \n",
      "                                                                  'activation_143[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_5_block31_MB_pw_conv (Co  (None, 7, 7, 512)   1572864     ['multiply_71[0][0]']            Y          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " stack_5_block31_MB_pw_bn (Batc  (None, 7, 7, 512)   2048        ['stack_5_block31_MB_pw_conv[0]  Y          \n",
      " hNormalization)                                                 [0]']                                       \n",
      "                                                                                                             \n",
      " add_86 (Add)                   (None, 7, 7, 512)    0           ['add_85[0][0]',                 Y          \n",
      "                                                                  'stack_5_block31_MB_pw_bn[0][0             \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_6_block0_sortcut_conv (C  (None, 7, 7, 3072)  1572864     ['add_86[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_6_block0_sortcut_bn (Bat  (None, 7, 7, 3072)  12288       ['stack_6_block0_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_6_block0_sortcut_swish (  (None, 7, 7, 3072)  0           ['stack_6_block0_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_6_block0_MB_dw_ (Depthwi  (None, 7, 7, 3072)  27648       ['stack_6_block0_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_6_block0_MB_dw_bn (Batch  (None, 7, 7, 3072)  12288       ['stack_6_block0_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_6_block0_MB_dw_swish (Ac  (None, 7, 7, 3072)  0           ['stack_6_block0_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_72 (TFOpLa  (None, 1, 1, 3072)  0           ['stack_6_block0_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_6_block0_se_1_conv (Conv  (None, 1, 1, 128)   393344      ['tf.math.reduce_mean_72[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_144 (Activation)    (None, 1, 1, 128)    0           ['stack_6_block0_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_6_block0_se_2_conv (Conv  (None, 1, 1, 3072)  396288      ['activation_144[0][0]']         Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_145 (Activation)    (None, 1, 1, 3072)   0           ['stack_6_block0_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_72 (Multiply)         (None, 7, 7, 3072)   0           ['stack_6_block0_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_145[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_6_block0_MB_pw_conv (Con  (None, 7, 7, 640)   1966080     ['multiply_72[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_6_block0_MB_pw_bn (Batch  (None, 7, 7, 640)   2560        ['stack_6_block0_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " stack_6_block1_sortcut_conv (C  (None, 7, 7, 3840)  2457600     ['stack_6_block0_MB_pw_bn[0][0]  Y          \n",
      " onv2D)                                                          ']                                          \n",
      "                                                                                                             \n",
      " stack_6_block1_sortcut_bn (Bat  (None, 7, 7, 3840)  15360       ['stack_6_block1_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_6_block1_sortcut_swish (  (None, 7, 7, 3840)  0           ['stack_6_block1_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_6_block1_MB_dw_ (Depthwi  (None, 7, 7, 3840)  34560       ['stack_6_block1_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_6_block1_MB_dw_bn (Batch  (None, 7, 7, 3840)  15360       ['stack_6_block1_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_6_block1_MB_dw_swish (Ac  (None, 7, 7, 3840)  0           ['stack_6_block1_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_73 (TFOpLa  (None, 1, 1, 3840)  0           ['stack_6_block1_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_6_block1_se_1_conv (Conv  (None, 1, 1, 160)   614560      ['tf.math.reduce_mean_73[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_146 (Activation)    (None, 1, 1, 160)    0           ['stack_6_block1_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_6_block1_se_2_conv (Conv  (None, 1, 1, 3840)  618240      ['activation_146[0][0]']         Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_147 (Activation)    (None, 1, 1, 3840)   0           ['stack_6_block1_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_73 (Multiply)         (None, 7, 7, 3840)   0           ['stack_6_block1_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_147[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_6_block1_MB_pw_conv (Con  (None, 7, 7, 640)   2457600     ['multiply_73[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_6_block1_MB_pw_bn (Batch  (None, 7, 7, 640)   2560        ['stack_6_block1_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_87 (Add)                   (None, 7, 7, 640)    0           ['stack_6_block0_MB_pw_bn[0][0]  Y          \n",
      "                                                                 ',                                          \n",
      "                                                                  'stack_6_block1_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_6_block2_sortcut_conv (C  (None, 7, 7, 3840)  2457600     ['add_87[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_6_block2_sortcut_bn (Bat  (None, 7, 7, 3840)  15360       ['stack_6_block2_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_6_block2_sortcut_swish (  (None, 7, 7, 3840)  0           ['stack_6_block2_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_6_block2_MB_dw_ (Depthwi  (None, 7, 7, 3840)  34560       ['stack_6_block2_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_6_block2_MB_dw_bn (Batch  (None, 7, 7, 3840)  15360       ['stack_6_block2_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_6_block2_MB_dw_swish (Ac  (None, 7, 7, 3840)  0           ['stack_6_block2_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_74 (TFOpLa  (None, 1, 1, 3840)  0           ['stack_6_block2_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_6_block2_se_1_conv (Conv  (None, 1, 1, 160)   614560      ['tf.math.reduce_mean_74[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_148 (Activation)    (None, 1, 1, 160)    0           ['stack_6_block2_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_6_block2_se_2_conv (Conv  (None, 1, 1, 3840)  618240      ['activation_148[0][0]']         Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_149 (Activation)    (None, 1, 1, 3840)   0           ['stack_6_block2_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_74 (Multiply)         (None, 7, 7, 3840)   0           ['stack_6_block2_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_149[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_6_block2_MB_pw_conv (Con  (None, 7, 7, 640)   2457600     ['multiply_74[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_6_block2_MB_pw_bn (Batch  (None, 7, 7, 640)   2560        ['stack_6_block2_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_88 (Add)                   (None, 7, 7, 640)    0           ['add_87[0][0]',                 Y          \n",
      "                                                                  'stack_6_block2_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_6_block3_sortcut_conv (C  (None, 7, 7, 3840)  2457600     ['add_88[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_6_block3_sortcut_bn (Bat  (None, 7, 7, 3840)  15360       ['stack_6_block3_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_6_block3_sortcut_swish (  (None, 7, 7, 3840)  0           ['stack_6_block3_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_6_block3_MB_dw_ (Depthwi  (None, 7, 7, 3840)  34560       ['stack_6_block3_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_6_block3_MB_dw_bn (Batch  (None, 7, 7, 3840)  15360       ['stack_6_block3_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_6_block3_MB_dw_swish (Ac  (None, 7, 7, 3840)  0           ['stack_6_block3_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_75 (TFOpLa  (None, 1, 1, 3840)  0           ['stack_6_block3_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_6_block3_se_1_conv (Conv  (None, 1, 1, 160)   614560      ['tf.math.reduce_mean_75[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_150 (Activation)    (None, 1, 1, 160)    0           ['stack_6_block3_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_6_block3_se_2_conv (Conv  (None, 1, 1, 3840)  618240      ['activation_150[0][0]']         Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_151 (Activation)    (None, 1, 1, 3840)   0           ['stack_6_block3_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_75 (Multiply)         (None, 7, 7, 3840)   0           ['stack_6_block3_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_151[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_6_block3_MB_pw_conv (Con  (None, 7, 7, 640)   2457600     ['multiply_75[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_6_block3_MB_pw_bn (Batch  (None, 7, 7, 640)   2560        ['stack_6_block3_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_89 (Add)                   (None, 7, 7, 640)    0           ['add_88[0][0]',                 Y          \n",
      "                                                                  'stack_6_block3_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_6_block4_sortcut_conv (C  (None, 7, 7, 3840)  2457600     ['add_89[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_6_block4_sortcut_bn (Bat  (None, 7, 7, 3840)  15360       ['stack_6_block4_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_6_block4_sortcut_swish (  (None, 7, 7, 3840)  0           ['stack_6_block4_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_6_block4_MB_dw_ (Depthwi  (None, 7, 7, 3840)  34560       ['stack_6_block4_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_6_block4_MB_dw_bn (Batch  (None, 7, 7, 3840)  15360       ['stack_6_block4_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_6_block4_MB_dw_swish (Ac  (None, 7, 7, 3840)  0           ['stack_6_block4_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_76 (TFOpLa  (None, 1, 1, 3840)  0           ['stack_6_block4_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_6_block4_se_1_conv (Conv  (None, 1, 1, 160)   614560      ['tf.math.reduce_mean_76[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_152 (Activation)    (None, 1, 1, 160)    0           ['stack_6_block4_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_6_block4_se_2_conv (Conv  (None, 1, 1, 3840)  618240      ['activation_152[0][0]']         Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_153 (Activation)    (None, 1, 1, 3840)   0           ['stack_6_block4_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_76 (Multiply)         (None, 7, 7, 3840)   0           ['stack_6_block4_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_153[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_6_block4_MB_pw_conv (Con  (None, 7, 7, 640)   2457600     ['multiply_76[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_6_block4_MB_pw_bn (Batch  (None, 7, 7, 640)   2560        ['stack_6_block4_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_90 (Add)                   (None, 7, 7, 640)    0           ['add_89[0][0]',                 Y          \n",
      "                                                                  'stack_6_block4_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_6_block5_sortcut_conv (C  (None, 7, 7, 3840)  2457600     ['add_90[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_6_block5_sortcut_bn (Bat  (None, 7, 7, 3840)  15360       ['stack_6_block5_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_6_block5_sortcut_swish (  (None, 7, 7, 3840)  0           ['stack_6_block5_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_6_block5_MB_dw_ (Depthwi  (None, 7, 7, 3840)  34560       ['stack_6_block5_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_6_block5_MB_dw_bn (Batch  (None, 7, 7, 3840)  15360       ['stack_6_block5_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_6_block5_MB_dw_swish (Ac  (None, 7, 7, 3840)  0           ['stack_6_block5_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_77 (TFOpLa  (None, 1, 1, 3840)  0           ['stack_6_block5_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_6_block5_se_1_conv (Conv  (None, 1, 1, 160)   614560      ['tf.math.reduce_mean_77[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_154 (Activation)    (None, 1, 1, 160)    0           ['stack_6_block5_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_6_block5_se_2_conv (Conv  (None, 1, 1, 3840)  618240      ['activation_154[0][0]']         Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_155 (Activation)    (None, 1, 1, 3840)   0           ['stack_6_block5_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_77 (Multiply)         (None, 7, 7, 3840)   0           ['stack_6_block5_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_155[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_6_block5_MB_pw_conv (Con  (None, 7, 7, 640)   2457600     ['multiply_77[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_6_block5_MB_pw_bn (Batch  (None, 7, 7, 640)   2560        ['stack_6_block5_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_91 (Add)                   (None, 7, 7, 640)    0           ['add_90[0][0]',                 Y          \n",
      "                                                                  'stack_6_block5_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_6_block6_sortcut_conv (C  (None, 7, 7, 3840)  2457600     ['add_91[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_6_block6_sortcut_bn (Bat  (None, 7, 7, 3840)  15360       ['stack_6_block6_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_6_block6_sortcut_swish (  (None, 7, 7, 3840)  0           ['stack_6_block6_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_6_block6_MB_dw_ (Depthwi  (None, 7, 7, 3840)  34560       ['stack_6_block6_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_6_block6_MB_dw_bn (Batch  (None, 7, 7, 3840)  15360       ['stack_6_block6_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_6_block6_MB_dw_swish (Ac  (None, 7, 7, 3840)  0           ['stack_6_block6_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_78 (TFOpLa  (None, 1, 1, 3840)  0           ['stack_6_block6_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_6_block6_se_1_conv (Conv  (None, 1, 1, 160)   614560      ['tf.math.reduce_mean_78[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_156 (Activation)    (None, 1, 1, 160)    0           ['stack_6_block6_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_6_block6_se_2_conv (Conv  (None, 1, 1, 3840)  618240      ['activation_156[0][0]']         Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_157 (Activation)    (None, 1, 1, 3840)   0           ['stack_6_block6_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_78 (Multiply)         (None, 7, 7, 3840)   0           ['stack_6_block6_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_157[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_6_block6_MB_pw_conv (Con  (None, 7, 7, 640)   2457600     ['multiply_78[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_6_block6_MB_pw_bn (Batch  (None, 7, 7, 640)   2560        ['stack_6_block6_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_92 (Add)                   (None, 7, 7, 640)    0           ['add_91[0][0]',                 Y          \n",
      "                                                                  'stack_6_block6_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " stack_6_block7_sortcut_conv (C  (None, 7, 7, 3840)  2457600     ['add_92[0][0]']                 Y          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " stack_6_block7_sortcut_bn (Bat  (None, 7, 7, 3840)  15360       ['stack_6_block7_sortcut_conv[0  Y          \n",
      " chNormalization)                                                ][0]']                                      \n",
      "                                                                                                             \n",
      " stack_6_block7_sortcut_swish (  (None, 7, 7, 3840)  0           ['stack_6_block7_sortcut_bn[0][  Y          \n",
      " Activation)                                                     0]']                                        \n",
      "                                                                                                             \n",
      " stack_6_block7_MB_dw_ (Depthwi  (None, 7, 7, 3840)  34560       ['stack_6_block7_sortcut_swish[  Y          \n",
      " seConv2D)                                                       0][0]']                                     \n",
      "                                                                                                             \n",
      " stack_6_block7_MB_dw_bn (Batch  (None, 7, 7, 3840)  15360       ['stack_6_block7_MB_dw_[0][0]']  Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " stack_6_block7_MB_dw_swish (Ac  (None, 7, 7, 3840)  0           ['stack_6_block7_MB_dw_bn[0][0]  Y          \n",
      " tivation)                                                       ']                                          \n",
      "                                                                                                             \n",
      " tf.math.reduce_mean_79 (TFOpLa  (None, 1, 1, 3840)  0           ['stack_6_block7_MB_dw_swish[0]  Y          \n",
      " mbda)                                                           [0]']                                       \n",
      "                                                                                                             \n",
      " stack_6_block7_se_1_conv (Conv  (None, 1, 1, 160)   614560      ['tf.math.reduce_mean_79[0][0]'  Y          \n",
      " 2D)                                                             ]                                           \n",
      "                                                                                                             \n",
      " activation_158 (Activation)    (None, 1, 1, 160)    0           ['stack_6_block7_se_1_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " stack_6_block7_se_2_conv (Conv  (None, 1, 1, 3840)  618240      ['activation_158[0][0]']         Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " activation_159 (Activation)    (None, 1, 1, 3840)   0           ['stack_6_block7_se_2_conv[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " multiply_79 (Multiply)         (None, 7, 7, 3840)   0           ['stack_6_block7_MB_dw_swish[0]  Y          \n",
      "                                                                 [0]',                                       \n",
      "                                                                  'activation_159[0][0]']                    \n",
      "                                                                                                             \n",
      " stack_6_block7_MB_pw_conv (Con  (None, 7, 7, 640)   2457600     ['multiply_79[0][0]']            Y          \n",
      " v2D)                                                                                                        \n",
      "                                                                                                             \n",
      " stack_6_block7_MB_pw_bn (Batch  (None, 7, 7, 640)   2560        ['stack_6_block7_MB_pw_conv[0][  Y          \n",
      " Normalization)                                                  0]']                                        \n",
      "                                                                                                             \n",
      " add_93 (Add)                   (None, 7, 7, 640)    0           ['add_92[0][0]',                 Y          \n",
      "                                                                  'stack_6_block7_MB_pw_bn[0][0]             \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " post_conv (Conv2D)             (None, 7, 7, 1280)   819200      ['add_93[0][0]']                 Y          \n",
      "                                                                                                             \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 1280)   5120        ['post_conv[0][0]']              Y          \n",
      "                                                                                                             \n",
      " post_swish (Activation)        (None, 7, 7, 1280)   0           ['post_bn[0][0]']                Y          \n",
      "                                                                                                             \n",
      " avg_pool (GlobalAveragePooling  (None, 1280)        0           ['post_swish[0][0]']             Y          \n",
      " 2D)                                                                                                         \n",
      "                                                                                                             \n",
      " dropout (Dropout)              (None, 1280)         0           ['avg_pool[0][0]']               Y          \n",
      "                                                                                                             \n",
      " predictions (Dense)            (None, 2)            2562        ['dropout[0][0]']                Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 207,618,394\n",
      "Trainable params: 206,841,370\n",
      "Non-trainable params: 777,024\n",
      "_____________________________________________________________________________________________________________\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from keras_efficientnet_v2 import EfficientNetV2XL\n",
    "\n",
    "EfficientNet_M = EfficientNetV2XL(\n",
    "    input_shape=(img_res[0], img_res[1], img_res[2]), pretrained=\"imagenet21k-ft1k\", num_classes=2, dropout=0.5\n",
    ")\n",
    "# define new model\n",
    "model = Model(inputs=EfficientNet_M.inputs, outputs=EfficientNet_M.outputs)\n",
    "\n",
    "# compile model\n",
    "opt = SGD(momentum=0.9)\n",
    "# opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-3)\n",
    "# opt = Adam()\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "freeze_layers = 0\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Total layers in the base model:  806\n",
      "Freezing 0 layers in the base model...\n",
      "Percentage of the base model that is frozen: 0.00%\n",
      "Total model layers:  815\n",
      "Model: \"model_1\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     Trainable  \n",
      "=============================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               Y          \n",
      "                                )]                                                                           \n",
      "                                                                                                             \n",
      " stem_conv (Conv2D)             (None, 112, 112, 64  1728        ['input_2[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 64  256         ['stem_conv[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_activation (Activation)   (None, 112, 112, 64  0           ['stem_bn[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 64  576        ['stem_activation[0][0]']        Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 64  256        ['block1a_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_activation (Activation  (None, 112, 112, 64  0          ['block1a_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_se_squeeze (GlobalAver  (None, 64)          0           ['block1a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 64)     0           ['block1a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 16)     1040        ['block1a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 64)     1088        ['block1a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 64  0           ['block1a_activation[0][0]',     Y          \n",
      "                                )                                 'block1a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 32  2048        ['block1a_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1a_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1b_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1a_project_bn[0][0]']     Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1b_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1b_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1b_activation (Activation  (None, 112, 112, 32  0          ['block1b_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1b_se_squeeze (GlobalAver  (None, 32)          0           ['block1b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1b_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1b_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1b_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1b_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1b_activation[0][0]',     Y          \n",
      "                                )                                 'block1b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1b_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1b_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1b_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1b_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1b_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1b_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1b_add (Add)              (None, 112, 112, 32  0           ['block1b_drop[0][0]',           Y          \n",
      "                                )                                 'block1a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block1c_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1b_add[0][0]']            Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1c_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1c_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1c_activation (Activation  (None, 112, 112, 32  0          ['block1c_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1c_se_squeeze (GlobalAver  (None, 32)          0           ['block1c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1c_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1c_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1c_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1c_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1c_activation[0][0]',     Y          \n",
      "                                )                                 'block1c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1c_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1c_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1c_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1c_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1c_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1c_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1c_add (Add)              (None, 112, 112, 32  0           ['block1c_drop[0][0]',           Y          \n",
      "                                )                                 'block1b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block1d_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1c_add[0][0]']            Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1d_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1d_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1d_activation (Activation  (None, 112, 112, 32  0          ['block1d_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1d_se_squeeze (GlobalAver  (None, 32)          0           ['block1d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1d_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1d_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1d_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1d_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1d_activation[0][0]',     Y          \n",
      "                                )                                 'block1d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1d_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1d_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1d_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1d_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1d_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1d_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1d_add (Add)              (None, 112, 112, 32  0           ['block1d_drop[0][0]',           Y          \n",
      "                                )                                 'block1c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 19  6144        ['block1d_add[0][0]']            Y          \n",
      "                                2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 19  768        ['block2a_expand_conv[0][0]']    Y          \n",
      " ization)                       2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_expand_activation (Act  (None, 112, 112, 19  0          ['block2a_expand_bn[0][0]']      Y          \n",
      " ivation)                       2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 192)  1728       ['block2a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 192)  768        ['block2a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_activation (Activation  (None, 56, 56, 192)  0          ['block2a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_se_squeeze (GlobalAver  (None, 192)         0           ['block2a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 192)  0           ['block2a_activation[0][0]',     Y          \n",
      "                                                                  'block2a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 48)   9216        ['block2a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_expand_activation (Act  (None, 56, 56, 288)  0          ['block2b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_activation (Activation  (None, 56, 56, 288)  0          ['block2b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_se_squeeze (GlobalAver  (None, 288)         0           ['block2b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2b_activation[0][0]',     Y          \n",
      "                                                                  'block2b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_add (Add)              (None, 56, 56, 48)   0           ['block2b_drop[0][0]',           Y          \n",
      "                                                                  'block2a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block2c_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2c_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2c_expand_activation (Act  (None, 56, 56, 288)  0          ['block2c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2c_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2c_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2c_activation (Activation  (None, 56, 56, 288)  0          ['block2c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2c_se_squeeze (GlobalAver  (None, 288)         0           ['block2c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2c_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2c_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2c_activation[0][0]',     Y          \n",
      "                                                                  'block2c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2c_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2c_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2c_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_add (Add)              (None, 56, 56, 48)   0           ['block2c_drop[0][0]',           Y          \n",
      "                                                                  'block2b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2d_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2d_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2d_expand_activation (Act  (None, 56, 56, 288)  0          ['block2d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2d_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2d_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2d_activation (Activation  (None, 56, 56, 288)  0          ['block2d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2d_se_squeeze (GlobalAver  (None, 288)         0           ['block2d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2d_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2d_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2d_activation[0][0]',     Y          \n",
      "                                                                  'block2d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2d_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2d_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2d_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_add (Add)              (None, 56, 56, 48)   0           ['block2d_drop[0][0]',           Y          \n",
      "                                                                  'block2c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2e_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2e_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2e_expand_activation (Act  (None, 56, 56, 288)  0          ['block2e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2e_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2e_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2e_activation (Activation  (None, 56, 56, 288)  0          ['block2e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2e_se_squeeze (GlobalAver  (None, 288)         0           ['block2e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2e_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2e_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2e_activation[0][0]',     Y          \n",
      "                                                                  'block2e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2e_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2e_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2e_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_add (Add)              (None, 56, 56, 48)   0           ['block2e_drop[0][0]',           Y          \n",
      "                                                                  'block2d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2f_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2f_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2f_expand_activation (Act  (None, 56, 56, 288)  0          ['block2f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2f_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2f_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2f_activation (Activation  (None, 56, 56, 288)  0          ['block2f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2f_se_squeeze (GlobalAver  (None, 288)         0           ['block2f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2f_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2f_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2f_activation[0][0]',     Y          \n",
      "                                                                  'block2f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2f_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2f_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2f_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_add (Add)              (None, 56, 56, 48)   0           ['block2f_drop[0][0]',           Y          \n",
      "                                                                  'block2e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2g_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2g_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2g_expand_activation (Act  (None, 56, 56, 288)  0          ['block2g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2g_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2g_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2g_activation (Activation  (None, 56, 56, 288)  0          ['block2g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2g_se_squeeze (GlobalAver  (None, 288)         0           ['block2g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2g_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2g_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2g_activation[0][0]',     Y          \n",
      "                                                                  'block2g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2g_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2g_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2g_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_add (Add)              (None, 56, 56, 48)   0           ['block2g_drop[0][0]',           Y          \n",
      "                                                                  'block2f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block3a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_expand_activation (Act  (None, 56, 56, 288)  0          ['block3a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 288)  7200       ['block3a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 288)  1152       ['block3a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_activation (Activation  (None, 28, 28, 288)  0          ['block3a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_se_squeeze (GlobalAver  (None, 288)         0           ['block3a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block3a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block3a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block3a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 288)  0           ['block3a_activation[0][0]',     Y          \n",
      "                                                                  'block3a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 80)   23040       ['block3a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_expand_activation (Act  (None, 28, 28, 480)  0          ['block3b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_activation (Activation  (None, 28, 28, 480)  0          ['block3b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_se_squeeze (GlobalAver  (None, 480)         0           ['block3b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3b_activation[0][0]',     Y          \n",
      "                                                                  'block3b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_add (Add)              (None, 28, 28, 80)   0           ['block3b_drop[0][0]',           Y          \n",
      "                                                                  'block3a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block3c_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3c_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3c_expand_activation (Act  (None, 28, 28, 480)  0          ['block3c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3c_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3c_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3c_activation (Activation  (None, 28, 28, 480)  0          ['block3c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3c_se_squeeze (GlobalAver  (None, 480)         0           ['block3c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3c_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3c_activation[0][0]',     Y          \n",
      "                                                                  'block3c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3c_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3c_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3c_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_add (Add)              (None, 28, 28, 80)   0           ['block3c_drop[0][0]',           Y          \n",
      "                                                                  'block3b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3d_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3d_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3d_expand_activation (Act  (None, 28, 28, 480)  0          ['block3d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3d_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3d_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3d_activation (Activation  (None, 28, 28, 480)  0          ['block3d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3d_se_squeeze (GlobalAver  (None, 480)         0           ['block3d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3d_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3d_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3d_activation[0][0]',     Y          \n",
      "                                                                  'block3d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3d_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3d_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3d_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_add (Add)              (None, 28, 28, 80)   0           ['block3d_drop[0][0]',           Y          \n",
      "                                                                  'block3c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3e_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3e_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3e_expand_activation (Act  (None, 28, 28, 480)  0          ['block3e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3e_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3e_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3e_activation (Activation  (None, 28, 28, 480)  0          ['block3e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3e_se_squeeze (GlobalAver  (None, 480)         0           ['block3e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3e_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3e_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3e_activation[0][0]',     Y          \n",
      "                                                                  'block3e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3e_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3e_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3e_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_add (Add)              (None, 28, 28, 80)   0           ['block3e_drop[0][0]',           Y          \n",
      "                                                                  'block3d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3f_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3f_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3f_expand_activation (Act  (None, 28, 28, 480)  0          ['block3f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3f_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3f_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3f_activation (Activation  (None, 28, 28, 480)  0          ['block3f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3f_se_squeeze (GlobalAver  (None, 480)         0           ['block3f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3f_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3f_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3f_activation[0][0]',     Y          \n",
      "                                                                  'block3f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3f_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3f_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3f_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_add (Add)              (None, 28, 28, 80)   0           ['block3f_drop[0][0]',           Y          \n",
      "                                                                  'block3e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3g_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3g_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3g_expand_activation (Act  (None, 28, 28, 480)  0          ['block3g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3g_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3g_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3g_activation (Activation  (None, 28, 28, 480)  0          ['block3g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3g_se_squeeze (GlobalAver  (None, 480)         0           ['block3g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3g_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3g_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3g_activation[0][0]',     Y          \n",
      "                                                                  'block3g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3g_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3g_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3g_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_add (Add)              (None, 28, 28, 80)   0           ['block3g_drop[0][0]',           Y          \n",
      "                                                                  'block3f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block4a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_expand_activation (Act  (None, 28, 28, 480)  0          ['block4a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_activation (Activation  (None, 14, 14, 480)  0          ['block4a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_se_squeeze (GlobalAver  (None, 480)         0           ['block4a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4a_activation[0][0]',     Y          \n",
      "                                                                  'block4a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 160)  76800       ['block4a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_expand_activation (Act  (None, 14, 14, 960)  0          ['block4b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_activation (Activation  (None, 14, 14, 960)  0          ['block4b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_se_squeeze (GlobalAver  (None, 960)         0           ['block4b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4b_activation[0][0]',     Y          \n",
      "                                                                  'block4b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_add (Add)              (None, 14, 14, 160)  0           ['block4b_drop[0][0]',           Y          \n",
      "                                                                  'block4a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_expand_activation (Act  (None, 14, 14, 960)  0          ['block4c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_activation (Activation  (None, 14, 14, 960)  0          ['block4c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_se_squeeze (GlobalAver  (None, 960)         0           ['block4c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4c_activation[0][0]',     Y          \n",
      "                                                                  'block4c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4c_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_add (Add)              (None, 14, 14, 160)  0           ['block4c_drop[0][0]',           Y          \n",
      "                                                                  'block4b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4d_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4d_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4d_expand_activation (Act  (None, 14, 14, 960)  0          ['block4d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4d_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4d_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4d_activation (Activation  (None, 14, 14, 960)  0          ['block4d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4d_se_squeeze (GlobalAver  (None, 960)         0           ['block4d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4d_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4d_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4d_activation[0][0]',     Y          \n",
      "                                                                  'block4d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4d_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4d_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4d_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_add (Add)              (None, 14, 14, 160)  0           ['block4d_drop[0][0]',           Y          \n",
      "                                                                  'block4c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4e_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4e_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4e_expand_activation (Act  (None, 14, 14, 960)  0          ['block4e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4e_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4e_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4e_activation (Activation  (None, 14, 14, 960)  0          ['block4e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4e_se_squeeze (GlobalAver  (None, 960)         0           ['block4e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4e_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4e_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4e_activation[0][0]',     Y          \n",
      "                                                                  'block4e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4e_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4e_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4e_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_add (Add)              (None, 14, 14, 160)  0           ['block4e_drop[0][0]',           Y          \n",
      "                                                                  'block4d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4f_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4f_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4f_expand_activation (Act  (None, 14, 14, 960)  0          ['block4f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4f_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4f_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4f_activation (Activation  (None, 14, 14, 960)  0          ['block4f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4f_se_squeeze (GlobalAver  (None, 960)         0           ['block4f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4f_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4f_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4f_activation[0][0]',     Y          \n",
      "                                                                  'block4f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4f_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4f_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4f_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_add (Add)              (None, 14, 14, 160)  0           ['block4f_drop[0][0]',           Y          \n",
      "                                                                  'block4e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4g_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4g_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4g_expand_activation (Act  (None, 14, 14, 960)  0          ['block4g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4g_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4g_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4g_activation (Activation  (None, 14, 14, 960)  0          ['block4g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4g_se_squeeze (GlobalAver  (None, 960)         0           ['block4g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4g_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4g_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4g_activation[0][0]',     Y          \n",
      "                                                                  'block4g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4g_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4g_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4g_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_add (Add)              (None, 14, 14, 160)  0           ['block4g_drop[0][0]',           Y          \n",
      "                                                                  'block4f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4h_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4h_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4h_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4h_expand_activation (Act  (None, 14, 14, 960)  0          ['block4h_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4h_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4h_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4h_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4h_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4h_activation (Activation  (None, 14, 14, 960)  0          ['block4h_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4h_se_squeeze (GlobalAver  (None, 960)         0           ['block4h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4h_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4h_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4h_activation[0][0]',     Y          \n",
      "                                                                  'block4h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4h_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4h_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4h_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_add (Add)              (None, 14, 14, 160)  0           ['block4h_drop[0][0]',           Y          \n",
      "                                                                  'block4g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4i_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4h_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4i_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4i_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4i_expand_activation (Act  (None, 14, 14, 960)  0          ['block4i_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4i_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4i_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4i_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4i_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4i_activation (Activation  (None, 14, 14, 960)  0          ['block4i_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4i_se_squeeze (GlobalAver  (None, 960)         0           ['block4i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4i_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4i_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4i_activation[0][0]',     Y          \n",
      "                                                                  'block4i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4i_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4i_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4i_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_add (Add)              (None, 14, 14, 160)  0           ['block4i_drop[0][0]',           Y          \n",
      "                                                                  'block4h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4j_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4i_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4j_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4j_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4j_expand_activation (Act  (None, 14, 14, 960)  0          ['block4j_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4j_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4j_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4j_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4j_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4j_activation (Activation  (None, 14, 14, 960)  0          ['block4j_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4j_se_squeeze (GlobalAver  (None, 960)         0           ['block4j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4j_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4j_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4j_activation[0][0]',     Y          \n",
      "                                                                  'block4j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4j_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4j_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4j_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_add (Add)              (None, 14, 14, 160)  0           ['block4j_drop[0][0]',           Y          \n",
      "                                                                  'block4i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4j_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block5a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_expand_activation (Act  (None, 14, 14, 960)  0          ['block5a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 960)  24000      ['block5a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block5a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_activation (Activation  (None, 14, 14, 960)  0          ['block5a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_se_squeeze (GlobalAver  (None, 960)         0           ['block5a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block5a_activation[0][0]',     Y          \n",
      "                                                                  'block5a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 224)  215040      ['block5a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5a_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5b_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5b_expand_activation (Act  (None, 14, 14, 1344  0          ['block5b_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5b_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5b_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5b_activation (Activation  (None, 14, 14, 1344  0          ['block5b_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5b_se_squeeze (GlobalAver  (None, 1344)        0           ['block5b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5b_activation[0][0]',     Y          \n",
      "                                )                                 'block5b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_add (Add)              (None, 14, 14, 224)  0           ['block5b_drop[0][0]',           Y          \n",
      "                                                                  'block5a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5b_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5c_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5c_expand_activation (Act  (None, 14, 14, 1344  0          ['block5c_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5c_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5c_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5c_activation (Activation  (None, 14, 14, 1344  0          ['block5c_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5c_se_squeeze (GlobalAver  (None, 1344)        0           ['block5c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5c_activation[0][0]',     Y          \n",
      "                                )                                 'block5c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5c_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_add (Add)              (None, 14, 14, 224)  0           ['block5c_drop[0][0]',           Y          \n",
      "                                                                  'block5b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5d_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5c_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5d_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5d_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5d_expand_activation (Act  (None, 14, 14, 1344  0          ['block5d_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5d_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5d_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5d_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5d_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5d_activation (Activation  (None, 14, 14, 1344  0          ['block5d_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5d_se_squeeze (GlobalAver  (None, 1344)        0           ['block5d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5d_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5d_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5d_activation[0][0]',     Y          \n",
      "                                )                                 'block5d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5d_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5d_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5d_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_add (Add)              (None, 14, 14, 224)  0           ['block5d_drop[0][0]',           Y          \n",
      "                                                                  'block5c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5e_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5d_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5e_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5e_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5e_expand_activation (Act  (None, 14, 14, 1344  0          ['block5e_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5e_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5e_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5e_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5e_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5e_activation (Activation  (None, 14, 14, 1344  0          ['block5e_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5e_se_squeeze (GlobalAver  (None, 1344)        0           ['block5e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5e_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5e_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5e_activation[0][0]',     Y          \n",
      "                                )                                 'block5e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5e_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5e_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5e_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_add (Add)              (None, 14, 14, 224)  0           ['block5e_drop[0][0]',           Y          \n",
      "                                                                  'block5d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5f_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5e_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5f_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5f_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5f_expand_activation (Act  (None, 14, 14, 1344  0          ['block5f_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5f_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5f_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5f_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5f_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5f_activation (Activation  (None, 14, 14, 1344  0          ['block5f_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5f_se_squeeze (GlobalAver  (None, 1344)        0           ['block5f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5f_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5f_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5f_activation[0][0]',     Y          \n",
      "                                )                                 'block5f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5f_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5f_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5f_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_add (Add)              (None, 14, 14, 224)  0           ['block5f_drop[0][0]',           Y          \n",
      "                                                                  'block5e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5g_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5f_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5g_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5g_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5g_expand_activation (Act  (None, 14, 14, 1344  0          ['block5g_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5g_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5g_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5g_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5g_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5g_activation (Activation  (None, 14, 14, 1344  0          ['block5g_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5g_se_squeeze (GlobalAver  (None, 1344)        0           ['block5g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5g_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5g_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5g_activation[0][0]',     Y          \n",
      "                                )                                 'block5g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5g_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5g_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5g_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_add (Add)              (None, 14, 14, 224)  0           ['block5g_drop[0][0]',           Y          \n",
      "                                                                  'block5f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5h_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5g_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5h_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5h_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5h_expand_activation (Act  (None, 14, 14, 1344  0          ['block5h_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5h_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5h_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5h_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5h_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5h_activation (Activation  (None, 14, 14, 1344  0          ['block5h_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5h_se_squeeze (GlobalAver  (None, 1344)        0           ['block5h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5h_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5h_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5h_activation[0][0]',     Y          \n",
      "                                )                                 'block5h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5h_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5h_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5h_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_add (Add)              (None, 14, 14, 224)  0           ['block5h_drop[0][0]',           Y          \n",
      "                                                                  'block5g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5i_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5h_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5i_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5i_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5i_expand_activation (Act  (None, 14, 14, 1344  0          ['block5i_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5i_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5i_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5i_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5i_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5i_activation (Activation  (None, 14, 14, 1344  0          ['block5i_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5i_se_squeeze (GlobalAver  (None, 1344)        0           ['block5i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5i_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5i_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5i_activation[0][0]',     Y          \n",
      "                                )                                 'block5i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5i_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5i_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5i_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_add (Add)              (None, 14, 14, 224)  0           ['block5i_drop[0][0]',           Y          \n",
      "                                                                  'block5h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5j_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5i_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5j_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5j_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5j_expand_activation (Act  (None, 14, 14, 1344  0          ['block5j_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5j_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5j_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5j_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5j_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5j_activation (Activation  (None, 14, 14, 1344  0          ['block5j_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5j_se_squeeze (GlobalAver  (None, 1344)        0           ['block5j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5j_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5j_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5j_activation[0][0]',     Y          \n",
      "                                )                                 'block5j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5j_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5j_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5j_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_add (Add)              (None, 14, 14, 224)  0           ['block5j_drop[0][0]',           Y          \n",
      "                                                                  'block5i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5j_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block6a_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block6a_expand_activation (Act  (None, 14, 14, 1344  0          ['block6a_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 1344)  33600       ['block6a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 1344)  5376        ['block6a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_activation (Activation  (None, 7, 7, 1344)  0           ['block6a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_se_squeeze (GlobalAver  (None, 1344)        0           ['block6a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block6a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block6a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block6a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 1344)   0           ['block6a_activation[0][0]',     Y          \n",
      "                                                                  'block6a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 384)    516096      ['block6a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_activation (Activation  (None, 7, 7, 2304)  0           ['block6b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_se_squeeze (GlobalAver  (None, 2304)        0           ['block6b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6b_activation[0][0]',     Y          \n",
      "                                                                  'block6b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_add (Add)              (None, 7, 7, 384)    0           ['block6b_drop[0][0]',           Y          \n",
      "                                                                  'block6a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_activation (Activation  (None, 7, 7, 2304)  0           ['block6c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_se_squeeze (GlobalAver  (None, 2304)        0           ['block6c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6c_activation[0][0]',     Y          \n",
      "                                                                  'block6c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6c_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_add (Add)              (None, 7, 7, 384)    0           ['block6c_drop[0][0]',           Y          \n",
      "                                                                  'block6b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_activation (Activation  (None, 7, 7, 2304)  0           ['block6d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_se_squeeze (GlobalAver  (None, 2304)        0           ['block6d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6d_activation[0][0]',     Y          \n",
      "                                                                  'block6d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6d_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_add (Add)              (None, 7, 7, 384)    0           ['block6d_drop[0][0]',           Y          \n",
      "                                                                  'block6c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6e_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6e_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6e_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6e_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6e_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6e_activation (Activation  (None, 7, 7, 2304)  0           ['block6e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6e_se_squeeze (GlobalAver  (None, 2304)        0           ['block6e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6e_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6e_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6e_activation[0][0]',     Y          \n",
      "                                                                  'block6e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6e_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6e_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6e_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_add (Add)              (None, 7, 7, 384)    0           ['block6e_drop[0][0]',           Y          \n",
      "                                                                  'block6d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6f_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6f_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6f_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6f_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6f_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6f_activation (Activation  (None, 7, 7, 2304)  0           ['block6f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6f_se_squeeze (GlobalAver  (None, 2304)        0           ['block6f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6f_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6f_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6f_activation[0][0]',     Y          \n",
      "                                                                  'block6f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6f_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6f_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6f_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_add (Add)              (None, 7, 7, 384)    0           ['block6f_drop[0][0]',           Y          \n",
      "                                                                  'block6e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6g_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6g_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6g_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6g_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6g_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6g_activation (Activation  (None, 7, 7, 2304)  0           ['block6g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6g_se_squeeze (GlobalAver  (None, 2304)        0           ['block6g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6g_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6g_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6g_activation[0][0]',     Y          \n",
      "                                                                  'block6g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6g_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6g_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6g_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_add (Add)              (None, 7, 7, 384)    0           ['block6g_drop[0][0]',           Y          \n",
      "                                                                  'block6f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6h_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6h_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6h_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6h_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6h_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6h_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6h_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6h_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6h_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6h_activation (Activation  (None, 7, 7, 2304)  0           ['block6h_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6h_se_squeeze (GlobalAver  (None, 2304)        0           ['block6h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6h_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6h_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6h_activation[0][0]',     Y          \n",
      "                                                                  'block6h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6h_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6h_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6h_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_add (Add)              (None, 7, 7, 384)    0           ['block6h_drop[0][0]',           Y          \n",
      "                                                                  'block6g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6i_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6h_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6i_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6i_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6i_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6i_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6i_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6i_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6i_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6i_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6i_activation (Activation  (None, 7, 7, 2304)  0           ['block6i_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6i_se_squeeze (GlobalAver  (None, 2304)        0           ['block6i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6i_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6i_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6i_activation[0][0]',     Y          \n",
      "                                                                  'block6i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6i_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6i_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6i_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_add (Add)              (None, 7, 7, 384)    0           ['block6i_drop[0][0]',           Y          \n",
      "                                                                  'block6h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6j_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6i_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6j_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6j_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6j_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6j_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6j_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6j_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6j_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6j_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6j_activation (Activation  (None, 7, 7, 2304)  0           ['block6j_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6j_se_squeeze (GlobalAver  (None, 2304)        0           ['block6j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6j_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6j_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6j_activation[0][0]',     Y          \n",
      "                                                                  'block6j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6j_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6j_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6j_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_add (Add)              (None, 7, 7, 384)    0           ['block6j_drop[0][0]',           Y          \n",
      "                                                                  'block6i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6k_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6j_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6k_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6k_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6k_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6k_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6k_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6k_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6k_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6k_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6k_activation (Activation  (None, 7, 7, 2304)  0           ['block6k_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6k_se_squeeze (GlobalAver  (None, 2304)        0           ['block6k_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6k_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6k_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6k_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6k_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6k_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6k_activation[0][0]',     Y          \n",
      "                                                                  'block6k_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6k_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6k_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6k_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6k_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6k_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6k_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_add (Add)              (None, 7, 7, 384)    0           ['block6k_drop[0][0]',           Y          \n",
      "                                                                  'block6j_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6l_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6k_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6l_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6l_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6l_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6l_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6l_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6l_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6l_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6l_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6l_activation (Activation  (None, 7, 7, 2304)  0           ['block6l_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6l_se_squeeze (GlobalAver  (None, 2304)        0           ['block6l_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6l_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6l_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6l_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6l_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6l_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6l_activation[0][0]',     Y          \n",
      "                                                                  'block6l_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6l_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6l_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6l_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6l_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6l_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6l_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_add (Add)              (None, 7, 7, 384)    0           ['block6l_drop[0][0]',           Y          \n",
      "                                                                  'block6k_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6m_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6l_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6m_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6m_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6m_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6m_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6m_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6m_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6m_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6m_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6m_activation (Activation  (None, 7, 7, 2304)  0           ['block6m_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6m_se_squeeze (GlobalAver  (None, 2304)        0           ['block6m_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6m_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6m_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6m_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6m_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6m_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6m_activation[0][0]',     Y          \n",
      "                                                                  'block6m_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6m_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6m_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6m_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6m_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6m_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6m_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_add (Add)              (None, 7, 7, 384)    0           ['block6m_drop[0][0]',           Y          \n",
      "                                                                  'block6l_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6m_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block7a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_expand_activation (Act  (None, 7, 7, 2304)  0           ['block7a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  20736       ['block7a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block7a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_activation (Activation  (None, 7, 7, 2304)  0           ['block7a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_se_squeeze (GlobalAver  (None, 2304)        0           ['block7a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block7a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block7a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block7a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block7a_activation[0][0]',     Y          \n",
      "                                                                  'block7a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 640)    1474560     ['block7a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7b_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7b_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7b_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7b_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7b_activation (Activation  (None, 7, 7, 3840)  0           ['block7b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7b_se_squeeze (GlobalAver  (None, 3840)        0           ['block7b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7b_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7b_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7b_activation[0][0]',     Y          \n",
      "                                                                  'block7b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7b_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7b_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7b_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_add (Add)              (None, 7, 7, 640)    0           ['block7b_drop[0][0]',           Y          \n",
      "                                                                  'block7a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block7c_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7c_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7c_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7c_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7c_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7c_activation (Activation  (None, 7, 7, 3840)  0           ['block7c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7c_se_squeeze (GlobalAver  (None, 3840)        0           ['block7c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7c_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7c_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7c_activation[0][0]',     Y          \n",
      "                                                                  'block7c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7c_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7c_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7c_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_add (Add)              (None, 7, 7, 640)    0           ['block7c_drop[0][0]',           Y          \n",
      "                                                                  'block7b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7d_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7d_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7d_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7d_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7d_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7d_activation (Activation  (None, 7, 7, 3840)  0           ['block7d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7d_se_squeeze (GlobalAver  (None, 3840)        0           ['block7d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7d_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7d_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7d_activation[0][0]',     Y          \n",
      "                                                                  'block7d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7d_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7d_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7d_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_add (Add)              (None, 7, 7, 640)    0           ['block7d_drop[0][0]',           Y          \n",
      "                                                                  'block7c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " top_conv (Conv2D)              (None, 7, 7, 2560)   1638400     ['block7d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 2560)   10240       ['top_conv[0][0]']               Y          \n",
      "                                                                                                             \n",
      " top_activation (Activation)    (None, 7, 7, 2560)   0           ['top_bn[0][0]']                 Y          \n",
      "                                                                                                             \n",
      " reshape_1 (Reshape)            (None, 49, 2560)     0           ['top_activation[0][0]']         Y          \n",
      "                                                                                                             \n",
      " cu_dnnlstm_1 (CuDNNLSTM)       (None, 512)          6295552     ['reshape_1[0][0]']              Y          \n",
      "                                                                                                             \n",
      " dense_4 (Dense)                (None, 1024)         525312      ['cu_dnnlstm_1[0][0]']           Y          \n",
      "                                                                                                             \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['dense_4[0][0]']                Y          \n",
      "                                                                                                             \n",
      " batch_normalization_2 (BatchNo  (None, 1024)        4096        ['dropout_1[0][0]']              Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " dense_5 (Dense)                (None, 512)          524800      ['batch_normalization_2[0][0]']  Y          \n",
      "                                                                                                             \n",
      " batch_normalization_3 (BatchNo  (None, 512)         2048        ['dense_5[0][0]']                Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " dense_6 (Dense)                (None, 128)          65664       ['batch_normalization_3[0][0]']  Y          \n",
      "                                                                                                             \n",
      " dense_7 (Dense)                (None, 2)            258         ['dense_6[0][0]']                Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 71,515,410\n",
      "Trainable params: 71,201,618\n",
      "Non-trainable params: 313,792\n",
      "_____________________________________________________________________________________________________________\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = KENB7(input_shape=(img_res[0], img_res[1], img_res[2]), weights=\"noisy-student\", include_top=False)\n",
    "    print(\"Total layers in the base model: \", len(base_model.layers))\n",
    "    print(f\"Freezing {freeze_layers} layers in the base model...\")\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) / len(base_model.layers)) * 100\n",
    "    print(f\"Percentage of the base model that is frozen: {frozen_percentage:.2f}%\")\n",
    "\n",
    "    # adding LSTM layers\n",
    "    lstm_seq_length = 49\n",
    "    lstm_input_shape = (lstm_seq_length, base_model.output_shape[1])\n",
    "    reshape_layer = Reshape(target_shape=(lstm_seq_length, -1))(base_model.output)\n",
    "    lstm_layer = CuDNNLSTM(512, input_shape=lstm_input_shape)(reshape_layer)\n",
    "\n",
    "    # adding dense layers\n",
    "    Dense_L1 = Dense(1024, activation=\"relu\", kernel_regularizer=l2(0.04))(lstm_layer)\n",
    "    Dropout_L1 = Dropout(0.4)(Dense_L1)\n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.02))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation=\"relu\")(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\")(Dense_L3)\n",
    "\n",
    "    model_EfficientNetB7_NS = Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(model_EfficientNetB7_NS.layers))\n",
    "\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V(T) Beta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Total layers in the base model:  780\n",
      "Freezing 0 layers in the base model...\n",
      "Percentage of the base model that is frozen: 0.00%\n",
      "Total model layers:  788\n",
      "Model: \"model\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     Trainable  \n",
      "=============================================================================================================\n",
      " input_1 (InputLayer)           [(None, 384, 384, 3  0           []                               Y          \n",
      "                                )]                                                                           \n",
      "                                                                                                             \n",
      " conv2d (Conv2D)                (None, 191, 191, 32  864         ['input_1[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " batch_normalization (BatchNorm  (None, 191, 191, 32  96         ['conv2d[0][0]']                 Y          \n",
      " alization)                     )                                                                            \n",
      "                                                                                                             \n",
      " activation (Activation)        (None, 191, 191, 32  0           ['batch_normalization[0][0]']    Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_1 (Conv2D)              (None, 189, 189, 32  9216        ['activation[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " batch_normalization_1 (BatchNo  (None, 189, 189, 32  96         ['conv2d_1[0][0]']               Y          \n",
      " rmalization)                   )                                                                            \n",
      "                                                                                                             \n",
      " activation_1 (Activation)      (None, 189, 189, 32  0           ['batch_normalization_1[0][0]']  Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_2 (Conv2D)              (None, 189, 189, 64  18432       ['activation_1[0][0]']           Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " batch_normalization_2 (BatchNo  (None, 189, 189, 64  192        ['conv2d_2[0][0]']               Y          \n",
      " rmalization)                   )                                                                            \n",
      "                                                                                                             \n",
      " activation_2 (Activation)      (None, 189, 189, 64  0           ['batch_normalization_2[0][0]']  Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " max_pooling2d (MaxPooling2D)   (None, 94, 94, 64)   0           ['activation_2[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_3 (Conv2D)              (None, 94, 94, 80)   5120        ['max_pooling2d[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_3 (BatchNo  (None, 94, 94, 80)  240         ['conv2d_3[0][0]']               Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " activation_3 (Activation)      (None, 94, 94, 80)   0           ['batch_normalization_3[0][0]']  Y          \n",
      "                                                                                                             \n",
      " conv2d_4 (Conv2D)              (None, 92, 92, 192)  138240      ['activation_3[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_4 (BatchNo  (None, 92, 92, 192)  576        ['conv2d_4[0][0]']               Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " activation_4 (Activation)      (None, 92, 92, 192)  0           ['batch_normalization_4[0][0]']  Y          \n",
      "                                                                                                             \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 45, 45, 192)  0          ['activation_4[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_8 (Conv2D)              (None, 45, 45, 64)   12288       ['max_pooling2d_1[0][0]']        Y          \n",
      "                                                                                                             \n",
      " batch_normalization_8 (BatchNo  (None, 45, 45, 64)  192         ['conv2d_8[0][0]']               Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " activation_8 (Activation)      (None, 45, 45, 64)   0           ['batch_normalization_8[0][0]']  Y          \n",
      "                                                                                                             \n",
      " conv2d_6 (Conv2D)              (None, 45, 45, 48)   9216        ['max_pooling2d_1[0][0]']        Y          \n",
      "                                                                                                             \n",
      " conv2d_9 (Conv2D)              (None, 45, 45, 96)   55296       ['activation_8[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_6 (BatchNo  (None, 45, 45, 48)  144         ['conv2d_6[0][0]']               Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " batch_normalization_9 (BatchNo  (None, 45, 45, 96)  288         ['conv2d_9[0][0]']               Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " activation_6 (Activation)      (None, 45, 45, 48)   0           ['batch_normalization_6[0][0]']  Y          \n",
      "                                                                                                             \n",
      " activation_9 (Activation)      (None, 45, 45, 96)   0           ['batch_normalization_9[0][0]']  Y          \n",
      "                                                                                                             \n",
      " average_pooling2d (AveragePool  (None, 45, 45, 192)  0          ['max_pooling2d_1[0][0]']        Y          \n",
      " ing2D)                                                                                                      \n",
      "                                                                                                             \n",
      " conv2d_5 (Conv2D)              (None, 45, 45, 96)   18432       ['max_pooling2d_1[0][0]']        Y          \n",
      "                                                                                                             \n",
      " conv2d_7 (Conv2D)              (None, 45, 45, 64)   76800       ['activation_6[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_10 (Conv2D)             (None, 45, 45, 96)   82944       ['activation_9[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_11 (Conv2D)             (None, 45, 45, 64)   12288       ['average_pooling2d[0][0]']      Y          \n",
      "                                                                                                             \n",
      " batch_normalization_5 (BatchNo  (None, 45, 45, 96)  288         ['conv2d_5[0][0]']               Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " batch_normalization_7 (BatchNo  (None, 45, 45, 64)  192         ['conv2d_7[0][0]']               Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " batch_normalization_10 (BatchN  (None, 45, 45, 96)  288         ['conv2d_10[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_11 (BatchN  (None, 45, 45, 64)  192         ['conv2d_11[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_5 (Activation)      (None, 45, 45, 96)   0           ['batch_normalization_5[0][0]']  Y          \n",
      "                                                                                                             \n",
      " activation_7 (Activation)      (None, 45, 45, 64)   0           ['batch_normalization_7[0][0]']  Y          \n",
      "                                                                                                             \n",
      " activation_10 (Activation)     (None, 45, 45, 96)   0           ['batch_normalization_10[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_11 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_11[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " mixed_5b (Concatenate)         (None, 45, 45, 320)  0           ['activation_5[0][0]',           Y          \n",
      "                                                                  'activation_7[0][0]',                      \n",
      "                                                                  'activation_10[0][0]',                     \n",
      "                                                                  'activation_11[0][0]']                     \n",
      "                                                                                                             \n",
      " conv2d_15 (Conv2D)             (None, 45, 45, 32)   10240       ['mixed_5b[0][0]']               Y          \n",
      "                                                                                                             \n",
      " batch_normalization_15 (BatchN  (None, 45, 45, 32)  96          ['conv2d_15[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_15 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_15[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_13 (Conv2D)             (None, 45, 45, 32)   10240       ['mixed_5b[0][0]']               Y          \n",
      "                                                                                                             \n",
      " conv2d_16 (Conv2D)             (None, 45, 45, 48)   13824       ['activation_15[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_13 (BatchN  (None, 45, 45, 32)  96          ['conv2d_13[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_16 (BatchN  (None, 45, 45, 48)  144         ['conv2d_16[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_13 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_13[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_16 (Activation)     (None, 45, 45, 48)   0           ['batch_normalization_16[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_12 (Conv2D)             (None, 45, 45, 32)   10240       ['mixed_5b[0][0]']               Y          \n",
      "                                                                                                             \n",
      " conv2d_14 (Conv2D)             (None, 45, 45, 32)   9216        ['activation_13[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_17 (Conv2D)             (None, 45, 45, 64)   27648       ['activation_16[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_12 (BatchN  (None, 45, 45, 32)  96          ['conv2d_12[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_14 (BatchN  (None, 45, 45, 32)  96          ['conv2d_14[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_17 (BatchN  (None, 45, 45, 64)  192         ['conv2d_17[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_12 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_12[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_14 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_14[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_17 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_17[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block35_1_mixed (Concatenate)  (None, 45, 45, 128)  0           ['activation_12[0][0]',          Y          \n",
      "                                                                  'activation_14[0][0]',                     \n",
      "                                                                  'activation_17[0][0]']                     \n",
      "                                                                                                             \n",
      " block35_1_conv (Conv2D)        (None, 45, 45, 320)  41280       ['block35_1_mixed[0][0]']        Y          \n",
      "                                                                                                             \n",
      " block35_1 (Lambda)             (None, 45, 45, 320)  0           ['mixed_5b[0][0]',               Y          \n",
      "                                                                  'block35_1_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block35_1_ac (Activation)      (None, 45, 45, 320)  0           ['block35_1[0][0]']              Y          \n",
      "                                                                                                             \n",
      " conv2d_21 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_1_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_21 (BatchN  (None, 45, 45, 32)  96          ['conv2d_21[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_21 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_21[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_19 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_1_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_22 (Conv2D)             (None, 45, 45, 48)   13824       ['activation_21[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_19 (BatchN  (None, 45, 45, 32)  96          ['conv2d_19[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_22 (BatchN  (None, 45, 45, 48)  144         ['conv2d_22[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_19 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_19[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_22 (Activation)     (None, 45, 45, 48)   0           ['batch_normalization_22[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_18 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_1_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_20 (Conv2D)             (None, 45, 45, 32)   9216        ['activation_19[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_23 (Conv2D)             (None, 45, 45, 64)   27648       ['activation_22[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_18 (BatchN  (None, 45, 45, 32)  96          ['conv2d_18[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_20 (BatchN  (None, 45, 45, 32)  96          ['conv2d_20[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_23 (BatchN  (None, 45, 45, 64)  192         ['conv2d_23[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_18 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_18[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_20 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_20[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_23 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_23[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block35_2_mixed (Concatenate)  (None, 45, 45, 128)  0           ['activation_18[0][0]',          Y          \n",
      "                                                                  'activation_20[0][0]',                     \n",
      "                                                                  'activation_23[0][0]']                     \n",
      "                                                                                                             \n",
      " block35_2_conv (Conv2D)        (None, 45, 45, 320)  41280       ['block35_2_mixed[0][0]']        Y          \n",
      "                                                                                                             \n",
      " block35_2 (Lambda)             (None, 45, 45, 320)  0           ['block35_1_ac[0][0]',           Y          \n",
      "                                                                  'block35_2_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block35_2_ac (Activation)      (None, 45, 45, 320)  0           ['block35_2[0][0]']              Y          \n",
      "                                                                                                             \n",
      " conv2d_27 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_2_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_27 (BatchN  (None, 45, 45, 32)  96          ['conv2d_27[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_27 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_27[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_25 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_2_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_28 (Conv2D)             (None, 45, 45, 48)   13824       ['activation_27[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_25 (BatchN  (None, 45, 45, 32)  96          ['conv2d_25[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_28 (BatchN  (None, 45, 45, 48)  144         ['conv2d_28[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_25 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_25[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_28 (Activation)     (None, 45, 45, 48)   0           ['batch_normalization_28[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_24 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_2_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_26 (Conv2D)             (None, 45, 45, 32)   9216        ['activation_25[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_29 (Conv2D)             (None, 45, 45, 64)   27648       ['activation_28[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_24 (BatchN  (None, 45, 45, 32)  96          ['conv2d_24[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_26 (BatchN  (None, 45, 45, 32)  96          ['conv2d_26[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_29 (BatchN  (None, 45, 45, 64)  192         ['conv2d_29[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_24 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_24[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_26 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_26[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_29 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_29[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block35_3_mixed (Concatenate)  (None, 45, 45, 128)  0           ['activation_24[0][0]',          Y          \n",
      "                                                                  'activation_26[0][0]',                     \n",
      "                                                                  'activation_29[0][0]']                     \n",
      "                                                                                                             \n",
      " block35_3_conv (Conv2D)        (None, 45, 45, 320)  41280       ['block35_3_mixed[0][0]']        Y          \n",
      "                                                                                                             \n",
      " block35_3 (Lambda)             (None, 45, 45, 320)  0           ['block35_2_ac[0][0]',           Y          \n",
      "                                                                  'block35_3_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block35_3_ac (Activation)      (None, 45, 45, 320)  0           ['block35_3[0][0]']              Y          \n",
      "                                                                                                             \n",
      " conv2d_33 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_3_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_33 (BatchN  (None, 45, 45, 32)  96          ['conv2d_33[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_33 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_33[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_31 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_3_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_34 (Conv2D)             (None, 45, 45, 48)   13824       ['activation_33[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_31 (BatchN  (None, 45, 45, 32)  96          ['conv2d_31[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_34 (BatchN  (None, 45, 45, 48)  144         ['conv2d_34[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_31 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_31[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_34 (Activation)     (None, 45, 45, 48)   0           ['batch_normalization_34[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_30 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_3_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_32 (Conv2D)             (None, 45, 45, 32)   9216        ['activation_31[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_35 (Conv2D)             (None, 45, 45, 64)   27648       ['activation_34[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_30 (BatchN  (None, 45, 45, 32)  96          ['conv2d_30[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_32 (BatchN  (None, 45, 45, 32)  96          ['conv2d_32[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_35 (BatchN  (None, 45, 45, 64)  192         ['conv2d_35[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_30 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_30[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_32 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_32[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_35 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_35[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block35_4_mixed (Concatenate)  (None, 45, 45, 128)  0           ['activation_30[0][0]',          Y          \n",
      "                                                                  'activation_32[0][0]',                     \n",
      "                                                                  'activation_35[0][0]']                     \n",
      "                                                                                                             \n",
      " block35_4_conv (Conv2D)        (None, 45, 45, 320)  41280       ['block35_4_mixed[0][0]']        Y          \n",
      "                                                                                                             \n",
      " block35_4 (Lambda)             (None, 45, 45, 320)  0           ['block35_3_ac[0][0]',           Y          \n",
      "                                                                  'block35_4_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block35_4_ac (Activation)      (None, 45, 45, 320)  0           ['block35_4[0][0]']              Y          \n",
      "                                                                                                             \n",
      " conv2d_39 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_4_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_39 (BatchN  (None, 45, 45, 32)  96          ['conv2d_39[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_39 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_39[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_37 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_4_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_40 (Conv2D)             (None, 45, 45, 48)   13824       ['activation_39[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_37 (BatchN  (None, 45, 45, 32)  96          ['conv2d_37[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_40 (BatchN  (None, 45, 45, 48)  144         ['conv2d_40[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_37 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_37[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_40 (Activation)     (None, 45, 45, 48)   0           ['batch_normalization_40[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_36 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_4_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_38 (Conv2D)             (None, 45, 45, 32)   9216        ['activation_37[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_41 (Conv2D)             (None, 45, 45, 64)   27648       ['activation_40[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_36 (BatchN  (None, 45, 45, 32)  96          ['conv2d_36[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_38 (BatchN  (None, 45, 45, 32)  96          ['conv2d_38[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_41 (BatchN  (None, 45, 45, 64)  192         ['conv2d_41[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_36 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_36[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_38 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_38[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_41 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_41[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block35_5_mixed (Concatenate)  (None, 45, 45, 128)  0           ['activation_36[0][0]',          Y          \n",
      "                                                                  'activation_38[0][0]',                     \n",
      "                                                                  'activation_41[0][0]']                     \n",
      "                                                                                                             \n",
      " block35_5_conv (Conv2D)        (None, 45, 45, 320)  41280       ['block35_5_mixed[0][0]']        Y          \n",
      "                                                                                                             \n",
      " block35_5 (Lambda)             (None, 45, 45, 320)  0           ['block35_4_ac[0][0]',           Y          \n",
      "                                                                  'block35_5_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block35_5_ac (Activation)      (None, 45, 45, 320)  0           ['block35_5[0][0]']              Y          \n",
      "                                                                                                             \n",
      " conv2d_45 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_5_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_45 (BatchN  (None, 45, 45, 32)  96          ['conv2d_45[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_45 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_45[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_43 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_5_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_46 (Conv2D)             (None, 45, 45, 48)   13824       ['activation_45[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_43 (BatchN  (None, 45, 45, 32)  96          ['conv2d_43[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_46 (BatchN  (None, 45, 45, 48)  144         ['conv2d_46[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_43 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_43[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_46 (Activation)     (None, 45, 45, 48)   0           ['batch_normalization_46[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_42 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_5_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_44 (Conv2D)             (None, 45, 45, 32)   9216        ['activation_43[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_47 (Conv2D)             (None, 45, 45, 64)   27648       ['activation_46[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_42 (BatchN  (None, 45, 45, 32)  96          ['conv2d_42[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_44 (BatchN  (None, 45, 45, 32)  96          ['conv2d_44[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_47 (BatchN  (None, 45, 45, 64)  192         ['conv2d_47[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_42 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_42[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_44 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_44[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_47 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_47[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block35_6_mixed (Concatenate)  (None, 45, 45, 128)  0           ['activation_42[0][0]',          Y          \n",
      "                                                                  'activation_44[0][0]',                     \n",
      "                                                                  'activation_47[0][0]']                     \n",
      "                                                                                                             \n",
      " block35_6_conv (Conv2D)        (None, 45, 45, 320)  41280       ['block35_6_mixed[0][0]']        Y          \n",
      "                                                                                                             \n",
      " block35_6 (Lambda)             (None, 45, 45, 320)  0           ['block35_5_ac[0][0]',           Y          \n",
      "                                                                  'block35_6_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block35_6_ac (Activation)      (None, 45, 45, 320)  0           ['block35_6[0][0]']              Y          \n",
      "                                                                                                             \n",
      " conv2d_51 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_6_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_51 (BatchN  (None, 45, 45, 32)  96          ['conv2d_51[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_51 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_51[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_49 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_6_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_52 (Conv2D)             (None, 45, 45, 48)   13824       ['activation_51[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_49 (BatchN  (None, 45, 45, 32)  96          ['conv2d_49[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_52 (BatchN  (None, 45, 45, 48)  144         ['conv2d_52[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_49 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_49[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_52 (Activation)     (None, 45, 45, 48)   0           ['batch_normalization_52[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_48 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_6_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_50 (Conv2D)             (None, 45, 45, 32)   9216        ['activation_49[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_53 (Conv2D)             (None, 45, 45, 64)   27648       ['activation_52[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_48 (BatchN  (None, 45, 45, 32)  96          ['conv2d_48[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_50 (BatchN  (None, 45, 45, 32)  96          ['conv2d_50[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_53 (BatchN  (None, 45, 45, 64)  192         ['conv2d_53[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_48 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_48[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_50 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_50[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_53 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_53[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block35_7_mixed (Concatenate)  (None, 45, 45, 128)  0           ['activation_48[0][0]',          Y          \n",
      "                                                                  'activation_50[0][0]',                     \n",
      "                                                                  'activation_53[0][0]']                     \n",
      "                                                                                                             \n",
      " block35_7_conv (Conv2D)        (None, 45, 45, 320)  41280       ['block35_7_mixed[0][0]']        Y          \n",
      "                                                                                                             \n",
      " block35_7 (Lambda)             (None, 45, 45, 320)  0           ['block35_6_ac[0][0]',           Y          \n",
      "                                                                  'block35_7_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block35_7_ac (Activation)      (None, 45, 45, 320)  0           ['block35_7[0][0]']              Y          \n",
      "                                                                                                             \n",
      " conv2d_57 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_7_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_57 (BatchN  (None, 45, 45, 32)  96          ['conv2d_57[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_57 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_57[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_55 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_7_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_58 (Conv2D)             (None, 45, 45, 48)   13824       ['activation_57[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_55 (BatchN  (None, 45, 45, 32)  96          ['conv2d_55[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_58 (BatchN  (None, 45, 45, 48)  144         ['conv2d_58[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_55 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_55[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_58 (Activation)     (None, 45, 45, 48)   0           ['batch_normalization_58[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_54 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_7_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_56 (Conv2D)             (None, 45, 45, 32)   9216        ['activation_55[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_59 (Conv2D)             (None, 45, 45, 64)   27648       ['activation_58[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_54 (BatchN  (None, 45, 45, 32)  96          ['conv2d_54[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_56 (BatchN  (None, 45, 45, 32)  96          ['conv2d_56[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_59 (BatchN  (None, 45, 45, 64)  192         ['conv2d_59[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_54 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_54[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_56 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_56[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_59 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_59[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block35_8_mixed (Concatenate)  (None, 45, 45, 128)  0           ['activation_54[0][0]',          Y          \n",
      "                                                                  'activation_56[0][0]',                     \n",
      "                                                                  'activation_59[0][0]']                     \n",
      "                                                                                                             \n",
      " block35_8_conv (Conv2D)        (None, 45, 45, 320)  41280       ['block35_8_mixed[0][0]']        Y          \n",
      "                                                                                                             \n",
      " block35_8 (Lambda)             (None, 45, 45, 320)  0           ['block35_7_ac[0][0]',           Y          \n",
      "                                                                  'block35_8_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block35_8_ac (Activation)      (None, 45, 45, 320)  0           ['block35_8[0][0]']              Y          \n",
      "                                                                                                             \n",
      " conv2d_63 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_8_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_63 (BatchN  (None, 45, 45, 32)  96          ['conv2d_63[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_63 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_63[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_61 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_8_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_64 (Conv2D)             (None, 45, 45, 48)   13824       ['activation_63[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_61 (BatchN  (None, 45, 45, 32)  96          ['conv2d_61[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_64 (BatchN  (None, 45, 45, 48)  144         ['conv2d_64[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_61 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_61[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_64 (Activation)     (None, 45, 45, 48)   0           ['batch_normalization_64[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_60 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_8_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_62 (Conv2D)             (None, 45, 45, 32)   9216        ['activation_61[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_65 (Conv2D)             (None, 45, 45, 64)   27648       ['activation_64[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_60 (BatchN  (None, 45, 45, 32)  96          ['conv2d_60[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_62 (BatchN  (None, 45, 45, 32)  96          ['conv2d_62[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_65 (BatchN  (None, 45, 45, 64)  192         ['conv2d_65[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_60 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_60[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_62 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_62[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_65 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_65[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block35_9_mixed (Concatenate)  (None, 45, 45, 128)  0           ['activation_60[0][0]',          Y          \n",
      "                                                                  'activation_62[0][0]',                     \n",
      "                                                                  'activation_65[0][0]']                     \n",
      "                                                                                                             \n",
      " block35_9_conv (Conv2D)        (None, 45, 45, 320)  41280       ['block35_9_mixed[0][0]']        Y          \n",
      "                                                                                                             \n",
      " block35_9 (Lambda)             (None, 45, 45, 320)  0           ['block35_8_ac[0][0]',           Y          \n",
      "                                                                  'block35_9_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block35_9_ac (Activation)      (None, 45, 45, 320)  0           ['block35_9[0][0]']              Y          \n",
      "                                                                                                             \n",
      " conv2d_69 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_9_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_69 (BatchN  (None, 45, 45, 32)  96          ['conv2d_69[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_69 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_69[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_67 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_9_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_70 (Conv2D)             (None, 45, 45, 48)   13824       ['activation_69[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_67 (BatchN  (None, 45, 45, 32)  96          ['conv2d_67[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_70 (BatchN  (None, 45, 45, 48)  144         ['conv2d_70[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_67 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_67[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_70 (Activation)     (None, 45, 45, 48)   0           ['batch_normalization_70[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_66 (Conv2D)             (None, 45, 45, 32)   10240       ['block35_9_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_68 (Conv2D)             (None, 45, 45, 32)   9216        ['activation_67[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_71 (Conv2D)             (None, 45, 45, 64)   27648       ['activation_70[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_66 (BatchN  (None, 45, 45, 32)  96          ['conv2d_66[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_68 (BatchN  (None, 45, 45, 32)  96          ['conv2d_68[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_71 (BatchN  (None, 45, 45, 64)  192         ['conv2d_71[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_66 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_66[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_68 (Activation)     (None, 45, 45, 32)   0           ['batch_normalization_68[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_71 (Activation)     (None, 45, 45, 64)   0           ['batch_normalization_71[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block35_10_mixed (Concatenate)  (None, 45, 45, 128)  0          ['activation_66[0][0]',          Y          \n",
      "                                                                  'activation_68[0][0]',                     \n",
      "                                                                  'activation_71[0][0]']                     \n",
      "                                                                                                             \n",
      " block35_10_conv (Conv2D)       (None, 45, 45, 320)  41280       ['block35_10_mixed[0][0]']       Y          \n",
      "                                                                                                             \n",
      " block35_10 (Lambda)            (None, 45, 45, 320)  0           ['block35_9_ac[0][0]',           Y          \n",
      "                                                                  'block35_10_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block35_10_ac (Activation)     (None, 45, 45, 320)  0           ['block35_10[0][0]']             Y          \n",
      "                                                                                                             \n",
      " conv2d_73 (Conv2D)             (None, 45, 45, 256)  81920       ['block35_10_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_73 (BatchN  (None, 45, 45, 256)  768        ['conv2d_73[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_73 (Activation)     (None, 45, 45, 256)  0           ['batch_normalization_73[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_74 (Conv2D)             (None, 45, 45, 256)  589824      ['activation_73[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_74 (BatchN  (None, 45, 45, 256)  768        ['conv2d_74[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_74 (Activation)     (None, 45, 45, 256)  0           ['batch_normalization_74[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_72 (Conv2D)             (None, 22, 22, 384)  1105920     ['block35_10_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_75 (Conv2D)             (None, 22, 22, 384)  884736      ['activation_74[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_72 (BatchN  (None, 22, 22, 384)  1152       ['conv2d_72[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_75 (BatchN  (None, 22, 22, 384)  1152       ['conv2d_75[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_72 (Activation)     (None, 22, 22, 384)  0           ['batch_normalization_72[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_75 (Activation)     (None, 22, 22, 384)  0           ['batch_normalization_75[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 22, 22, 320)  0          ['block35_10_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " mixed_6a (Concatenate)         (None, 22, 22, 1088  0           ['activation_72[0][0]',          Y          \n",
      "                                )                                 'activation_75[0][0]',                     \n",
      "                                                                  'max_pooling2d_2[0][0]']                   \n",
      "                                                                                                             \n",
      " conv2d_77 (Conv2D)             (None, 22, 22, 128)  139264      ['mixed_6a[0][0]']               Y          \n",
      "                                                                                                             \n",
      " batch_normalization_77 (BatchN  (None, 22, 22, 128)  384        ['conv2d_77[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_77 (Activation)     (None, 22, 22, 128)  0           ['batch_normalization_77[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_78 (Conv2D)             (None, 22, 22, 160)  143360      ['activation_77[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_78 (BatchN  (None, 22, 22, 160)  480        ['conv2d_78[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_78 (Activation)     (None, 22, 22, 160)  0           ['batch_normalization_78[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_76 (Conv2D)             (None, 22, 22, 192)  208896      ['mixed_6a[0][0]']               Y          \n",
      "                                                                                                             \n",
      " conv2d_79 (Conv2D)             (None, 22, 22, 192)  215040      ['activation_78[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_76 (BatchN  (None, 22, 22, 192)  576        ['conv2d_76[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_79 (BatchN  (None, 22, 22, 192)  576        ['conv2d_79[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_76 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_76[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_79 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_79[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block17_1_mixed (Concatenate)  (None, 22, 22, 384)  0           ['activation_76[0][0]',          Y          \n",
      "                                                                  'activation_79[0][0]']                     \n",
      "                                                                                                             \n",
      " block17_1_conv (Conv2D)        (None, 22, 22, 1088  418880      ['block17_1_mixed[0][0]']        Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_1 (Lambda)             (None, 22, 22, 1088  0           ['mixed_6a[0][0]',               Y          \n",
      "                                )                                 'block17_1_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_1_ac (Activation)      (None, 22, 22, 1088  0           ['block17_1[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_81 (Conv2D)             (None, 22, 22, 128)  139264      ['block17_1_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_81 (BatchN  (None, 22, 22, 128)  384        ['conv2d_81[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_81 (Activation)     (None, 22, 22, 128)  0           ['batch_normalization_81[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_82 (Conv2D)             (None, 22, 22, 160)  143360      ['activation_81[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_82 (BatchN  (None, 22, 22, 160)  480        ['conv2d_82[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_82 (Activation)     (None, 22, 22, 160)  0           ['batch_normalization_82[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_80 (Conv2D)             (None, 22, 22, 192)  208896      ['block17_1_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_83 (Conv2D)             (None, 22, 22, 192)  215040      ['activation_82[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_80 (BatchN  (None, 22, 22, 192)  576        ['conv2d_80[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_83 (BatchN  (None, 22, 22, 192)  576        ['conv2d_83[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_80 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_80[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_83 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_83[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block17_2_mixed (Concatenate)  (None, 22, 22, 384)  0           ['activation_80[0][0]',          Y          \n",
      "                                                                  'activation_83[0][0]']                     \n",
      "                                                                                                             \n",
      " block17_2_conv (Conv2D)        (None, 22, 22, 1088  418880      ['block17_2_mixed[0][0]']        Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_2 (Lambda)             (None, 22, 22, 1088  0           ['block17_1_ac[0][0]',           Y          \n",
      "                                )                                 'block17_2_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_2_ac (Activation)      (None, 22, 22, 1088  0           ['block17_2[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_85 (Conv2D)             (None, 22, 22, 128)  139264      ['block17_2_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_85 (BatchN  (None, 22, 22, 128)  384        ['conv2d_85[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_85 (Activation)     (None, 22, 22, 128)  0           ['batch_normalization_85[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_86 (Conv2D)             (None, 22, 22, 160)  143360      ['activation_85[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_86 (BatchN  (None, 22, 22, 160)  480        ['conv2d_86[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_86 (Activation)     (None, 22, 22, 160)  0           ['batch_normalization_86[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_84 (Conv2D)             (None, 22, 22, 192)  208896      ['block17_2_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_87 (Conv2D)             (None, 22, 22, 192)  215040      ['activation_86[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_84 (BatchN  (None, 22, 22, 192)  576        ['conv2d_84[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_87 (BatchN  (None, 22, 22, 192)  576        ['conv2d_87[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_84 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_84[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_87 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_87[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block17_3_mixed (Concatenate)  (None, 22, 22, 384)  0           ['activation_84[0][0]',          Y          \n",
      "                                                                  'activation_87[0][0]']                     \n",
      "                                                                                                             \n",
      " block17_3_conv (Conv2D)        (None, 22, 22, 1088  418880      ['block17_3_mixed[0][0]']        Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_3 (Lambda)             (None, 22, 22, 1088  0           ['block17_2_ac[0][0]',           Y          \n",
      "                                )                                 'block17_3_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_3_ac (Activation)      (None, 22, 22, 1088  0           ['block17_3[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_89 (Conv2D)             (None, 22, 22, 128)  139264      ['block17_3_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_89 (BatchN  (None, 22, 22, 128)  384        ['conv2d_89[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_89 (Activation)     (None, 22, 22, 128)  0           ['batch_normalization_89[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_90 (Conv2D)             (None, 22, 22, 160)  143360      ['activation_89[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_90 (BatchN  (None, 22, 22, 160)  480        ['conv2d_90[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_90 (Activation)     (None, 22, 22, 160)  0           ['batch_normalization_90[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_88 (Conv2D)             (None, 22, 22, 192)  208896      ['block17_3_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_91 (Conv2D)             (None, 22, 22, 192)  215040      ['activation_90[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_88 (BatchN  (None, 22, 22, 192)  576        ['conv2d_88[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_91 (BatchN  (None, 22, 22, 192)  576        ['conv2d_91[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_88 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_88[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_91 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_91[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block17_4_mixed (Concatenate)  (None, 22, 22, 384)  0           ['activation_88[0][0]',          Y          \n",
      "                                                                  'activation_91[0][0]']                     \n",
      "                                                                                                             \n",
      " block17_4_conv (Conv2D)        (None, 22, 22, 1088  418880      ['block17_4_mixed[0][0]']        Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_4 (Lambda)             (None, 22, 22, 1088  0           ['block17_3_ac[0][0]',           Y          \n",
      "                                )                                 'block17_4_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_4_ac (Activation)      (None, 22, 22, 1088  0           ['block17_4[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_93 (Conv2D)             (None, 22, 22, 128)  139264      ['block17_4_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_93 (BatchN  (None, 22, 22, 128)  384        ['conv2d_93[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_93 (Activation)     (None, 22, 22, 128)  0           ['batch_normalization_93[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_94 (Conv2D)             (None, 22, 22, 160)  143360      ['activation_93[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_94 (BatchN  (None, 22, 22, 160)  480        ['conv2d_94[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_94 (Activation)     (None, 22, 22, 160)  0           ['batch_normalization_94[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_92 (Conv2D)             (None, 22, 22, 192)  208896      ['block17_4_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_95 (Conv2D)             (None, 22, 22, 192)  215040      ['activation_94[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_92 (BatchN  (None, 22, 22, 192)  576        ['conv2d_92[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_95 (BatchN  (None, 22, 22, 192)  576        ['conv2d_95[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_92 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_92[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_95 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_95[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block17_5_mixed (Concatenate)  (None, 22, 22, 384)  0           ['activation_92[0][0]',          Y          \n",
      "                                                                  'activation_95[0][0]']                     \n",
      "                                                                                                             \n",
      " block17_5_conv (Conv2D)        (None, 22, 22, 1088  418880      ['block17_5_mixed[0][0]']        Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_5 (Lambda)             (None, 22, 22, 1088  0           ['block17_4_ac[0][0]',           Y          \n",
      "                                )                                 'block17_5_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_5_ac (Activation)      (None, 22, 22, 1088  0           ['block17_5[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_97 (Conv2D)             (None, 22, 22, 128)  139264      ['block17_5_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_97 (BatchN  (None, 22, 22, 128)  384        ['conv2d_97[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_97 (Activation)     (None, 22, 22, 128)  0           ['batch_normalization_97[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_98 (Conv2D)             (None, 22, 22, 160)  143360      ['activation_97[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_98 (BatchN  (None, 22, 22, 160)  480        ['conv2d_98[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_98 (Activation)     (None, 22, 22, 160)  0           ['batch_normalization_98[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_96 (Conv2D)             (None, 22, 22, 192)  208896      ['block17_5_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_99 (Conv2D)             (None, 22, 22, 192)  215040      ['activation_98[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_96 (BatchN  (None, 22, 22, 192)  576        ['conv2d_96[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " batch_normalization_99 (BatchN  (None, 22, 22, 192)  576        ['conv2d_99[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_96 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_96[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " activation_99 (Activation)     (None, 22, 22, 192)  0           ['batch_normalization_99[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block17_6_mixed (Concatenate)  (None, 22, 22, 384)  0           ['activation_96[0][0]',          Y          \n",
      "                                                                  'activation_99[0][0]']                     \n",
      "                                                                                                             \n",
      " block17_6_conv (Conv2D)        (None, 22, 22, 1088  418880      ['block17_6_mixed[0][0]']        Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_6 (Lambda)             (None, 22, 22, 1088  0           ['block17_5_ac[0][0]',           Y          \n",
      "                                )                                 'block17_6_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_6_ac (Activation)      (None, 22, 22, 1088  0           ['block17_6[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_101 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_6_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_101 (Batch  (None, 22, 22, 128)  384        ['conv2d_101[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_101 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_101[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_102 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_101[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_102 (Batch  (None, 22, 22, 160)  480        ['conv2d_102[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_102 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_102[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_100 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_6_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_103 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_102[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_100 (Batch  (None, 22, 22, 192)  576        ['conv2d_100[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_103 (Batch  (None, 22, 22, 192)  576        ['conv2d_103[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_100 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_100[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_103 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_103[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_7_mixed (Concatenate)  (None, 22, 22, 384)  0           ['activation_100[0][0]',         Y          \n",
      "                                                                  'activation_103[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_7_conv (Conv2D)        (None, 22, 22, 1088  418880      ['block17_7_mixed[0][0]']        Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_7 (Lambda)             (None, 22, 22, 1088  0           ['block17_6_ac[0][0]',           Y          \n",
      "                                )                                 'block17_7_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_7_ac (Activation)      (None, 22, 22, 1088  0           ['block17_7[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_105 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_7_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_105 (Batch  (None, 22, 22, 128)  384        ['conv2d_105[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_105 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_105[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_106 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_105[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_106 (Batch  (None, 22, 22, 160)  480        ['conv2d_106[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_106 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_106[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_104 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_7_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_107 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_106[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_104 (Batch  (None, 22, 22, 192)  576        ['conv2d_104[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_107 (Batch  (None, 22, 22, 192)  576        ['conv2d_107[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_104 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_104[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_107 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_107[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_8_mixed (Concatenate)  (None, 22, 22, 384)  0           ['activation_104[0][0]',         Y          \n",
      "                                                                  'activation_107[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_8_conv (Conv2D)        (None, 22, 22, 1088  418880      ['block17_8_mixed[0][0]']        Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_8 (Lambda)             (None, 22, 22, 1088  0           ['block17_7_ac[0][0]',           Y          \n",
      "                                )                                 'block17_8_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_8_ac (Activation)      (None, 22, 22, 1088  0           ['block17_8[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_109 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_8_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_109 (Batch  (None, 22, 22, 128)  384        ['conv2d_109[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_109 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_109[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_110 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_109[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_110 (Batch  (None, 22, 22, 160)  480        ['conv2d_110[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_110 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_110[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_108 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_8_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_111 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_110[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_108 (Batch  (None, 22, 22, 192)  576        ['conv2d_108[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_111 (Batch  (None, 22, 22, 192)  576        ['conv2d_111[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_108 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_108[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_111 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_111[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_9_mixed (Concatenate)  (None, 22, 22, 384)  0           ['activation_108[0][0]',         Y          \n",
      "                                                                  'activation_111[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_9_conv (Conv2D)        (None, 22, 22, 1088  418880      ['block17_9_mixed[0][0]']        Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_9 (Lambda)             (None, 22, 22, 1088  0           ['block17_8_ac[0][0]',           Y          \n",
      "                                )                                 'block17_9_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_9_ac (Activation)      (None, 22, 22, 1088  0           ['block17_9[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_113 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_9_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " batch_normalization_113 (Batch  (None, 22, 22, 128)  384        ['conv2d_113[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_113 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_113[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_114 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_113[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_114 (Batch  (None, 22, 22, 160)  480        ['conv2d_114[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_114 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_114[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_112 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_9_ac[0][0]']           Y          \n",
      "                                                                                                             \n",
      " conv2d_115 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_114[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_112 (Batch  (None, 22, 22, 192)  576        ['conv2d_112[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_115 (Batch  (None, 22, 22, 192)  576        ['conv2d_115[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_112 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_112[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_115 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_115[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_10_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_112[0][0]',         Y          \n",
      "                                                                  'activation_115[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_10_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_10_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_10 (Lambda)            (None, 22, 22, 1088  0           ['block17_9_ac[0][0]',           Y          \n",
      "                                )                                 'block17_10_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_10_ac (Activation)     (None, 22, 22, 1088  0           ['block17_10[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_117 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_10_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_117 (Batch  (None, 22, 22, 128)  384        ['conv2d_117[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_117 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_117[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_118 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_117[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_118 (Batch  (None, 22, 22, 160)  480        ['conv2d_118[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_118 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_118[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_116 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_10_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_119 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_118[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_116 (Batch  (None, 22, 22, 192)  576        ['conv2d_116[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_119 (Batch  (None, 22, 22, 192)  576        ['conv2d_119[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_116 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_116[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_119 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_119[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_11_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_116[0][0]',         Y          \n",
      "                                                                  'activation_119[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_11_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_11_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_11 (Lambda)            (None, 22, 22, 1088  0           ['block17_10_ac[0][0]',          Y          \n",
      "                                )                                 'block17_11_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_11_ac (Activation)     (None, 22, 22, 1088  0           ['block17_11[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_121 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_11_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_121 (Batch  (None, 22, 22, 128)  384        ['conv2d_121[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_121 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_121[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_122 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_121[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_122 (Batch  (None, 22, 22, 160)  480        ['conv2d_122[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_122 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_122[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_120 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_11_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_123 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_122[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_120 (Batch  (None, 22, 22, 192)  576        ['conv2d_120[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_123 (Batch  (None, 22, 22, 192)  576        ['conv2d_123[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_120 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_120[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_123 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_123[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_12_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_120[0][0]',         Y          \n",
      "                                                                  'activation_123[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_12_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_12_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_12 (Lambda)            (None, 22, 22, 1088  0           ['block17_11_ac[0][0]',          Y          \n",
      "                                )                                 'block17_12_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_12_ac (Activation)     (None, 22, 22, 1088  0           ['block17_12[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_125 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_12_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_125 (Batch  (None, 22, 22, 128)  384        ['conv2d_125[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_125 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_125[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_126 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_125[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_126 (Batch  (None, 22, 22, 160)  480        ['conv2d_126[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_126 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_126[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_124 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_12_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_127 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_126[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_124 (Batch  (None, 22, 22, 192)  576        ['conv2d_124[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_127 (Batch  (None, 22, 22, 192)  576        ['conv2d_127[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_124 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_124[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_127 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_127[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_13_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_124[0][0]',         Y          \n",
      "                                                                  'activation_127[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_13_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_13_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_13 (Lambda)            (None, 22, 22, 1088  0           ['block17_12_ac[0][0]',          Y          \n",
      "                                )                                 'block17_13_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_13_ac (Activation)     (None, 22, 22, 1088  0           ['block17_13[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_129 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_13_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_129 (Batch  (None, 22, 22, 128)  384        ['conv2d_129[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_129 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_129[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_130 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_129[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_130 (Batch  (None, 22, 22, 160)  480        ['conv2d_130[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_130 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_130[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_128 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_13_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_131 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_130[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_128 (Batch  (None, 22, 22, 192)  576        ['conv2d_128[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_131 (Batch  (None, 22, 22, 192)  576        ['conv2d_131[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_128 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_128[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_131 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_131[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_14_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_128[0][0]',         Y          \n",
      "                                                                  'activation_131[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_14_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_14_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_14 (Lambda)            (None, 22, 22, 1088  0           ['block17_13_ac[0][0]',          Y          \n",
      "                                )                                 'block17_14_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_14_ac (Activation)     (None, 22, 22, 1088  0           ['block17_14[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_133 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_14_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_133 (Batch  (None, 22, 22, 128)  384        ['conv2d_133[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_133 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_133[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_134 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_133[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_134 (Batch  (None, 22, 22, 160)  480        ['conv2d_134[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_134 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_134[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_132 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_14_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_135 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_134[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_132 (Batch  (None, 22, 22, 192)  576        ['conv2d_132[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_135 (Batch  (None, 22, 22, 192)  576        ['conv2d_135[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_132 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_132[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_135 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_135[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_15_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_132[0][0]',         Y          \n",
      "                                                                  'activation_135[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_15_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_15_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_15 (Lambda)            (None, 22, 22, 1088  0           ['block17_14_ac[0][0]',          Y          \n",
      "                                )                                 'block17_15_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_15_ac (Activation)     (None, 22, 22, 1088  0           ['block17_15[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_137 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_15_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_137 (Batch  (None, 22, 22, 128)  384        ['conv2d_137[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_137 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_137[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_138 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_137[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_138 (Batch  (None, 22, 22, 160)  480        ['conv2d_138[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_138 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_138[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_136 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_15_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_139 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_138[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_136 (Batch  (None, 22, 22, 192)  576        ['conv2d_136[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_139 (Batch  (None, 22, 22, 192)  576        ['conv2d_139[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_136 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_136[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_139 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_139[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_16_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_136[0][0]',         Y          \n",
      "                                                                  'activation_139[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_16_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_16_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_16 (Lambda)            (None, 22, 22, 1088  0           ['block17_15_ac[0][0]',          Y          \n",
      "                                )                                 'block17_16_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_16_ac (Activation)     (None, 22, 22, 1088  0           ['block17_16[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_141 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_16_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_141 (Batch  (None, 22, 22, 128)  384        ['conv2d_141[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_141 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_141[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_142 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_141[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_142 (Batch  (None, 22, 22, 160)  480        ['conv2d_142[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_142 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_142[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_140 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_16_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_143 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_142[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_140 (Batch  (None, 22, 22, 192)  576        ['conv2d_140[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_143 (Batch  (None, 22, 22, 192)  576        ['conv2d_143[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_140 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_140[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_143 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_143[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_17_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_140[0][0]',         Y          \n",
      "                                                                  'activation_143[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_17_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_17_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_17 (Lambda)            (None, 22, 22, 1088  0           ['block17_16_ac[0][0]',          Y          \n",
      "                                )                                 'block17_17_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_17_ac (Activation)     (None, 22, 22, 1088  0           ['block17_17[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_145 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_17_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_145 (Batch  (None, 22, 22, 128)  384        ['conv2d_145[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_145 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_145[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_146 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_145[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_146 (Batch  (None, 22, 22, 160)  480        ['conv2d_146[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_146 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_146[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_144 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_17_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_147 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_146[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_144 (Batch  (None, 22, 22, 192)  576        ['conv2d_144[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_147 (Batch  (None, 22, 22, 192)  576        ['conv2d_147[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_144 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_144[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_147 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_147[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_18_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_144[0][0]',         Y          \n",
      "                                                                  'activation_147[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_18_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_18_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_18 (Lambda)            (None, 22, 22, 1088  0           ['block17_17_ac[0][0]',          Y          \n",
      "                                )                                 'block17_18_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_18_ac (Activation)     (None, 22, 22, 1088  0           ['block17_18[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_149 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_18_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_149 (Batch  (None, 22, 22, 128)  384        ['conv2d_149[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_149 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_149[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_150 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_149[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_150 (Batch  (None, 22, 22, 160)  480        ['conv2d_150[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_150 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_150[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_148 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_18_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_151 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_150[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_148 (Batch  (None, 22, 22, 192)  576        ['conv2d_148[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_151 (Batch  (None, 22, 22, 192)  576        ['conv2d_151[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_148 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_148[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_151 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_151[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_19_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_148[0][0]',         Y          \n",
      "                                                                  'activation_151[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_19_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_19_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_19 (Lambda)            (None, 22, 22, 1088  0           ['block17_18_ac[0][0]',          Y          \n",
      "                                )                                 'block17_19_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_19_ac (Activation)     (None, 22, 22, 1088  0           ['block17_19[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_153 (Conv2D)            (None, 22, 22, 128)  139264      ['block17_19_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_153 (Batch  (None, 22, 22, 128)  384        ['conv2d_153[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_153 (Activation)    (None, 22, 22, 128)  0           ['batch_normalization_153[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_154 (Conv2D)            (None, 22, 22, 160)  143360      ['activation_153[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_154 (Batch  (None, 22, 22, 160)  480        ['conv2d_154[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_154 (Activation)    (None, 22, 22, 160)  0           ['batch_normalization_154[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_152 (Conv2D)            (None, 22, 22, 192)  208896      ['block17_19_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_155 (Conv2D)            (None, 22, 22, 192)  215040      ['activation_154[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_152 (Batch  (None, 22, 22, 192)  576        ['conv2d_152[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_155 (Batch  (None, 22, 22, 192)  576        ['conv2d_155[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_152 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_152[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_155 (Activation)    (None, 22, 22, 192)  0           ['batch_normalization_155[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block17_20_mixed (Concatenate)  (None, 22, 22, 384)  0          ['activation_152[0][0]',         Y          \n",
      "                                                                  'activation_155[0][0]']                    \n",
      "                                                                                                             \n",
      " block17_20_conv (Conv2D)       (None, 22, 22, 1088  418880      ['block17_20_mixed[0][0]']       Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block17_20 (Lambda)            (None, 22, 22, 1088  0           ['block17_19_ac[0][0]',          Y          \n",
      "                                )                                 'block17_20_conv[0][0]']                   \n",
      "                                                                                                             \n",
      " block17_20_ac (Activation)     (None, 22, 22, 1088  0           ['block17_20[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_160 (Conv2D)            (None, 22, 22, 256)  278528      ['block17_20_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_160 (Batch  (None, 22, 22, 256)  768        ['conv2d_160[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_160 (Activation)    (None, 22, 22, 256)  0           ['batch_normalization_160[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_156 (Conv2D)            (None, 22, 22, 256)  278528      ['block17_20_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_158 (Conv2D)            (None, 22, 22, 256)  278528      ['block17_20_ac[0][0]']          Y          \n",
      "                                                                                                             \n",
      " conv2d_161 (Conv2D)            (None, 22, 22, 288)  663552      ['activation_160[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_156 (Batch  (None, 22, 22, 256)  768        ['conv2d_156[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_158 (Batch  (None, 22, 22, 256)  768        ['conv2d_158[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_161 (Batch  (None, 22, 22, 288)  864        ['conv2d_161[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_156 (Activation)    (None, 22, 22, 256)  0           ['batch_normalization_156[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_158 (Activation)    (None, 22, 22, 256)  0           ['batch_normalization_158[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_161 (Activation)    (None, 22, 22, 288)  0           ['batch_normalization_161[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_157 (Conv2D)            (None, 10, 10, 384)  884736      ['activation_156[0][0]']         Y          \n",
      "                                                                                                             \n",
      " conv2d_159 (Conv2D)            (None, 10, 10, 288)  663552      ['activation_158[0][0]']         Y          \n",
      "                                                                                                             \n",
      " conv2d_162 (Conv2D)            (None, 10, 10, 320)  829440      ['activation_161[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_157 (Batch  (None, 10, 10, 384)  1152       ['conv2d_157[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_159 (Batch  (None, 10, 10, 288)  864        ['conv2d_159[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_162 (Batch  (None, 10, 10, 320)  960        ['conv2d_162[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_157 (Activation)    (None, 10, 10, 384)  0           ['batch_normalization_157[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_159 (Activation)    (None, 10, 10, 288)  0           ['batch_normalization_159[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_162 (Activation)    (None, 10, 10, 320)  0           ['batch_normalization_162[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 10, 10, 1088  0          ['block17_20_ac[0][0]']          Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " mixed_7a (Concatenate)         (None, 10, 10, 2080  0           ['activation_157[0][0]',         Y          \n",
      "                                )                                 'activation_159[0][0]',                    \n",
      "                                                                  'activation_162[0][0]',                    \n",
      "                                                                  'max_pooling2d_3[0][0]']                   \n",
      "                                                                                                             \n",
      " conv2d_164 (Conv2D)            (None, 10, 10, 192)  399360      ['mixed_7a[0][0]']               Y          \n",
      "                                                                                                             \n",
      " batch_normalization_164 (Batch  (None, 10, 10, 192)  576        ['conv2d_164[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_164 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_164[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_165 (Conv2D)            (None, 10, 10, 224)  129024      ['activation_164[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_165 (Batch  (None, 10, 10, 224)  672        ['conv2d_165[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_165 (Activation)    (None, 10, 10, 224)  0           ['batch_normalization_165[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_163 (Conv2D)            (None, 10, 10, 192)  399360      ['mixed_7a[0][0]']               Y          \n",
      "                                                                                                             \n",
      " conv2d_166 (Conv2D)            (None, 10, 10, 256)  172032      ['activation_165[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_163 (Batch  (None, 10, 10, 192)  576        ['conv2d_163[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_166 (Batch  (None, 10, 10, 256)  768        ['conv2d_166[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_163 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_163[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_166 (Activation)    (None, 10, 10, 256)  0           ['batch_normalization_166[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block8_1_mixed (Concatenate)   (None, 10, 10, 448)  0           ['activation_163[0][0]',         Y          \n",
      "                                                                  'activation_166[0][0]']                    \n",
      "                                                                                                             \n",
      " block8_1_conv (Conv2D)         (None, 10, 10, 2080  933920      ['block8_1_mixed[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block8_1 (Lambda)              (None, 10, 10, 2080  0           ['mixed_7a[0][0]',               Y          \n",
      "                                )                                 'block8_1_conv[0][0]']                     \n",
      "                                                                                                             \n",
      " block8_1_ac (Activation)       (None, 10, 10, 2080  0           ['block8_1[0][0]']               Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_168 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_1_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " batch_normalization_168 (Batch  (None, 10, 10, 192)  576        ['conv2d_168[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_168 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_168[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_169 (Conv2D)            (None, 10, 10, 224)  129024      ['activation_168[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_169 (Batch  (None, 10, 10, 224)  672        ['conv2d_169[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_169 (Activation)    (None, 10, 10, 224)  0           ['batch_normalization_169[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_167 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_1_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " conv2d_170 (Conv2D)            (None, 10, 10, 256)  172032      ['activation_169[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_167 (Batch  (None, 10, 10, 192)  576        ['conv2d_167[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_170 (Batch  (None, 10, 10, 256)  768        ['conv2d_170[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_167 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_167[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_170 (Activation)    (None, 10, 10, 256)  0           ['batch_normalization_170[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block8_2_mixed (Concatenate)   (None, 10, 10, 448)  0           ['activation_167[0][0]',         Y          \n",
      "                                                                  'activation_170[0][0]']                    \n",
      "                                                                                                             \n",
      " block8_2_conv (Conv2D)         (None, 10, 10, 2080  933920      ['block8_2_mixed[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block8_2 (Lambda)              (None, 10, 10, 2080  0           ['block8_1_ac[0][0]',            Y          \n",
      "                                )                                 'block8_2_conv[0][0]']                     \n",
      "                                                                                                             \n",
      " block8_2_ac (Activation)       (None, 10, 10, 2080  0           ['block8_2[0][0]']               Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_172 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_2_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " batch_normalization_172 (Batch  (None, 10, 10, 192)  576        ['conv2d_172[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_172 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_172[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_173 (Conv2D)            (None, 10, 10, 224)  129024      ['activation_172[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_173 (Batch  (None, 10, 10, 224)  672        ['conv2d_173[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_173 (Activation)    (None, 10, 10, 224)  0           ['batch_normalization_173[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_171 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_2_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " conv2d_174 (Conv2D)            (None, 10, 10, 256)  172032      ['activation_173[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_171 (Batch  (None, 10, 10, 192)  576        ['conv2d_171[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_174 (Batch  (None, 10, 10, 256)  768        ['conv2d_174[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_171 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_171[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_174 (Activation)    (None, 10, 10, 256)  0           ['batch_normalization_174[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block8_3_mixed (Concatenate)   (None, 10, 10, 448)  0           ['activation_171[0][0]',         Y          \n",
      "                                                                  'activation_174[0][0]']                    \n",
      "                                                                                                             \n",
      " block8_3_conv (Conv2D)         (None, 10, 10, 2080  933920      ['block8_3_mixed[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block8_3 (Lambda)              (None, 10, 10, 2080  0           ['block8_2_ac[0][0]',            Y          \n",
      "                                )                                 'block8_3_conv[0][0]']                     \n",
      "                                                                                                             \n",
      " block8_3_ac (Activation)       (None, 10, 10, 2080  0           ['block8_3[0][0]']               Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_176 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_3_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " batch_normalization_176 (Batch  (None, 10, 10, 192)  576        ['conv2d_176[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_176 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_176[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_177 (Conv2D)            (None, 10, 10, 224)  129024      ['activation_176[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_177 (Batch  (None, 10, 10, 224)  672        ['conv2d_177[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_177 (Activation)    (None, 10, 10, 224)  0           ['batch_normalization_177[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_175 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_3_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " conv2d_178 (Conv2D)            (None, 10, 10, 256)  172032      ['activation_177[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_175 (Batch  (None, 10, 10, 192)  576        ['conv2d_175[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_178 (Batch  (None, 10, 10, 256)  768        ['conv2d_178[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_175 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_175[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_178 (Activation)    (None, 10, 10, 256)  0           ['batch_normalization_178[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block8_4_mixed (Concatenate)   (None, 10, 10, 448)  0           ['activation_175[0][0]',         Y          \n",
      "                                                                  'activation_178[0][0]']                    \n",
      "                                                                                                             \n",
      " block8_4_conv (Conv2D)         (None, 10, 10, 2080  933920      ['block8_4_mixed[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block8_4 (Lambda)              (None, 10, 10, 2080  0           ['block8_3_ac[0][0]',            Y          \n",
      "                                )                                 'block8_4_conv[0][0]']                     \n",
      "                                                                                                             \n",
      " block8_4_ac (Activation)       (None, 10, 10, 2080  0           ['block8_4[0][0]']               Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_180 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_4_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " batch_normalization_180 (Batch  (None, 10, 10, 192)  576        ['conv2d_180[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_180 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_180[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_181 (Conv2D)            (None, 10, 10, 224)  129024      ['activation_180[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_181 (Batch  (None, 10, 10, 224)  672        ['conv2d_181[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_181 (Activation)    (None, 10, 10, 224)  0           ['batch_normalization_181[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_179 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_4_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " conv2d_182 (Conv2D)            (None, 10, 10, 256)  172032      ['activation_181[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_179 (Batch  (None, 10, 10, 192)  576        ['conv2d_179[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_182 (Batch  (None, 10, 10, 256)  768        ['conv2d_182[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_179 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_179[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_182 (Activation)    (None, 10, 10, 256)  0           ['batch_normalization_182[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block8_5_mixed (Concatenate)   (None, 10, 10, 448)  0           ['activation_179[0][0]',         Y          \n",
      "                                                                  'activation_182[0][0]']                    \n",
      "                                                                                                             \n",
      " block8_5_conv (Conv2D)         (None, 10, 10, 2080  933920      ['block8_5_mixed[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block8_5 (Lambda)              (None, 10, 10, 2080  0           ['block8_4_ac[0][0]',            Y          \n",
      "                                )                                 'block8_5_conv[0][0]']                     \n",
      "                                                                                                             \n",
      " block8_5_ac (Activation)       (None, 10, 10, 2080  0           ['block8_5[0][0]']               Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_184 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_5_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " batch_normalization_184 (Batch  (None, 10, 10, 192)  576        ['conv2d_184[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_184 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_184[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_185 (Conv2D)            (None, 10, 10, 224)  129024      ['activation_184[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_185 (Batch  (None, 10, 10, 224)  672        ['conv2d_185[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_185 (Activation)    (None, 10, 10, 224)  0           ['batch_normalization_185[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_183 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_5_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " conv2d_186 (Conv2D)            (None, 10, 10, 256)  172032      ['activation_185[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_183 (Batch  (None, 10, 10, 192)  576        ['conv2d_183[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_186 (Batch  (None, 10, 10, 256)  768        ['conv2d_186[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_183 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_183[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_186 (Activation)    (None, 10, 10, 256)  0           ['batch_normalization_186[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block8_6_mixed (Concatenate)   (None, 10, 10, 448)  0           ['activation_183[0][0]',         Y          \n",
      "                                                                  'activation_186[0][0]']                    \n",
      "                                                                                                             \n",
      " block8_6_conv (Conv2D)         (None, 10, 10, 2080  933920      ['block8_6_mixed[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block8_6 (Lambda)              (None, 10, 10, 2080  0           ['block8_5_ac[0][0]',            Y          \n",
      "                                )                                 'block8_6_conv[0][0]']                     \n",
      "                                                                                                             \n",
      " block8_6_ac (Activation)       (None, 10, 10, 2080  0           ['block8_6[0][0]']               Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_188 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_6_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " batch_normalization_188 (Batch  (None, 10, 10, 192)  576        ['conv2d_188[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_188 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_188[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_189 (Conv2D)            (None, 10, 10, 224)  129024      ['activation_188[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_189 (Batch  (None, 10, 10, 224)  672        ['conv2d_189[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_189 (Activation)    (None, 10, 10, 224)  0           ['batch_normalization_189[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_187 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_6_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " conv2d_190 (Conv2D)            (None, 10, 10, 256)  172032      ['activation_189[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_187 (Batch  (None, 10, 10, 192)  576        ['conv2d_187[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_190 (Batch  (None, 10, 10, 256)  768        ['conv2d_190[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_187 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_187[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_190 (Activation)    (None, 10, 10, 256)  0           ['batch_normalization_190[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block8_7_mixed (Concatenate)   (None, 10, 10, 448)  0           ['activation_187[0][0]',         Y          \n",
      "                                                                  'activation_190[0][0]']                    \n",
      "                                                                                                             \n",
      " block8_7_conv (Conv2D)         (None, 10, 10, 2080  933920      ['block8_7_mixed[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block8_7 (Lambda)              (None, 10, 10, 2080  0           ['block8_6_ac[0][0]',            Y          \n",
      "                                )                                 'block8_7_conv[0][0]']                     \n",
      "                                                                                                             \n",
      " block8_7_ac (Activation)       (None, 10, 10, 2080  0           ['block8_7[0][0]']               Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_192 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_7_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " batch_normalization_192 (Batch  (None, 10, 10, 192)  576        ['conv2d_192[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_192 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_192[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_193 (Conv2D)            (None, 10, 10, 224)  129024      ['activation_192[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_193 (Batch  (None, 10, 10, 224)  672        ['conv2d_193[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_193 (Activation)    (None, 10, 10, 224)  0           ['batch_normalization_193[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_191 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_7_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " conv2d_194 (Conv2D)            (None, 10, 10, 256)  172032      ['activation_193[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_191 (Batch  (None, 10, 10, 192)  576        ['conv2d_191[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_194 (Batch  (None, 10, 10, 256)  768        ['conv2d_194[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_191 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_191[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_194 (Activation)    (None, 10, 10, 256)  0           ['batch_normalization_194[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block8_8_mixed (Concatenate)   (None, 10, 10, 448)  0           ['activation_191[0][0]',         Y          \n",
      "                                                                  'activation_194[0][0]']                    \n",
      "                                                                                                             \n",
      " block8_8_conv (Conv2D)         (None, 10, 10, 2080  933920      ['block8_8_mixed[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block8_8 (Lambda)              (None, 10, 10, 2080  0           ['block8_7_ac[0][0]',            Y          \n",
      "                                )                                 'block8_8_conv[0][0]']                     \n",
      "                                                                                                             \n",
      " block8_8_ac (Activation)       (None, 10, 10, 2080  0           ['block8_8[0][0]']               Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_196 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_8_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " batch_normalization_196 (Batch  (None, 10, 10, 192)  576        ['conv2d_196[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_196 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_196[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_197 (Conv2D)            (None, 10, 10, 224)  129024      ['activation_196[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_197 (Batch  (None, 10, 10, 224)  672        ['conv2d_197[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_197 (Activation)    (None, 10, 10, 224)  0           ['batch_normalization_197[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_195 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_8_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " conv2d_198 (Conv2D)            (None, 10, 10, 256)  172032      ['activation_197[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_195 (Batch  (None, 10, 10, 192)  576        ['conv2d_195[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_198 (Batch  (None, 10, 10, 256)  768        ['conv2d_198[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_195 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_195[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_198 (Activation)    (None, 10, 10, 256)  0           ['batch_normalization_198[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block8_9_mixed (Concatenate)   (None, 10, 10, 448)  0           ['activation_195[0][0]',         Y          \n",
      "                                                                  'activation_198[0][0]']                    \n",
      "                                                                                                             \n",
      " block8_9_conv (Conv2D)         (None, 10, 10, 2080  933920      ['block8_9_mixed[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block8_9 (Lambda)              (None, 10, 10, 2080  0           ['block8_8_ac[0][0]',            Y          \n",
      "                                )                                 'block8_9_conv[0][0]']                     \n",
      "                                                                                                             \n",
      " block8_9_ac (Activation)       (None, 10, 10, 2080  0           ['block8_9[0][0]']               Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv2d_200 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_9_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " batch_normalization_200 (Batch  (None, 10, 10, 192)  576        ['conv2d_200[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_200 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_200[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_201 (Conv2D)            (None, 10, 10, 224)  129024      ['activation_200[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_201 (Batch  (None, 10, 10, 224)  672        ['conv2d_201[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_201 (Activation)    (None, 10, 10, 224)  0           ['batch_normalization_201[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " conv2d_199 (Conv2D)            (None, 10, 10, 192)  399360      ['block8_9_ac[0][0]']            Y          \n",
      "                                                                                                             \n",
      " conv2d_202 (Conv2D)            (None, 10, 10, 256)  172032      ['activation_201[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_199 (Batch  (None, 10, 10, 192)  576        ['conv2d_199[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " batch_normalization_202 (Batch  (None, 10, 10, 256)  768        ['conv2d_202[0][0]']             Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " activation_199 (Activation)    (None, 10, 10, 192)  0           ['batch_normalization_199[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " activation_202 (Activation)    (None, 10, 10, 256)  0           ['batch_normalization_202[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block8_10_mixed (Concatenate)  (None, 10, 10, 448)  0           ['activation_199[0][0]',         Y          \n",
      "                                                                  'activation_202[0][0]']                    \n",
      "                                                                                                             \n",
      " block8_10_conv (Conv2D)        (None, 10, 10, 2080  933920      ['block8_10_mixed[0][0]']        Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block8_10 (Lambda)             (None, 10, 10, 2080  0           ['block8_9_ac[0][0]',            Y          \n",
      "                                )                                 'block8_10_conv[0][0]']                    \n",
      "                                                                                                             \n",
      " conv_7b (Conv2D)               (None, 10, 10, 1536  3194880     ['block8_10[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " conv_7b_bn (BatchNormalization  (None, 10, 10, 1536  4608       ['conv_7b[0][0]']                Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " conv_7b_ac (Activation)        (None, 10, 10, 1536  0           ['conv_7b_bn[0][0]']             Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " global_average_pooling2d (Glob  (None, 1536)        0           ['conv_7b_ac[0][0]']             Y          \n",
      " alAveragePooling2D)                                                                                         \n",
      "                                                                                                             \n",
      " dense (Dense)                  (None, 1024)         1573888     ['global_average_pooling2d[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  Y          \n",
      "                                                                                                             \n",
      " batch_normalization_203 (Batch  (None, 1024)        4096        ['dropout[0][0]']                Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " dense_1 (Dense)                (None, 512)          524800      ['batch_normalization_203[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " batch_normalization_204 (Batch  (None, 512)         2048        ['dense_1[0][0]']                Y          \n",
      " Normalization)                                                                                              \n",
      "                                                                                                             \n",
      " dense_2 (Dense)                (None, 128)          65664       ['batch_normalization_204[0][0]  Y          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " dense_3 (Dense)                (None, 2)            258         ['dense_2[0][0]']                Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 56,507,490\n",
      "Trainable params: 56,443,874\n",
      "Non-trainable params: 63,616\n",
      "_____________________________________________________________________________________________________________\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "\n",
    "\n",
    "# FUNC\n",
    "def Eff_B7_NS(freeze_layers):\n",
    "    base_model = InceptionResNetV2(input_shape=(img_res[0], img_res[1], img_res[2]), weights=None, include_top=False)\n",
    "    print(\"Total layers in the base model: \", len(base_model.layers))\n",
    "    print(f\"Freezing {freeze_layers} layers in the base model...\")\n",
    "    # Freeze the specified number of layers\n",
    "    for layer in base_model.layers[:freeze_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the rest\n",
    "    for layer in base_model.layers[freeze_layers:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Calculate the percentage of the model that is frozen\n",
    "    frozen_percentage = ((freeze_layers + 1e-10) / len(base_model.layers)) * 100\n",
    "    print(f\"Percentage of the base model that is frozen: {frozen_percentage:.2f}%\")\n",
    "    # adding CDL\n",
    "    base_model_FT = GlobalAveragePooling2D()(base_model.output)\n",
    "    Dense_L1 = Dense(1024, activation=\"relu\", kernel_regularizer=l2(0.04))(base_model_FT)\n",
    "    Dropout_L1 = Dropout(0.4)(Dense_L1)\n",
    "    BatchNorm_L2 = BatchNormalization()(Dropout_L1)\n",
    "    Dense_L2 = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.02))(BatchNorm_L2)\n",
    "    BatchNorm_L3 = BatchNormalization()(Dense_L2)\n",
    "    Dense_L3 = Dense(128, activation=\"relu\")(BatchNorm_L3)\n",
    "    predictions = Dense(2, activation=\"softmax\")(Dense_L3)\n",
    "\n",
    "    model_EfficientNetB7_NS = Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Total model layers: \", len(model_EfficientNetB7_NS.layers))\n",
    "    # OPT/compile\n",
    "    opt = SGD(momentum=0.9)\n",
    "    # opt = Yogi()\n",
    "    model_EfficientNetB7_NS.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model_EfficientNetB7_NS\n",
    "\n",
    "\n",
    "print(\"Creating the model...\")\n",
    "# Main\n",
    "freeze_layers = 0\n",
    "model = Eff_B7_NS(freeze_layers)\n",
    "model.summary(show_trainable=True, expand_nested=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aydin\\Desktop\\Pneumonia AI\\Model_T&T_BETA.ipynb Cell 29\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m LRF_OPT \u001b[39m=\u001b[39m SGD(momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X40sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m LFR_batch_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# or any other batch size that fits in your memory\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m LRF_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensor_slices((x_train, y_train))\u001b[39m.\u001b[39mbatch(LFR_batch_size)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Instantiate LrFinder\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X40sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m lr_find \u001b[39m=\u001b[39m LrFinder(model, LRF_OPT, tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mcategorical_crossentropy)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:814\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    737\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_tensor_slices\u001b[39m(tensors, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    738\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \n\u001b[0;32m    740\u001b[0m \u001b[39m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m   \u001b[39mreturn\u001b[39;00m TensorSliceDataset(tensors, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4708\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m   4706\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, element, is_files\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   4707\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4708\u001b[0m   element \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39;49mnormalize_element(element)\n\u001b[0;32m   4709\u001b[0m   batched_spec \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m   4710\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensors \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:126\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    123\u001b[0m       \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m         dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(spec, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    125\u001b[0m         normalized_components\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 126\u001b[0m             ops\u001b[39m.\u001b[39;49mconvert_to_tensor(t, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcomponent_\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m i, dtype\u001b[39m=\u001b[39;49mdtype))\n\u001b[0;32m    127\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1629\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1631\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1634\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1635\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m   1637\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1638\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1640\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1641\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     47\u001b[0m   \u001b[39mdel\u001b[39;00m as_ref  \u001b[39m# Unused.\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m   \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39;49mconstant(value, dtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    303\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "# CONF/Other\n",
    "LRF_OPT = SGD(momentum=0.9)\n",
    "LFR_batch_size = 1  # or any other batch size that fits in your memory\n",
    "LRF_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(LFR_batch_size)\n",
    "# Instantiate LrFinder\n",
    "lr_find = LrFinder(model, LRF_OPT, tf.keras.losses.categorical_crossentropy)\n",
    "\n",
    "# Start range_test\n",
    "lr_find.range_test(LRF_dataset)\n",
    "lr_find.plot_lrs(skip_end=0, suggestion=True, show_grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mLoading model done.\n",
      "Compiling the AI model...\u001b[0m\n",
      "Model: \"model_10\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     Trainable  \n",
      "=============================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               Y          \n",
      "                                )]                                                                           \n",
      "                                                                                                             \n",
      " stem_conv (Conv2D)             (None, 112, 112, 64  1728        ['input_1[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 64  256         ['stem_conv[0][0]']              Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " stem_activation (Activation)   (None, 112, 112, 64  0           ['stem_bn[0][0]']                Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 64  576        ['stem_activation[0][0]']        Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 64  256        ['block1a_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_activation (Activation  (None, 112, 112, 64  0          ['block1a_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1a_se_squeeze (GlobalAver  (None, 64)          0           ['block1a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 64)     0           ['block1a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 16)     1040        ['block1a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 64)     1088        ['block1a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 64  0           ['block1a_activation[0][0]',     Y          \n",
      "                                )                                 'block1a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 32  2048        ['block1a_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1a_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1b_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1a_project_bn[0][0]']     Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1b_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1b_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1b_activation (Activation  (None, 112, 112, 32  0          ['block1b_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1b_se_squeeze (GlobalAver  (None, 32)          0           ['block1b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1b_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1b_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1b_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1b_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1b_activation[0][0]',     Y          \n",
      "                                )                                 'block1b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1b_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1b_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1b_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1b_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1b_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1b_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1b_add (Add)              (None, 112, 112, 32  0           ['block1b_drop[0][0]',           Y          \n",
      "                                )                                 'block1a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block1c_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1b_add[0][0]']            Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1c_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1c_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1c_activation (Activation  (None, 112, 112, 32  0          ['block1c_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1c_se_squeeze (GlobalAver  (None, 32)          0           ['block1c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1c_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1c_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1c_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1c_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1c_activation[0][0]',     Y          \n",
      "                                )                                 'block1c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1c_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1c_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1c_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1c_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1c_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1c_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1c_add (Add)              (None, 112, 112, 32  0           ['block1c_drop[0][0]',           Y          \n",
      "                                )                                 'block1b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block1d_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['block1c_add[0][0]']            Y          \n",
      " D)                             )                                                                            \n",
      "                                                                                                             \n",
      " block1d_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1d_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1d_activation (Activation  (None, 112, 112, 32  0          ['block1d_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block1d_se_squeeze (GlobalAver  (None, 32)          0           ['block1d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block1d_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1d_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block1d_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block1d_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1d_activation[0][0]',     Y          \n",
      "                                )                                 'block1d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block1d_project_conv (Conv2D)  (None, 112, 112, 32  1024        ['block1d_se_excite[0][0]']      Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1d_project_bn (BatchNorma  (None, 112, 112, 32  128        ['block1d_project_conv[0][0]']   Y          \n",
      " lization)                      )                                                                            \n",
      "                                                                                                             \n",
      " block1d_drop (FixedDropout)    (None, 112, 112, 32  0           ['block1d_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block1d_add (Add)              (None, 112, 112, 32  0           ['block1d_drop[0][0]',           Y          \n",
      "                                )                                 'block1c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 19  6144        ['block1d_add[0][0]']            Y          \n",
      "                                2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 19  768        ['block2a_expand_conv[0][0]']    Y          \n",
      " ization)                       2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_expand_activation (Act  (None, 112, 112, 19  0          ['block2a_expand_bn[0][0]']      Y          \n",
      " ivation)                       2)                                                                           \n",
      "                                                                                                             \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 192)  1728       ['block2a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 192)  768        ['block2a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_activation (Activation  (None, 56, 56, 192)  0          ['block2a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2a_se_squeeze (GlobalAver  (None, 192)         0           ['block2a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 192)  0           ['block2a_activation[0][0]',     Y          \n",
      "                                                                  'block2a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 48)   9216        ['block2a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_expand_activation (Act  (None, 56, 56, 288)  0          ['block2b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_activation (Activation  (None, 56, 56, 288)  0          ['block2b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2b_se_squeeze (GlobalAver  (None, 288)         0           ['block2b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2b_activation[0][0]',     Y          \n",
      "                                                                  'block2b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2b_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2b_add (Add)              (None, 56, 56, 48)   0           ['block2b_drop[0][0]',           Y          \n",
      "                                                                  'block2a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block2c_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2c_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2c_expand_activation (Act  (None, 56, 56, 288)  0          ['block2c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2c_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2c_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2c_activation (Activation  (None, 56, 56, 288)  0          ['block2c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2c_se_squeeze (GlobalAver  (None, 288)         0           ['block2c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2c_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2c_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2c_activation[0][0]',     Y          \n",
      "                                                                  'block2c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2c_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2c_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2c_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2c_add (Add)              (None, 56, 56, 48)   0           ['block2c_drop[0][0]',           Y          \n",
      "                                                                  'block2b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2d_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2d_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2d_expand_activation (Act  (None, 56, 56, 288)  0          ['block2d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2d_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2d_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2d_activation (Activation  (None, 56, 56, 288)  0          ['block2d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2d_se_squeeze (GlobalAver  (None, 288)         0           ['block2d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2d_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2d_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2d_activation[0][0]',     Y          \n",
      "                                                                  'block2d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2d_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2d_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2d_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2d_add (Add)              (None, 56, 56, 48)   0           ['block2d_drop[0][0]',           Y          \n",
      "                                                                  'block2c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2e_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2e_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2e_expand_activation (Act  (None, 56, 56, 288)  0          ['block2e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2e_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2e_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2e_activation (Activation  (None, 56, 56, 288)  0          ['block2e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2e_se_squeeze (GlobalAver  (None, 288)         0           ['block2e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2e_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2e_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2e_activation[0][0]',     Y          \n",
      "                                                                  'block2e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2e_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2e_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2e_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2e_add (Add)              (None, 56, 56, 48)   0           ['block2e_drop[0][0]',           Y          \n",
      "                                                                  'block2d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2f_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2f_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2f_expand_activation (Act  (None, 56, 56, 288)  0          ['block2f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2f_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2f_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2f_activation (Activation  (None, 56, 56, 288)  0          ['block2f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2f_se_squeeze (GlobalAver  (None, 288)         0           ['block2f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2f_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2f_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2f_activation[0][0]',     Y          \n",
      "                                                                  'block2f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2f_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2f_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2f_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2f_add (Add)              (None, 56, 56, 48)   0           ['block2f_drop[0][0]',           Y          \n",
      "                                                                  'block2e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block2g_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block2g_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block2g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block2g_expand_activation (Act  (None, 56, 56, 288)  0          ['block2g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block2g_dwconv (DepthwiseConv2  (None, 56, 56, 288)  2592       ['block2g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block2g_bn (BatchNormalization  (None, 56, 56, 288)  1152       ['block2g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2g_activation (Activation  (None, 56, 56, 288)  0          ['block2g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block2g_se_squeeze (GlobalAver  (None, 288)         0           ['block2g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block2g_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block2g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block2g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block2g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2g_se_excite (Multiply)   (None, 56, 56, 288)  0           ['block2g_activation[0][0]',     Y          \n",
      "                                                                  'block2g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block2g_project_conv (Conv2D)  (None, 56, 56, 48)   13824       ['block2g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block2g_project_bn (BatchNorma  (None, 56, 56, 48)  192         ['block2g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block2g_drop (FixedDropout)    (None, 56, 56, 48)   0           ['block2g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block2g_add (Add)              (None, 56, 56, 48)   0           ['block2g_drop[0][0]',           Y          \n",
      "                                                                  'block2f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 288)  13824       ['block2g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 288)  1152       ['block3a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_expand_activation (Act  (None, 56, 56, 288)  0          ['block3a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 288)  7200       ['block3a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 288)  1152       ['block3a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_activation (Activation  (None, 28, 28, 288)  0          ['block3a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3a_se_squeeze (GlobalAver  (None, 288)         0           ['block3a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block3a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block3a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block3a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 288)  0           ['block3a_activation[0][0]',     Y          \n",
      "                                                                  'block3a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 80)   23040       ['block3a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_expand_activation (Act  (None, 28, 28, 480)  0          ['block3b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_activation (Activation  (None, 28, 28, 480)  0          ['block3b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3b_se_squeeze (GlobalAver  (None, 480)         0           ['block3b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3b_activation[0][0]',     Y          \n",
      "                                                                  'block3b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3b_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3b_add (Add)              (None, 28, 28, 80)   0           ['block3b_drop[0][0]',           Y          \n",
      "                                                                  'block3a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block3c_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3c_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3c_expand_activation (Act  (None, 28, 28, 480)  0          ['block3c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3c_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3c_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3c_activation (Activation  (None, 28, 28, 480)  0          ['block3c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3c_se_squeeze (GlobalAver  (None, 480)         0           ['block3c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3c_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3c_activation[0][0]',     Y          \n",
      "                                                                  'block3c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3c_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3c_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3c_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3c_add (Add)              (None, 28, 28, 80)   0           ['block3c_drop[0][0]',           Y          \n",
      "                                                                  'block3b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3d_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3d_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3d_expand_activation (Act  (None, 28, 28, 480)  0          ['block3d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3d_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3d_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3d_activation (Activation  (None, 28, 28, 480)  0          ['block3d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3d_se_squeeze (GlobalAver  (None, 480)         0           ['block3d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3d_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3d_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3d_activation[0][0]',     Y          \n",
      "                                                                  'block3d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3d_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3d_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3d_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3d_add (Add)              (None, 28, 28, 80)   0           ['block3d_drop[0][0]',           Y          \n",
      "                                                                  'block3c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3e_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3e_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3e_expand_activation (Act  (None, 28, 28, 480)  0          ['block3e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3e_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3e_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3e_activation (Activation  (None, 28, 28, 480)  0          ['block3e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3e_se_squeeze (GlobalAver  (None, 480)         0           ['block3e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3e_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3e_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3e_activation[0][0]',     Y          \n",
      "                                                                  'block3e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3e_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3e_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3e_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3e_add (Add)              (None, 28, 28, 80)   0           ['block3e_drop[0][0]',           Y          \n",
      "                                                                  'block3d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3f_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3f_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3f_expand_activation (Act  (None, 28, 28, 480)  0          ['block3f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3f_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3f_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3f_activation (Activation  (None, 28, 28, 480)  0          ['block3f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3f_se_squeeze (GlobalAver  (None, 480)         0           ['block3f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3f_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3f_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3f_activation[0][0]',     Y          \n",
      "                                                                  'block3f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3f_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3f_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3f_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3f_add (Add)              (None, 28, 28, 80)   0           ['block3f_drop[0][0]',           Y          \n",
      "                                                                  'block3e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block3g_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block3g_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block3g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block3g_expand_activation (Act  (None, 28, 28, 480)  0          ['block3g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block3g_dwconv (DepthwiseConv2  (None, 28, 28, 480)  12000      ['block3g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block3g_bn (BatchNormalization  (None, 28, 28, 480)  1920       ['block3g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3g_activation (Activation  (None, 28, 28, 480)  0          ['block3g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block3g_se_squeeze (GlobalAver  (None, 480)         0           ['block3g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block3g_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block3g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block3g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block3g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3g_se_excite (Multiply)   (None, 28, 28, 480)  0           ['block3g_activation[0][0]',     Y          \n",
      "                                                                  'block3g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block3g_project_conv (Conv2D)  (None, 28, 28, 80)   38400       ['block3g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block3g_project_bn (BatchNorma  (None, 28, 28, 80)  320         ['block3g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block3g_drop (FixedDropout)    (None, 28, 28, 80)   0           ['block3g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block3g_add (Add)              (None, 28, 28, 80)   0           ['block3g_drop[0][0]',           Y          \n",
      "                                                                  'block3f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 480)  38400       ['block3g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 480)  1920       ['block4a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_expand_activation (Act  (None, 28, 28, 480)  0          ['block4a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_activation (Activation  (None, 14, 14, 480)  0          ['block4a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4a_se_squeeze (GlobalAver  (None, 480)         0           ['block4a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4a_activation[0][0]',     Y          \n",
      "                                                                  'block4a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 160)  76800       ['block4a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_expand_activation (Act  (None, 14, 14, 960)  0          ['block4b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_activation (Activation  (None, 14, 14, 960)  0          ['block4b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4b_se_squeeze (GlobalAver  (None, 960)         0           ['block4b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4b_activation[0][0]',     Y          \n",
      "                                                                  'block4b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4b_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4b_add (Add)              (None, 14, 14, 160)  0           ['block4b_drop[0][0]',           Y          \n",
      "                                                                  'block4a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_expand_activation (Act  (None, 14, 14, 960)  0          ['block4c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_activation (Activation  (None, 14, 14, 960)  0          ['block4c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4c_se_squeeze (GlobalAver  (None, 960)         0           ['block4c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4c_activation[0][0]',     Y          \n",
      "                                                                  'block4c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4c_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4c_add (Add)              (None, 14, 14, 160)  0           ['block4c_drop[0][0]',           Y          \n",
      "                                                                  'block4b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4d_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4d_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4d_expand_activation (Act  (None, 14, 14, 960)  0          ['block4d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4d_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4d_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4d_activation (Activation  (None, 14, 14, 960)  0          ['block4d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4d_se_squeeze (GlobalAver  (None, 960)         0           ['block4d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4d_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4d_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4d_activation[0][0]',     Y          \n",
      "                                                                  'block4d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4d_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4d_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4d_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4d_add (Add)              (None, 14, 14, 160)  0           ['block4d_drop[0][0]',           Y          \n",
      "                                                                  'block4c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4e_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4e_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4e_expand_activation (Act  (None, 14, 14, 960)  0          ['block4e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4e_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4e_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4e_activation (Activation  (None, 14, 14, 960)  0          ['block4e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4e_se_squeeze (GlobalAver  (None, 960)         0           ['block4e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4e_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4e_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4e_activation[0][0]',     Y          \n",
      "                                                                  'block4e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4e_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4e_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4e_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4e_add (Add)              (None, 14, 14, 160)  0           ['block4e_drop[0][0]',           Y          \n",
      "                                                                  'block4d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4f_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4f_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4f_expand_activation (Act  (None, 14, 14, 960)  0          ['block4f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4f_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4f_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4f_activation (Activation  (None, 14, 14, 960)  0          ['block4f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4f_se_squeeze (GlobalAver  (None, 960)         0           ['block4f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4f_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4f_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4f_activation[0][0]',     Y          \n",
      "                                                                  'block4f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4f_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4f_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4f_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4f_add (Add)              (None, 14, 14, 160)  0           ['block4f_drop[0][0]',           Y          \n",
      "                                                                  'block4e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4g_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4g_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4g_expand_activation (Act  (None, 14, 14, 960)  0          ['block4g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4g_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4g_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4g_activation (Activation  (None, 14, 14, 960)  0          ['block4g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4g_se_squeeze (GlobalAver  (None, 960)         0           ['block4g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4g_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4g_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4g_activation[0][0]',     Y          \n",
      "                                                                  'block4g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4g_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4g_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4g_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4g_add (Add)              (None, 14, 14, 160)  0           ['block4g_drop[0][0]',           Y          \n",
      "                                                                  'block4f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4h_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4h_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4h_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4h_expand_activation (Act  (None, 14, 14, 960)  0          ['block4h_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4h_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4h_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4h_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4h_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4h_activation (Activation  (None, 14, 14, 960)  0          ['block4h_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4h_se_squeeze (GlobalAver  (None, 960)         0           ['block4h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4h_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4h_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4h_activation[0][0]',     Y          \n",
      "                                                                  'block4h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4h_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4h_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4h_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4h_add (Add)              (None, 14, 14, 160)  0           ['block4h_drop[0][0]',           Y          \n",
      "                                                                  'block4g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4i_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4h_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4i_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4i_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4i_expand_activation (Act  (None, 14, 14, 960)  0          ['block4i_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4i_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4i_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4i_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4i_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4i_activation (Activation  (None, 14, 14, 960)  0          ['block4i_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4i_se_squeeze (GlobalAver  (None, 960)         0           ['block4i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4i_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4i_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4i_activation[0][0]',     Y          \n",
      "                                                                  'block4i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4i_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4i_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4i_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4i_add (Add)              (None, 14, 14, 160)  0           ['block4i_drop[0][0]',           Y          \n",
      "                                                                  'block4h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block4j_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4i_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block4j_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block4j_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block4j_expand_activation (Act  (None, 14, 14, 960)  0          ['block4j_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block4j_dwconv (DepthwiseConv2  (None, 14, 14, 960)  8640       ['block4j_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block4j_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block4j_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4j_activation (Activation  (None, 14, 14, 960)  0          ['block4j_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block4j_se_squeeze (GlobalAver  (None, 960)         0           ['block4j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block4j_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block4j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block4j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block4j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4j_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block4j_activation[0][0]',     Y          \n",
      "                                                                  'block4j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block4j_project_conv (Conv2D)  (None, 14, 14, 160)  153600      ['block4j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block4j_project_bn (BatchNorma  (None, 14, 14, 160)  640        ['block4j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block4j_drop (FixedDropout)    (None, 14, 14, 160)  0           ['block4j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block4j_add (Add)              (None, 14, 14, 160)  0           ['block4j_drop[0][0]',           Y          \n",
      "                                                                  'block4i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 960)  153600      ['block4j_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 960)  3840       ['block5a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_expand_activation (Act  (None, 14, 14, 960)  0          ['block5a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 960)  24000      ['block5a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 960)  3840       ['block5a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_activation (Activation  (None, 14, 14, 960)  0          ['block5a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block5a_se_squeeze (GlobalAver  (None, 960)         0           ['block5a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 960)    0           ['block5a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 40)     38440       ['block5a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 960)    39360       ['block5a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 960)  0           ['block5a_activation[0][0]',     Y          \n",
      "                                                                  'block5a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 224)  215040      ['block5a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5a_project_bn[0][0]']     Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5b_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5b_expand_activation (Act  (None, 14, 14, 1344  0          ['block5b_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5b_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5b_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5b_activation (Activation  (None, 14, 14, 1344  0          ['block5b_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5b_se_squeeze (GlobalAver  (None, 1344)        0           ['block5b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5b_activation[0][0]',     Y          \n",
      "                                )                                 'block5b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5b_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5b_add (Add)              (None, 14, 14, 224)  0           ['block5b_drop[0][0]',           Y          \n",
      "                                                                  'block5a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5b_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5c_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5c_expand_activation (Act  (None, 14, 14, 1344  0          ['block5c_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5c_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5c_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5c_activation (Activation  (None, 14, 14, 1344  0          ['block5c_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5c_se_squeeze (GlobalAver  (None, 1344)        0           ['block5c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5c_activation[0][0]',     Y          \n",
      "                                )                                 'block5c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5c_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5c_add (Add)              (None, 14, 14, 224)  0           ['block5c_drop[0][0]',           Y          \n",
      "                                                                  'block5b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5d_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5c_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5d_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5d_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5d_expand_activation (Act  (None, 14, 14, 1344  0          ['block5d_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5d_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5d_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5d_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5d_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5d_activation (Activation  (None, 14, 14, 1344  0          ['block5d_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5d_se_squeeze (GlobalAver  (None, 1344)        0           ['block5d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5d_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5d_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5d_activation[0][0]',     Y          \n",
      "                                )                                 'block5d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5d_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5d_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5d_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5d_add (Add)              (None, 14, 14, 224)  0           ['block5d_drop[0][0]',           Y          \n",
      "                                                                  'block5c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5e_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5d_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5e_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5e_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5e_expand_activation (Act  (None, 14, 14, 1344  0          ['block5e_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5e_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5e_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5e_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5e_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5e_activation (Activation  (None, 14, 14, 1344  0          ['block5e_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5e_se_squeeze (GlobalAver  (None, 1344)        0           ['block5e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5e_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5e_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5e_activation[0][0]',     Y          \n",
      "                                )                                 'block5e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5e_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5e_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5e_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5e_add (Add)              (None, 14, 14, 224)  0           ['block5e_drop[0][0]',           Y          \n",
      "                                                                  'block5d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5f_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5e_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5f_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5f_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5f_expand_activation (Act  (None, 14, 14, 1344  0          ['block5f_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5f_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5f_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5f_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5f_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5f_activation (Activation  (None, 14, 14, 1344  0          ['block5f_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5f_se_squeeze (GlobalAver  (None, 1344)        0           ['block5f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5f_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5f_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5f_activation[0][0]',     Y          \n",
      "                                )                                 'block5f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5f_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5f_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5f_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5f_add (Add)              (None, 14, 14, 224)  0           ['block5f_drop[0][0]',           Y          \n",
      "                                                                  'block5e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5g_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5f_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5g_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5g_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5g_expand_activation (Act  (None, 14, 14, 1344  0          ['block5g_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5g_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5g_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5g_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5g_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5g_activation (Activation  (None, 14, 14, 1344  0          ['block5g_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5g_se_squeeze (GlobalAver  (None, 1344)        0           ['block5g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5g_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5g_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5g_activation[0][0]',     Y          \n",
      "                                )                                 'block5g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5g_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5g_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5g_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5g_add (Add)              (None, 14, 14, 224)  0           ['block5g_drop[0][0]',           Y          \n",
      "                                                                  'block5f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5h_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5g_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5h_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5h_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5h_expand_activation (Act  (None, 14, 14, 1344  0          ['block5h_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5h_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5h_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5h_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5h_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5h_activation (Activation  (None, 14, 14, 1344  0          ['block5h_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5h_se_squeeze (GlobalAver  (None, 1344)        0           ['block5h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5h_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5h_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5h_activation[0][0]',     Y          \n",
      "                                )                                 'block5h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5h_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5h_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5h_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5h_add (Add)              (None, 14, 14, 224)  0           ['block5h_drop[0][0]',           Y          \n",
      "                                                                  'block5g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5i_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5h_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5i_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5i_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5i_expand_activation (Act  (None, 14, 14, 1344  0          ['block5i_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5i_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5i_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5i_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5i_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5i_activation (Activation  (None, 14, 14, 1344  0          ['block5i_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5i_se_squeeze (GlobalAver  (None, 1344)        0           ['block5i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5i_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5i_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5i_activation[0][0]',     Y          \n",
      "                                )                                 'block5i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5i_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5i_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5i_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5i_add (Add)              (None, 14, 14, 224)  0           ['block5i_drop[0][0]',           Y          \n",
      "                                                                  'block5h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block5j_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5i_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block5j_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block5j_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5j_expand_activation (Act  (None, 14, 14, 1344  0          ['block5j_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block5j_dwconv (DepthwiseConv2  (None, 14, 14, 1344  33600      ['block5j_expand_activation[0][  Y          \n",
      " D)                             )                                0]']                                        \n",
      "                                                                                                             \n",
      " block5j_bn (BatchNormalization  (None, 14, 14, 1344  5376       ['block5j_dwconv[0][0]']         Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5j_activation (Activation  (None, 14, 14, 1344  0          ['block5j_bn[0][0]']             Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " block5j_se_squeeze (GlobalAver  (None, 1344)        0           ['block5j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block5j_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block5j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block5j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block5j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5j_se_excite (Multiply)   (None, 14, 14, 1344  0           ['block5j_activation[0][0]',     Y          \n",
      "                                )                                 'block5j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block5j_project_conv (Conv2D)  (None, 14, 14, 224)  301056      ['block5j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block5j_project_bn (BatchNorma  (None, 14, 14, 224)  896        ['block5j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block5j_drop (FixedDropout)    (None, 14, 14, 224)  0           ['block5j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block5j_add (Add)              (None, 14, 14, 224)  0           ['block5j_drop[0][0]',           Y          \n",
      "                                                                  'block5i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 1344  301056      ['block5j_add[0][0]']            Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 1344  5376       ['block6a_expand_conv[0][0]']    Y          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block6a_expand_activation (Act  (None, 14, 14, 1344  0          ['block6a_expand_bn[0][0]']      Y          \n",
      " ivation)                       )                                                                            \n",
      "                                                                                                             \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 1344)  33600       ['block6a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 1344)  5376        ['block6a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_activation (Activation  (None, 7, 7, 1344)  0           ['block6a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6a_se_squeeze (GlobalAver  (None, 1344)        0           ['block6a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 1344)   0           ['block6a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 56)     75320       ['block6a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 1344)   76608       ['block6a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 1344)   0           ['block6a_activation[0][0]',     Y          \n",
      "                                                                  'block6a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 384)    516096      ['block6a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_activation (Activation  (None, 7, 7, 2304)  0           ['block6b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6b_se_squeeze (GlobalAver  (None, 2304)        0           ['block6b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6b_activation[0][0]',     Y          \n",
      "                                                                  'block6b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6b_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6b_add (Add)              (None, 7, 7, 384)    0           ['block6b_drop[0][0]',           Y          \n",
      "                                                                  'block6a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_activation (Activation  (None, 7, 7, 2304)  0           ['block6c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6c_se_squeeze (GlobalAver  (None, 2304)        0           ['block6c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6c_activation[0][0]',     Y          \n",
      "                                                                  'block6c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6c_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6c_add (Add)              (None, 7, 7, 384)    0           ['block6c_drop[0][0]',           Y          \n",
      "                                                                  'block6b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_activation (Activation  (None, 7, 7, 2304)  0           ['block6d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6d_se_squeeze (GlobalAver  (None, 2304)        0           ['block6d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6d_activation[0][0]',     Y          \n",
      "                                                                  'block6d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6d_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6d_add (Add)              (None, 7, 7, 384)    0           ['block6d_drop[0][0]',           Y          \n",
      "                                                                  'block6c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6e_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6e_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6e_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6e_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6e_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6e_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6e_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6e_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6e_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6e_activation (Activation  (None, 7, 7, 2304)  0           ['block6e_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6e_se_squeeze (GlobalAver  (None, 2304)        0           ['block6e_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6e_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6e_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6e_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6e_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6e_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6e_activation[0][0]',     Y          \n",
      "                                                                  'block6e_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6e_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6e_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6e_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6e_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6e_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6e_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6e_add (Add)              (None, 7, 7, 384)    0           ['block6e_drop[0][0]',           Y          \n",
      "                                                                  'block6d_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6f_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6e_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6f_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6f_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6f_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6f_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6f_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6f_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6f_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6f_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6f_activation (Activation  (None, 7, 7, 2304)  0           ['block6f_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6f_se_squeeze (GlobalAver  (None, 2304)        0           ['block6f_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6f_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6f_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6f_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6f_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6f_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6f_activation[0][0]',     Y          \n",
      "                                                                  'block6f_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6f_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6f_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6f_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6f_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6f_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6f_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6f_add (Add)              (None, 7, 7, 384)    0           ['block6f_drop[0][0]',           Y          \n",
      "                                                                  'block6e_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6g_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6f_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6g_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6g_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6g_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6g_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6g_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6g_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6g_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6g_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6g_activation (Activation  (None, 7, 7, 2304)  0           ['block6g_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6g_se_squeeze (GlobalAver  (None, 2304)        0           ['block6g_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6g_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6g_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6g_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6g_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6g_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6g_activation[0][0]',     Y          \n",
      "                                                                  'block6g_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6g_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6g_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6g_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6g_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6g_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6g_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6g_add (Add)              (None, 7, 7, 384)    0           ['block6g_drop[0][0]',           Y          \n",
      "                                                                  'block6f_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6h_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6g_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6h_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6h_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6h_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6h_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6h_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6h_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6h_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6h_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6h_activation (Activation  (None, 7, 7, 2304)  0           ['block6h_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6h_se_squeeze (GlobalAver  (None, 2304)        0           ['block6h_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6h_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6h_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6h_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6h_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6h_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6h_activation[0][0]',     Y          \n",
      "                                                                  'block6h_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6h_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6h_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6h_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6h_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6h_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6h_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6h_add (Add)              (None, 7, 7, 384)    0           ['block6h_drop[0][0]',           Y          \n",
      "                                                                  'block6g_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6i_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6h_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6i_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6i_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6i_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6i_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6i_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6i_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6i_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6i_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6i_activation (Activation  (None, 7, 7, 2304)  0           ['block6i_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6i_se_squeeze (GlobalAver  (None, 2304)        0           ['block6i_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6i_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6i_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6i_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6i_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6i_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6i_activation[0][0]',     Y          \n",
      "                                                                  'block6i_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6i_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6i_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6i_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6i_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6i_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6i_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6i_add (Add)              (None, 7, 7, 384)    0           ['block6i_drop[0][0]',           Y          \n",
      "                                                                  'block6h_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6j_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6i_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6j_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6j_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6j_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6j_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6j_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6j_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6j_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6j_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6j_activation (Activation  (None, 7, 7, 2304)  0           ['block6j_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6j_se_squeeze (GlobalAver  (None, 2304)        0           ['block6j_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6j_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6j_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6j_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6j_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6j_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6j_activation[0][0]',     Y          \n",
      "                                                                  'block6j_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6j_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6j_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6j_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6j_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6j_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6j_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6j_add (Add)              (None, 7, 7, 384)    0           ['block6j_drop[0][0]',           Y          \n",
      "                                                                  'block6i_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6k_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6j_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6k_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6k_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6k_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6k_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6k_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6k_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6k_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6k_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6k_activation (Activation  (None, 7, 7, 2304)  0           ['block6k_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6k_se_squeeze (GlobalAver  (None, 2304)        0           ['block6k_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6k_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6k_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6k_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6k_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6k_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6k_activation[0][0]',     Y          \n",
      "                                                                  'block6k_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6k_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6k_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6k_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6k_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6k_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6k_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6k_add (Add)              (None, 7, 7, 384)    0           ['block6k_drop[0][0]',           Y          \n",
      "                                                                  'block6j_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6l_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6k_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6l_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6l_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6l_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6l_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6l_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6l_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6l_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6l_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6l_activation (Activation  (None, 7, 7, 2304)  0           ['block6l_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6l_se_squeeze (GlobalAver  (None, 2304)        0           ['block6l_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6l_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6l_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6l_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6l_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6l_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6l_activation[0][0]',     Y          \n",
      "                                                                  'block6l_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6l_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6l_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6l_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6l_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6l_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6l_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6l_add (Add)              (None, 7, 7, 384)    0           ['block6l_drop[0][0]',           Y          \n",
      "                                                                  'block6k_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block6m_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6l_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block6m_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block6m_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block6m_expand_activation (Act  (None, 7, 7, 2304)  0           ['block6m_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block6m_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  57600       ['block6m_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block6m_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block6m_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6m_activation (Activation  (None, 7, 7, 2304)  0           ['block6m_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block6m_se_squeeze (GlobalAver  (None, 2304)        0           ['block6m_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block6m_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block6m_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block6m_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block6m_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6m_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block6m_activation[0][0]',     Y          \n",
      "                                                                  'block6m_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block6m_project_conv (Conv2D)  (None, 7, 7, 384)    884736      ['block6m_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block6m_project_bn (BatchNorma  (None, 7, 7, 384)   1536        ['block6m_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block6m_drop (FixedDropout)    (None, 7, 7, 384)    0           ['block6m_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block6m_add (Add)              (None, 7, 7, 384)    0           ['block6m_drop[0][0]',           Y          \n",
      "                                                                  'block6l_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 2304)   884736      ['block6m_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 2304)  9216        ['block7a_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_expand_activation (Act  (None, 7, 7, 2304)  0           ['block7a_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 2304)  20736       ['block7a_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 2304)  9216        ['block7a_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_activation (Activation  (None, 7, 7, 2304)  0           ['block7a_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7a_se_squeeze (GlobalAver  (None, 2304)        0           ['block7a_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block7a_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block7a_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block7a_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 2304)   0           ['block7a_activation[0][0]',     Y          \n",
      "                                                                  'block7a_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 640)    1474560     ['block7a_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7a_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7b_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7a_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7b_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7b_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7b_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7b_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7b_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7b_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7b_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7b_activation (Activation  (None, 7, 7, 3840)  0           ['block7b_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7b_se_squeeze (GlobalAver  (None, 3840)        0           ['block7b_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7b_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7b_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7b_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7b_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7b_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7b_activation[0][0]',     Y          \n",
      "                                                                  'block7b_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7b_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7b_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7b_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7b_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7b_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7b_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7b_add (Add)              (None, 7, 7, 640)    0           ['block7b_drop[0][0]',           Y          \n",
      "                                                                  'block7a_project_bn[0][0]']                \n",
      "                                                                                                             \n",
      " block7c_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7b_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7c_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7c_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7c_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7c_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7c_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7c_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7c_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7c_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7c_activation (Activation  (None, 7, 7, 3840)  0           ['block7c_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7c_se_squeeze (GlobalAver  (None, 3840)        0           ['block7c_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7c_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7c_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7c_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7c_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7c_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7c_activation[0][0]',     Y          \n",
      "                                                                  'block7c_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7c_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7c_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7c_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7c_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7c_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7c_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7c_add (Add)              (None, 7, 7, 640)    0           ['block7c_drop[0][0]',           Y          \n",
      "                                                                  'block7b_add[0][0]']                       \n",
      "                                                                                                             \n",
      " block7d_expand_conv (Conv2D)   (None, 7, 7, 3840)   2457600     ['block7c_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " block7d_expand_bn (BatchNormal  (None, 7, 7, 3840)  15360       ['block7d_expand_conv[0][0]']    Y          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block7d_expand_activation (Act  (None, 7, 7, 3840)  0           ['block7d_expand_bn[0][0]']      Y          \n",
      " ivation)                                                                                                    \n",
      "                                                                                                             \n",
      " block7d_dwconv (DepthwiseConv2  (None, 7, 7, 3840)  34560       ['block7d_expand_activation[0][  Y          \n",
      " D)                                                              0]']                                        \n",
      "                                                                                                             \n",
      " block7d_bn (BatchNormalization  (None, 7, 7, 3840)  15360       ['block7d_dwconv[0][0]']         Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7d_activation (Activation  (None, 7, 7, 3840)  0           ['block7d_bn[0][0]']             Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " block7d_se_squeeze (GlobalAver  (None, 3840)        0           ['block7d_activation[0][0]']     Y          \n",
      " agePooling2D)                                                                                               \n",
      "                                                                                                             \n",
      " block7d_se_reshape (Reshape)   (None, 1, 1, 3840)   0           ['block7d_se_squeeze[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_se_reduce (Conv2D)     (None, 1, 1, 160)    614560      ['block7d_se_reshape[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_se_expand (Conv2D)     (None, 1, 1, 3840)   618240      ['block7d_se_reduce[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7d_se_excite (Multiply)   (None, 7, 7, 3840)   0           ['block7d_activation[0][0]',     Y          \n",
      "                                                                  'block7d_se_expand[0][0]']                 \n",
      "                                                                                                             \n",
      " block7d_project_conv (Conv2D)  (None, 7, 7, 640)    2457600     ['block7d_se_excite[0][0]']      Y          \n",
      "                                                                                                             \n",
      " block7d_project_bn (BatchNorma  (None, 7, 7, 640)   2560        ['block7d_project_conv[0][0]']   Y          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block7d_drop (FixedDropout)    (None, 7, 7, 640)    0           ['block7d_project_bn[0][0]']     Y          \n",
      "                                                                                                             \n",
      " block7d_add (Add)              (None, 7, 7, 640)    0           ['block7d_drop[0][0]',           Y          \n",
      "                                                                  'block7c_add[0][0]']                       \n",
      "                                                                                                             \n",
      " top_conv (Conv2D)              (None, 7, 7, 2560)   1638400     ['block7d_add[0][0]']            Y          \n",
      "                                                                                                             \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 2560)   10240       ['top_conv[0][0]']               Y          \n",
      "                                                                                                             \n",
      " top_activation (Activation)    (None, 7, 7, 2560)   0           ['top_bn[0][0]']                 Y          \n",
      "                                                                                                             \n",
      " global_average_pooling2d (Glob  (None, 2560)        0           ['top_activation[0][0]']         Y          \n",
      " alAveragePooling2D)                                                                                         \n",
      "                                                                                                             \n",
      " dense (Dense)                  (None, 512)          1311232     ['global_average_pooling2d[0][0  Y          \n",
      "                                                                 ]']                                         \n",
      "                                                                                                             \n",
      " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  Y          \n",
      "                                                                                                             \n",
      " batch_normalization (BatchNorm  (None, 512)         2048        ['dropout[0][0]']                Y          \n",
      " alization)                                                                                                  \n",
      "                                                                                                             \n",
      " dense_1 (Dense)                (None, 512)          262656      ['batch_normalization[0][0]']    Y          \n",
      "                                                                                                             \n",
      " batch_normalization_1 (BatchNo  (None, 512)         2048        ['dense_1[0][0]']                Y          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " dense_2 (Dense)                (None, 128)          65664       ['batch_normalization_1[0][0]']  Y          \n",
      "                                                                                                             \n",
      " dense_3 (Dense)                (None, 2)            258         ['dense_2[0][0]']                Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 65,741,586\n",
      "Trainable params: 65,428,818\n",
      "Non-trainable params: 312,768\n",
      "_____________________________________________________________________________________________________________\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "PRMC = False\n",
    "freeze_from_opposite = True\n",
    "Extra_EXT = \"_T\"\n",
    "freeze_layers = 0\n",
    "randomly_frozen_layers = 0\n",
    "freeze_last_seven = False\n",
    "# CEC_opt = Adagrad()\n",
    "# CEC_opt = Yogi()\n",
    "# CEC_opt = AdaBeliefOptimizer(epsilon=1e-7, rectify=False, weight_decay=1e-3)\n",
    "CEC_opt = SGD(momentum=0.9, nesterov=False)\n",
    "# CEC_opt = Adam()\n",
    "# Main\n",
    "try:\n",
    "    if SAVE_TYPE == \"TF\":\n",
    "        model = load_model(f\"PAI_model{Extra_EXT}\", compile=PRMC)\n",
    "    else:\n",
    "        model = load_model(f\"PAI_model{Extra_EXT}.h5\", compile=PRMC)\n",
    "except (ImportError, IOError) as e:\n",
    "    print(f\"\\033[91mfailed to load the model ERROR:\\n{e}\")\n",
    "else:\n",
    "    print(\"\\033[92mLoading model done.\")\n",
    "    if not PRMC:\n",
    "        print(\"Compiling the AI model...\\033[0m\")\n",
    "\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "        # Select random layers to freeze\n",
    "        frozen_layer_indices = random.sample(range(len(model.layers)), randomly_frozen_layers)\n",
    "\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if i in frozen_layer_indices:\n",
    "                layer.trainable = False\n",
    "            else:\n",
    "                if freeze_from_opposite and (i > len(model.layers) - freeze_layers):\n",
    "                    layer.trainable = False\n",
    "                elif (not freeze_from_opposite) and i < freeze_layers:\n",
    "                    layer.trainable = False\n",
    "                else:\n",
    "                    layer.trainable = True\n",
    "\n",
    "        for layer in model.layers[-7:]:\n",
    "            layer.trainable = not freeze_last_seven\n",
    "\n",
    "        model.compile(optimizer=CEC_opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.summary(show_trainable=True, expand_nested=True)\n",
    "        print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"PAI_model_weights.h5\")\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage:\n",
    "##### Start with Rev2 if it didnt work train it a little bit with Rev1 and then train it with Rev2\n",
    "##### flowchart:\n",
    "![FC](TRAIN_FC.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rev2 (THE BEST)\n",
    "```\n",
    "Working: âœ…\n",
    "Other:\n",
    " - Tensorboard doesn't work.\n",
    " + Perverts overfitting.\n",
    " - Slow training.\n",
    " + Achieving higher acc.\n",
    " - Some models dont work.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m1\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 55s 166ms/step - loss: 20.4375 - accuracy: 0.6216 - val_loss: 15.7907 - val_accuracy: 0.8157\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 10.5470 - accuracy: 0.7383 - val_loss: 6.2110 - val_accuracy: 0.8205\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 4.1127 - accuracy: 0.7842 - val_loss: 2.5556 - val_accuracy: 0.8702\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 1.8795 - accuracy: 0.8096 - val_loss: 1.2612 - val_accuracy: 0.8718\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 1.0468 - accuracy: 0.8398 - val_loss: 0.8444 - val_accuracy: 0.8686\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.7275 - accuracy: 0.8555 - val_loss: 0.6163 - val_accuracy: 0.8766\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.5332 - accuracy: 0.8926 - val_loss: 0.5743 - val_accuracy: 0.8878\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.4697 - accuracy: 0.8979 - val_loss: 0.5413 - val_accuracy: 0.8702\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Improved model accuracy from 0 to 0.870192289352417. Saving model.\n",
      "Improved model loss from inf to 0.5412302017211914. Saving model.\n",
      "Time taken for epoch(FULL) 1: 386.46 sec\n",
      "Time taken for epoch(SUBo) 1: 333.70 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [1] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m2\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 44s 159ms/step - loss: 0.5620 - accuracy: 0.8359 - val_loss: 0.5067 - val_accuracy: 0.8446\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.5338 - accuracy: 0.8403 - val_loss: 0.6622 - val_accuracy: 0.8926\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.5047 - accuracy: 0.8418 - val_loss: 0.3689 - val_accuracy: 0.8926\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.4192 - accuracy: 0.8638 - val_loss: 0.4566 - val_accuracy: 0.8686\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.4020 - accuracy: 0.8677 - val_loss: 0.3214 - val_accuracy: 0.8670\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.3681 - accuracy: 0.8813 - val_loss: 0.3148 - val_accuracy: 0.9199\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.3198 - accuracy: 0.8931 - val_loss: 0.2567 - val_accuracy: 0.9279\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2715 - accuracy: 0.9180 - val_loss: 0.2393 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Improved model accuracy from 0.870192289352417 to 0.9310897588729858. Saving model.\n",
      "Improved model loss from 0.5412302017211914 to 0.23925769329071045. Saving model.\n",
      "Time taken for epoch(FULL) 2: 381.03 sec\n",
      "Time taken for epoch(SUBo) 2: 325.77 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [2] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m3\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.3640 - accuracy: 0.8696 - val_loss: 0.3126 - val_accuracy: 0.9247\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3588 - accuracy: 0.8735 - val_loss: 0.3768 - val_accuracy: 0.9295\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.3830 - accuracy: 0.8730 - val_loss: 0.4670 - val_accuracy: 0.9391\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3658 - accuracy: 0.8887 - val_loss: 0.2308 - val_accuracy: 0.9359\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.3717 - accuracy: 0.8779 - val_loss: 0.2747 - val_accuracy: 0.9199\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3136 - accuracy: 0.9028 - val_loss: 0.3153 - val_accuracy: 0.9022\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2696 - accuracy: 0.9136 - val_loss: 0.2452 - val_accuracy: 0.9247\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2407 - accuracy: 0.9243 - val_loss: 0.2541 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9310897588729858. Not saving model.\n",
      "Model loss did not improve from 0.23925769329071045. Not saving model.\n",
      "Time taken for epoch(FULL) 3: 376.52 sec\n",
      "Time taken for epoch(SUBo) 3: 324.58 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [3] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m4\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.3534 - accuracy: 0.8784 - val_loss: 0.2325 - val_accuracy: 0.9215\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.3861 - accuracy: 0.8584 - val_loss: 0.4468 - val_accuracy: 0.9103\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3696 - accuracy: 0.8765 - val_loss: 0.4794 - val_accuracy: 0.9038\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3680 - accuracy: 0.8828 - val_loss: 0.2781 - val_accuracy: 0.9231\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2897 - accuracy: 0.9165 - val_loss: 0.2823 - val_accuracy: 0.9327\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2801 - accuracy: 0.9165 - val_loss: 0.2447 - val_accuracy: 0.9071\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2460 - accuracy: 0.9326 - val_loss: 0.2840 - val_accuracy: 0.9359\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1982 - accuracy: 0.9414 - val_loss: 0.2283 - val_accuracy: 0.9343\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Improved model accuracy from 0.9310897588729858 to 0.9342948794364929. Saving model.\n",
      "Improved model loss from 0.23925769329071045 to 0.22827185690402985. Saving model.\n",
      "Time taken for epoch(FULL) 4: 379.86 sec\n",
      "Time taken for epoch(SUBo) 4: 325.33 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [4] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m5\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.3226 - accuracy: 0.8950 - val_loss: 0.3022 - val_accuracy: 0.9311\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3538 - accuracy: 0.8862 - val_loss: 0.3310 - val_accuracy: 0.9279\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3201 - accuracy: 0.8892 - val_loss: 0.2884 - val_accuracy: 0.9071\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.3229 - accuracy: 0.9009 - val_loss: 0.5201 - val_accuracy: 0.7340\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.3079 - accuracy: 0.8926 - val_loss: 0.2863 - val_accuracy: 0.9215\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2670 - accuracy: 0.9141 - val_loss: 0.2587 - val_accuracy: 0.9151\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2639 - accuracy: 0.9209 - val_loss: 0.2800 - val_accuracy: 0.9054\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1925 - accuracy: 0.9541 - val_loss: 0.2547 - val_accuracy: 0.9087\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9342948794364929. Not saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 5: 375.38 sec\n",
      "Time taken for epoch(SUBo) 5: 323.81 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [5] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m6\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 44s 159ms/step - loss: 0.2908 - accuracy: 0.8994 - val_loss: 0.3886 - val_accuracy: 0.9151\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2973 - accuracy: 0.8984 - val_loss: 0.4025 - val_accuracy: 0.7917\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3093 - accuracy: 0.8945 - val_loss: 0.9113 - val_accuracy: 0.6907\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.2903 - accuracy: 0.9048 - val_loss: 0.3253 - val_accuracy: 0.8766\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.2965 - accuracy: 0.9131 - val_loss: 0.3971 - val_accuracy: 0.8798\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.2341 - accuracy: 0.9238 - val_loss: 0.3240 - val_accuracy: 0.9071\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.2202 - accuracy: 0.9316 - val_loss: 0.3072 - val_accuracy: 0.9151\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1613 - accuracy: 0.9614 - val_loss: 0.3554 - val_accuracy: 0.9167\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9342948794364929. Not saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 6: 377.12 sec\n",
      "Time taken for epoch(SUBo) 6: 325.55 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [6] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m7\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.2840 - accuracy: 0.9102 - val_loss: 0.3625 - val_accuracy: 0.8878\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3095 - accuracy: 0.9033 - val_loss: 0.3963 - val_accuracy: 0.8926\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3532 - accuracy: 0.8887 - val_loss: 0.2555 - val_accuracy: 0.9263\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.3018 - accuracy: 0.8979 - val_loss: 0.2644 - val_accuracy: 0.9375\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.3154 - accuracy: 0.9048 - val_loss: 0.4598 - val_accuracy: 0.9215\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2509 - accuracy: 0.9312 - val_loss: 0.2478 - val_accuracy: 0.9295\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1902 - accuracy: 0.9478 - val_loss: 0.2697 - val_accuracy: 0.9311\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1628 - accuracy: 0.9531 - val_loss: 0.2426 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9342948794364929. Not saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 7: 376.09 sec\n",
      "Time taken for epoch(SUBo) 7: 324.32 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [7] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m8\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.2691 - accuracy: 0.9106 - val_loss: 0.4805 - val_accuracy: 0.9071\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3014 - accuracy: 0.8994 - val_loss: 0.2715 - val_accuracy: 0.8926\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3387 - accuracy: 0.8818 - val_loss: 0.3345 - val_accuracy: 0.8542\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3069 - accuracy: 0.9072 - val_loss: 0.3671 - val_accuracy: 0.9359\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2874 - accuracy: 0.9058 - val_loss: 0.2579 - val_accuracy: 0.9343\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2255 - accuracy: 0.9399 - val_loss: 0.3501 - val_accuracy: 0.9375\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1835 - accuracy: 0.9492 - val_loss: 0.2757 - val_accuracy: 0.9407\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1739 - accuracy: 0.9492 - val_loss: 0.2712 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Improved model accuracy from 0.9342948794364929 to 0.9391025900840759. Saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 8: 377.68 sec\n",
      "Time taken for epoch(SUBo) 8: 324.30 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [8] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m9\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 44s 159ms/step - loss: 0.2921 - accuracy: 0.9077 - val_loss: 0.3537 - val_accuracy: 0.9311\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2866 - accuracy: 0.9082 - val_loss: 0.3213 - val_accuracy: 0.9359\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2978 - accuracy: 0.8999 - val_loss: 0.3623 - val_accuracy: 0.9199\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2635 - accuracy: 0.9209 - val_loss: 0.4593 - val_accuracy: 0.8942\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2444 - accuracy: 0.9287 - val_loss: 0.3207 - val_accuracy: 0.9215\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2366 - accuracy: 0.9277 - val_loss: 0.3259 - val_accuracy: 0.9167\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1802 - accuracy: 0.9478 - val_loss: 0.3234 - val_accuracy: 0.9231\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1437 - accuracy: 0.9648 - val_loss: 0.2856 - val_accuracy: 0.9247\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9391025900840759. Not saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 9: 373.86 sec\n",
      "Time taken for epoch(SUBo) 9: 323.15 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [9] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m10\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 44s 159ms/step - loss: 0.2630 - accuracy: 0.9165 - val_loss: 0.2739 - val_accuracy: 0.9311\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.3113 - accuracy: 0.9082 - val_loss: 0.3775 - val_accuracy: 0.9054\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2991 - accuracy: 0.9102 - val_loss: 0.4075 - val_accuracy: 0.9247\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2560 - accuracy: 0.9365 - val_loss: 0.3893 - val_accuracy: 0.9103\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2622 - accuracy: 0.9360 - val_loss: 0.3810 - val_accuracy: 0.9311\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2561 - accuracy: 0.9360 - val_loss: 0.3800 - val_accuracy: 0.9215\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1804 - accuracy: 0.9561 - val_loss: 0.2602 - val_accuracy: 0.9295\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1792 - accuracy: 0.9565 - val_loss: 0.3396 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9391025900840759. Not saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 10: 375.11 sec\n",
      "Time taken for epoch(SUBo) 10: 323.65 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [10] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m11\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.2826 - accuracy: 0.9058 - val_loss: 0.2663 - val_accuracy: 0.9183\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3059 - accuracy: 0.9033 - val_loss: 0.3297 - val_accuracy: 0.9199\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.3283 - accuracy: 0.9102 - val_loss: 0.3599 - val_accuracy: 0.9375\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2491 - accuracy: 0.9375 - val_loss: 0.3099 - val_accuracy: 0.9327\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.2357 - accuracy: 0.9336 - val_loss: 0.4078 - val_accuracy: 0.9167\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2435 - accuracy: 0.9365 - val_loss: 0.2847 - val_accuracy: 0.9359\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1802 - accuracy: 0.9575 - val_loss: 0.3534 - val_accuracy: 0.9295\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1446 - accuracy: 0.9644 - val_loss: 0.3434 - val_accuracy: 0.9359\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9391025900840759. Not saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 11: 374.31 sec\n",
      "Time taken for epoch(SUBo) 11: 322.89 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [11] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m12\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.2543 - accuracy: 0.9263 - val_loss: 0.4121 - val_accuracy: 0.9327\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2741 - accuracy: 0.9258 - val_loss: 0.3493 - val_accuracy: 0.9359\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2763 - accuracy: 0.9307 - val_loss: 0.3661 - val_accuracy: 0.9359\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2352 - accuracy: 0.9414 - val_loss: 0.3281 - val_accuracy: 0.9215\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2251 - accuracy: 0.9453 - val_loss: 0.2411 - val_accuracy: 0.9311\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1783 - accuracy: 0.9595 - val_loss: 0.3297 - val_accuracy: 0.9247\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1812 - accuracy: 0.9619 - val_loss: 0.2638 - val_accuracy: 0.9087\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1356 - accuracy: 0.9702 - val_loss: 0.2747 - val_accuracy: 0.9135\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9391025900840759. Not saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 12: 375.91 sec\n",
      "Time taken for epoch(SUBo) 12: 324.60 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [12] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m13\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 44s 159ms/step - loss: 0.2384 - accuracy: 0.9326 - val_loss: 0.2895 - val_accuracy: 0.9231\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2609 - accuracy: 0.9287 - val_loss: 0.2950 - val_accuracy: 0.9119\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2872 - accuracy: 0.9277 - val_loss: 0.3571 - val_accuracy: 0.9087\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2855 - accuracy: 0.9229 - val_loss: 0.5538 - val_accuracy: 0.9087\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2314 - accuracy: 0.9478 - val_loss: 0.2693 - val_accuracy: 0.9311\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1893 - accuracy: 0.9546 - val_loss: 0.2341 - val_accuracy: 0.9343\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1685 - accuracy: 0.9600 - val_loss: 0.2727 - val_accuracy: 0.9439\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1422 - accuracy: 0.9736 - val_loss: 0.2968 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Improved model accuracy from 0.9391025900840759 to 0.9407051205635071. Saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 13: 376.01 sec\n",
      "Time taken for epoch(SUBo) 13: 323.00 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [13] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m14\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.2536 - accuracy: 0.9341 - val_loss: 0.3728 - val_accuracy: 0.9295\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2549 - accuracy: 0.9272 - val_loss: 0.2704 - val_accuracy: 0.9279\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2345 - accuracy: 0.9419 - val_loss: 0.3342 - val_accuracy: 0.9327\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2225 - accuracy: 0.9541 - val_loss: 0.3081 - val_accuracy: 0.9151\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2233 - accuracy: 0.9443 - val_loss: 0.2983 - val_accuracy: 0.9263\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1875 - accuracy: 0.9521 - val_loss: 0.2882 - val_accuracy: 0.9327\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1461 - accuracy: 0.9673 - val_loss: 0.2289 - val_accuracy: 0.9359\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1285 - accuracy: 0.9717 - val_loss: 0.2355 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9407051205635071. Not saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 14: 376.09 sec\n",
      "Time taken for epoch(SUBo) 14: 324.46 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [14] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m15\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Learning the patterns]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[8]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/8\n",
      "256/256 [==============================] - 44s 158ms/step - loss: 0.2348 - accuracy: 0.9341 - val_loss: 0.3880 - val_accuracy: 0.9263\n",
      "Epoch 2/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2625 - accuracy: 0.9224 - val_loss: 0.3617 - val_accuracy: 0.9327\n",
      "Epoch 3/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2578 - accuracy: 0.9292 - val_loss: 0.3288 - val_accuracy: 0.9263\n",
      "Epoch 4/8\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2543 - accuracy: 0.9302 - val_loss: 0.3120 - val_accuracy: 0.9038\n",
      "Epoch 5/8\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.3444 - accuracy: 0.9067 - val_loss: 0.2470 - val_accuracy: 0.9391\n",
      "Epoch 6/8\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.2173 - accuracy: 0.9424 - val_loss: 0.3219 - val_accuracy: 0.9343\n",
      "Epoch 7/8\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1908 - accuracy: 0.9526 - val_loss: 0.2278 - val_accuracy: 0.9407\n",
      "Epoch 8/8\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1584 - accuracy: 0.9600 - val_loss: 0.2384 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Improved model accuracy from 0.9407051205635071 to 0.9439102411270142. Saving model.\n",
      "Model loss did not improve from 0.22827185690402985. Not saving model.\n",
      "Time taken for epoch(FULL) 15: 374.28 sec\n",
      "Time taken for epoch(SUBo) 15: 321.58 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [15] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m16\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.010000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.2419 - accuracy: 0.9302 - val_loss: 0.2960 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.3020 - accuracy: 0.9111 - val_loss: 0.3527 - val_accuracy: 0.8622\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2673 - accuracy: 0.9238 - val_loss: 0.5715 - val_accuracy: 0.7340\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2500 - accuracy: 0.9277 - val_loss: 0.5034 - val_accuracy: 0.7484\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2083 - accuracy: 0.9478 - val_loss: 0.2478 - val_accuracy: 0.9071\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1548 - accuracy: 0.9624 - val_loss: 0.2110 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9439102411270142. Not saving model.\n",
      "Improved model loss from 0.22827185690402985 to 0.21101020276546478. Saving model.\n",
      "Time taken for epoch(FULL) 16: 297.03 sec\n",
      "Time taken for epoch(SUBo) 16: 244.35 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [16] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m17\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.009500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 159ms/step - loss: 0.2628 - accuracy: 0.9282 - val_loss: 0.2316 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2760 - accuracy: 0.9209 - val_loss: 0.3350 - val_accuracy: 0.9279\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2708 - accuracy: 0.9189 - val_loss: 0.3418 - val_accuracy: 0.9279\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.2240 - accuracy: 0.9419 - val_loss: 0.2829 - val_accuracy: 0.9279\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1962 - accuracy: 0.9526 - val_loss: 0.2832 - val_accuracy: 0.8926\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1605 - accuracy: 0.9609 - val_loss: 0.2716 - val_accuracy: 0.8974\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9439102411270142. Not saving model.\n",
      "Model loss did not improve from 0.21101020276546478. Not saving model.\n",
      "Time taken for epoch(FULL) 17: 294.63 sec\n",
      "Time taken for epoch(SUBo) 17: 243.78 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [17] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m18\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.009000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.2515 - accuracy: 0.9263 - val_loss: 0.2493 - val_accuracy: 0.9199\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3009 - accuracy: 0.9219 - val_loss: 0.3727 - val_accuracy: 0.8894\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2677 - accuracy: 0.9224 - val_loss: 0.3309 - val_accuracy: 0.9151\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.2292 - accuracy: 0.9395 - val_loss: 0.2943 - val_accuracy: 0.8910\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 153ms/step - loss: 0.1811 - accuracy: 0.9556 - val_loss: 0.2777 - val_accuracy: 0.9087\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1560 - accuracy: 0.9663 - val_loss: 0.2857 - val_accuracy: 0.9215\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9439102411270142. Not saving model.\n",
      "Model loss did not improve from 0.21101020276546478. Not saving model.\n",
      "Time taken for epoch(FULL) 18: 293.64 sec\n",
      "Time taken for epoch(SUBo) 18: 242.80 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [18] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m19\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.008500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.2747 - accuracy: 0.9248 - val_loss: 0.2540 - val_accuracy: 0.9038\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.3029 - accuracy: 0.9082 - val_loss: 0.2379 - val_accuracy: 0.9231\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2496 - accuracy: 0.9297 - val_loss: 0.2431 - val_accuracy: 0.9103\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2807 - accuracy: 0.9087 - val_loss: 0.2517 - val_accuracy: 0.8958\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1925 - accuracy: 0.9463 - val_loss: 0.2512 - val_accuracy: 0.9279\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1510 - accuracy: 0.9639 - val_loss: 0.2388 - val_accuracy: 0.9263\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9439102411270142. Not saving model.\n",
      "Model loss did not improve from 0.21101020276546478. Not saving model.\n",
      "Time taken for epoch(FULL) 19: 287.17 sec\n",
      "Time taken for epoch(SUBo) 19: 237.22 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [19] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m20\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.008000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.2361 - accuracy: 0.9326 - val_loss: 0.3213 - val_accuracy: 0.9231\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2437 - accuracy: 0.9282 - val_loss: 0.3130 - val_accuracy: 0.9295\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2265 - accuracy: 0.9390 - val_loss: 0.7231 - val_accuracy: 0.5817\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2058 - accuracy: 0.9463 - val_loss: 0.2048 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1747 - accuracy: 0.9585 - val_loss: 0.2309 - val_accuracy: 0.9135\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1581 - accuracy: 0.9624 - val_loss: 0.2022 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9439102411270142. Not saving model.\n",
      "Improved model loss from 0.21101020276546478 to 0.20221146941184998. Saving model.\n",
      "Time taken for epoch(FULL) 20: 287.49 sec\n",
      "Time taken for epoch(SUBo) 20: 236.52 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [20] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m21\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.007500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.2639 - accuracy: 0.9204 - val_loss: 0.3842 - val_accuracy: 0.8542\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.2602 - accuracy: 0.9224 - val_loss: 0.2024 - val_accuracy: 0.9311\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.2491 - accuracy: 0.9204 - val_loss: 0.3014 - val_accuracy: 0.9311\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2034 - accuracy: 0.9521 - val_loss: 0.2709 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2075 - accuracy: 0.9429 - val_loss: 0.3214 - val_accuracy: 0.9327\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1429 - accuracy: 0.9648 - val_loss: 0.2890 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9439102411270142. Not saving model.\n",
      "Model loss did not improve from 0.20221146941184998. Not saving model.\n",
      "Time taken for epoch(FULL) 21: 285.90 sec\n",
      "Time taken for epoch(SUBo) 21: 236.69 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [21] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m22\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.007000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.2293 - accuracy: 0.9360 - val_loss: 0.1936 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2278 - accuracy: 0.9341 - val_loss: 0.2616 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2114 - accuracy: 0.9438 - val_loss: 0.2647 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.2235 - accuracy: 0.9453 - val_loss: 0.2567 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1777 - accuracy: 0.9541 - val_loss: 0.2569 - val_accuracy: 0.9343\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1626 - accuracy: 0.9575 - val_loss: 0.2484 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9439102411270142. Not saving model.\n",
      "Model loss did not improve from 0.20221146941184998. Not saving model.\n",
      "Time taken for epoch(FULL) 22: 285.94 sec\n",
      "Time taken for epoch(SUBo) 22: 236.66 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [22] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m23\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.006500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.2132 - accuracy: 0.9385 - val_loss: 0.2144 - val_accuracy: 0.9359\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.2413 - accuracy: 0.9360 - val_loss: 0.5426 - val_accuracy: 0.8750\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 38s 149ms/step - loss: 0.2458 - accuracy: 0.9375 - val_loss: 0.2533 - val_accuracy: 0.9343\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1869 - accuracy: 0.9453 - val_loss: 0.2258 - val_accuracy: 0.9359\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1498 - accuracy: 0.9663 - val_loss: 0.2642 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 38s 149ms/step - loss: 0.1227 - accuracy: 0.9746 - val_loss: 0.2471 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9439102411270142. Not saving model.\n",
      "Model loss did not improve from 0.20221146941184998. Not saving model.\n",
      "Time taken for epoch(FULL) 23: 284.47 sec\n",
      "Time taken for epoch(SUBo) 23: 235.20 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [23] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m24\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.006000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.2147 - accuracy: 0.9365 - val_loss: 0.2431 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2151 - accuracy: 0.9385 - val_loss: 0.2308 - val_accuracy: 0.9327\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2120 - accuracy: 0.9380 - val_loss: 0.2704 - val_accuracy: 0.9311\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1936 - accuracy: 0.9453 - val_loss: 0.2529 - val_accuracy: 0.9359\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1498 - accuracy: 0.9644 - val_loss: 0.1866 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1086 - accuracy: 0.9756 - val_loss: 0.1858 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Improved model accuracy from 0.9439102411270142 to 0.9471153616905212. Saving model.\n",
      "Improved model loss from 0.20221146941184998 to 0.1857679933309555. Saving model.\n",
      "Time taken for epoch(FULL) 24: 288.85 sec\n",
      "Time taken for epoch(SUBo) 24: 236.73 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [24] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m25\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.005500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.2106 - accuracy: 0.9414 - val_loss: 0.2085 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2304 - accuracy: 0.9326 - val_loss: 0.2498 - val_accuracy: 0.9199\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2059 - accuracy: 0.9482 - val_loss: 0.3972 - val_accuracy: 0.9247\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1980 - accuracy: 0.9458 - val_loss: 0.2653 - val_accuracy: 0.9375\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1310 - accuracy: 0.9731 - val_loss: 0.2222 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1402 - accuracy: 0.9604 - val_loss: 0.2944 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9471153616905212. Not saving model.\n",
      "Model loss did not improve from 0.1857679933309555. Not saving model.\n",
      "Time taken for epoch(FULL) 25: 285.39 sec\n",
      "Time taken for epoch(SUBo) 25: 236.55 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [25] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m26\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.005000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.2292 - accuracy: 0.9341 - val_loss: 0.2645 - val_accuracy: 0.9327\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.2017 - accuracy: 0.9414 - val_loss: 0.2456 - val_accuracy: 0.9311\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.2125 - accuracy: 0.9341 - val_loss: 0.3309 - val_accuracy: 0.9215\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1715 - accuracy: 0.9536 - val_loss: 0.2653 - val_accuracy: 0.9183\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1361 - accuracy: 0.9658 - val_loss: 0.2156 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1183 - accuracy: 0.9741 - val_loss: 0.2134 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9471153616905212. Not saving model.\n",
      "Model loss did not improve from 0.1857679933309555. Not saving model.\n",
      "Time taken for epoch(FULL) 26: 285.12 sec\n",
      "Time taken for epoch(SUBo) 26: 236.07 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [26] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m27\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.004500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.1868 - accuracy: 0.9463 - val_loss: 0.1853 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2043 - accuracy: 0.9351 - val_loss: 0.3479 - val_accuracy: 0.9199\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1911 - accuracy: 0.9453 - val_loss: 0.2130 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1510 - accuracy: 0.9600 - val_loss: 0.2097 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1655 - accuracy: 0.9561 - val_loss: 0.1885 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1346 - accuracy: 0.9692 - val_loss: 0.1939 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9471153616905212. Not saving model.\n",
      "Model loss did not improve from 0.1857679933309555. Not saving model.\n",
      "Time taken for epoch(FULL) 27: 285.71 sec\n",
      "Time taken for epoch(SUBo) 27: 236.48 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [27] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m28\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.004000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.2180 - accuracy: 0.9360 - val_loss: 0.1893 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2060 - accuracy: 0.9385 - val_loss: 0.1826 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1867 - accuracy: 0.9448 - val_loss: 0.1701 - val_accuracy: 0.9583\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1611 - accuracy: 0.9614 - val_loss: 0.1821 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1444 - accuracy: 0.9609 - val_loss: 0.1652 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1409 - accuracy: 0.9644 - val_loss: 0.1546 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Improved model accuracy from 0.9471153616905212 to 0.9567307829856873. Saving model.\n",
      "Improved model loss from 0.1857679933309555 to 0.15460731089115143. Saving model.\n",
      "Time taken for epoch(FULL) 28: 288.65 sec\n",
      "Time taken for epoch(SUBo) 28: 236.43 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [28] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m29\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.003500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1936 - accuracy: 0.9404 - val_loss: 0.1560 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1892 - accuracy: 0.9390 - val_loss: 0.1654 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1752 - accuracy: 0.9541 - val_loss: 0.2738 - val_accuracy: 0.8926\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1570 - accuracy: 0.9561 - val_loss: 0.1721 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1441 - accuracy: 0.9639 - val_loss: 0.1639 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1111 - accuracy: 0.9692 - val_loss: 0.1661 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15460731089115143. Not saving model.\n",
      "Time taken for epoch(FULL) 29: 285.51 sec\n",
      "Time taken for epoch(SUBo) 29: 236.35 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [29] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m30\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.003000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.1650 - accuracy: 0.9531 - val_loss: 0.1881 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1823 - accuracy: 0.9468 - val_loss: 0.2431 - val_accuracy: 0.9231\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1812 - accuracy: 0.9473 - val_loss: 0.1803 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1608 - accuracy: 0.9546 - val_loss: 0.1606 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1399 - accuracy: 0.9609 - val_loss: 0.1624 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1155 - accuracy: 0.9702 - val_loss: 0.1665 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15460731089115143. Not saving model.\n",
      "Time taken for epoch(FULL) 30: 285.48 sec\n",
      "Time taken for epoch(SUBo) 30: 236.40 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [30] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m31\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.002500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1981 - accuracy: 0.9370 - val_loss: 0.1560 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1661 - accuracy: 0.9482 - val_loss: 0.1612 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1624 - accuracy: 0.9517 - val_loss: 0.1743 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1685 - accuracy: 0.9517 - val_loss: 0.1903 - val_accuracy: 0.9247\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1254 - accuracy: 0.9644 - val_loss: 0.1866 - val_accuracy: 0.9231\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1109 - accuracy: 0.9707 - val_loss: 0.1807 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15460731089115143. Not saving model.\n",
      "Time taken for epoch(FULL) 31: 285.66 sec\n",
      "Time taken for epoch(SUBo) 31: 236.69 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [31] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m32\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.002000]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.1669 - accuracy: 0.9502 - val_loss: 0.1911 - val_accuracy: 0.9327\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1540 - accuracy: 0.9531 - val_loss: 0.1633 - val_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1395 - accuracy: 0.9624 - val_loss: 0.1597 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1643 - accuracy: 0.9551 - val_loss: 0.1712 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1365 - accuracy: 0.9585 - val_loss: 0.1951 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1076 - accuracy: 0.9658 - val_loss: 0.1953 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15460731089115143. Not saving model.\n",
      "Time taken for epoch(FULL) 32: 285.69 sec\n",
      "Time taken for epoch(SUBo) 32: 236.38 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [32] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m33\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1745 - accuracy: 0.9463 - val_loss: 0.1852 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1641 - accuracy: 0.9512 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1578 - accuracy: 0.9512 - val_loss: 0.1950 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1493 - accuracy: 0.9507 - val_loss: 0.1669 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1312 - accuracy: 0.9619 - val_loss: 0.1736 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1185 - accuracy: 0.9658 - val_loss: 0.1680 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15460731089115143. Not saving model.\n",
      "Time taken for epoch(FULL) 33: 286.31 sec\n",
      "Time taken for epoch(SUBo) 33: 236.60 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [33] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m34\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.1615 - accuracy: 0.9521 - val_loss: 0.1627 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1649 - accuracy: 0.9521 - val_loss: 0.2083 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1395 - accuracy: 0.9575 - val_loss: 0.1949 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1419 - accuracy: 0.9517 - val_loss: 0.1563 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1317 - accuracy: 0.9565 - val_loss: 0.1606 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1158 - accuracy: 0.9688 - val_loss: 0.1512 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Improved model loss from 0.15460731089115143 to 0.15118563175201416. Saving model.\n",
      "Time taken for epoch(FULL) 34: 287.71 sec\n",
      "Time taken for epoch(SUBo) 34: 236.71 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [34] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m35\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1739 - accuracy: 0.9443 - val_loss: 0.1441 - val_accuracy: 0.9519\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2022 - accuracy: 0.9336 - val_loss: 0.1491 - val_accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1754 - accuracy: 0.9458 - val_loss: 0.1782 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1629 - accuracy: 0.9458 - val_loss: 0.1656 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1582 - accuracy: 0.9546 - val_loss: 0.1640 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1418 - accuracy: 0.9531 - val_loss: 0.1650 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 35: 287.73 sec\n",
      "Time taken for epoch(SUBo) 35: 237.55 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [35] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m36\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1573 - accuracy: 0.9526 - val_loss: 0.1498 - val_accuracy: 0.9519\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1602 - accuracy: 0.9468 - val_loss: 0.1686 - val_accuracy: 0.9359\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1520 - accuracy: 0.9521 - val_loss: 0.1585 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1418 - accuracy: 0.9561 - val_loss: 0.1683 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1210 - accuracy: 0.9604 - val_loss: 0.1843 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1206 - accuracy: 0.9644 - val_loss: 0.1951 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 36: 287.50 sec\n",
      "Time taken for epoch(SUBo) 36: 237.39 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [36] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m37\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1843 - accuracy: 0.9414 - val_loss: 0.1578 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1683 - accuracy: 0.9497 - val_loss: 0.1731 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1612 - accuracy: 0.9463 - val_loss: 0.2032 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1507 - accuracy: 0.9521 - val_loss: 0.1985 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1510 - accuracy: 0.9590 - val_loss: 0.1618 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1361 - accuracy: 0.9595 - val_loss: 0.1653 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 37: 287.80 sec\n",
      "Time taken for epoch(SUBo) 37: 237.45 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [37] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m38\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1649 - accuracy: 0.9487 - val_loss: 0.1677 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1775 - accuracy: 0.9438 - val_loss: 0.1582 - val_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1564 - accuracy: 0.9526 - val_loss: 0.1516 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1513 - accuracy: 0.9541 - val_loss: 0.1526 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1408 - accuracy: 0.9595 - val_loss: 0.1522 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1186 - accuracy: 0.9634 - val_loss: 0.1668 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 38: 287.81 sec\n",
      "Time taken for epoch(SUBo) 38: 237.65 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [38] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m39\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1748 - accuracy: 0.9414 - val_loss: 0.1468 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1517 - accuracy: 0.9521 - val_loss: 0.1940 - val_accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1527 - accuracy: 0.9536 - val_loss: 0.1679 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1440 - accuracy: 0.9521 - val_loss: 0.2192 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1304 - accuracy: 0.9570 - val_loss: 0.1655 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1088 - accuracy: 0.9697 - val_loss: 0.1865 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 39: 288.44 sec\n",
      "Time taken for epoch(SUBo) 39: 237.93 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [39] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m40\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1613 - accuracy: 0.9502 - val_loss: 0.1476 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1465 - accuracy: 0.9590 - val_loss: 0.1613 - val_accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1391 - accuracy: 0.9609 - val_loss: 0.1533 - val_accuracy: 0.9567\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1231 - accuracy: 0.9648 - val_loss: 0.1602 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1393 - accuracy: 0.9609 - val_loss: 0.1537 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1065 - accuracy: 0.9727 - val_loss: 0.1562 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 40: 287.78 sec\n",
      "Time taken for epoch(SUBo) 40: 237.78 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [40] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m41\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1631 - accuracy: 0.9478 - val_loss: 0.1572 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1542 - accuracy: 0.9517 - val_loss: 0.2025 - val_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1441 - accuracy: 0.9531 - val_loss: 0.1653 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1359 - accuracy: 0.9614 - val_loss: 0.1968 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1395 - accuracy: 0.9575 - val_loss: 0.1599 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1292 - accuracy: 0.9609 - val_loss: 0.1870 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 41: 287.23 sec\n",
      "Time taken for epoch(SUBo) 41: 237.14 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [41] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m42\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1298 - accuracy: 0.9531 - val_loss: 0.2101 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1359 - accuracy: 0.9565 - val_loss: 0.1721 - val_accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1334 - accuracy: 0.9614 - val_loss: 0.1705 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1103 - accuracy: 0.9678 - val_loss: 0.1819 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1071 - accuracy: 0.9678 - val_loss: 0.1882 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0998 - accuracy: 0.9712 - val_loss: 0.2143 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 42: 287.96 sec\n",
      "Time taken for epoch(SUBo) 42: 237.29 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [42] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m43\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1517 - accuracy: 0.9556 - val_loss: 0.1814 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1406 - accuracy: 0.9565 - val_loss: 0.2212 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1260 - accuracy: 0.9609 - val_loss: 0.2157 - val_accuracy: 0.9359\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1259 - accuracy: 0.9648 - val_loss: 0.2624 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1266 - accuracy: 0.9648 - val_loss: 0.2113 - val_accuracy: 0.9279\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1122 - accuracy: 0.9678 - val_loss: 0.2185 - val_accuracy: 0.9359\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 43: 288.58 sec\n",
      "Time taken for epoch(SUBo) 43: 237.71 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [43] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m44\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1549 - accuracy: 0.9507 - val_loss: 0.1907 - val_accuracy: 0.9391\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1406 - accuracy: 0.9561 - val_loss: 0.1945 - val_accuracy: 0.9279\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1416 - accuracy: 0.9556 - val_loss: 0.2094 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1300 - accuracy: 0.9619 - val_loss: 0.2000 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1146 - accuracy: 0.9678 - val_loss: 0.2591 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1207 - accuracy: 0.9648 - val_loss: 0.2343 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 44: 288.18 sec\n",
      "Time taken for epoch(SUBo) 44: 237.53 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [44] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m45\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1691 - accuracy: 0.9507 - val_loss: 0.1829 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1517 - accuracy: 0.9570 - val_loss: 0.1635 - val_accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1363 - accuracy: 0.9609 - val_loss: 0.2010 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1235 - accuracy: 0.9624 - val_loss: 0.1995 - val_accuracy: 0.9551\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1312 - accuracy: 0.9600 - val_loss: 0.2820 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1434 - accuracy: 0.9512 - val_loss: 0.2766 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 45: 288.43 sec\n",
      "Time taken for epoch(SUBo) 45: 237.92 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [45] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m46\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1684 - accuracy: 0.9468 - val_loss: 0.3024 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1606 - accuracy: 0.9478 - val_loss: 0.3133 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1545 - accuracy: 0.9585 - val_loss: 0.2165 - val_accuracy: 0.9311\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1639 - accuracy: 0.9468 - val_loss: 0.2465 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1447 - accuracy: 0.9575 - val_loss: 0.2787 - val_accuracy: 0.9359\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1406 - accuracy: 0.9551 - val_loss: 0.2559 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 46: 288.00 sec\n",
      "Time taken for epoch(SUBo) 46: 237.42 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [46] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m47\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1874 - accuracy: 0.9414 - val_loss: 0.2024 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1816 - accuracy: 0.9487 - val_loss: 0.2076 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1674 - accuracy: 0.9434 - val_loss: 0.3245 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1442 - accuracy: 0.9604 - val_loss: 0.2564 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1221 - accuracy: 0.9609 - val_loss: 0.3057 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1317 - accuracy: 0.9556 - val_loss: 0.2604 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 47: 287.69 sec\n",
      "Time taken for epoch(SUBo) 47: 236.59 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [47] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m48\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1541 - accuracy: 0.9453 - val_loss: 0.2779 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1480 - accuracy: 0.9526 - val_loss: 0.2490 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1341 - accuracy: 0.9614 - val_loss: 0.2237 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1366 - accuracy: 0.9570 - val_loss: 0.2314 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1416 - accuracy: 0.9517 - val_loss: 0.2416 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1106 - accuracy: 0.9644 - val_loss: 0.2330 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 48: 286.84 sec\n",
      "Time taken for epoch(SUBo) 48: 236.62 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [48] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m49\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1551 - accuracy: 0.9561 - val_loss: 0.2252 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1493 - accuracy: 0.9570 - val_loss: 0.2131 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1401 - accuracy: 0.9580 - val_loss: 0.1908 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1271 - accuracy: 0.9639 - val_loss: 0.2179 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1260 - accuracy: 0.9634 - val_loss: 0.2022 - val_accuracy: 0.9567\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1087 - accuracy: 0.9717 - val_loss: 0.1932 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 49: 286.33 sec\n",
      "Time taken for epoch(SUBo) 49: 236.60 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [49] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m50\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.1449 - accuracy: 0.9521 - val_loss: 0.1748 - val_accuracy: 0.9567\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1448 - accuracy: 0.9507 - val_loss: 0.2003 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1395 - accuracy: 0.9521 - val_loss: 0.2190 - val_accuracy: 0.9535\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1726 - accuracy: 0.9390 - val_loss: 0.2207 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1430 - accuracy: 0.9521 - val_loss: 0.2131 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1572 - accuracy: 0.9478 - val_loss: 0.2142 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 50: 286.59 sec\n",
      "Time taken for epoch(SUBo) 50: 236.86 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [50] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m51\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1601 - accuracy: 0.9497 - val_loss: 0.1783 - val_accuracy: 0.9519\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1519 - accuracy: 0.9517 - val_loss: 0.2485 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1687 - accuracy: 0.9521 - val_loss: 0.2295 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1445 - accuracy: 0.9600 - val_loss: 0.2580 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1283 - accuracy: 0.9619 - val_loss: 0.2596 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1248 - accuracy: 0.9624 - val_loss: 0.2709 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 51: 286.23 sec\n",
      "Time taken for epoch(SUBo) 51: 236.38 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [51] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m52\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.1478 - accuracy: 0.9512 - val_loss: 0.2317 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1364 - accuracy: 0.9614 - val_loss: 0.2805 - val_accuracy: 0.9359\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1341 - accuracy: 0.9634 - val_loss: 0.2886 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1320 - accuracy: 0.9634 - val_loss: 0.2800 - val_accuracy: 0.9391\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1081 - accuracy: 0.9712 - val_loss: 0.2406 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1113 - accuracy: 0.9702 - val_loss: 0.2587 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 52: 286.99 sec\n",
      "Time taken for epoch(SUBo) 52: 236.83 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [52] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m53\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1500 - accuracy: 0.9541 - val_loss: 0.2206 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1726 - accuracy: 0.9468 - val_loss: 0.2399 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1522 - accuracy: 0.9546 - val_loss: 0.2213 - val_accuracy: 0.9359\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1520 - accuracy: 0.9546 - val_loss: 0.1943 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1258 - accuracy: 0.9580 - val_loss: 0.1851 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1252 - accuracy: 0.9541 - val_loss: 0.1898 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 53: 287.29 sec\n",
      "Time taken for epoch(SUBo) 53: 237.19 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [53] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m54\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1649 - accuracy: 0.9429 - val_loss: 0.2123 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1791 - accuracy: 0.9424 - val_loss: 0.2041 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1739 - accuracy: 0.9429 - val_loss: 0.2438 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1467 - accuracy: 0.9521 - val_loss: 0.2370 - val_accuracy: 0.9375\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1384 - accuracy: 0.9541 - val_loss: 0.3072 - val_accuracy: 0.9359\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1439 - accuracy: 0.9580 - val_loss: 0.2901 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 54: 287.00 sec\n",
      "Time taken for epoch(SUBo) 54: 236.97 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [54] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m55\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.1734 - accuracy: 0.9438 - val_loss: 0.2456 - val_accuracy: 0.9391\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1551 - accuracy: 0.9512 - val_loss: 0.2227 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1490 - accuracy: 0.9468 - val_loss: 0.2150 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1365 - accuracy: 0.9600 - val_loss: 0.1964 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1341 - accuracy: 0.9595 - val_loss: 0.2038 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1313 - accuracy: 0.9609 - val_loss: 0.2228 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 55: 286.51 sec\n",
      "Time taken for epoch(SUBo) 55: 236.75 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [55] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m56\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1372 - accuracy: 0.9575 - val_loss: 0.2215 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1534 - accuracy: 0.9541 - val_loss: 0.2516 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1325 - accuracy: 0.9629 - val_loss: 0.2329 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1098 - accuracy: 0.9673 - val_loss: 0.2124 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1028 - accuracy: 0.9727 - val_loss: 0.2299 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0982 - accuracy: 0.9736 - val_loss: 0.2280 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 56: 286.73 sec\n",
      "Time taken for epoch(SUBo) 56: 237.12 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [56] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m57\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 154ms/step - loss: 0.1279 - accuracy: 0.9604 - val_loss: 0.1954 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1365 - accuracy: 0.9590 - val_loss: 0.2062 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1403 - accuracy: 0.9580 - val_loss: 0.1679 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1308 - accuracy: 0.9570 - val_loss: 0.1776 - val_accuracy: 0.9487\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1117 - accuracy: 0.9648 - val_loss: 0.1890 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1019 - accuracy: 0.9717 - val_loss: 0.1922 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 57: 286.14 sec\n",
      "Time taken for epoch(SUBo) 57: 235.92 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [57] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m58\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1579 - accuracy: 0.9468 - val_loss: 0.1934 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1771 - accuracy: 0.9409 - val_loss: 0.1981 - val_accuracy: 0.9327\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1471 - accuracy: 0.9561 - val_loss: 0.2460 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1365 - accuracy: 0.9595 - val_loss: 0.1832 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1430 - accuracy: 0.9536 - val_loss: 0.1711 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1317 - accuracy: 0.9609 - val_loss: 0.1742 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 58: 287.08 sec\n",
      "Time taken for epoch(SUBo) 58: 236.57 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [58] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m59\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1481 - accuracy: 0.9551 - val_loss: 0.1874 - val_accuracy: 0.9519\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1438 - accuracy: 0.9546 - val_loss: 0.1799 - val_accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1512 - accuracy: 0.9575 - val_loss: 0.1774 - val_accuracy: 0.9535\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1369 - accuracy: 0.9595 - val_loss: 0.1793 - val_accuracy: 0.9487\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1269 - accuracy: 0.9663 - val_loss: 0.1713 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1103 - accuracy: 0.9688 - val_loss: 0.1879 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 59: 286.52 sec\n",
      "Time taken for epoch(SUBo) 59: 237.12 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [59] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m60\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1493 - accuracy: 0.9531 - val_loss: 0.1852 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1386 - accuracy: 0.9575 - val_loss: 0.1995 - val_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1102 - accuracy: 0.9663 - val_loss: 0.2111 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1169 - accuracy: 0.9663 - val_loss: 0.2195 - val_accuracy: 0.9391\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1004 - accuracy: 0.9717 - val_loss: 0.2351 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1016 - accuracy: 0.9668 - val_loss: 0.2677 - val_accuracy: 0.9343\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 60: 287.80 sec\n",
      "Time taken for epoch(SUBo) 60: 237.20 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [60] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m61\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1434 - accuracy: 0.9551 - val_loss: 0.2024 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1346 - accuracy: 0.9604 - val_loss: 0.2110 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1218 - accuracy: 0.9644 - val_loss: 0.1917 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1252 - accuracy: 0.9629 - val_loss: 0.2180 - val_accuracy: 0.9407\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1204 - accuracy: 0.9639 - val_loss: 0.1932 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1012 - accuracy: 0.9683 - val_loss: 0.1964 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 61: 288.27 sec\n",
      "Time taken for epoch(SUBo) 61: 237.72 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [61] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m62\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1389 - accuracy: 0.9575 - val_loss: 0.2335 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1295 - accuracy: 0.9561 - val_loss: 0.2828 - val_accuracy: 0.9327\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1223 - accuracy: 0.9619 - val_loss: 0.2642 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1103 - accuracy: 0.9673 - val_loss: 0.2734 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1068 - accuracy: 0.9683 - val_loss: 0.2583 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1019 - accuracy: 0.9707 - val_loss: 0.2563 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 62: 288.25 sec\n",
      "Time taken for epoch(SUBo) 62: 237.52 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [62] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m63\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1588 - accuracy: 0.9517 - val_loss: 0.2404 - val_accuracy: 0.9391\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1392 - accuracy: 0.9624 - val_loss: 0.1892 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1352 - accuracy: 0.9634 - val_loss: 0.1851 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1258 - accuracy: 0.9634 - val_loss: 0.1914 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1298 - accuracy: 0.9619 - val_loss: 0.2004 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1128 - accuracy: 0.9673 - val_loss: 0.1989 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 63: 288.35 sec\n",
      "Time taken for epoch(SUBo) 63: 237.48 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [63] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m64\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1376 - accuracy: 0.9556 - val_loss: 0.1802 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1370 - accuracy: 0.9575 - val_loss: 0.2342 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1335 - accuracy: 0.9604 - val_loss: 0.1916 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1462 - accuracy: 0.9580 - val_loss: 0.1591 - val_accuracy: 0.9407\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1061 - accuracy: 0.9663 - val_loss: 0.2386 - val_accuracy: 0.9311\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1104 - accuracy: 0.9688 - val_loss: 0.2423 - val_accuracy: 0.9263\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 64: 288.62 sec\n",
      "Time taken for epoch(SUBo) 64: 237.68 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [64] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m65\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1365 - accuracy: 0.9556 - val_loss: 0.2579 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1324 - accuracy: 0.9595 - val_loss: 0.2196 - val_accuracy: 0.9375\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1193 - accuracy: 0.9619 - val_loss: 0.2640 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1136 - accuracy: 0.9663 - val_loss: 0.2262 - val_accuracy: 0.9391\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1052 - accuracy: 0.9692 - val_loss: 0.2272 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0993 - accuracy: 0.9697 - val_loss: 0.2402 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 65: 288.68 sec\n",
      "Time taken for epoch(SUBo) 65: 238.01 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [65] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m66\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1383 - accuracy: 0.9590 - val_loss: 0.2096 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1272 - accuracy: 0.9604 - val_loss: 0.2505 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1286 - accuracy: 0.9561 - val_loss: 0.2210 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1085 - accuracy: 0.9683 - val_loss: 0.1834 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1106 - accuracy: 0.9668 - val_loss: 0.1793 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1017 - accuracy: 0.9697 - val_loss: 0.2070 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 66: 288.12 sec\n",
      "Time taken for epoch(SUBo) 66: 237.92 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [66] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m67\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1517 - accuracy: 0.9565 - val_loss: 0.1927 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1471 - accuracy: 0.9502 - val_loss: 0.2064 - val_accuracy: 0.9359\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1327 - accuracy: 0.9556 - val_loss: 0.2286 - val_accuracy: 0.9295\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1262 - accuracy: 0.9619 - val_loss: 0.1877 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1157 - accuracy: 0.9639 - val_loss: 0.1992 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1126 - accuracy: 0.9658 - val_loss: 0.1889 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 67: 288.09 sec\n",
      "Time taken for epoch(SUBo) 67: 237.40 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [67] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m68\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1311 - accuracy: 0.9556 - val_loss: 0.1958 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1119 - accuracy: 0.9644 - val_loss: 0.2010 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1263 - accuracy: 0.9595 - val_loss: 0.1595 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1183 - accuracy: 0.9595 - val_loss: 0.1492 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1132 - accuracy: 0.9639 - val_loss: 0.1464 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1003 - accuracy: 0.9712 - val_loss: 0.1529 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 68: 288.54 sec\n",
      "Time taken for epoch(SUBo) 68: 237.57 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [68] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m69\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1554 - accuracy: 0.9546 - val_loss: 0.1697 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1375 - accuracy: 0.9570 - val_loss: 0.1428 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1287 - accuracy: 0.9629 - val_loss: 0.2158 - val_accuracy: 0.9407\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1152 - accuracy: 0.9634 - val_loss: 0.1788 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1029 - accuracy: 0.9697 - val_loss: 0.1732 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0991 - accuracy: 0.9722 - val_loss: 0.1837 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 69: 287.94 sec\n",
      "Time taken for epoch(SUBo) 69: 237.46 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [69] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m70\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1386 - accuracy: 0.9648 - val_loss: 0.1742 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1446 - accuracy: 0.9546 - val_loss: 0.2681 - val_accuracy: 0.9295\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1782 - accuracy: 0.9482 - val_loss: 0.3058 - val_accuracy: 0.9215\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1468 - accuracy: 0.9526 - val_loss: 0.2156 - val_accuracy: 0.9327\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1217 - accuracy: 0.9634 - val_loss: 0.1891 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1098 - accuracy: 0.9668 - val_loss: 0.1983 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9567307829856873. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 70: 288.24 sec\n",
      "Time taken for epoch(SUBo) 70: 237.80 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [70] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m71\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1711 - accuracy: 0.9468 - val_loss: 0.1688 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1528 - accuracy: 0.9546 - val_loss: 0.1514 - val_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1392 - accuracy: 0.9609 - val_loss: 0.1770 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1311 - accuracy: 0.9585 - val_loss: 0.1579 - val_accuracy: 0.9567\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1195 - accuracy: 0.9653 - val_loss: 0.1543 - val_accuracy: 0.9583\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1292 - accuracy: 0.9609 - val_loss: 0.1538 - val_accuracy: 0.9599\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Improved model accuracy from 0.9567307829856873 to 0.9599359035491943. Saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 71: 289.74 sec\n",
      "Time taken for epoch(SUBo) 71: 237.66 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [71] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m72\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1505 - accuracy: 0.9521 - val_loss: 0.1529 - val_accuracy: 0.9567\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1589 - accuracy: 0.9512 - val_loss: 0.1426 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1484 - accuracy: 0.9546 - val_loss: 0.1592 - val_accuracy: 0.9583\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1276 - accuracy: 0.9619 - val_loss: 0.2010 - val_accuracy: 0.9487\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1210 - accuracy: 0.9658 - val_loss: 0.1791 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1154 - accuracy: 0.9673 - val_loss: 0.1634 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 72: 288.91 sec\n",
      "Time taken for epoch(SUBo) 72: 237.07 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [72] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m73\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1304 - accuracy: 0.9609 - val_loss: 0.1894 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1423 - accuracy: 0.9561 - val_loss: 0.1949 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1392 - accuracy: 0.9526 - val_loss: 0.2177 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.1142 - accuracy: 0.9678 - val_loss: 0.2006 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1074 - accuracy: 0.9746 - val_loss: 0.2530 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0955 - accuracy: 0.9692 - val_loss: 0.2516 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 73: 286.60 sec\n",
      "Time taken for epoch(SUBo) 73: 236.85 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [73] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m74\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1103 - accuracy: 0.9653 - val_loss: 0.2006 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1242 - accuracy: 0.9600 - val_loss: 0.2702 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1351 - accuracy: 0.9580 - val_loss: 0.2475 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0999 - accuracy: 0.9731 - val_loss: 0.2133 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0995 - accuracy: 0.9717 - val_loss: 0.2043 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 150ms/step - loss: 0.0768 - accuracy: 0.9780 - val_loss: 0.2014 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 74: 287.09 sec\n",
      "Time taken for epoch(SUBo) 74: 237.29 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [74] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m75\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1430 - accuracy: 0.9546 - val_loss: 0.2063 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1306 - accuracy: 0.9619 - val_loss: 0.1984 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1205 - accuracy: 0.9663 - val_loss: 0.1844 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1186 - accuracy: 0.9653 - val_loss: 0.1739 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0999 - accuracy: 0.9727 - val_loss: 0.1955 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0930 - accuracy: 0.9731 - val_loss: 0.1780 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 75: 287.36 sec\n",
      "Time taken for epoch(SUBo) 75: 237.36 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [75] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m76\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1332 - accuracy: 0.9561 - val_loss: 0.1757 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1358 - accuracy: 0.9590 - val_loss: 0.1649 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1475 - accuracy: 0.9546 - val_loss: 0.1689 - val_accuracy: 0.9567\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1416 - accuracy: 0.9570 - val_loss: 0.1557 - val_accuracy: 0.9551\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1127 - accuracy: 0.9619 - val_loss: 0.1633 - val_accuracy: 0.9567\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0955 - accuracy: 0.9717 - val_loss: 0.1716 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 76: 286.87 sec\n",
      "Time taken for epoch(SUBo) 76: 237.21 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [76] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m77\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1613 - accuracy: 0.9429 - val_loss: 0.1702 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1557 - accuracy: 0.9463 - val_loss: 0.1623 - val_accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1399 - accuracy: 0.9546 - val_loss: 0.2084 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1245 - accuracy: 0.9619 - val_loss: 0.2221 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1156 - accuracy: 0.9624 - val_loss: 0.2435 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1155 - accuracy: 0.9683 - val_loss: 0.2508 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 77: 286.93 sec\n",
      "Time taken for epoch(SUBo) 77: 236.81 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [77] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m78\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1258 - accuracy: 0.9609 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1473 - accuracy: 0.9507 - val_loss: 0.1763 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1170 - accuracy: 0.9658 - val_loss: 0.2302 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1490 - accuracy: 0.9551 - val_loss: 0.1573 - val_accuracy: 0.9359\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1236 - accuracy: 0.9585 - val_loss: 0.1819 - val_accuracy: 0.9327\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1150 - accuracy: 0.9639 - val_loss: 0.1925 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 78: 287.03 sec\n",
      "Time taken for epoch(SUBo) 78: 237.13 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [78] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m79\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1394 - accuracy: 0.9570 - val_loss: 0.1949 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1345 - accuracy: 0.9604 - val_loss: 0.2434 - val_accuracy: 0.9327\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1293 - accuracy: 0.9575 - val_loss: 0.2313 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1145 - accuracy: 0.9648 - val_loss: 0.2336 - val_accuracy: 0.9279\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1077 - accuracy: 0.9707 - val_loss: 0.2261 - val_accuracy: 0.9311\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1020 - accuracy: 0.9688 - val_loss: 0.2249 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 79: 286.93 sec\n",
      "Time taken for epoch(SUBo) 79: 237.31 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [79] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m80\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1493 - accuracy: 0.9512 - val_loss: 0.2335 - val_accuracy: 0.9231\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1416 - accuracy: 0.9517 - val_loss: 0.2401 - val_accuracy: 0.9183\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2689 - accuracy: 0.9048 - val_loss: 0.4998 - val_accuracy: 0.7821\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.2924 - accuracy: 0.8955 - val_loss: 0.4549 - val_accuracy: 0.8782\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2427 - accuracy: 0.9136 - val_loss: 0.3899 - val_accuracy: 0.8830\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.2071 - accuracy: 0.9292 - val_loss: 0.3938 - val_accuracy: 0.8830\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 80: 287.37 sec\n",
      "Time taken for epoch(SUBo) 80: 237.50 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [80] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m81\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.2117 - accuracy: 0.9272 - val_loss: 0.3888 - val_accuracy: 0.8942\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.2039 - accuracy: 0.9326 - val_loss: 0.4718 - val_accuracy: 0.9038\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1797 - accuracy: 0.9424 - val_loss: 0.4449 - val_accuracy: 0.9087\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1627 - accuracy: 0.9512 - val_loss: 0.2830 - val_accuracy: 0.9151\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1495 - accuracy: 0.9565 - val_loss: 0.3565 - val_accuracy: 0.9167\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1510 - accuracy: 0.9541 - val_loss: 0.3372 - val_accuracy: 0.9199\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 81: 287.21 sec\n",
      "Time taken for epoch(SUBo) 81: 237.47 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [81] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m82\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1753 - accuracy: 0.9424 - val_loss: 0.3639 - val_accuracy: 0.9087\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 38s 150ms/step - loss: 0.1803 - accuracy: 0.9429 - val_loss: 0.3132 - val_accuracy: 0.9215\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1485 - accuracy: 0.9565 - val_loss: 0.2975 - val_accuracy: 0.9263\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1447 - accuracy: 0.9575 - val_loss: 0.3335 - val_accuracy: 0.9247\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1446 - accuracy: 0.9561 - val_loss: 0.2650 - val_accuracy: 0.9295\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1261 - accuracy: 0.9653 - val_loss: 0.2362 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 82: 286.96 sec\n",
      "Time taken for epoch(SUBo) 82: 236.90 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [82] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m83\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1623 - accuracy: 0.9492 - val_loss: 0.2152 - val_accuracy: 0.9327\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1599 - accuracy: 0.9502 - val_loss: 0.2598 - val_accuracy: 0.9231\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1508 - accuracy: 0.9609 - val_loss: 0.2304 - val_accuracy: 0.9295\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1310 - accuracy: 0.9517 - val_loss: 0.2164 - val_accuracy: 0.9295\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1274 - accuracy: 0.9624 - val_loss: 0.2169 - val_accuracy: 0.9327\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1250 - accuracy: 0.9595 - val_loss: 0.2147 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 83: 287.52 sec\n",
      "Time taken for epoch(SUBo) 83: 237.43 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [83] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m84\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1400 - accuracy: 0.9595 - val_loss: 0.2386 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1397 - accuracy: 0.9561 - val_loss: 0.1926 - val_accuracy: 0.9375\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1437 - accuracy: 0.9526 - val_loss: 0.2082 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1389 - accuracy: 0.9556 - val_loss: 0.2051 - val_accuracy: 0.9391\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1211 - accuracy: 0.9634 - val_loss: 0.1852 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1104 - accuracy: 0.9702 - val_loss: 0.1848 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 84: 286.91 sec\n",
      "Time taken for epoch(SUBo) 84: 237.24 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [84] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m85\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1612 - accuracy: 0.9478 - val_loss: 0.2066 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1647 - accuracy: 0.9448 - val_loss: 0.1899 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1606 - accuracy: 0.9448 - val_loss: 0.1948 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1336 - accuracy: 0.9561 - val_loss: 0.1954 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1293 - accuracy: 0.9575 - val_loss: 0.1911 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1122 - accuracy: 0.9678 - val_loss: 0.1925 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 85: 288.09 sec\n",
      "Time taken for epoch(SUBo) 85: 237.57 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [85] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m86\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1545 - accuracy: 0.9507 - val_loss: 0.1890 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1532 - accuracy: 0.9517 - val_loss: 0.2042 - val_accuracy: 0.9375\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1454 - accuracy: 0.9492 - val_loss: 0.1683 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1330 - accuracy: 0.9604 - val_loss: 0.1693 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1233 - accuracy: 0.9604 - val_loss: 0.1930 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1207 - accuracy: 0.9619 - val_loss: 0.1804 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 86: 288.17 sec\n",
      "Time taken for epoch(SUBo) 86: 237.64 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [86] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m87\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1573 - accuracy: 0.9536 - val_loss: 0.1667 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1656 - accuracy: 0.9478 - val_loss: 0.1621 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1384 - accuracy: 0.9595 - val_loss: 0.1620 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1258 - accuracy: 0.9585 - val_loss: 0.1718 - val_accuracy: 0.9407\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1227 - accuracy: 0.9595 - val_loss: 0.1562 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1226 - accuracy: 0.9653 - val_loss: 0.1679 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 87: 288.63 sec\n",
      "Time taken for epoch(SUBo) 87: 237.58 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [87] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m88\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1496 - accuracy: 0.9502 - val_loss: 0.1901 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1700 - accuracy: 0.9399 - val_loss: 0.1543 - val_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1560 - accuracy: 0.9546 - val_loss: 0.1877 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1373 - accuracy: 0.9561 - val_loss: 0.1802 - val_accuracy: 0.9407\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1187 - accuracy: 0.9609 - val_loss: 0.1640 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1221 - accuracy: 0.9629 - val_loss: 0.1898 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 88: 289.56 sec\n",
      "Time taken for epoch(SUBo) 88: 238.18 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [88] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m89\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1682 - accuracy: 0.9497 - val_loss: 0.1799 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1313 - accuracy: 0.9580 - val_loss: 0.2257 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1408 - accuracy: 0.9585 - val_loss: 0.2209 - val_accuracy: 0.9295\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1873 - accuracy: 0.9399 - val_loss: 0.1585 - val_accuracy: 0.9375\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1695 - accuracy: 0.9458 - val_loss: 0.1725 - val_accuracy: 0.9327\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1436 - accuracy: 0.9580 - val_loss: 0.1682 - val_accuracy: 0.9359\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 89: 288.75 sec\n",
      "Time taken for epoch(SUBo) 89: 238.29 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [89] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m90\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1505 - accuracy: 0.9502 - val_loss: 0.1977 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1613 - accuracy: 0.9478 - val_loss: 0.1510 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1232 - accuracy: 0.9614 - val_loss: 0.1844 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1183 - accuracy: 0.9658 - val_loss: 0.1810 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1060 - accuracy: 0.9717 - val_loss: 0.1728 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1102 - accuracy: 0.9658 - val_loss: 0.1794 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 90: 288.69 sec\n",
      "Time taken for epoch(SUBo) 90: 237.88 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [90] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m91\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1210 - accuracy: 0.9619 - val_loss: 0.1654 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1286 - accuracy: 0.9604 - val_loss: 0.2092 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1339 - accuracy: 0.9604 - val_loss: 0.1610 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1106 - accuracy: 0.9668 - val_loss: 0.1881 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1108 - accuracy: 0.9688 - val_loss: 0.2103 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.0968 - accuracy: 0.9741 - val_loss: 0.2091 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 91: 290.04 sec\n",
      "Time taken for epoch(SUBo) 91: 238.32 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [91] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m92\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1806 - accuracy: 0.9453 - val_loss: 0.1973 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1625 - accuracy: 0.9502 - val_loss: 0.1934 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1476 - accuracy: 0.9517 - val_loss: 0.1993 - val_accuracy: 0.9359\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1311 - accuracy: 0.9551 - val_loss: 0.1942 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1282 - accuracy: 0.9580 - val_loss: 0.1883 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1260 - accuracy: 0.9619 - val_loss: 0.1955 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 92: 288.96 sec\n",
      "Time taken for epoch(SUBo) 92: 237.66 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [92] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m93\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1499 - accuracy: 0.9473 - val_loss: 0.1841 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1426 - accuracy: 0.9507 - val_loss: 0.2240 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1467 - accuracy: 0.9600 - val_loss: 0.1832 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1411 - accuracy: 0.9531 - val_loss: 0.4701 - val_accuracy: 0.8910\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1303 - accuracy: 0.9600 - val_loss: 0.3182 - val_accuracy: 0.9103\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 153ms/step - loss: 0.1197 - accuracy: 0.9692 - val_loss: 0.2972 - val_accuracy: 0.9151\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 93: 290.33 sec\n",
      "Time taken for epoch(SUBo) 93: 239.01 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [93] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m94\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1449 - accuracy: 0.9536 - val_loss: 0.2477 - val_accuracy: 0.9295\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1695 - accuracy: 0.9458 - val_loss: 0.1876 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1408 - accuracy: 0.9526 - val_loss: 0.2062 - val_accuracy: 0.9359\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1405 - accuracy: 0.9531 - val_loss: 0.1995 - val_accuracy: 0.9375\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1120 - accuracy: 0.9692 - val_loss: 0.2110 - val_accuracy: 0.9327\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1060 - accuracy: 0.9712 - val_loss: 0.2041 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 94: 289.36 sec\n",
      "Time taken for epoch(SUBo) 94: 238.47 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [94] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m95\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1489 - accuracy: 0.9580 - val_loss: 0.1769 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1445 - accuracy: 0.9512 - val_loss: 0.1728 - val_accuracy: 0.9375\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1269 - accuracy: 0.9565 - val_loss: 0.2260 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1205 - accuracy: 0.9624 - val_loss: 0.1696 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1278 - accuracy: 0.9624 - val_loss: 0.1737 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1040 - accuracy: 0.9707 - val_loss: 0.1714 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 95: 289.33 sec\n",
      "Time taken for epoch(SUBo) 95: 238.40 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [95] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m96\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1672 - accuracy: 0.9492 - val_loss: 0.1677 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1451 - accuracy: 0.9565 - val_loss: 0.1917 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1325 - accuracy: 0.9614 - val_loss: 0.2296 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1260 - accuracy: 0.9575 - val_loss: 0.2639 - val_accuracy: 0.9375\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.0987 - accuracy: 0.9717 - val_loss: 0.3081 - val_accuracy: 0.9215\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1016 - accuracy: 0.9653 - val_loss: 0.2600 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 96: 288.89 sec\n",
      "Time taken for epoch(SUBo) 96: 237.88 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [96] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m97\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1431 - accuracy: 0.9463 - val_loss: 0.2139 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1526 - accuracy: 0.9492 - val_loss: 0.2200 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1348 - accuracy: 0.9575 - val_loss: 0.2507 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1261 - accuracy: 0.9575 - val_loss: 0.2652 - val_accuracy: 0.9391\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1126 - accuracy: 0.9683 - val_loss: 0.2767 - val_accuracy: 0.9311\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1255 - accuracy: 0.9604 - val_loss: 0.2645 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 97: 288.48 sec\n",
      "Time taken for epoch(SUBo) 97: 237.23 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [97] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m98\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1327 - accuracy: 0.9556 - val_loss: 0.2275 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1329 - accuracy: 0.9614 - val_loss: 0.2393 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1515 - accuracy: 0.9556 - val_loss: 0.3716 - val_accuracy: 0.9135\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1402 - accuracy: 0.9595 - val_loss: 0.3404 - val_accuracy: 0.9087\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1193 - accuracy: 0.9712 - val_loss: 0.2649 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1155 - accuracy: 0.9648 - val_loss: 0.2462 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 98: 287.65 sec\n",
      "Time taken for epoch(SUBo) 98: 237.26 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [98] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m99\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1441 - accuracy: 0.9556 - val_loss: 0.2086 - val_accuracy: 0.9343\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1320 - accuracy: 0.9580 - val_loss: 0.2175 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1388 - accuracy: 0.9556 - val_loss: 0.1846 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1222 - accuracy: 0.9658 - val_loss: 0.2280 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1001 - accuracy: 0.9692 - val_loss: 0.2335 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0935 - accuracy: 0.9741 - val_loss: 0.2289 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 99: 287.39 sec\n",
      "Time taken for epoch(SUBo) 99: 237.52 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [99] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m100\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1431 - accuracy: 0.9580 - val_loss: 0.2261 - val_accuracy: 0.9247\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1552 - accuracy: 0.9536 - val_loss: 0.1987 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1221 - accuracy: 0.9619 - val_loss: 0.2009 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1274 - accuracy: 0.9604 - val_loss: 0.2111 - val_accuracy: 0.9311\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1100 - accuracy: 0.9692 - val_loss: 0.2023 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0975 - accuracy: 0.9736 - val_loss: 0.1899 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 100: 287.11 sec\n",
      "Time taken for epoch(SUBo) 100: 237.35 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [100] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m101\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1400 - accuracy: 0.9541 - val_loss: 0.2182 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1364 - accuracy: 0.9629 - val_loss: 0.1850 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1349 - accuracy: 0.9600 - val_loss: 0.2381 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1142 - accuracy: 0.9678 - val_loss: 0.1880 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1042 - accuracy: 0.9692 - val_loss: 0.2007 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.0986 - accuracy: 0.9731 - val_loss: 0.2144 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 101: 287.74 sec\n",
      "Time taken for epoch(SUBo) 101: 237.93 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [101] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m102\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1327 - accuracy: 0.9570 - val_loss: 0.2415 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1164 - accuracy: 0.9653 - val_loss: 0.2319 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1270 - accuracy: 0.9658 - val_loss: 0.2692 - val_accuracy: 0.9359\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1342 - accuracy: 0.9629 - val_loss: 0.2067 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1174 - accuracy: 0.9688 - val_loss: 0.1845 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1135 - accuracy: 0.9688 - val_loss: 0.2075 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 102: 288.00 sec\n",
      "Time taken for epoch(SUBo) 102: 237.50 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [102] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m103\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1454 - accuracy: 0.9531 - val_loss: 0.2672 - val_accuracy: 0.9359\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1464 - accuracy: 0.9556 - val_loss: 0.1568 - val_accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1430 - accuracy: 0.9614 - val_loss: 0.2431 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1267 - accuracy: 0.9595 - val_loss: 0.1676 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1114 - accuracy: 0.9648 - val_loss: 0.1947 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1131 - accuracy: 0.9688 - val_loss: 0.1926 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 103: 287.73 sec\n",
      "Time taken for epoch(SUBo) 103: 237.64 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [103] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m104\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1319 - accuracy: 0.9551 - val_loss: 0.2187 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1435 - accuracy: 0.9565 - val_loss: 0.2262 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1363 - accuracy: 0.9556 - val_loss: 0.1924 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1133 - accuracy: 0.9678 - val_loss: 0.2607 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1085 - accuracy: 0.9717 - val_loss: 0.2344 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1026 - accuracy: 0.9673 - val_loss: 0.2418 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 104: 286.90 sec\n",
      "Time taken for epoch(SUBo) 104: 237.53 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [104] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m105\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1383 - accuracy: 0.9580 - val_loss: 0.2079 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1252 - accuracy: 0.9614 - val_loss: 0.1844 - val_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1239 - accuracy: 0.9600 - val_loss: 0.2032 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1005 - accuracy: 0.9722 - val_loss: 0.2134 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1002 - accuracy: 0.9688 - val_loss: 0.1937 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0898 - accuracy: 0.9741 - val_loss: 0.1968 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 105: 287.02 sec\n",
      "Time taken for epoch(SUBo) 105: 237.52 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [105] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m106\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1352 - accuracy: 0.9575 - val_loss: 0.1525 - val_accuracy: 0.9599\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1355 - accuracy: 0.9570 - val_loss: 0.1892 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1163 - accuracy: 0.9692 - val_loss: 0.1639 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1066 - accuracy: 0.9678 - val_loss: 0.1816 - val_accuracy: 0.9583\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.0869 - accuracy: 0.9736 - val_loss: 0.1968 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.0897 - accuracy: 0.9741 - val_loss: 0.2022 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9599359035491943. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 106: 287.48 sec\n",
      "Time taken for epoch(SUBo) 106: 237.69 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [106] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m107\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 155ms/step - loss: 0.1194 - accuracy: 0.9644 - val_loss: 0.1767 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1113 - accuracy: 0.9668 - val_loss: 0.1995 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1046 - accuracy: 0.9663 - val_loss: 0.1818 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0864 - accuracy: 0.9746 - val_loss: 0.1969 - val_accuracy: 0.9551\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0910 - accuracy: 0.9722 - val_loss: 0.1441 - val_accuracy: 0.9663\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1109 - accuracy: 0.9653 - val_loss: 0.1590 - val_accuracy: 0.9696\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Improved model accuracy from 0.9599359035491943 to 0.9695512652397156. Saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 107: 289.43 sec\n",
      "Time taken for epoch(SUBo) 107: 237.56 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [107] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m108\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1730 - accuracy: 0.9492 - val_loss: 0.1516 - val_accuracy: 0.9679\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1326 - accuracy: 0.9600 - val_loss: 0.1736 - val_accuracy: 0.9583\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1225 - accuracy: 0.9644 - val_loss: 0.1854 - val_accuracy: 0.9583\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1192 - accuracy: 0.9658 - val_loss: 0.2242 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1115 - accuracy: 0.9663 - val_loss: 0.1922 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.0976 - accuracy: 0.9722 - val_loss: 0.1996 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 108: 288.48 sec\n",
      "Time taken for epoch(SUBo) 108: 238.16 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [108] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m109\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1546 - accuracy: 0.9526 - val_loss: 0.1503 - val_accuracy: 0.9583\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1529 - accuracy: 0.9551 - val_loss: 0.1752 - val_accuracy: 0.9631\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1421 - accuracy: 0.9580 - val_loss: 0.1519 - val_accuracy: 0.9599\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1593 - accuracy: 0.9492 - val_loss: 0.1787 - val_accuracy: 0.9551\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1744 - accuracy: 0.9434 - val_loss: 0.1705 - val_accuracy: 0.9599\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1520 - accuracy: 0.9502 - val_loss: 0.1609 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 109: 287.98 sec\n",
      "Time taken for epoch(SUBo) 109: 238.06 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [109] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m110\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1470 - accuracy: 0.9482 - val_loss: 0.1651 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1690 - accuracy: 0.9443 - val_loss: 0.2425 - val_accuracy: 0.9327\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1394 - accuracy: 0.9561 - val_loss: 0.1863 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1128 - accuracy: 0.9619 - val_loss: 0.1728 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1037 - accuracy: 0.9653 - val_loss: 0.1770 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.0962 - accuracy: 0.9712 - val_loss: 0.1774 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 110: 288.95 sec\n",
      "Time taken for epoch(SUBo) 110: 238.41 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [110] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m111\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1625 - accuracy: 0.9487 - val_loss: 0.1659 - val_accuracy: 0.9519\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1540 - accuracy: 0.9556 - val_loss: 0.1548 - val_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1331 - accuracy: 0.9590 - val_loss: 0.1736 - val_accuracy: 0.9567\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1230 - accuracy: 0.9639 - val_loss: 0.2110 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1110 - accuracy: 0.9717 - val_loss: 0.1803 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1079 - accuracy: 0.9688 - val_loss: 0.1742 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 111: 288.76 sec\n",
      "Time taken for epoch(SUBo) 111: 238.28 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [111] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m112\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1423 - accuracy: 0.9561 - val_loss: 0.1898 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1493 - accuracy: 0.9473 - val_loss: 0.2439 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1295 - accuracy: 0.9614 - val_loss: 0.2080 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1483 - accuracy: 0.9604 - val_loss: 0.2009 - val_accuracy: 0.9375\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1230 - accuracy: 0.9614 - val_loss: 0.2107 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.0981 - accuracy: 0.9717 - val_loss: 0.2227 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 112: 288.69 sec\n",
      "Time taken for epoch(SUBo) 112: 237.84 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [112] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m113\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1289 - accuracy: 0.9604 - val_loss: 0.1870 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1315 - accuracy: 0.9619 - val_loss: 0.1862 - val_accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1271 - accuracy: 0.9604 - val_loss: 0.1778 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1002 - accuracy: 0.9707 - val_loss: 0.1887 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0981 - accuracy: 0.9717 - val_loss: 0.2135 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0856 - accuracy: 0.9741 - val_loss: 0.2159 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 113: 289.27 sec\n",
      "Time taken for epoch(SUBo) 113: 237.88 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [113] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m114\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 43s 155ms/step - loss: 0.1358 - accuracy: 0.9595 - val_loss: 0.1854 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1183 - accuracy: 0.9644 - val_loss: 0.2141 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1114 - accuracy: 0.9688 - val_loss: 0.2008 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1108 - accuracy: 0.9639 - val_loss: 0.1953 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1022 - accuracy: 0.9663 - val_loss: 0.1951 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.0806 - accuracy: 0.9775 - val_loss: 0.1923 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 114: 288.83 sec\n",
      "Time taken for epoch(SUBo) 114: 237.68 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [114] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m115\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1186 - accuracy: 0.9600 - val_loss: 0.2549 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1196 - accuracy: 0.9604 - val_loss: 0.2198 - val_accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1253 - accuracy: 0.9590 - val_loss: 0.2396 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1043 - accuracy: 0.9736 - val_loss: 0.2314 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.0960 - accuracy: 0.9712 - val_loss: 0.2056 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.0915 - accuracy: 0.9722 - val_loss: 0.2126 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 115: 289.11 sec\n",
      "Time taken for epoch(SUBo) 115: 238.53 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [115] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m116\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1352 - accuracy: 0.9609 - val_loss: 0.2195 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1368 - accuracy: 0.9595 - val_loss: 0.1903 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 151ms/step - loss: 0.1198 - accuracy: 0.9614 - val_loss: 0.2051 - val_accuracy: 0.9535\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1077 - accuracy: 0.9688 - val_loss: 0.1856 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1008 - accuracy: 0.9702 - val_loss: 0.1742 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1027 - accuracy: 0.9717 - val_loss: 0.1697 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 116: 289.60 sec\n",
      "Time taken for epoch(SUBo) 116: 239.21 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [116] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m117\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1267 - accuracy: 0.9614 - val_loss: 0.1718 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1188 - accuracy: 0.9580 - val_loss: 0.2046 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0925 - accuracy: 0.9722 - val_loss: 0.2292 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0834 - accuracy: 0.9751 - val_loss: 0.2023 - val_accuracy: 0.9487\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0882 - accuracy: 0.9727 - val_loss: 0.2151 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1000 - accuracy: 0.9722 - val_loss: 0.2206 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 117: 294.65 sec\n",
      "Time taken for epoch(SUBo) 117: 244.16 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [117] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m118\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1199 - accuracy: 0.9644 - val_loss: 0.2294 - val_accuracy: 0.9391\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1139 - accuracy: 0.9663 - val_loss: 0.1655 - val_accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1037 - accuracy: 0.9707 - val_loss: 0.1589 - val_accuracy: 0.9535\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0889 - accuracy: 0.9741 - val_loss: 0.2250 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0840 - accuracy: 0.9785 - val_loss: 0.1895 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0828 - accuracy: 0.9727 - val_loss: 0.1852 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.15118563175201416. Not saving model.\n",
      "Time taken for epoch(FULL) 118: 295.73 sec\n",
      "Time taken for epoch(SUBo) 118: 244.43 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [118] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m119\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1416 - accuracy: 0.9585 - val_loss: 0.1226 - val_accuracy: 0.9599\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1682 - accuracy: 0.9434 - val_loss: 0.1301 - val_accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1486 - accuracy: 0.9497 - val_loss: 0.1562 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1247 - accuracy: 0.9604 - val_loss: 0.1408 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1257 - accuracy: 0.9648 - val_loss: 0.1476 - val_accuracy: 0.9599\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1120 - accuracy: 0.9629 - val_loss: 0.1468 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Improved model loss from 0.15118563175201416 to 0.146798238158226. Saving model.\n",
      "Time taken for epoch(FULL) 119: 296.83 sec\n",
      "Time taken for epoch(SUBo) 119: 244.81 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [119] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m120\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 159ms/step - loss: 0.1305 - accuracy: 0.9570 - val_loss: 0.1442 - val_accuracy: 0.9567\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1428 - accuracy: 0.9551 - val_loss: 0.1382 - val_accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1094 - accuracy: 0.9653 - val_loss: 0.1388 - val_accuracy: 0.9599\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1095 - accuracy: 0.9692 - val_loss: 0.1446 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0795 - accuracy: 0.9790 - val_loss: 0.1430 - val_accuracy: 0.9583\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0866 - accuracy: 0.9736 - val_loss: 0.1469 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 120: 295.05 sec\n",
      "Time taken for epoch(SUBo) 120: 244.35 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [120] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m121\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1313 - accuracy: 0.9609 - val_loss: 0.1539 - val_accuracy: 0.9551\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1415 - accuracy: 0.9541 - val_loss: 0.1573 - val_accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1153 - accuracy: 0.9717 - val_loss: 0.1778 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1108 - accuracy: 0.9683 - val_loss: 0.1774 - val_accuracy: 0.9551\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1016 - accuracy: 0.9697 - val_loss: 0.1738 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0880 - accuracy: 0.9727 - val_loss: 0.1716 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 121: 294.56 sec\n",
      "Time taken for epoch(SUBo) 121: 244.29 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [121] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m122\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 159ms/step - loss: 0.1261 - accuracy: 0.9619 - val_loss: 0.1905 - val_accuracy: 0.9567\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1233 - accuracy: 0.9634 - val_loss: 0.1801 - val_accuracy: 0.9599\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1278 - accuracy: 0.9580 - val_loss: 0.2058 - val_accuracy: 0.9567\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1094 - accuracy: 0.9663 - val_loss: 0.2683 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1103 - accuracy: 0.9648 - val_loss: 0.1943 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1033 - accuracy: 0.9692 - val_loss: 0.2182 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 122: 295.23 sec\n",
      "Time taken for epoch(SUBo) 122: 244.50 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [122] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m123\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1423 - accuracy: 0.9570 - val_loss: 0.1759 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1263 - accuracy: 0.9624 - val_loss: 0.2300 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1347 - accuracy: 0.9600 - val_loss: 0.2434 - val_accuracy: 0.9359\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1360 - accuracy: 0.9565 - val_loss: 0.2215 - val_accuracy: 0.9359\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1029 - accuracy: 0.9678 - val_loss: 0.2258 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1030 - accuracy: 0.9658 - val_loss: 0.1975 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 123: 294.95 sec\n",
      "Time taken for epoch(SUBo) 123: 244.32 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [123] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m124\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1253 - accuracy: 0.9614 - val_loss: 0.2786 - val_accuracy: 0.9327\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1241 - accuracy: 0.9600 - val_loss: 0.2731 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1414 - accuracy: 0.9575 - val_loss: 0.2149 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1280 - accuracy: 0.9609 - val_loss: 0.2693 - val_accuracy: 0.9375\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1312 - accuracy: 0.9619 - val_loss: 0.2356 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1075 - accuracy: 0.9688 - val_loss: 0.2349 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 124: 294.95 sec\n",
      "Time taken for epoch(SUBo) 124: 244.30 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [124] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m125\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1388 - accuracy: 0.9570 - val_loss: 0.2241 - val_accuracy: 0.9391\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1322 - accuracy: 0.9595 - val_loss: 0.2067 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1604 - accuracy: 0.9448 - val_loss: 0.2070 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1206 - accuracy: 0.9629 - val_loss: 0.1951 - val_accuracy: 0.9487\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1370 - accuracy: 0.9556 - val_loss: 0.1795 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1162 - accuracy: 0.9614 - val_loss: 0.1803 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 125: 296.66 sec\n",
      "Time taken for epoch(SUBo) 125: 245.25 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [125] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m126\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1659 - accuracy: 0.9443 - val_loss: 0.1636 - val_accuracy: 0.9551\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1469 - accuracy: 0.9531 - val_loss: 0.1743 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1290 - accuracy: 0.9600 - val_loss: 0.2001 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1122 - accuracy: 0.9634 - val_loss: 0.2148 - val_accuracy: 0.9375\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1013 - accuracy: 0.9692 - val_loss: 0.1990 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0975 - accuracy: 0.9727 - val_loss: 0.1967 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 126: 296.05 sec\n",
      "Time taken for epoch(SUBo) 126: 244.69 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [126] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m127\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1350 - accuracy: 0.9590 - val_loss: 0.2002 - val_accuracy: 0.9391\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1241 - accuracy: 0.9604 - val_loss: 0.1730 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1136 - accuracy: 0.9658 - val_loss: 0.2452 - val_accuracy: 0.9279\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0970 - accuracy: 0.9756 - val_loss: 0.2381 - val_accuracy: 0.9311\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0872 - accuracy: 0.9707 - val_loss: 0.2602 - val_accuracy: 0.9263\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0813 - accuracy: 0.9761 - val_loss: 0.2530 - val_accuracy: 0.9295\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 127: 295.58 sec\n",
      "Time taken for epoch(SUBo) 127: 244.41 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [127] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m128\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1365 - accuracy: 0.9521 - val_loss: 0.1995 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1338 - accuracy: 0.9575 - val_loss: 0.1957 - val_accuracy: 0.9359\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1184 - accuracy: 0.9609 - val_loss: 0.1864 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1086 - accuracy: 0.9712 - val_loss: 0.2123 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1137 - accuracy: 0.9653 - val_loss: 0.1765 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1008 - accuracy: 0.9697 - val_loss: 0.1619 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 128: 303.71 sec\n",
      "Time taken for epoch(SUBo) 128: 244.02 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [128] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m129\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1492 - accuracy: 0.9492 - val_loss: 0.1890 - val_accuracy: 0.9519\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1478 - accuracy: 0.9565 - val_loss: 0.1770 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1285 - accuracy: 0.9609 - val_loss: 0.1963 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1331 - accuracy: 0.9590 - val_loss: 0.1629 - val_accuracy: 0.9599\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1027 - accuracy: 0.9722 - val_loss: 0.1720 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0962 - accuracy: 0.9722 - val_loss: 0.1728 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 129: 304.31 sec\n",
      "Time taken for epoch(SUBo) 129: 243.77 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [129] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m130\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1344 - accuracy: 0.9595 - val_loss: 0.1606 - val_accuracy: 0.9551\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1276 - accuracy: 0.9624 - val_loss: 0.1791 - val_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1111 - accuracy: 0.9663 - val_loss: 0.1730 - val_accuracy: 0.9615\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1088 - accuracy: 0.9683 - val_loss: 0.1984 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1004 - accuracy: 0.9668 - val_loss: 0.2138 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1041 - accuracy: 0.9683 - val_loss: 0.1963 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 130: 301.26 sec\n",
      "Time taken for epoch(SUBo) 130: 244.07 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [130] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m131\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1314 - accuracy: 0.9614 - val_loss: 0.1733 - val_accuracy: 0.9551\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1437 - accuracy: 0.9556 - val_loss: 0.1815 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1247 - accuracy: 0.9639 - val_loss: 0.1522 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1197 - accuracy: 0.9644 - val_loss: 0.1593 - val_accuracy: 0.9615\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1065 - accuracy: 0.9707 - val_loss: 0.1619 - val_accuracy: 0.9615\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0984 - accuracy: 0.9697 - val_loss: 0.1596 - val_accuracy: 0.9631\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 131: 300.73 sec\n",
      "Time taken for epoch(SUBo) 131: 244.44 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [131] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m132\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1359 - accuracy: 0.9590 - val_loss: 0.1611 - val_accuracy: 0.9567\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1136 - accuracy: 0.9644 - val_loss: 0.1692 - val_accuracy: 0.9615\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1270 - accuracy: 0.9629 - val_loss: 0.2881 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1380 - accuracy: 0.9609 - val_loss: 0.1959 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1193 - accuracy: 0.9658 - val_loss: 0.2176 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1125 - accuracy: 0.9648 - val_loss: 0.2147 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 132: 298.91 sec\n",
      "Time taken for epoch(SUBo) 132: 243.60 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [132] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m133\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1469 - accuracy: 0.9521 - val_loss: 0.2294 - val_accuracy: 0.9359\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1442 - accuracy: 0.9580 - val_loss: 0.2275 - val_accuracy: 0.9327\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1246 - accuracy: 0.9619 - val_loss: 0.2881 - val_accuracy: 0.9295\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1150 - accuracy: 0.9673 - val_loss: 0.2647 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1132 - accuracy: 0.9648 - val_loss: 0.2474 - val_accuracy: 0.9311\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0897 - accuracy: 0.9751 - val_loss: 0.2609 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 133: 296.74 sec\n",
      "Time taken for epoch(SUBo) 133: 242.77 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [133] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m134\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 159ms/step - loss: 0.1280 - accuracy: 0.9604 - val_loss: 0.2374 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1308 - accuracy: 0.9590 - val_loss: 0.2543 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1377 - accuracy: 0.9565 - val_loss: 0.2752 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1032 - accuracy: 0.9736 - val_loss: 0.2675 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1142 - accuracy: 0.9663 - val_loss: 0.2584 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0954 - accuracy: 0.9756 - val_loss: 0.2853 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 134: 297.41 sec\n",
      "Time taken for epoch(SUBo) 134: 243.12 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [134] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m135\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1629 - accuracy: 0.9482 - val_loss: 0.2191 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1362 - accuracy: 0.9575 - val_loss: 0.2275 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1400 - accuracy: 0.9570 - val_loss: 0.1914 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1302 - accuracy: 0.9639 - val_loss: 0.1995 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1173 - accuracy: 0.9653 - val_loss: 0.2003 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1085 - accuracy: 0.9697 - val_loss: 0.2064 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 135: 298.46 sec\n",
      "Time taken for epoch(SUBo) 135: 243.19 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [135] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m136\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1415 - accuracy: 0.9561 - val_loss: 0.1941 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1323 - accuracy: 0.9648 - val_loss: 0.2252 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1230 - accuracy: 0.9614 - val_loss: 0.1982 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1100 - accuracy: 0.9658 - val_loss: 0.2166 - val_accuracy: 0.9487\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1041 - accuracy: 0.9678 - val_loss: 0.2508 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0991 - accuracy: 0.9707 - val_loss: 0.2181 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 136: 300.20 sec\n",
      "Time taken for epoch(SUBo) 136: 243.49 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [136] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m137\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1551 - accuracy: 0.9531 - val_loss: 0.2049 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1405 - accuracy: 0.9546 - val_loss: 0.2349 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1254 - accuracy: 0.9595 - val_loss: 0.1758 - val_accuracy: 0.9535\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1130 - accuracy: 0.9634 - val_loss: 0.2124 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0963 - accuracy: 0.9736 - val_loss: 0.1902 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1092 - accuracy: 0.9648 - val_loss: 0.1870 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 137: 300.02 sec\n",
      "Time taken for epoch(SUBo) 137: 243.90 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [137] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m138\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1243 - accuracy: 0.9644 - val_loss: 0.1907 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1289 - accuracy: 0.9590 - val_loss: 0.1533 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1203 - accuracy: 0.9604 - val_loss: 0.1708 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1025 - accuracy: 0.9717 - val_loss: 0.1635 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0951 - accuracy: 0.9736 - val_loss: 0.1628 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0872 - accuracy: 0.9756 - val_loss: 0.1781 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 138: 298.57 sec\n",
      "Time taken for epoch(SUBo) 138: 243.89 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [138] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m139\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1322 - accuracy: 0.9629 - val_loss: 0.1652 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1569 - accuracy: 0.9458 - val_loss: 0.2143 - val_accuracy: 0.9375\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1260 - accuracy: 0.9609 - val_loss: 0.2487 - val_accuracy: 0.9231\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1343 - accuracy: 0.9585 - val_loss: 0.1756 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1018 - accuracy: 0.9678 - val_loss: 0.1879 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0864 - accuracy: 0.9751 - val_loss: 0.2002 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 139: 296.96 sec\n",
      "Time taken for epoch(SUBo) 139: 243.53 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [139] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m140\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1223 - accuracy: 0.9604 - val_loss: 0.1588 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1337 - accuracy: 0.9595 - val_loss: 0.1786 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1241 - accuracy: 0.9619 - val_loss: 0.1725 - val_accuracy: 0.9599\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1104 - accuracy: 0.9683 - val_loss: 0.1877 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1057 - accuracy: 0.9702 - val_loss: 0.1923 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0902 - accuracy: 0.9741 - val_loss: 0.1891 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 140: 298.07 sec\n",
      "Time taken for epoch(SUBo) 140: 243.40 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [140] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m141\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1314 - accuracy: 0.9541 - val_loss: 0.1613 - val_accuracy: 0.9599\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1441 - accuracy: 0.9556 - val_loss: 0.1692 - val_accuracy: 0.9583\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1292 - accuracy: 0.9580 - val_loss: 0.1645 - val_accuracy: 0.9583\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1142 - accuracy: 0.9673 - val_loss: 0.1783 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0957 - accuracy: 0.9727 - val_loss: 0.1860 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0972 - accuracy: 0.9717 - val_loss: 0.1725 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 141: 298.52 sec\n",
      "Time taken for epoch(SUBo) 141: 243.77 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [141] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m142\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1406 - accuracy: 0.9565 - val_loss: 0.1811 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1378 - accuracy: 0.9536 - val_loss: 0.1458 - val_accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1216 - accuracy: 0.9614 - val_loss: 0.1723 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1112 - accuracy: 0.9683 - val_loss: 0.1895 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1075 - accuracy: 0.9707 - val_loss: 0.1709 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0898 - accuracy: 0.9746 - val_loss: 0.1590 - val_accuracy: 0.9599\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 142: 297.84 sec\n",
      "Time taken for epoch(SUBo) 142: 243.24 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [142] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m143\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 159ms/step - loss: 0.1446 - accuracy: 0.9512 - val_loss: 0.1575 - val_accuracy: 0.9519\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1237 - accuracy: 0.9600 - val_loss: 0.1438 - val_accuracy: 0.9583\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1499 - accuracy: 0.9556 - val_loss: 0.1531 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1312 - accuracy: 0.9575 - val_loss: 0.1520 - val_accuracy: 0.9551\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1219 - accuracy: 0.9629 - val_loss: 0.1651 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1007 - accuracy: 0.9741 - val_loss: 0.1688 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 143: 296.59 sec\n",
      "Time taken for epoch(SUBo) 143: 243.29 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [143] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m144\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 158ms/step - loss: 0.1502 - accuracy: 0.9531 - val_loss: 0.1520 - val_accuracy: 0.9567\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1484 - accuracy: 0.9536 - val_loss: 0.1554 - val_accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1475 - accuracy: 0.9575 - val_loss: 0.1452 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1296 - accuracy: 0.9624 - val_loss: 0.1943 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1104 - accuracy: 0.9648 - val_loss: 0.1803 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0984 - accuracy: 0.9736 - val_loss: 0.1858 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 144: 296.73 sec\n",
      "Time taken for epoch(SUBo) 144: 242.88 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [144] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m145\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1262 - accuracy: 0.9600 - val_loss: 0.1634 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1191 - accuracy: 0.9639 - val_loss: 0.1680 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1056 - accuracy: 0.9658 - val_loss: 0.1970 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1031 - accuracy: 0.9707 - val_loss: 0.2054 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0822 - accuracy: 0.9800 - val_loss: 0.2039 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0879 - accuracy: 0.9746 - val_loss: 0.2102 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 145: 298.13 sec\n",
      "Time taken for epoch(SUBo) 145: 242.21 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [145] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m146\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1362 - accuracy: 0.9570 - val_loss: 0.1822 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1300 - accuracy: 0.9595 - val_loss: 0.2085 - val_accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1156 - accuracy: 0.9629 - val_loss: 0.2197 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0958 - accuracy: 0.9761 - val_loss: 0.2403 - val_accuracy: 0.9407\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1046 - accuracy: 0.9688 - val_loss: 0.2088 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0887 - accuracy: 0.9702 - val_loss: 0.2360 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 146: 301.03 sec\n",
      "Time taken for epoch(SUBo) 146: 242.33 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [146] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m147\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1234 - accuracy: 0.9619 - val_loss: 0.2010 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1173 - accuracy: 0.9614 - val_loss: 0.1836 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1030 - accuracy: 0.9717 - val_loss: 0.1736 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0980 - accuracy: 0.9707 - val_loss: 0.1931 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0948 - accuracy: 0.9722 - val_loss: 0.1875 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0902 - accuracy: 0.9741 - val_loss: 0.1813 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 147: 303.25 sec\n",
      "Time taken for epoch(SUBo) 147: 242.94 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [147] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m148\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1321 - accuracy: 0.9565 - val_loss: 0.2085 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1171 - accuracy: 0.9629 - val_loss: 0.1716 - val_accuracy: 0.9583\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1375 - accuracy: 0.9570 - val_loss: 0.1633 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1077 - accuracy: 0.9688 - val_loss: 0.1642 - val_accuracy: 0.9487\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1000 - accuracy: 0.9702 - val_loss: 0.1597 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0804 - accuracy: 0.9756 - val_loss: 0.1575 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 148: 301.98 sec\n",
      "Time taken for epoch(SUBo) 148: 243.14 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [148] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m149\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1178 - accuracy: 0.9634 - val_loss: 0.1412 - val_accuracy: 0.9615\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1271 - accuracy: 0.9580 - val_loss: 0.1553 - val_accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1074 - accuracy: 0.9658 - val_loss: 0.1972 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0920 - accuracy: 0.9741 - val_loss: 0.1781 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1054 - accuracy: 0.9692 - val_loss: 0.1791 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0850 - accuracy: 0.9761 - val_loss: 0.1786 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 149: 298.73 sec\n",
      "Time taken for epoch(SUBo) 149: 242.85 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [149] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m150\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1315 - accuracy: 0.9580 - val_loss: 0.1966 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1324 - accuracy: 0.9551 - val_loss: 0.2153 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1131 - accuracy: 0.9634 - val_loss: 0.2608 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1028 - accuracy: 0.9697 - val_loss: 0.2539 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0900 - accuracy: 0.9707 - val_loss: 0.2782 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1002 - accuracy: 0.9697 - val_loss: 0.2693 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 150: 300.25 sec\n",
      "Time taken for epoch(SUBo) 150: 243.69 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [150] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m151\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1267 - accuracy: 0.9614 - val_loss: 0.2125 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1103 - accuracy: 0.9712 - val_loss: 0.2087 - val_accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1040 - accuracy: 0.9653 - val_loss: 0.2110 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0983 - accuracy: 0.9727 - val_loss: 0.1971 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0813 - accuracy: 0.9780 - val_loss: 0.1968 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0845 - accuracy: 0.9751 - val_loss: 0.2230 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 151: 298.97 sec\n",
      "Time taken for epoch(SUBo) 151: 242.93 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [151] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m152\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1268 - accuracy: 0.9663 - val_loss: 0.2006 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1114 - accuracy: 0.9678 - val_loss: 0.1805 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1365 - accuracy: 0.9565 - val_loss: 0.1432 - val_accuracy: 0.9631\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1488 - accuracy: 0.9517 - val_loss: 0.1688 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1657 - accuracy: 0.9458 - val_loss: 0.1674 - val_accuracy: 0.9599\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1403 - accuracy: 0.9561 - val_loss: 0.1698 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 152: 302.68 sec\n",
      "Time taken for epoch(SUBo) 152: 243.68 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [152] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m153\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1499 - accuracy: 0.9507 - val_loss: 0.1872 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1414 - accuracy: 0.9580 - val_loss: 0.1947 - val_accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1562 - accuracy: 0.9463 - val_loss: 0.2135 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1247 - accuracy: 0.9629 - val_loss: 0.1884 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1041 - accuracy: 0.9712 - val_loss: 0.2042 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0982 - accuracy: 0.9712 - val_loss: 0.1936 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 153: 299.14 sec\n",
      "Time taken for epoch(SUBo) 153: 243.89 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [153] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m154\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1391 - accuracy: 0.9531 - val_loss: 0.1623 - val_accuracy: 0.9551\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1460 - accuracy: 0.9497 - val_loss: 0.2164 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1347 - accuracy: 0.9619 - val_loss: 0.4024 - val_accuracy: 0.8686\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1524 - accuracy: 0.9512 - val_loss: 0.2569 - val_accuracy: 0.9311\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1417 - accuracy: 0.9546 - val_loss: 0.2886 - val_accuracy: 0.9279\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1267 - accuracy: 0.9614 - val_loss: 0.2901 - val_accuracy: 0.9263\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 154: 303.43 sec\n",
      "Time taken for epoch(SUBo) 154: 244.09 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [154] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m155\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1674 - accuracy: 0.9424 - val_loss: 0.2398 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1466 - accuracy: 0.9556 - val_loss: 0.2424 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1350 - accuracy: 0.9565 - val_loss: 0.2398 - val_accuracy: 0.9343\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1153 - accuracy: 0.9639 - val_loss: 0.2173 - val_accuracy: 0.9551\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1016 - accuracy: 0.9692 - val_loss: 0.2637 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0905 - accuracy: 0.9766 - val_loss: 0.2615 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 155: 299.62 sec\n",
      "Time taken for epoch(SUBo) 155: 243.67 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [155] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m156\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1659 - accuracy: 0.9434 - val_loss: 0.2209 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1493 - accuracy: 0.9517 - val_loss: 0.2582 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1431 - accuracy: 0.9502 - val_loss: 0.2281 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1327 - accuracy: 0.9551 - val_loss: 0.2542 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1168 - accuracy: 0.9600 - val_loss: 0.1981 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1290 - accuracy: 0.9531 - val_loss: 0.2167 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 156: 301.27 sec\n",
      "Time taken for epoch(SUBo) 156: 244.46 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [156] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m157\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1338 - accuracy: 0.9565 - val_loss: 0.2626 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1420 - accuracy: 0.9473 - val_loss: 0.3502 - val_accuracy: 0.9215\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1291 - accuracy: 0.9585 - val_loss: 0.2344 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1022 - accuracy: 0.9683 - val_loss: 0.2722 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1164 - accuracy: 0.9648 - val_loss: 0.2915 - val_accuracy: 0.9215\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1043 - accuracy: 0.9688 - val_loss: 0.2660 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 157: 298.53 sec\n",
      "Time taken for epoch(SUBo) 157: 243.70 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [157] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m158\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1569 - accuracy: 0.9517 - val_loss: 0.2548 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1227 - accuracy: 0.9609 - val_loss: 0.3033 - val_accuracy: 0.9295\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1267 - accuracy: 0.9575 - val_loss: 0.2928 - val_accuracy: 0.9343\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1117 - accuracy: 0.9663 - val_loss: 0.2713 - val_accuracy: 0.9359\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0982 - accuracy: 0.9717 - val_loss: 0.2921 - val_accuracy: 0.9327\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0927 - accuracy: 0.9741 - val_loss: 0.2760 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 158: 305.20 sec\n",
      "Time taken for epoch(SUBo) 158: 244.85 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [158] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m159\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1135 - accuracy: 0.9668 - val_loss: 0.2714 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1001 - accuracy: 0.9663 - val_loss: 0.3513 - val_accuracy: 0.9263\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0937 - accuracy: 0.9712 - val_loss: 0.2725 - val_accuracy: 0.9343\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0861 - accuracy: 0.9780 - val_loss: 0.2921 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0836 - accuracy: 0.9751 - val_loss: 0.2788 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0809 - accuracy: 0.9780 - val_loss: 0.2651 - val_accuracy: 0.9359\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 159: 306.51 sec\n",
      "Time taken for epoch(SUBo) 159: 245.04 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [159] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m160\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 161ms/step - loss: 0.1241 - accuracy: 0.9609 - val_loss: 0.2724 - val_accuracy: 0.9391\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1337 - accuracy: 0.9570 - val_loss: 0.2510 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1102 - accuracy: 0.9653 - val_loss: 0.2081 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1101 - accuracy: 0.9702 - val_loss: 0.1942 - val_accuracy: 0.9567\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0956 - accuracy: 0.9688 - val_loss: 0.2166 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0885 - accuracy: 0.9727 - val_loss: 0.2052 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 160: 305.10 sec\n",
      "Time taken for epoch(SUBo) 160: 245.83 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [160] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m161\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1290 - accuracy: 0.9614 - val_loss: 0.1891 - val_accuracy: 0.9583\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1327 - accuracy: 0.9575 - val_loss: 0.1965 - val_accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1284 - accuracy: 0.9663 - val_loss: 0.2083 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1031 - accuracy: 0.9678 - val_loss: 0.2418 - val_accuracy: 0.9407\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1070 - accuracy: 0.9678 - val_loss: 0.2420 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0859 - accuracy: 0.9761 - val_loss: 0.2691 - val_accuracy: 0.9247\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 161: 299.90 sec\n",
      "Time taken for epoch(SUBo) 161: 244.85 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [161] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m162\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1228 - accuracy: 0.9629 - val_loss: 0.2065 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1223 - accuracy: 0.9604 - val_loss: 0.1999 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1606 - accuracy: 0.9517 - val_loss: 0.2025 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1366 - accuracy: 0.9575 - val_loss: 0.2026 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1233 - accuracy: 0.9619 - val_loss: 0.2040 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1096 - accuracy: 0.9673 - val_loss: 0.2063 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 162: 299.56 sec\n",
      "Time taken for epoch(SUBo) 162: 244.33 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [162] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m163\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1399 - accuracy: 0.9565 - val_loss: 0.2292 - val_accuracy: 0.9359\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1215 - accuracy: 0.9585 - val_loss: 0.2450 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1078 - accuracy: 0.9648 - val_loss: 0.2188 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1154 - accuracy: 0.9648 - val_loss: 0.2537 - val_accuracy: 0.9407\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1237 - accuracy: 0.9619 - val_loss: 0.2278 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1111 - accuracy: 0.9634 - val_loss: 0.2206 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 163: 297.49 sec\n",
      "Time taken for epoch(SUBo) 163: 243.39 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [163] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m164\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1580 - accuracy: 0.9507 - val_loss: 0.2399 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1401 - accuracy: 0.9570 - val_loss: 0.2307 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1342 - accuracy: 0.9604 - val_loss: 0.1897 - val_accuracy: 0.9535\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1060 - accuracy: 0.9697 - val_loss: 0.2260 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1083 - accuracy: 0.9668 - val_loss: 0.2024 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0980 - accuracy: 0.9673 - val_loss: 0.2013 - val_accuracy: 0.9551\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 164: 300.36 sec\n",
      "Time taken for epoch(SUBo) 164: 244.25 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [164] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m165\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 160ms/step - loss: 0.1589 - accuracy: 0.9497 - val_loss: 0.1661 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1300 - accuracy: 0.9575 - val_loss: 0.2048 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1393 - accuracy: 0.9600 - val_loss: 0.1941 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1145 - accuracy: 0.9629 - val_loss: 0.2079 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1092 - accuracy: 0.9688 - val_loss: 0.2288 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0878 - accuracy: 0.9761 - val_loss: 0.2080 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 165: 307.38 sec\n",
      "Time taken for epoch(SUBo) 165: 245.49 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [165] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m166\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1276 - accuracy: 0.9585 - val_loss: 0.2018 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1326 - accuracy: 0.9600 - val_loss: 0.1838 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1107 - accuracy: 0.9673 - val_loss: 0.1818 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1072 - accuracy: 0.9663 - val_loss: 0.1782 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0880 - accuracy: 0.9731 - val_loss: 0.1845 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0775 - accuracy: 0.9756 - val_loss: 0.1787 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 166: 306.37 sec\n",
      "Time taken for epoch(SUBo) 166: 244.99 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [166] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m167\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 162ms/step - loss: 0.1360 - accuracy: 0.9585 - val_loss: 0.1928 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1248 - accuracy: 0.9604 - val_loss: 0.1949 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1286 - accuracy: 0.9600 - val_loss: 0.2223 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1548 - accuracy: 0.9487 - val_loss: 0.3237 - val_accuracy: 0.9199\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1733 - accuracy: 0.9395 - val_loss: 0.2911 - val_accuracy: 0.9135\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1389 - accuracy: 0.9565 - val_loss: 0.2720 - val_accuracy: 0.9231\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 167: 302.14 sec\n",
      "Time taken for epoch(SUBo) 167: 244.91 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [167] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m168\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1783 - accuracy: 0.9365 - val_loss: 0.3662 - val_accuracy: 0.9006\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1679 - accuracy: 0.9419 - val_loss: 0.2450 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1442 - accuracy: 0.9512 - val_loss: 0.2916 - val_accuracy: 0.9343\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1321 - accuracy: 0.9575 - val_loss: 0.3255 - val_accuracy: 0.9231\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1195 - accuracy: 0.9624 - val_loss: 0.3551 - val_accuracy: 0.9199\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1084 - accuracy: 0.9668 - val_loss: 0.3794 - val_accuracy: 0.9135\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 168: 299.21 sec\n",
      "Time taken for epoch(SUBo) 168: 243.84 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [168] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m169\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1427 - accuracy: 0.9624 - val_loss: 0.2396 - val_accuracy: 0.9327\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1854 - accuracy: 0.9336 - val_loss: 0.2213 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1539 - accuracy: 0.9458 - val_loss: 0.2068 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1354 - accuracy: 0.9585 - val_loss: 0.3011 - val_accuracy: 0.9359\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1135 - accuracy: 0.9629 - val_loss: 0.2591 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1127 - accuracy: 0.9629 - val_loss: 0.2691 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 169: 300.15 sec\n",
      "Time taken for epoch(SUBo) 169: 243.82 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [169] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m170\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1595 - accuracy: 0.9438 - val_loss: 0.2370 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1465 - accuracy: 0.9492 - val_loss: 0.1867 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1322 - accuracy: 0.9565 - val_loss: 0.2246 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1295 - accuracy: 0.9609 - val_loss: 0.2039 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1179 - accuracy: 0.9644 - val_loss: 0.1999 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1043 - accuracy: 0.9688 - val_loss: 0.2048 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 170: 299.63 sec\n",
      "Time taken for epoch(SUBo) 170: 242.91 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [170] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m171\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1650 - accuracy: 0.9541 - val_loss: 0.1615 - val_accuracy: 0.9551\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1401 - accuracy: 0.9565 - val_loss: 0.1734 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1397 - accuracy: 0.9570 - val_loss: 0.1680 - val_accuracy: 0.9535\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1035 - accuracy: 0.9741 - val_loss: 0.1722 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1021 - accuracy: 0.9668 - val_loss: 0.1847 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1145 - accuracy: 0.9629 - val_loss: 0.1761 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 171: 304.06 sec\n",
      "Time taken for epoch(SUBo) 171: 243.87 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [171] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m172\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 161ms/step - loss: 0.1201 - accuracy: 0.9629 - val_loss: 0.1739 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1188 - accuracy: 0.9614 - val_loss: 0.1925 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1138 - accuracy: 0.9673 - val_loss: 0.2372 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1000 - accuracy: 0.9697 - val_loss: 0.1883 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0899 - accuracy: 0.9731 - val_loss: 0.2044 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0740 - accuracy: 0.9790 - val_loss: 0.2011 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 172: 304.33 sec\n",
      "Time taken for epoch(SUBo) 172: 243.65 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [172] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m173\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1373 - accuracy: 0.9541 - val_loss: 0.1948 - val_accuracy: 0.9567\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1472 - accuracy: 0.9502 - val_loss: 0.2673 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1669 - accuracy: 0.9453 - val_loss: 0.1954 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1616 - accuracy: 0.9502 - val_loss: 0.1729 - val_accuracy: 0.9519\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1263 - accuracy: 0.9629 - val_loss: 0.2251 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1095 - accuracy: 0.9658 - val_loss: 0.2223 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 173: 302.38 sec\n",
      "Time taken for epoch(SUBo) 173: 244.10 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [173] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m174\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1421 - accuracy: 0.9580 - val_loss: 0.2098 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1407 - accuracy: 0.9561 - val_loss: 0.2066 - val_accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1279 - accuracy: 0.9609 - val_loss: 0.2408 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1170 - accuracy: 0.9629 - val_loss: 0.2116 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1061 - accuracy: 0.9688 - val_loss: 0.2266 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0989 - accuracy: 0.9722 - val_loss: 0.2566 - val_accuracy: 0.9295\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 174: 298.38 sec\n",
      "Time taken for epoch(SUBo) 174: 242.96 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [174] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m175\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1366 - accuracy: 0.9546 - val_loss: 0.2196 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.1153 - accuracy: 0.9619 - val_loss: 0.2363 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1186 - accuracy: 0.9624 - val_loss: 0.2094 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1060 - accuracy: 0.9683 - val_loss: 0.2792 - val_accuracy: 0.9391\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0901 - accuracy: 0.9736 - val_loss: 0.2793 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0818 - accuracy: 0.9751 - val_loss: 0.3102 - val_accuracy: 0.9359\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 175: 298.34 sec\n",
      "Time taken for epoch(SUBo) 175: 243.27 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [175] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m176\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1217 - accuracy: 0.9561 - val_loss: 0.3390 - val_accuracy: 0.8894\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1363 - accuracy: 0.9600 - val_loss: 0.3365 - val_accuracy: 0.9151\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1219 - accuracy: 0.9580 - val_loss: 0.2768 - val_accuracy: 0.9343\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.1262 - accuracy: 0.9629 - val_loss: 0.2921 - val_accuracy: 0.9135\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0952 - accuracy: 0.9717 - val_loss: 0.3173 - val_accuracy: 0.9151\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.0972 - accuracy: 0.9731 - val_loss: 0.3247 - val_accuracy: 0.9135\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 176: 300.75 sec\n",
      "Time taken for epoch(SUBo) 176: 244.46 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [176] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m177\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 161ms/step - loss: 0.1301 - accuracy: 0.9600 - val_loss: 0.2746 - val_accuracy: 0.9215\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1191 - accuracy: 0.9658 - val_loss: 0.2657 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1160 - accuracy: 0.9629 - val_loss: 0.2625 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0987 - accuracy: 0.9722 - val_loss: 0.2429 - val_accuracy: 0.9391\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0863 - accuracy: 0.9756 - val_loss: 0.2320 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0852 - accuracy: 0.9771 - val_loss: 0.2548 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 177: 307.13 sec\n",
      "Time taken for epoch(SUBo) 177: 245.28 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [177] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m178\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 161ms/step - loss: 0.1285 - accuracy: 0.9634 - val_loss: 0.1938 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1361 - accuracy: 0.9551 - val_loss: 0.2198 - val_accuracy: 0.9375\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1310 - accuracy: 0.9614 - val_loss: 0.2257 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1178 - accuracy: 0.9658 - val_loss: 0.1883 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1097 - accuracy: 0.9673 - val_loss: 0.2366 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0935 - accuracy: 0.9697 - val_loss: 0.2949 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 178: 307.31 sec\n",
      "Time taken for epoch(SUBo) 178: 246.17 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [178] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m179\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 161ms/step - loss: 0.1366 - accuracy: 0.9551 - val_loss: 0.2232 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1883 - accuracy: 0.9370 - val_loss: 0.2155 - val_accuracy: 0.9359\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1590 - accuracy: 0.9492 - val_loss: 0.2392 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1456 - accuracy: 0.9517 - val_loss: 0.2673 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1245 - accuracy: 0.9604 - val_loss: 0.2418 - val_accuracy: 0.9311\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1098 - accuracy: 0.9658 - val_loss: 0.2398 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 179: 304.66 sec\n",
      "Time taken for epoch(SUBo) 179: 246.00 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [179] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m180\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1470 - accuracy: 0.9546 - val_loss: 0.2427 - val_accuracy: 0.9231\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1592 - accuracy: 0.9521 - val_loss: 0.3052 - val_accuracy: 0.9103\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1297 - accuracy: 0.9629 - val_loss: 0.2849 - val_accuracy: 0.9263\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1300 - accuracy: 0.9551 - val_loss: 0.2115 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1155 - accuracy: 0.9644 - val_loss: 0.2489 - val_accuracy: 0.9295\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1184 - accuracy: 0.9648 - val_loss: 0.2458 - val_accuracy: 0.9295\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 180: 303.24 sec\n",
      "Time taken for epoch(SUBo) 180: 245.01 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [180] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m181\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1431 - accuracy: 0.9556 - val_loss: 0.2670 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1354 - accuracy: 0.9580 - val_loss: 0.3152 - val_accuracy: 0.9071\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1250 - accuracy: 0.9604 - val_loss: 0.2952 - val_accuracy: 0.9054\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1128 - accuracy: 0.9624 - val_loss: 0.3917 - val_accuracy: 0.8958\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0896 - accuracy: 0.9756 - val_loss: 0.3502 - val_accuracy: 0.8990\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0898 - accuracy: 0.9707 - val_loss: 0.3361 - val_accuracy: 0.9071\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 181: 302.34 sec\n",
      "Time taken for epoch(SUBo) 181: 244.62 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [181] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m182\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1245 - accuracy: 0.9604 - val_loss: 0.2772 - val_accuracy: 0.9247\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1336 - accuracy: 0.9600 - val_loss: 0.2250 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1114 - accuracy: 0.9644 - val_loss: 0.3103 - val_accuracy: 0.9135\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1016 - accuracy: 0.9731 - val_loss: 0.3044 - val_accuracy: 0.9295\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0906 - accuracy: 0.9702 - val_loss: 0.3051 - val_accuracy: 0.9343\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0863 - accuracy: 0.9731 - val_loss: 0.3318 - val_accuracy: 0.9295\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 182: 304.09 sec\n",
      "Time taken for epoch(SUBo) 182: 245.03 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [182] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m183\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1180 - accuracy: 0.9609 - val_loss: 0.3431 - val_accuracy: 0.9087\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1122 - accuracy: 0.9678 - val_loss: 0.2777 - val_accuracy: 0.9199\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1235 - accuracy: 0.9634 - val_loss: 0.1881 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0921 - accuracy: 0.9717 - val_loss: 0.2754 - val_accuracy: 0.9263\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0831 - accuracy: 0.9712 - val_loss: 0.3383 - val_accuracy: 0.9103\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0866 - accuracy: 0.9751 - val_loss: 0.3123 - val_accuracy: 0.9215\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 183: 304.60 sec\n",
      "Time taken for epoch(SUBo) 183: 244.97 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [183] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m184\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 160ms/step - loss: 0.1436 - accuracy: 0.9565 - val_loss: 0.2403 - val_accuracy: 0.9327\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1356 - accuracy: 0.9575 - val_loss: 0.2531 - val_accuracy: 0.9263\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1325 - accuracy: 0.9531 - val_loss: 0.3488 - val_accuracy: 0.9215\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1183 - accuracy: 0.9634 - val_loss: 0.2155 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1100 - accuracy: 0.9658 - val_loss: 0.2753 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1108 - accuracy: 0.9644 - val_loss: 0.2761 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 184: 304.30 sec\n",
      "Time taken for epoch(SUBo) 184: 244.89 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [184] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m185\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 160ms/step - loss: 0.1250 - accuracy: 0.9619 - val_loss: 0.2633 - val_accuracy: 0.9391\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1248 - accuracy: 0.9604 - val_loss: 0.2972 - val_accuracy: 0.9359\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1252 - accuracy: 0.9639 - val_loss: 0.2754 - val_accuracy: 0.9263\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1152 - accuracy: 0.9683 - val_loss: 0.2419 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0866 - accuracy: 0.9736 - val_loss: 0.2478 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0871 - accuracy: 0.9736 - val_loss: 0.2475 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 185: 306.52 sec\n",
      "Time taken for epoch(SUBo) 185: 245.42 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [185] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m186\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 161ms/step - loss: 0.1323 - accuracy: 0.9585 - val_loss: 0.2456 - val_accuracy: 0.9295\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1374 - accuracy: 0.9639 - val_loss: 0.2509 - val_accuracy: 0.9263\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1351 - accuracy: 0.9639 - val_loss: 0.2669 - val_accuracy: 0.9311\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1114 - accuracy: 0.9639 - val_loss: 0.2947 - val_accuracy: 0.9263\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0944 - accuracy: 0.9766 - val_loss: 0.2886 - val_accuracy: 0.9263\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0906 - accuracy: 0.9736 - val_loss: 0.2739 - val_accuracy: 0.9343\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 186: 307.26 sec\n",
      "Time taken for epoch(SUBo) 186: 246.41 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [186] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m187\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1226 - accuracy: 0.9644 - val_loss: 0.2625 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1695 - accuracy: 0.9453 - val_loss: 1.2514 - val_accuracy: 0.7115\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1965 - accuracy: 0.9336 - val_loss: 0.5935 - val_accuracy: 0.8429\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1654 - accuracy: 0.9458 - val_loss: 0.4132 - val_accuracy: 0.9054\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1389 - accuracy: 0.9551 - val_loss: 0.4170 - val_accuracy: 0.9038\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1316 - accuracy: 0.9595 - val_loss: 0.4311 - val_accuracy: 0.9022\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 187: 297.48 sec\n",
      "Time taken for epoch(SUBo) 187: 244.18 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [187] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m188\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1581 - accuracy: 0.9458 - val_loss: 0.3557 - val_accuracy: 0.9087\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1425 - accuracy: 0.9561 - val_loss: 0.3358 - val_accuracy: 0.9199\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1316 - accuracy: 0.9551 - val_loss: 0.3622 - val_accuracy: 0.9231\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1155 - accuracy: 0.9634 - val_loss: 0.3811 - val_accuracy: 0.9119\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1323 - accuracy: 0.9546 - val_loss: 0.3472 - val_accuracy: 0.9167\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1224 - accuracy: 0.9644 - val_loss: 0.3330 - val_accuracy: 0.9295\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 188: 299.49 sec\n",
      "Time taken for epoch(SUBo) 188: 244.91 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [188] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m189\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1436 - accuracy: 0.9517 - val_loss: 0.2752 - val_accuracy: 0.9279\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1421 - accuracy: 0.9531 - val_loss: 0.2516 - val_accuracy: 0.9263\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1263 - accuracy: 0.9600 - val_loss: 0.2514 - val_accuracy: 0.9279\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1058 - accuracy: 0.9663 - val_loss: 0.2660 - val_accuracy: 0.9263\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1131 - accuracy: 0.9663 - val_loss: 0.2356 - val_accuracy: 0.9311\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1111 - accuracy: 0.9663 - val_loss: 0.2356 - val_accuracy: 0.9295\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 189: 301.75 sec\n",
      "Time taken for epoch(SUBo) 189: 245.44 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [189] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m190\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1480 - accuracy: 0.9570 - val_loss: 0.1996 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1882 - accuracy: 0.9380 - val_loss: 0.2167 - val_accuracy: 0.9327\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1597 - accuracy: 0.9512 - val_loss: 0.2156 - val_accuracy: 0.9247\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1344 - accuracy: 0.9590 - val_loss: 0.2198 - val_accuracy: 0.9295\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1345 - accuracy: 0.9609 - val_loss: 0.2668 - val_accuracy: 0.9327\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1128 - accuracy: 0.9644 - val_loss: 0.2396 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 190: 300.24 sec\n",
      "Time taken for epoch(SUBo) 190: 245.01 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [190] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m191\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1471 - accuracy: 0.9570 - val_loss: 0.2358 - val_accuracy: 0.9279\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1378 - accuracy: 0.9551 - val_loss: 0.2055 - val_accuracy: 0.9327\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1446 - accuracy: 0.9546 - val_loss: 0.1978 - val_accuracy: 0.9343\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1355 - accuracy: 0.9595 - val_loss: 0.1849 - val_accuracy: 0.9375\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1076 - accuracy: 0.9727 - val_loss: 0.2088 - val_accuracy: 0.9327\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1103 - accuracy: 0.9663 - val_loss: 0.1988 - val_accuracy: 0.9343\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 191: 301.30 sec\n",
      "Time taken for epoch(SUBo) 191: 245.49 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [191] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m192\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 161ms/step - loss: 0.1421 - accuracy: 0.9575 - val_loss: 0.2050 - val_accuracy: 0.9359\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1355 - accuracy: 0.9541 - val_loss: 0.3539 - val_accuracy: 0.9311\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1398 - accuracy: 0.9551 - val_loss: 0.2728 - val_accuracy: 0.9343\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1200 - accuracy: 0.9653 - val_loss: 0.2649 - val_accuracy: 0.9103\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1288 - accuracy: 0.9604 - val_loss: 0.2364 - val_accuracy: 0.9247\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1229 - accuracy: 0.9580 - val_loss: 0.2355 - val_accuracy: 0.9279\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 192: 300.20 sec\n",
      "Time taken for epoch(SUBo) 192: 245.83 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [192] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m193\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1544 - accuracy: 0.9478 - val_loss: 0.2400 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1478 - accuracy: 0.9507 - val_loss: 0.2931 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1254 - accuracy: 0.9619 - val_loss: 0.2789 - val_accuracy: 0.9327\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1375 - accuracy: 0.9585 - val_loss: 0.2220 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1067 - accuracy: 0.9712 - val_loss: 0.2248 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0902 - accuracy: 0.9751 - val_loss: 0.2198 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 193: 298.24 sec\n",
      "Time taken for epoch(SUBo) 193: 245.22 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [193] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m194\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1352 - accuracy: 0.9634 - val_loss: 0.2151 - val_accuracy: 0.9359\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1429 - accuracy: 0.9595 - val_loss: 0.2100 - val_accuracy: 0.9359\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1182 - accuracy: 0.9653 - val_loss: 0.2180 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1083 - accuracy: 0.9683 - val_loss: 0.2342 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1105 - accuracy: 0.9683 - val_loss: 0.2624 - val_accuracy: 0.9327\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0829 - accuracy: 0.9741 - val_loss: 0.2530 - val_accuracy: 0.9343\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 194: 299.52 sec\n",
      "Time taken for epoch(SUBo) 194: 245.69 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [194] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m195\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 159ms/step - loss: 0.1158 - accuracy: 0.9673 - val_loss: 0.2753 - val_accuracy: 0.9343\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.1058 - accuracy: 0.9648 - val_loss: 0.2734 - val_accuracy: 0.9327\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1013 - accuracy: 0.9673 - val_loss: 0.2366 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0861 - accuracy: 0.9756 - val_loss: 0.2831 - val_accuracy: 0.9311\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0798 - accuracy: 0.9775 - val_loss: 0.2666 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0687 - accuracy: 0.9824 - val_loss: 0.3035 - val_accuracy: 0.9359\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 195: 299.74 sec\n",
      "Time taken for epoch(SUBo) 195: 244.18 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [195] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m196\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1189 - accuracy: 0.9604 - val_loss: 0.2907 - val_accuracy: 0.9343\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1172 - accuracy: 0.9658 - val_loss: 0.2743 - val_accuracy: 0.9311\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1052 - accuracy: 0.9663 - val_loss: 0.2412 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1047 - accuracy: 0.9653 - val_loss: 0.4034 - val_accuracy: 0.9006\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1205 - accuracy: 0.9580 - val_loss: 0.3797 - val_accuracy: 0.9199\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1042 - accuracy: 0.9678 - val_loss: 0.3400 - val_accuracy: 0.9279\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 196: 300.20 sec\n",
      "Time taken for epoch(SUBo) 196: 246.37 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [196] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m197\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1318 - accuracy: 0.9595 - val_loss: 0.2433 - val_accuracy: 0.9343\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1237 - accuracy: 0.9624 - val_loss: 0.2380 - val_accuracy: 0.9311\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1288 - accuracy: 0.9600 - val_loss: 0.2326 - val_accuracy: 0.9279\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0909 - accuracy: 0.9727 - val_loss: 0.2398 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0943 - accuracy: 0.9751 - val_loss: 0.2242 - val_accuracy: 0.9343\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0824 - accuracy: 0.9736 - val_loss: 0.2357 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 197: 297.68 sec\n",
      "Time taken for epoch(SUBo) 197: 246.24 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [197] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m198\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1174 - accuracy: 0.9658 - val_loss: 0.2696 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1242 - accuracy: 0.9575 - val_loss: 0.2424 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0977 - accuracy: 0.9707 - val_loss: 0.2852 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.0980 - accuracy: 0.9688 - val_loss: 0.2780 - val_accuracy: 0.9359\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0881 - accuracy: 0.9736 - val_loss: 0.2471 - val_accuracy: 0.9359\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0809 - accuracy: 0.9751 - val_loss: 0.2606 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 198: 297.77 sec\n",
      "Time taken for epoch(SUBo) 198: 246.78 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [198] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m199\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1334 - accuracy: 0.9609 - val_loss: 0.2220 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1240 - accuracy: 0.9604 - val_loss: 0.2392 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1112 - accuracy: 0.9658 - val_loss: 0.2233 - val_accuracy: 0.9407\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1175 - accuracy: 0.9673 - val_loss: 0.2212 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1032 - accuracy: 0.9678 - val_loss: 0.2742 - val_accuracy: 0.9295\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1011 - accuracy: 0.9663 - val_loss: 0.2787 - val_accuracy: 0.9295\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 199: 298.50 sec\n",
      "Time taken for epoch(SUBo) 199: 246.76 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [199] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m200\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1285 - accuracy: 0.9580 - val_loss: 0.3062 - val_accuracy: 0.9103\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1324 - accuracy: 0.9570 - val_loss: 0.2178 - val_accuracy: 0.9375\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1266 - accuracy: 0.9624 - val_loss: 0.2289 - val_accuracy: 0.9327\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1193 - accuracy: 0.9565 - val_loss: 0.2471 - val_accuracy: 0.9359\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1040 - accuracy: 0.9673 - val_loss: 0.2422 - val_accuracy: 0.9343\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0873 - accuracy: 0.9741 - val_loss: 0.2505 - val_accuracy: 0.9311\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 200: 298.67 sec\n",
      "Time taken for epoch(SUBo) 200: 246.74 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [200] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m201\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1427 - accuracy: 0.9551 - val_loss: 0.2224 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1369 - accuracy: 0.9541 - val_loss: 0.2401 - val_accuracy: 0.9295\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1309 - accuracy: 0.9595 - val_loss: 0.2131 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1004 - accuracy: 0.9683 - val_loss: 0.2495 - val_accuracy: 0.9311\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0969 - accuracy: 0.9697 - val_loss: 0.2331 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0972 - accuracy: 0.9697 - val_loss: 0.2479 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 201: 297.63 sec\n",
      "Time taken for epoch(SUBo) 201: 245.98 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [201] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m202\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1129 - accuracy: 0.9663 - val_loss: 0.2707 - val_accuracy: 0.9327\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1298 - accuracy: 0.9600 - val_loss: 0.2119 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1173 - accuracy: 0.9644 - val_loss: 0.2111 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1074 - accuracy: 0.9712 - val_loss: 0.1881 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0924 - accuracy: 0.9702 - val_loss: 0.2089 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0812 - accuracy: 0.9805 - val_loss: 0.2168 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 202: 298.33 sec\n",
      "Time taken for epoch(SUBo) 202: 246.64 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [202] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m203\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1369 - accuracy: 0.9561 - val_loss: 0.2180 - val_accuracy: 0.9343\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1303 - accuracy: 0.9541 - val_loss: 0.2391 - val_accuracy: 0.9359\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1245 - accuracy: 0.9634 - val_loss: 0.2390 - val_accuracy: 0.9359\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1135 - accuracy: 0.9648 - val_loss: 0.2664 - val_accuracy: 0.9279\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0981 - accuracy: 0.9727 - val_loss: 0.2374 - val_accuracy: 0.9359\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0972 - accuracy: 0.9722 - val_loss: 0.2165 - val_accuracy: 0.9375\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 203: 296.86 sec\n",
      "Time taken for epoch(SUBo) 203: 245.14 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [203] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m204\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1145 - accuracy: 0.9663 - val_loss: 0.2079 - val_accuracy: 0.9359\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1075 - accuracy: 0.9648 - val_loss: 0.2058 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0978 - accuracy: 0.9673 - val_loss: 0.2125 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1015 - accuracy: 0.9722 - val_loss: 0.2370 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0780 - accuracy: 0.9775 - val_loss: 0.2245 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0684 - accuracy: 0.9814 - val_loss: 0.2192 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 204: 298.03 sec\n",
      "Time taken for epoch(SUBo) 204: 246.30 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [204] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m205\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1153 - accuracy: 0.9614 - val_loss: 0.2277 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1168 - accuracy: 0.9629 - val_loss: 0.2214 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1209 - accuracy: 0.9629 - val_loss: 0.1874 - val_accuracy: 0.9407\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1025 - accuracy: 0.9692 - val_loss: 0.2265 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0891 - accuracy: 0.9766 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0753 - accuracy: 0.9805 - val_loss: 0.2138 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 205: 297.87 sec\n",
      "Time taken for epoch(SUBo) 205: 245.90 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [205] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m206\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1070 - accuracy: 0.9697 - val_loss: 0.2057 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1039 - accuracy: 0.9673 - val_loss: 0.2215 - val_accuracy: 0.9391\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0855 - accuracy: 0.9741 - val_loss: 0.2183 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0878 - accuracy: 0.9746 - val_loss: 0.3037 - val_accuracy: 0.9359\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0819 - accuracy: 0.9766 - val_loss: 0.2560 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0760 - accuracy: 0.9766 - val_loss: 0.2418 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 206: 297.94 sec\n",
      "Time taken for epoch(SUBo) 206: 246.21 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [206] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m207\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1259 - accuracy: 0.9658 - val_loss: 0.2366 - val_accuracy: 0.9359\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1204 - accuracy: 0.9644 - val_loss: 0.2283 - val_accuracy: 0.9359\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1144 - accuracy: 0.9624 - val_loss: 0.1889 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0992 - accuracy: 0.9683 - val_loss: 0.2450 - val_accuracy: 0.9407\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0875 - accuracy: 0.9775 - val_loss: 0.2601 - val_accuracy: 0.9343\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0808 - accuracy: 0.9800 - val_loss: 0.2478 - val_accuracy: 0.9343\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 207: 298.66 sec\n",
      "Time taken for epoch(SUBo) 207: 246.51 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [207] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m208\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1141 - accuracy: 0.9648 - val_loss: 0.2134 - val_accuracy: 0.9407\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1072 - accuracy: 0.9663 - val_loss: 0.1996 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0942 - accuracy: 0.9697 - val_loss: 0.1941 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0885 - accuracy: 0.9741 - val_loss: 0.2165 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0837 - accuracy: 0.9741 - val_loss: 0.2150 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0726 - accuracy: 0.9829 - val_loss: 0.2024 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 208: 298.91 sec\n",
      "Time taken for epoch(SUBo) 208: 246.69 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [208] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m209\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1141 - accuracy: 0.9639 - val_loss: 0.2234 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1162 - accuracy: 0.9629 - val_loss: 0.2288 - val_accuracy: 0.9375\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1251 - accuracy: 0.9624 - val_loss: 0.2119 - val_accuracy: 0.9407\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0898 - accuracy: 0.9746 - val_loss: 0.2092 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1016 - accuracy: 0.9678 - val_loss: 0.2370 - val_accuracy: 0.9327\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0761 - accuracy: 0.9771 - val_loss: 0.2383 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 209: 296.92 sec\n",
      "Time taken for epoch(SUBo) 209: 245.42 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [209] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m210\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1219 - accuracy: 0.9619 - val_loss: 0.2331 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1128 - accuracy: 0.9624 - val_loss: 0.2102 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1038 - accuracy: 0.9658 - val_loss: 0.1857 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0935 - accuracy: 0.9727 - val_loss: 0.2113 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1070 - accuracy: 0.9668 - val_loss: 0.2461 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0851 - accuracy: 0.9766 - val_loss: 0.2336 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 210: 295.74 sec\n",
      "Time taken for epoch(SUBo) 210: 245.46 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [210] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m211\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1203 - accuracy: 0.9658 - val_loss: 0.1951 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1033 - accuracy: 0.9673 - val_loss: 0.1898 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0882 - accuracy: 0.9771 - val_loss: 0.1876 - val_accuracy: 0.9423\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0830 - accuracy: 0.9751 - val_loss: 0.1828 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0600 - accuracy: 0.9829 - val_loss: 0.2026 - val_accuracy: 0.9423\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0587 - accuracy: 0.9854 - val_loss: 0.1957 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 211: 295.87 sec\n",
      "Time taken for epoch(SUBo) 211: 245.59 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [211] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m212\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.0972 - accuracy: 0.9746 - val_loss: 0.1699 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1037 - accuracy: 0.9673 - val_loss: 0.2054 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0907 - accuracy: 0.9731 - val_loss: 0.2072 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0802 - accuracy: 0.9771 - val_loss: 0.1906 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0749 - accuracy: 0.9814 - val_loss: 0.1856 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0661 - accuracy: 0.9824 - val_loss: 0.1860 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 212: 295.86 sec\n",
      "Time taken for epoch(SUBo) 212: 245.69 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [212] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m213\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1047 - accuracy: 0.9688 - val_loss: 0.1803 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0977 - accuracy: 0.9746 - val_loss: 0.1586 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0919 - accuracy: 0.9722 - val_loss: 0.1882 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1002 - accuracy: 0.9756 - val_loss: 0.2034 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0865 - accuracy: 0.9766 - val_loss: 0.2175 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0730 - accuracy: 0.9790 - val_loss: 0.2228 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 213: 295.87 sec\n",
      "Time taken for epoch(SUBo) 213: 245.31 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [213] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m214\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1225 - accuracy: 0.9619 - val_loss: 0.1941 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1188 - accuracy: 0.9658 - val_loss: 0.1750 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1020 - accuracy: 0.9644 - val_loss: 0.2022 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0990 - accuracy: 0.9668 - val_loss: 0.1984 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.0992 - accuracy: 0.9722 - val_loss: 0.2096 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0697 - accuracy: 0.9814 - val_loss: 0.2177 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 214: 295.73 sec\n",
      "Time taken for epoch(SUBo) 214: 245.40 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [214] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m215\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.0995 - accuracy: 0.9717 - val_loss: 0.2052 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1099 - accuracy: 0.9688 - val_loss: 0.2122 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0904 - accuracy: 0.9712 - val_loss: 0.2057 - val_accuracy: 0.9455\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0789 - accuracy: 0.9756 - val_loss: 0.2348 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0699 - accuracy: 0.9834 - val_loss: 0.2055 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0564 - accuracy: 0.9839 - val_loss: 0.2412 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 215: 296.11 sec\n",
      "Time taken for epoch(SUBo) 215: 245.32 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [215] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m216\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1354 - accuracy: 0.9619 - val_loss: 1.9127 - val_accuracy: 0.6250\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.6524 - accuracy: 0.6860 - val_loss: 0.5187 - val_accuracy: 0.8253\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.4618 - accuracy: 0.8057 - val_loss: 0.4150 - val_accuracy: 0.9103\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3662 - accuracy: 0.8638 - val_loss: 0.2908 - val_accuracy: 0.9263\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.3131 - accuracy: 0.8921 - val_loss: 0.3339 - val_accuracy: 0.9263\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2602 - accuracy: 0.9121 - val_loss: 0.3118 - val_accuracy: 0.9279\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 216: 294.77 sec\n",
      "Time taken for epoch(SUBo) 216: 244.51 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [216] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m217\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.3051 - accuracy: 0.8945 - val_loss: 0.2281 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2581 - accuracy: 0.9053 - val_loss: 0.2585 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.2153 - accuracy: 0.9385 - val_loss: 0.1958 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1935 - accuracy: 0.9463 - val_loss: 0.1896 - val_accuracy: 0.9487\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1759 - accuracy: 0.9492 - val_loss: 0.2038 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1616 - accuracy: 0.9502 - val_loss: 0.2104 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 217: 295.94 sec\n",
      "Time taken for epoch(SUBo) 217: 245.61 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [217] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m218\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.2018 - accuracy: 0.9331 - val_loss: 0.2546 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1969 - accuracy: 0.9355 - val_loss: 0.2012 - val_accuracy: 0.9471\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1747 - accuracy: 0.9453 - val_loss: 0.1932 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1722 - accuracy: 0.9507 - val_loss: 0.2019 - val_accuracy: 0.9487\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1437 - accuracy: 0.9536 - val_loss: 0.2124 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1302 - accuracy: 0.9609 - val_loss: 0.2347 - val_accuracy: 0.9391\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 218: 295.43 sec\n",
      "Time taken for epoch(SUBo) 218: 245.14 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [218] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m219\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1756 - accuracy: 0.9478 - val_loss: 0.1971 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1803 - accuracy: 0.9414 - val_loss: 0.1779 - val_accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1618 - accuracy: 0.9424 - val_loss: 0.2014 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1546 - accuracy: 0.9600 - val_loss: 0.2209 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1289 - accuracy: 0.9639 - val_loss: 0.2224 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1036 - accuracy: 0.9692 - val_loss: 0.2182 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 219: 293.27 sec\n",
      "Time taken for epoch(SUBo) 219: 243.09 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [219] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m220\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 156ms/step - loss: 0.1384 - accuracy: 0.9580 - val_loss: 0.1899 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1636 - accuracy: 0.9497 - val_loss: 0.1965 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1510 - accuracy: 0.9561 - val_loss: 0.1807 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1192 - accuracy: 0.9629 - val_loss: 0.2034 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 39s 152ms/step - loss: 0.1268 - accuracy: 0.9585 - val_loss: 0.1812 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1151 - accuracy: 0.9663 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 220: 289.19 sec\n",
      "Time taken for epoch(SUBo) 220: 239.59 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [220] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m221\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 162ms/step - loss: 0.1293 - accuracy: 0.9604 - val_loss: 0.2001 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1258 - accuracy: 0.9629 - val_loss: 0.2138 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1242 - accuracy: 0.9629 - val_loss: 0.2242 - val_accuracy: 0.9471\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1100 - accuracy: 0.9712 - val_loss: 0.2425 - val_accuracy: 0.9391\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1082 - accuracy: 0.9712 - val_loss: 0.2177 - val_accuracy: 0.9455\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0903 - accuracy: 0.9751 - val_loss: 0.2145 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 221: 303.15 sec\n",
      "Time taken for epoch(SUBo) 221: 246.93 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [221] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m222\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 162ms/step - loss: 0.1582 - accuracy: 0.9531 - val_loss: 0.2076 - val_accuracy: 0.9375\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1585 - accuracy: 0.9556 - val_loss: 0.2135 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.1446 - accuracy: 0.9575 - val_loss: 0.2137 - val_accuracy: 0.9375\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 158ms/step - loss: 0.1215 - accuracy: 0.9663 - val_loss: 0.2196 - val_accuracy: 0.9343\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.1310 - accuracy: 0.9609 - val_loss: 0.2567 - val_accuracy: 0.9295\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.1038 - accuracy: 0.9727 - val_loss: 0.2416 - val_accuracy: 0.9327\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 222: 299.03 sec\n",
      "Time taken for epoch(SUBo) 222: 248.17 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [222] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m223\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 47s 165ms/step - loss: 0.1276 - accuracy: 0.9619 - val_loss: 0.2650 - val_accuracy: 0.9311\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 42s 165ms/step - loss: 0.1193 - accuracy: 0.9570 - val_loss: 0.1668 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.1061 - accuracy: 0.9688 - val_loss: 0.1817 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.1098 - accuracy: 0.9697 - val_loss: 0.2031 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 43s 166ms/step - loss: 0.0876 - accuracy: 0.9751 - val_loss: 0.1877 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 42s 164ms/step - loss: 0.0826 - accuracy: 0.9766 - val_loss: 0.1862 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 223: 312.69 sec\n",
      "Time taken for epoch(SUBo) 223: 256.34 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [223] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m224\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 162ms/step - loss: 0.1238 - accuracy: 0.9668 - val_loss: 0.1797 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.1198 - accuracy: 0.9624 - val_loss: 0.1924 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.1028 - accuracy: 0.9712 - val_loss: 0.2374 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.1065 - accuracy: 0.9722 - val_loss: 0.2279 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.0899 - accuracy: 0.9771 - val_loss: 0.1902 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0824 - accuracy: 0.9795 - val_loss: 0.1907 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 224: 301.18 sec\n",
      "Time taken for epoch(SUBo) 224: 248.32 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [224] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m225\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1296 - accuracy: 0.9609 - val_loss: 0.1972 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1254 - accuracy: 0.9619 - val_loss: 0.1699 - val_accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.1233 - accuracy: 0.9624 - val_loss: 0.2114 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0785 - accuracy: 0.9775 - val_loss: 0.1953 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0820 - accuracy: 0.9780 - val_loss: 0.2077 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0815 - accuracy: 0.9814 - val_loss: 0.2196 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 225: 302.66 sec\n",
      "Time taken for epoch(SUBo) 225: 248.69 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [225] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m226\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 164ms/step - loss: 0.1353 - accuracy: 0.9604 - val_loss: 0.2359 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.1373 - accuracy: 0.9561 - val_loss: 0.2577 - val_accuracy: 0.9359\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.1259 - accuracy: 0.9648 - val_loss: 0.2211 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.1084 - accuracy: 0.9707 - val_loss: 0.1719 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.1007 - accuracy: 0.9712 - val_loss: 0.1720 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0895 - accuracy: 0.9751 - val_loss: 0.1756 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 226: 313.16 sec\n",
      "Time taken for epoch(SUBo) 226: 251.41 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [226] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m227\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1123 - accuracy: 0.9639 - val_loss: 0.1721 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.1115 - accuracy: 0.9653 - val_loss: 0.2263 - val_accuracy: 0.9375\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.1077 - accuracy: 0.9639 - val_loss: 0.1975 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0943 - accuracy: 0.9717 - val_loss: 0.2010 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0949 - accuracy: 0.9736 - val_loss: 0.1780 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0812 - accuracy: 0.9771 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 227: 306.72 sec\n",
      "Time taken for epoch(SUBo) 227: 248.78 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [227] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m228\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 164ms/step - loss: 0.1398 - accuracy: 0.9546 - val_loss: 0.1847 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.1483 - accuracy: 0.9551 - val_loss: 0.1827 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.1162 - accuracy: 0.9678 - val_loss: 0.2110 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.1037 - accuracy: 0.9639 - val_loss: 0.1890 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0836 - accuracy: 0.9775 - val_loss: 0.1704 - val_accuracy: 0.9567\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 158ms/step - loss: 0.0876 - accuracy: 0.9746 - val_loss: 0.1758 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 228: 307.11 sec\n",
      "Time taken for epoch(SUBo) 228: 249.60 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [228] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m229\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 162ms/step - loss: 0.1046 - accuracy: 0.9688 - val_loss: 0.1633 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.1031 - accuracy: 0.9702 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 158ms/step - loss: 0.1045 - accuracy: 0.9717 - val_loss: 0.1849 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.0950 - accuracy: 0.9780 - val_loss: 0.1626 - val_accuracy: 0.9551\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0764 - accuracy: 0.9800 - val_loss: 0.1711 - val_accuracy: 0.9567\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0747 - accuracy: 0.9795 - val_loss: 0.1604 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 229: 302.46 sec\n",
      "Time taken for epoch(SUBo) 229: 249.29 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [229] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m230\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 163ms/step - loss: 0.1203 - accuracy: 0.9648 - val_loss: 0.1849 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 158ms/step - loss: 0.1080 - accuracy: 0.9639 - val_loss: 0.1861 - val_accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.0951 - accuracy: 0.9697 - val_loss: 0.2135 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.1004 - accuracy: 0.9712 - val_loss: 0.2054 - val_accuracy: 0.9439\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.0709 - accuracy: 0.9771 - val_loss: 0.2113 - val_accuracy: 0.9439\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0771 - accuracy: 0.9766 - val_loss: 0.2083 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 230: 299.92 sec\n",
      "Time taken for epoch(SUBo) 230: 248.71 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [230] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m231\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 47s 167ms/step - loss: 0.0909 - accuracy: 0.9707 - val_loss: 0.1829 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0896 - accuracy: 0.9746 - val_loss: 0.1859 - val_accuracy: 0.9423\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0809 - accuracy: 0.9766 - val_loss: 0.1953 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 162ms/step - loss: 0.0791 - accuracy: 0.9780 - val_loss: 0.1783 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0703 - accuracy: 0.9800 - val_loss: 0.1679 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0497 - accuracy: 0.9863 - val_loss: 0.1703 - val_accuracy: 0.9455\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 231: 304.17 sec\n",
      "Time taken for epoch(SUBo) 231: 253.03 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [231] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m232\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 47s 165ms/step - loss: 0.1107 - accuracy: 0.9683 - val_loss: 0.1718 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 162ms/step - loss: 0.1060 - accuracy: 0.9697 - val_loss: 0.1952 - val_accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0898 - accuracy: 0.9746 - val_loss: 0.1595 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0998 - accuracy: 0.9722 - val_loss: 0.1685 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 42s 164ms/step - loss: 0.0773 - accuracy: 0.9795 - val_loss: 0.2042 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 162ms/step - loss: 0.0897 - accuracy: 0.9780 - val_loss: 0.1887 - val_accuracy: 0.9407\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 232: 312.43 sec\n",
      "Time taken for epoch(SUBo) 232: 254.46 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [232] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m233\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 48s 167ms/step - loss: 0.1260 - accuracy: 0.9575 - val_loss: 0.1891 - val_accuracy: 0.9391\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 42s 163ms/step - loss: 0.1052 - accuracy: 0.9688 - val_loss: 0.1659 - val_accuracy: 0.9455\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 42s 164ms/step - loss: 0.1140 - accuracy: 0.9688 - val_loss: 0.1445 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 162ms/step - loss: 0.0954 - accuracy: 0.9717 - val_loss: 0.1710 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 42s 163ms/step - loss: 0.0933 - accuracy: 0.9761 - val_loss: 0.1612 - val_accuracy: 0.9519\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0744 - accuracy: 0.9814 - val_loss: 0.1741 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 233: 313.69 sec\n",
      "Time taken for epoch(SUBo) 233: 256.06 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [233] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m234\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 47s 167ms/step - loss: 0.1023 - accuracy: 0.9683 - val_loss: 0.1438 - val_accuracy: 0.9519\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 42s 162ms/step - loss: 0.0962 - accuracy: 0.9707 - val_loss: 0.2408 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 42s 162ms/step - loss: 0.0875 - accuracy: 0.9736 - val_loss: 0.1795 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 42s 163ms/step - loss: 0.0846 - accuracy: 0.9722 - val_loss: 0.1669 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 162ms/step - loss: 0.0591 - accuracy: 0.9844 - val_loss: 0.1704 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0565 - accuracy: 0.9873 - val_loss: 0.1818 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 234: 311.13 sec\n",
      "Time taken for epoch(SUBo) 234: 255.01 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [234] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m235\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 164ms/step - loss: 0.1210 - accuracy: 0.9629 - val_loss: 0.1778 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.1125 - accuracy: 0.9663 - val_loss: 0.1453 - val_accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.1075 - accuracy: 0.9688 - val_loss: 0.1608 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0843 - accuracy: 0.9775 - val_loss: 0.1615 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0782 - accuracy: 0.9771 - val_loss: 0.1832 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0672 - accuracy: 0.9800 - val_loss: 0.1808 - val_accuracy: 0.9439\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 235: 300.21 sec\n",
      "Time taken for epoch(SUBo) 235: 251.11 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [235] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m236\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 164ms/step - loss: 0.1133 - accuracy: 0.9639 - val_loss: 0.1626 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0993 - accuracy: 0.9648 - val_loss: 0.1585 - val_accuracy: 0.9583\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0924 - accuracy: 0.9717 - val_loss: 0.1581 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0813 - accuracy: 0.9780 - val_loss: 0.1336 - val_accuracy: 0.9583\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0724 - accuracy: 0.9790 - val_loss: 0.1694 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0585 - accuracy: 0.9839 - val_loss: 0.1735 - val_accuracy: 0.9503\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 236: 302.45 sec\n",
      "Time taken for epoch(SUBo) 236: 251.67 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [236] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m237\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 163ms/step - loss: 0.1015 - accuracy: 0.9663 - val_loss: 0.1594 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0919 - accuracy: 0.9736 - val_loss: 0.1593 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0886 - accuracy: 0.9746 - val_loss: 0.1714 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0809 - accuracy: 0.9795 - val_loss: 0.1978 - val_accuracy: 0.9503\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0690 - accuracy: 0.9829 - val_loss: 0.2800 - val_accuracy: 0.9375\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0600 - accuracy: 0.9873 - val_loss: 0.2560 - val_accuracy: 0.9359\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 237: 301.88 sec\n",
      "Time taken for epoch(SUBo) 237: 251.53 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [237] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m238\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 47s 166ms/step - loss: 0.1051 - accuracy: 0.9663 - val_loss: 0.2133 - val_accuracy: 0.9423\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0934 - accuracy: 0.9717 - val_loss: 0.2560 - val_accuracy: 0.9375\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0785 - accuracy: 0.9790 - val_loss: 0.2045 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 161ms/step - loss: 0.0702 - accuracy: 0.9790 - val_loss: 0.2433 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 160ms/step - loss: 0.0706 - accuracy: 0.9800 - val_loss: 0.1769 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0689 - accuracy: 0.9819 - val_loss: 0.1796 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 238: 307.10 sec\n",
      "Time taken for epoch(SUBo) 238: 252.62 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [238] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m239\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 46s 163ms/step - loss: 0.1147 - accuracy: 0.9673 - val_loss: 0.1823 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0958 - accuracy: 0.9751 - val_loss: 0.2081 - val_accuracy: 0.9407\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0865 - accuracy: 0.9775 - val_loss: 0.2058 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0716 - accuracy: 0.9795 - val_loss: 0.2068 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: 0.2146 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 41s 158ms/step - loss: 0.0562 - accuracy: 0.9834 - val_loss: 0.2186 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 239: 303.13 sec\n",
      "Time taken for epoch(SUBo) 239: 249.48 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [239] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m240\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 162ms/step - loss: 0.1219 - accuracy: 0.9595 - val_loss: 0.1957 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1010 - accuracy: 0.9717 - val_loss: 0.2189 - val_accuracy: 0.9327\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.0829 - accuracy: 0.9756 - val_loss: 0.2015 - val_accuracy: 0.9439\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 41s 159ms/step - loss: 0.0715 - accuracy: 0.9780 - val_loss: 0.2191 - val_accuracy: 0.9487\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0614 - accuracy: 0.9839 - val_loss: 0.2335 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0522 - accuracy: 0.9858 - val_loss: 0.2491 - val_accuracy: 0.9295\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 240: 296.96 sec\n",
      "Time taken for epoch(SUBo) 240: 247.49 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [240] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m241\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.0874 - accuracy: 0.9731 - val_loss: 0.2011 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0942 - accuracy: 0.9731 - val_loss: 0.1900 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0867 - accuracy: 0.9731 - val_loss: 0.2119 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0814 - accuracy: 0.9727 - val_loss: 0.2344 - val_accuracy: 0.9455\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0619 - accuracy: 0.9834 - val_loss: 0.2379 - val_accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0528 - accuracy: 0.9868 - val_loss: 0.2390 - val_accuracy: 0.9423\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 241: 301.50 sec\n",
      "Time taken for epoch(SUBo) 241: 244.85 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [241] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m242\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 157ms/step - loss: 0.1068 - accuracy: 0.9692 - val_loss: 0.2088 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 39s 153ms/step - loss: 0.0962 - accuracy: 0.9692 - val_loss: 0.2827 - val_accuracy: 0.9343\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 153ms/step - loss: 0.0859 - accuracy: 0.9731 - val_loss: 0.2028 - val_accuracy: 0.9535\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0831 - accuracy: 0.9761 - val_loss: 0.2217 - val_accuracy: 0.9551\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0908 - accuracy: 0.9775 - val_loss: 0.2048 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0678 - accuracy: 0.9814 - val_loss: 0.1931 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 242: 289.32 sec\n",
      "Time taken for epoch(SUBo) 242: 241.25 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [242] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m243\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 44s 158ms/step - loss: 0.1125 - accuracy: 0.9692 - val_loss: 0.1588 - val_accuracy: 0.9487\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 154ms/step - loss: 0.0962 - accuracy: 0.9668 - val_loss: 0.1660 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0947 - accuracy: 0.9717 - val_loss: 0.2053 - val_accuracy: 0.9343\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 39s 154ms/step - loss: 0.0780 - accuracy: 0.9756 - val_loss: 0.1659 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0762 - accuracy: 0.9805 - val_loss: 0.1947 - val_accuracy: 0.9407\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0544 - accuracy: 0.9844 - val_loss: 0.1827 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 243: 289.77 sec\n",
      "Time taken for epoch(SUBo) 243: 242.82 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [243] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m244\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.0972 - accuracy: 0.9717 - val_loss: 0.1976 - val_accuracy: 0.9439\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0864 - accuracy: 0.9775 - val_loss: 0.2101 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0845 - accuracy: 0.9746 - val_loss: 0.1914 - val_accuracy: 0.9487\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0668 - accuracy: 0.9814 - val_loss: 0.2286 - val_accuracy: 0.9375\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0735 - accuracy: 0.9819 - val_loss: 0.2039 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0471 - accuracy: 0.9897 - val_loss: 0.2055 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 244: 292.32 sec\n",
      "Time taken for epoch(SUBo) 244: 245.77 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [244] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m245\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1215 - accuracy: 0.9648 - val_loss: 0.1895 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.1283 - accuracy: 0.9629 - val_loss: 0.1734 - val_accuracy: 0.9439\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0933 - accuracy: 0.9731 - val_loss: 0.1550 - val_accuracy: 0.9583\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0845 - accuracy: 0.9746 - val_loss: 0.1631 - val_accuracy: 0.9567\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0857 - accuracy: 0.9731 - val_loss: 0.1576 - val_accuracy: 0.9583\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0706 - accuracy: 0.9824 - val_loss: 0.1603 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 245: 293.35 sec\n",
      "Time taken for epoch(SUBo) 245: 246.05 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [245] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m246\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.0914 - accuracy: 0.9771 - val_loss: 0.1657 - val_accuracy: 0.9567\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1083 - accuracy: 0.9697 - val_loss: 0.1844 - val_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0831 - accuracy: 0.9756 - val_loss: 0.1675 - val_accuracy: 0.9567\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0649 - accuracy: 0.9800 - val_loss: 0.1947 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0551 - accuracy: 0.9839 - val_loss: 0.1802 - val_accuracy: 0.9567\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0458 - accuracy: 0.9897 - val_loss: 0.1977 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 246: 292.03 sec\n",
      "Time taken for epoch(SUBo) 246: 245.80 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [246] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m247\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 162ms/step - loss: 0.0973 - accuracy: 0.9727 - val_loss: 0.1630 - val_accuracy: 0.9503\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0989 - accuracy: 0.9702 - val_loss: 0.1590 - val_accuracy: 0.9551\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0671 - accuracy: 0.9800 - val_loss: 0.1650 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0731 - accuracy: 0.9805 - val_loss: 0.1396 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0612 - accuracy: 0.9854 - val_loss: 0.1649 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0560 - accuracy: 0.9883 - val_loss: 0.1677 - val_accuracy: 0.9535\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 247: 294.16 sec\n",
      "Time taken for epoch(SUBo) 247: 247.01 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [247] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m248\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.0900 - accuracy: 0.9756 - val_loss: 0.1515 - val_accuracy: 0.9551\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0812 - accuracy: 0.9761 - val_loss: 0.1617 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0733 - accuracy: 0.9800 - val_loss: 0.1895 - val_accuracy: 0.9519\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0630 - accuracy: 0.9858 - val_loss: 0.1660 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0626 - accuracy: 0.9834 - val_loss: 0.1958 - val_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0587 - accuracy: 0.9849 - val_loss: 0.1824 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 248: 293.13 sec\n",
      "Time taken for epoch(SUBo) 248: 246.15 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [248] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m249\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1069 - accuracy: 0.9717 - val_loss: 0.1567 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.1036 - accuracy: 0.9717 - val_loss: 0.1435 - val_accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0755 - accuracy: 0.9780 - val_loss: 0.1969 - val_accuracy: 0.9503\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0742 - accuracy: 0.9775 - val_loss: 0.1623 - val_accuracy: 0.9567\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0608 - accuracy: 0.9810 - val_loss: 0.1840 - val_accuracy: 0.9551\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0557 - accuracy: 0.9844 - val_loss: 0.1914 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 249: 293.33 sec\n",
      "Time taken for epoch(SUBo) 249: 245.80 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [249] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m250\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.1097 - accuracy: 0.9658 - val_loss: 0.1761 - val_accuracy: 0.9519\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0999 - accuracy: 0.9697 - val_loss: 0.1736 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 155ms/step - loss: 0.0943 - accuracy: 0.9673 - val_loss: 0.1766 - val_accuracy: 0.9535\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0878 - accuracy: 0.9746 - val_loss: 0.1743 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0821 - accuracy: 0.9727 - val_loss: 0.1941 - val_accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0683 - accuracy: 0.9800 - val_loss: 0.1990 - val_accuracy: 0.9487\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 250: 292.13 sec\n",
      "Time taken for epoch(SUBo) 250: 244.59 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [250] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m251\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 160ms/step - loss: 0.0972 - accuracy: 0.9707 - val_loss: 0.1764 - val_accuracy: 0.9471\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0835 - accuracy: 0.9736 - val_loss: 0.1675 - val_accuracy: 0.9567\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0819 - accuracy: 0.9785 - val_loss: 0.1513 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0704 - accuracy: 0.9800 - val_loss: 0.1564 - val_accuracy: 0.9567\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0581 - accuracy: 0.9839 - val_loss: 0.1602 - val_accuracy: 0.9567\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0579 - accuracy: 0.9849 - val_loss: 0.1547 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.146798238158226. Not saving model.\n",
      "Time taken for epoch(FULL) 251: 292.96 sec\n",
      "Time taken for epoch(SUBo) 251: 246.01 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [251] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m252\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.0999 - accuracy: 0.9707 - val_loss: 0.1387 - val_accuracy: 0.9567\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0826 - accuracy: 0.9756 - val_loss: 0.1897 - val_accuracy: 0.9599\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0722 - accuracy: 0.9775 - val_loss: 0.1514 - val_accuracy: 0.9615\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0767 - accuracy: 0.9780 - val_loss: 0.1432 - val_accuracy: 0.9599\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0720 - accuracy: 0.9814 - val_loss: 0.1414 - val_accuracy: 0.9599\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0650 - accuracy: 0.9795 - val_loss: 0.1418 - val_accuracy: 0.9583\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Improved model loss from 0.146798238158226 to 0.14178654551506042. Saving model.\n",
      "Time taken for epoch(FULL) 252: 295.30 sec\n",
      "Time taken for epoch(SUBo) 252: 246.41 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [252] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m253\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.0918 - accuracy: 0.9722 - val_loss: 0.1538 - val_accuracy: 0.9599\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0866 - accuracy: 0.9761 - val_loss: 0.1447 - val_accuracy: 0.9599\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0777 - accuracy: 0.9800 - val_loss: 0.1519 - val_accuracy: 0.9583\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0644 - accuracy: 0.9829 - val_loss: 0.1863 - val_accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0585 - accuracy: 0.9868 - val_loss: 0.1939 - val_accuracy: 0.9471\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0511 - accuracy: 0.9878 - val_loss: 0.1766 - val_accuracy: 0.9471\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.14178654551506042. Not saving model.\n",
      "Time taken for epoch(FULL) 253: 293.56 sec\n",
      "Time taken for epoch(SUBo) 253: 246.59 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [253] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m254\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.1089 - accuracy: 0.9673 - val_loss: 0.1512 - val_accuracy: 0.9583\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0968 - accuracy: 0.9653 - val_loss: 0.1482 - val_accuracy: 0.9535\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0950 - accuracy: 0.9658 - val_loss: 0.1955 - val_accuracy: 0.9391\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0852 - accuracy: 0.9756 - val_loss: 0.1505 - val_accuracy: 0.9567\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0796 - accuracy: 0.9795 - val_loss: 0.1484 - val_accuracy: 0.9567\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0683 - accuracy: 0.9810 - val_loss: 0.1534 - val_accuracy: 0.9567\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.14178654551506042. Not saving model.\n",
      "Time taken for epoch(FULL) 254: 293.79 sec\n",
      "Time taken for epoch(SUBo) 254: 246.40 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [254] END|--------------------------------------->\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[0mEpoch: \u001b[0m\u001b[0;36m255\u001b[0m\u001b[0m/\u001b[0m\u001b[0;32m256\u001b[0m\u001b[0;34m | \u001b[0m\u001b[0;32m[Fine tuning]\u001b[0m\n",
      "\u001b[0;33mShuffling data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mTaking a subset of \u001b[0m\u001b[0;32m[2048]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;33mAugmenting data...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model OneCycleLr::maxlr to \u001b[0m\u001b[0;32m[0.001500]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0m\u001b[0m\u001b[0;33mSetting model subset epoch.c to \u001b[0m\u001b[0;32m[6]\u001b[0m\u001b[0;33m...\u001b[0m\n",
      "\u001b[0;32mTraining on subset...\u001b[0m\n",
      "Epoch 1/6\n",
      "256/256 [==============================] - 45s 161ms/step - loss: 0.0860 - accuracy: 0.9746 - val_loss: 0.1747 - val_accuracy: 0.9535\n",
      "Epoch 2/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0919 - accuracy: 0.9727 - val_loss: 0.1806 - val_accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "256/256 [==============================] - 40s 156ms/step - loss: 0.0816 - accuracy: 0.9756 - val_loss: 0.1677 - val_accuracy: 0.9551\n",
      "Epoch 4/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0612 - accuracy: 0.9834 - val_loss: 0.1808 - val_accuracy: 0.9535\n",
      "Epoch 5/6\n",
      "256/256 [==============================] - 40s 157ms/step - loss: 0.0564 - accuracy: 0.9844 - val_loss: 0.2127 - val_accuracy: 0.9391\n",
      "Epoch 6/6\n",
      "256/256 [==============================] - 40s 158ms/step - loss: 0.0513 - accuracy: 0.9883 - val_loss: 0.1953 - val_accuracy: 0.9519\n",
      "\u001b[0;32mSubset training done.\u001b[0m\n",
      "Model accuracy did not improve from 0.9695512652397156. Not saving model.\n",
      "Model loss did not improve from 0.14178654551506042. Not saving model.\n",
      "Time taken for epoch(FULL) 255: 293.85 sec\n",
      "Time taken for epoch(SUBo) 255: 246.35 sec\n",
      "\u001b[0;36m<---------------------------------------|Epoch [255] END|--------------------------------------->\u001b[0m\n",
      "Training done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "# CONF\n",
    "max_epoch = 256  # 128 for small models 256 for full Fine tuning and big models\n",
    "subset_epoch = 8  # change it if you are using a combined model or a big one| DEF=6 / COMM=8 | Too little can result the model not Learn the patterns and too much makes the model overfit on that subset and perform badly on the next subset\n",
    "subset_epoch_FT = 6\n",
    "PL_epoch = 16  # <=16 for small models and >=24 for big models\n",
    "subset_size = 2048\n",
    "Conf_batch_size_REV2 = 8\n",
    "OneCycleLr_MAXLR = 0.01\n",
    "OneCycleLr_DEC_A = 0.0005\n",
    "OneCycleLr_MINLR = 0.0015\n",
    "TerminateOnHighTemp_M = (\n",
    "    True  # can make your training a little bit slower, but it can save your expensive gpu (TURN IT OFF FOR TPU OR CPU TRAINING)\n",
    ")\n",
    "Use_ES_ONSUBT = False\n",
    "EarlyStopping_P = 5\n",
    "BEST_RSN = \"PAI_model_T\"\n",
    "# VAR\n",
    "OneCycleLr_CUNLR = OneCycleLr_MAXLR\n",
    "all_histories = []\n",
    "best_acc = 0\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "# Funcs\n",
    "def add_image_grain_TRLRev2(image, intensity=0.01):\n",
    "    # Generate random noise array\n",
    "    noise = np.random.randint(0, 255, size=image.shape, dtype=np.uint8)\n",
    "\n",
    "    # Scale the noise array\n",
    "    scaled_noise = (noise * intensity).astype(np.float32)\n",
    "    # Add the noise to the image\n",
    "    noisy_image = cv2.add(image, scaled_noise)\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "def noise_func_TRLRev2(image):\n",
    "    noise_type = np.random.choice([\"L1\", \"L2\", \"L3\", \"none\"])\n",
    "    new_image = np.copy(image)\n",
    "\n",
    "    if noise_type == \"L3\":\n",
    "        intensityL2 = random.uniform(0.001, 0.016)\n",
    "        intensityL1 = random.uniform(0.005, 0.020)\n",
    "    else:\n",
    "        intensityL2 = random.uniform(0.001, 0.027)\n",
    "        intensityL1 = random.uniform(0.001, 0.028)\n",
    "\n",
    "    block_size_L1 = random.randint(16, 32)\n",
    "    block_size_L2 = random.randint(32, 64)\n",
    "\n",
    "    if noise_type == \"L2\" or noise_type == \"L3\":\n",
    "        for i in range(0, image.shape[0], block_size_L2):\n",
    "            for j in range(0, image.shape[1], block_size_L2):\n",
    "                block = image[i : i + block_size_L2, j : j + block_size_L2]\n",
    "                block = (np.random.rand() * intensityL2 + 1) * block\n",
    "                new_image[i : i + block_size_L2, j : j + block_size_L2] = block\n",
    "        image = new_image\n",
    "\n",
    "    if noise_type == \"L1\" or noise_type == \"L3\":\n",
    "        for i in range(0, image.shape[0], block_size_L1):\n",
    "            for j in range(0, image.shape[1], block_size_L1):\n",
    "                block = image[i : i + block_size_L1, j : j + block_size_L1]\n",
    "                block = (np.random.rand() * intensityL1 + 1) * block\n",
    "                new_image[i : i + block_size_L1, j : j + block_size_L1] = block\n",
    "\n",
    "    if add_img_grain:\n",
    "        intensity = random.uniform(0, 0.022)  # Random intensity\n",
    "        new_image = add_image_grain_TRLRev2(new_image, intensity=intensity)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "# CONST\n",
    "train_SUB_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=179,\n",
    "    zoom_range=0.24,\n",
    "    shear_range=0.22,\n",
    "    width_shift_range=0.21,\n",
    "    brightness_range=(0.88, 1.12),\n",
    "    height_shift_range=0.21,\n",
    "    channel_shift_range=100,\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    interpolation_order=2,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=noise_func_TRLRev2,\n",
    ")\n",
    "\n",
    "\n",
    "class TerminateOnHighTemp(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, active=True, check_every_n_batches=2, high_temp=75, low_temp=60, pause_time=60):\n",
    "        super().__init__()\n",
    "        self.active = active\n",
    "        self.check_every_n_batches = check_every_n_batches\n",
    "        self.high_temp = high_temp\n",
    "        self.low_temp = low_temp\n",
    "        self.pause_time = pause_time\n",
    "        self.batch_counter = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if not self.active:\n",
    "            return\n",
    "        self.batch_counter += 1\n",
    "        if self.batch_counter % self.check_every_n_batches == 0:\n",
    "            temperature = gpu_control.get_temperature()\n",
    "            if temperature > self.high_temp:\n",
    "                print_Color(f\"\\nPausing training due to high GPU temperature! (for [{self.pause_time}]sec)\", [\"red\"], advanced_mode=False)\n",
    "                time.sleep(self.pause_time)\n",
    "                while gpu_control.get_temperature() > self.low_temp:\n",
    "                    time.sleep(4)\n",
    "                print_Color(\"Resuming training...\", [\"yellow\"])\n",
    "\n",
    "\n",
    "# callbacks\n",
    "steps_per_epoch_train_SUB = subset_size // Conf_batch_size_REV2\n",
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=EarlyStopping_P, verbose=1, restore_best_weights=True, mode=\"max\")\n",
    "TerminateOnHighTemp_CB = TerminateOnHighTemp(\n",
    "    active=TerminateOnHighTemp_M, check_every_n_batches=5, high_temp=75, low_temp=58, pause_time=60\n",
    ")\n",
    "# MAIN\n",
    "print(\"Training the model...\")\n",
    "try:\n",
    "    for epoch in range(1, max_epoch):\n",
    "        # Start Epoch\n",
    "        STG = \"Learning the patterns\" if epoch < PL_epoch else \"Fine tuning\"\n",
    "        C_subset_epoch = subset_epoch if epoch < PL_epoch else subset_epoch_FT\n",
    "        start_FULL_time = time.time()\n",
    "        print_Color(\n",
    "            f\"\\n~*Epoch: ~*{epoch}~*/~*{max_epoch}~* | ~*[{STG}]\",\n",
    "            [\"normal\", \"cyan\", \"normal\", \"green\", \"blue\", \"green\"],\n",
    "            advanced_mode=True,\n",
    "        )\n",
    "        # DP\n",
    "        print_Color(\"Shuffling data...\", [\"yellow\"])\n",
    "        x_train, y_train = shuffle_data(x_train, y_train)\n",
    "        print_Color(f\"~*Taking a subset of ~*[{subset_size}]~*...\", [\"yellow\", \"green\", \"yellow\"], advanced_mode=True)\n",
    "        subset_indices = np.random.choice(x_train.shape[0], subset_size, replace=False)\n",
    "        x_SUB_train = x_train[subset_indices]\n",
    "        y_SUB_train = y_train[subset_indices]\n",
    "        print_Color(\"Augmenting data...\", [\"yellow\"])\n",
    "        train_SUB_augmented_images = train_SUB_datagen.flow(\n",
    "            x_SUB_train * 255, y_SUB_train, shuffle=False, batch_size=len(x_SUB_train)\n",
    "        ).next()\n",
    "        x_SUB_train = np.clip(train_SUB_augmented_images[0], 0, 255) / 255\n",
    "        y_SUB_train = train_SUB_augmented_images[1]\n",
    "        # learning_rate_schedule_SUB\n",
    "        if epoch > PL_epoch and OneCycleLr_CUNLR > OneCycleLr_MINLR:\n",
    "            OneCycleLr_CUNLR -= OneCycleLr_DEC_A\n",
    "\n",
    "        learning_rate_schedule_SUB = OneCycleLr(max_lr=OneCycleLr_CUNLR, steps_per_epoch=steps_per_epoch_train_SUB, epochs=C_subset_epoch)\n",
    "        # FV\n",
    "        print_Color(\n",
    "            f\"~*Setting model OneCycleLr::maxlr to ~*[{OneCycleLr_CUNLR:.6f}]~*...\", [\"yellow\", \"green\", \"yellow\"], advanced_mode=True\n",
    "        )\n",
    "        print_Color(f\"~*Setting model subset epoch.c to ~*[{C_subset_epoch}]~*...\", [\"yellow\", \"green\", \"yellow\"], advanced_mode=True)\n",
    "        # Train\n",
    "        print_Color(\"Training on subset...\", [\"green\"])\n",
    "        start_SUBO_time = time.time()\n",
    "        SUB_history = model.fit(\n",
    "            x_SUB_train,\n",
    "            y_SUB_train,\n",
    "            epochs=C_subset_epoch,\n",
    "            batch_size=Conf_batch_size_REV2,\n",
    "            validation_data=(x_test, y_test),\n",
    "            verbose=\"auto\",\n",
    "            callbacks=[learning_rate_schedule_SUB, TerminateOnHighTemp_CB, early_stopping]\n",
    "            if Use_ES_ONSUBT\n",
    "            else [learning_rate_schedule_SUB, TerminateOnHighTemp_CB],\n",
    "        )\n",
    "        end_SUBO_time = time.time()\n",
    "        print_Color(\"Subset training done.\", [\"green\"])\n",
    "        all_histories.append(SUB_history.history)\n",
    "        # Garbage Collection (memory)\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "        # Evaluate the model on the test data\n",
    "        evaluation = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "        # Extract the loss and accuracy from the evaluation results\n",
    "        loss = evaluation[0]\n",
    "        acc = evaluation[1]\n",
    "\n",
    "        # If the accuracy is higher than the best_acc\n",
    "        if acc > best_acc:\n",
    "            print(\"Improved model accuracy from {} to {}. Saving model.\".format(best_acc, acc))\n",
    "\n",
    "            # Update the best_acc\n",
    "            best_acc = acc\n",
    "\n",
    "            # Save the model\n",
    "            if SAVE_TYPE == \"TF\":\n",
    "                print(\"Saving full model tf format...\")\n",
    "                model.save(BEST_RSN, save_format=\"tf\")\n",
    "            else:\n",
    "                model.save(f\"{BEST_RSN}.h5\")\n",
    "        else:\n",
    "            print(\"Model accuracy did not improve from {}. Not saving model.\".format(best_acc))\n",
    "\n",
    "        # If the loss is higher than the best_loss\n",
    "        if loss < best_loss:\n",
    "            print(\"Improved model loss from {} to {}. Saving model.\".format(best_loss, loss))\n",
    "\n",
    "            # Update the best_acc\n",
    "            best_loss = loss\n",
    "\n",
    "            # Save the model\n",
    "            if SAVE_TYPE == \"TF\":\n",
    "                print(\"Saving full model tf format...\")\n",
    "                model.save(BEST_RSN + \"_BL\", save_format=\"tf\")\n",
    "            else:\n",
    "                model.save(f\"{BEST_RSN}_BL.h5\")\n",
    "        else:\n",
    "            print(\"Model loss did not improve from {}. Not saving model.\".format(best_loss))\n",
    "        # Garbage Collection (memory)\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "        # Epoch end\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_FULL_time\n",
    "        print(f\"Time taken for epoch(FULL) {epoch}: {epoch_time:.2f} sec\")\n",
    "        epoch_SUB_time = end_SUBO_time - start_SUBO_time\n",
    "        print(f\"Time taken for epoch(SUBo) {epoch}: {epoch_SUB_time:.2f} sec\")\n",
    "        print_Color(f\"<---------------------------------------|Epoch [{epoch}] END|--------------------------------------->\", [\"cyan\"])\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nKeyboardInterrupt.\")\n",
    "# End\n",
    "history = {}\n",
    "for key in all_histories[0].keys():\n",
    "    # For each metric, concatenate the values from all histories\n",
    "    history[key] = np.concatenate([h[key] for h in all_histories])\n",
    "print(\"Training done.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rev1 \n",
    "```\n",
    "Working: âœ…\n",
    "Other:\n",
    " + Tensorboard works.\n",
    " - Can cause overfitting.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33mUsing WTD_augmentation...\u001b[0m\n",
      "Log dir: logs/fit/y2023_m11_d10-h09_m46_s41\n",
      "Input Shape: (None, 224, 224, 3)\n",
      "Output Shape: (None, 2)\n",
      "Loss Function: categorical_crossentropy\n",
      "Training the model...\n",
      "\n",
      "Epoch 1/256\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 21.8761 - accuracy: 0.6135\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46154, saving model to models\\Temp\\bestVAC_model.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.47701, saving model to models\\Temp\\bestVL_model.h5\n",
      "\n",
      "Learning rate for epoch 1 is 0.0018143485067412257\n",
      "Momentum for epoch 1 is 0.9433048963546753\n",
      "Validation loss for epoch 1 is 1.4770132303237915\n",
      "Validation accuracy for epoch 1 is 0.4615384638309479\n",
      "\u001b[0m\u001b[0m\u001b[0;31m<!--------------------------------------|Epoch\u001b[0m\u001b[0;33m [1]\u001b[0m\u001b[0;31m End|--------------------------------------!> \u001b[0m\u001b[0;32mPBEâ†“\u001b[0m\n",
      "3000/3000 [==============================] - 624s 198ms/step - loss: 21.8761 - accuracy: 0.6135 - val_loss: 1.4770 - val_accuracy: 0.4615\n",
      "Epoch 2/256\n",
      " 152/3000 [>.............................] - ETA: 8:42 - loss: 1.5077 - accuracy: 0.5625"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aydin\\Desktop\\Pneumonia AI\\Model_T&T_BETA.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining the model...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m \u001b[39mif\u001b[39;00m WTD_augmentation:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataset,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m                         epochs\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m                         steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch_train,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m                         batch_size\u001b[39m=\u001b[39;49mConf_batch_size,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m                         validation_data\u001b[39m=\u001b[39;49m(x_test, y_test),\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=168'>169</a>\u001b[0m                         verbose\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m                         callbacks\u001b[39m=\u001b[39;49m[early_stopping,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m                                 tensorboard_callback,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m                                 learning_rate_schedule,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m                                 checkpoint_BVAC,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m                                 checkpoint_BVL,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m                                 EpochEndMON_callback])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(x_train,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m                         y_train,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m                         epochs\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=186'>187</a>\u001b[0m                                 checkpoint_BVL,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#X53sZmlsZQ%3D%3D?line=187'>188</a>\u001b[0m                                 EpochEndMON_callback])\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "# CONF\n",
    "WTD_augmentation = True\n",
    "Conf_batch_size = 4\n",
    "Learning_rate_conf = 3  # 1 and 2 for custom learning_rate_fn and 3 for OneCycleLr (Better for full training)\n",
    "# TensorBoard conf\n",
    "TensorBoard_UF = 1  # 1 for Slow 2 for fast (very slow tarining)\n",
    "# Learning rate configuration\n",
    "Learning_rate_conf_SET2C = 3  # 1 for SGD and 2 for Adam and... for lower lr 3 for very high lr\n",
    "OneCycleLr_MAXLR = 0.0174\n",
    "# First time\n",
    "if Learning_rate_conf == 1:\n",
    "    learning_rate_start = 8e-04\n",
    "    learning_rate_max = 5e-03\n",
    "    learning_rate_min = 5e-05\n",
    "    learning_rate_rampup_epochs = 5\n",
    "    learning_rate_sustain_epochs = 1\n",
    "    learning_rate_exp_decay = 0.3\n",
    "    # TEMP\n",
    "    # learning_rate_start = 8e-04\n",
    "    # learning_rate_max = 1e-02\n",
    "    # learning_rate_min = 8e-04\n",
    "    # learning_rate_rampup_epochs = 5\n",
    "    # learning_rate_sustain_epochs = 3\n",
    "    # learning_rate_exp_decay = .45\n",
    "# 2th time\n",
    "if Learning_rate_conf == 2:\n",
    "    if Learning_rate_conf_SET2C == 1:\n",
    "        learning_rate_start = 4.10e-06\n",
    "        learning_rate_max = 4.10e-06\n",
    "        learning_rate_min = 4.10e-06\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = 0.1\n",
    "\n",
    "    elif Learning_rate_conf_SET2C == 2:\n",
    "        learning_rate_start = 4e-07\n",
    "        learning_rate_max = 4e-07\n",
    "        learning_rate_min = 4e-07\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = 0.1\n",
    "\n",
    "    elif Learning_rate_conf_SET2C == 3:\n",
    "        learning_rate_start = 5e-04\n",
    "        learning_rate_max = 5e-04\n",
    "        learning_rate_min = 5e-04\n",
    "        learning_rate_rampup_epochs = 0\n",
    "        learning_rate_sustain_epochs = 0\n",
    "        learning_rate_exp_decay = 0.1\n",
    "# Function to build learning rate schedule\n",
    "if Learning_rate_conf in [1, 2]:\n",
    "\n",
    "    def build_learning_rate_fn(\n",
    "        lr_start=learning_rate_start,\n",
    "        lr_max=learning_rate_max,\n",
    "        lr_min=learning_rate_min,\n",
    "        lr_rampup_epochs=learning_rate_rampup_epochs,\n",
    "        lr_sustain_epochs=learning_rate_sustain_epochs,\n",
    "        lr_exp_decay=learning_rate_exp_decay,\n",
    "    ):\n",
    "        lr_max = lr_max * tf.distribute.get_strategy().num_replicas_in_sync\n",
    "\n",
    "        def learning_rate_fn(epoch):\n",
    "            if epoch < lr_rampup_epochs:\n",
    "                lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "            elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "                lr = lr_max\n",
    "            else:\n",
    "                lr = (lr_max - lr_min) * lr_exp_decay ** (epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "            return lr\n",
    "\n",
    "        return learning_rate_fn\n",
    "\n",
    "\n",
    "# WTD_augmentation\n",
    "if WTD_augmentation:\n",
    "    print_Color(\"Using WTD_augmentation...\", [\"yellow\"])\n",
    "\n",
    "    def TF_add_image_grain(image, intensity=0.01):\n",
    "        # Generate random noise array in the range [0, 1]\n",
    "        noise = tf.random.uniform(shape=tf.shape(image), minval=0, maxval=1, dtype=tf.float32)\n",
    "\n",
    "        # Scale the noise array\n",
    "        scaled_noise = noise * intensity\n",
    "\n",
    "        # Add the noise to the image\n",
    "        noisy_image = tf.math.add(image, scaled_noise)\n",
    "\n",
    "        # Clip\n",
    "        if RANGE_NOM:\n",
    "            noisy_image = tf.clip_by_value(noisy_image, -1.0, 1.0)\n",
    "        else:\n",
    "            noisy_image = tf.clip_by_value(noisy_image, 0.0, 255.0)\n",
    "\n",
    "        return noisy_image\n",
    "\n",
    "    # Function to augment images\n",
    "    def augment_images(image, label):\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        image = tf.image.random_contrast(image, 0.2, 1.8)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.3)\n",
    "        # Random intensity between 0 and 0.04\n",
    "        intensity = random.uniform(0, 0.04)\n",
    "        image = TF_add_image_grain(image, intensity=intensity)\n",
    "        # Add random rotation\n",
    "        # image = tf.image.rot90(image, k=random.randint(0, 3))\n",
    "        return image, label\n",
    "\n",
    "    # Create TensorFlow dataset\n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "        .map(augment_images, num_parallel_calls=AUTO)\n",
    "        .repeat()\n",
    "        .shuffle(len(x_train))\n",
    "        .batch(Conf_batch_size)\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch_train = len(x_train) // Conf_batch_size\n",
    "\n",
    "\n",
    "# Set up callbacks\n",
    "class EpochEndMON(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        optimizer = self.model.optimizer\n",
    "        if hasattr(optimizer, \"lr\"):\n",
    "            lr = tf.keras.backend.get_value(optimizer.lr)\n",
    "            print(f\"\\nLearning rate for epoch {epoch + 1} is {lr}\")\n",
    "        if hasattr(optimizer, \"momentum\"):\n",
    "            momentum = tf.keras.backend.get_value(optimizer.momentum)\n",
    "            print(f\"Momentum for epoch {epoch + 1} is {momentum}\")\n",
    "        if logs:\n",
    "            val_loss = logs.get(\"val_loss\")\n",
    "            val_acc = logs.get(\"val_accuracy\")\n",
    "            print(f\"Validation loss for epoch {epoch + 1} is {val_loss}\")\n",
    "            print(f\"Validation accuracy for epoch {epoch + 1} is {val_acc}\")\n",
    "\n",
    "        print_Color_V2(\n",
    "            f\"`red`<!--------------------------------------|Epoch`yellow` [{epoch + 1}]`red` End|--------------------------------------!> `green`PBEâ†“\",\n",
    "            start_char=\"`\",\n",
    "            end_char=\"`\",\n",
    "        )\n",
    "\n",
    "\n",
    "# Instantiate the callback\n",
    "EpochEndMON_callback = EpochEndMON()\n",
    "if Learning_rate_conf in [1, 2]:\n",
    "    learning_rate_fn = build_learning_rate_fn()\n",
    "    learning_rate_schedule = LearningRateScheduler(learning_rate_fn, verbose=1)\n",
    "else:\n",
    "    learning_rate_schedule = OneCycleLr(max_lr=OneCycleLr_MAXLR, steps_per_epoch=steps_per_epoch_train, epochs=20)\n",
    "if SAVE_TYPE == \"TF\":\n",
    "    checkpoint_BVAC = ModelCheckpoint(\"models\\\\Temp\\\\bestVAC_model\", monitor=\"val_accuracy\", mode=\"max\", save_best_only=True, verbose=1)\n",
    "    checkpoint_BVL = ModelCheckpoint(\"models\\\\Temp\\\\bestVL_model\", monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "else:\n",
    "    checkpoint_BVAC = ModelCheckpoint(\"models\\\\Temp\\\\bestVAC_model.h5\", monitor=\"val_accuracy\", mode=\"max\", save_best_only=True, verbose=1)\n",
    "    checkpoint_BVL = ModelCheckpoint(\"models\\\\Temp\\\\bestVL_model.h5\", monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=2, verbose=1, restore_best_weights=True)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"y%Y_m%m_d%d-h%H_m%M_s%S\")\n",
    "TensorBoard_update_freq = \"batch\" if TensorBoard_UF == 2 else \"epoch\"\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, write_images=True, histogram_freq=1, update_freq=TensorBoard_update_freq)\n",
    "\n",
    "# Train the model\n",
    "print(\"Log dir:\", log_dir)\n",
    "# MInfo\n",
    "print(\"Input Shape:\", model.input_shape)\n",
    "print(\"Output Shape:\", model.output_shape)\n",
    "print(\"Loss Function:\", model.loss)\n",
    "print(\"Training the model...\\n\")\n",
    "if WTD_augmentation:\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=256,\n",
    "        steps_per_epoch=steps_per_epoch_train,\n",
    "        batch_size=Conf_batch_size,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=\"auto\",\n",
    "        callbacks=[early_stopping, tensorboard_callback, learning_rate_schedule, checkpoint_BVAC, checkpoint_BVL, EpochEndMON_callback],\n",
    "    )\n",
    "else:\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=256,\n",
    "        batch_size=Conf_batch_size,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=\"auto\",\n",
    "        callbacks=[early_stopping, tensorboard_callback, learning_rate_schedule, checkpoint_BVAC, checkpoint_BVL, EpochEndMON_callback],\n",
    "    )\n",
    "print(\"Training done.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving weights...\n",
      "Saving full model...\n"
     ]
    }
   ],
   "source": [
    "Extra_EXT = \"_T\"\n",
    "# Save the weights\n",
    "print(\"Saving weights...\")\n",
    "model.save_weights(\"PAI_model_weights.h5\")\n",
    "print(\"Saving full model...\")\n",
    "if SAVE_TYPE == \"TF\":\n",
    "    print(\"Saving full model tf format...\")\n",
    "    model.save(f\"PAI_model{Extra_EXT}\", save_format=\"tf\")\n",
    "else:\n",
    "    try:\n",
    "        model.save(f\"PAI_model{Extra_EXT}.h5\")\n",
    "    except ValueError:\n",
    "        print(\"failed to save in .h5 format!\")\n",
    "        print(\"Saving full model in tf format...\")\n",
    "        model.save(f\"PAI_model{Extra_EXT}\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage Collection (memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse model Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_history(history):\n",
    "    if isinstance(history, tf.keras.callbacks.History):\n",
    "        return history.history\n",
    "    else:\n",
    "        return history\n",
    "\n",
    "\n",
    "try:\n",
    "    EPM = \"Epoch(Subset)\" if not isinstance(history, tf.keras.callbacks.History) else \"Epoch\"\n",
    "    history = convert_history(history)\n",
    "    # loss\n",
    "    plt.plot(history[\"loss\"], label=\"loss\")\n",
    "    try:\n",
    "        plt.plot(history[\"val_loss\"], label=\"val_loss\", color=\"orange\")\n",
    "    except (ValueError, NameError):\n",
    "        print(\"\\033[91mfailed to load val_loss.\")\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "    plt.ylim(top=(max(history[\"val_loss\"][8:]) + min(history[\"val_loss\"])) / 2, bottom=0)\n",
    "    plt.show()\n",
    "    # acc\n",
    "    plt.plot(history[\"accuracy\"], label=\"accuracy\")\n",
    "    try:\n",
    "        plt.plot(history[\"val_accuracy\"], label=\"val_accuracy\", color=\"orange\")\n",
    "    except (ValueError, NameError):\n",
    "        print(\"\\033[91mfailed to load val_accuracy.\")\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(EPM)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "except (ValueError, NameError):\n",
    "    print(\"\\033[91mfailed to load model history.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse model Predicting performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradcam heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_heatmap(model, img_array, conv_layer_name, pred_index):\n",
    "    \"\"\"\n",
    "    Helper function to compute the heatmap for a given convolutional layer.\n",
    "    \"\"\"\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(conv_layer_name).output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_layer_output, preds = grad_model(img_array)\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_layer_output = conv_layer_output[0]\n",
    "    heatmap = conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(\n",
    "    img_array, model, last_conv_layer_name, second_last_conv_layer_name=None, pred_index=None, threshold=0, sensitivity_map=1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to compute the Grad-CAM heatmap for a specific class, given an input image.\n",
    "    \"\"\"\n",
    "    if pred_index is None:\n",
    "        preds = model.predict(img_array)\n",
    "        pred_index = tf.argmax(preds[0])\n",
    "\n",
    "    # Compute heatmap for the last convolutional layer\n",
    "    heatmap = compute_heatmap(model, img_array, last_conv_layer_name, pred_index)\n",
    "\n",
    "    # Apply threshold and adjust sensitivity\n",
    "    heatmap = np.where(heatmap > threshold, heatmap, 0)\n",
    "    heatmap = heatmap**sensitivity_map\n",
    "\n",
    "    if second_last_conv_layer_name is not None:\n",
    "        # Compute heatmap for the second last convolutional layer\n",
    "        heatmap_second = compute_heatmap(model, img_array, second_last_conv_layer_name, pred_index)\n",
    "\n",
    "        # Apply threshold and adjust sensitivity\n",
    "        heatmap_second = np.where(heatmap_second > threshold, heatmap_second, 0)\n",
    "        heatmap_second = heatmap_second**sensitivity_map\n",
    "\n",
    "        # Average the two heatmaps\n",
    "        heatmap = (heatmap + heatmap_second) / 2.0\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aydin\\Desktop\\Pneumonia AI\\Model_T&T_BETA.ipynb Cell 55\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#Y102sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     model \u001b[39m=\u001b[39m load_model(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPAI_model\u001b[39m\u001b[39m{\u001b[39;00mExtra_EXT\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#Y102sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#Y102sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# Load the pre-trained model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#Y102sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     model \u001b[39m=\u001b[39m load_model(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mPAI_model\u001b[39;49m\u001b[39m{\u001b[39;49;00mExtra_EXT\u001b[39m}\u001b[39;49;00m\u001b[39m.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#Y102sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Ensure the model's input_shape matches your data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aydin/Desktop/Pneumonia%20AI/Model_T%26T_BETA.ipynb#Y102sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39massert\u001b[39;00m model\u001b[39m.\u001b[39minput_shape[\u001b[39m1\u001b[39m:] \u001b[39m==\u001b[39m (img_res[\u001b[39m0\u001b[39m], img_res[\u001b[39m1\u001b[39m], img_res[\u001b[39m2\u001b[39m]), \u001b[39m'\u001b[39m\u001b[39mModels input shape doesnt match data.\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\save.py:241\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[39mif\u001b[39;00m h5py \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    237\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mFilepath looks like a hdf5 file but h5py is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mnot available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m filepath=\u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m             )\n\u001b[1;32m--> 241\u001b[0m         \u001b[39mreturn\u001b[39;00m hdf5_format\u001b[39m.\u001b[39;49mload_model_from_hdf5(\n\u001b[0;32m    242\u001b[0m             tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mgfile\u001b[39m.\u001b[39;49mGFile(filepath_str, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    243\u001b[0m             custom_objects,\n\u001b[0;32m    244\u001b[0m             \u001b[39mcompile\u001b[39;49m,\n\u001b[0;32m    245\u001b[0m         )\n\u001b[0;32m    246\u001b[0m \u001b[39melif\u001b[39;00m h5py \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath, h5py\u001b[39m.\u001b[39mFile):\n\u001b[0;32m    247\u001b[0m     \u001b[39mreturn\u001b[39;00m hdf5_format\u001b[39m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    248\u001b[0m         filepath, custom_objects, \u001b[39mcompile\u001b[39m\n\u001b[0;32m    249\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\hdf5_format.py:200\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    198\u001b[0m     model_config \u001b[39m=\u001b[39m model_config\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    199\u001b[0m model_config \u001b[39m=\u001b[39m json_utils\u001b[39m.\u001b[39mdecode(model_config)\n\u001b[1;32m--> 200\u001b[0m model \u001b[39m=\u001b[39m model_config_lib\u001b[39m.\u001b[39;49mmodel_from_config(\n\u001b[0;32m    201\u001b[0m     model_config, custom_objects\u001b[39m=\u001b[39;49mcustom_objects\n\u001b[0;32m    202\u001b[0m )\n\u001b[0;32m    204\u001b[0m \u001b[39m# set weights\u001b[39;00m\n\u001b[0;32m    205\u001b[0m load_weights_from_hdf5_group(f[\u001b[39m\"\u001b[39m\u001b[39mmodel_weights\u001b[39m\u001b[39m\"\u001b[39m], model)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\model_config.py:55\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     49\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`model_from_config` expects a dictionary, not a list. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     50\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: config=\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m}\u001b[39;00m\u001b[39m. Did you meant to use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Sequential.from_config(config)`?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize\n\u001b[1;32m---> 55\u001b[0m \u001b[39mreturn\u001b[39;00m deserialize(config, custom_objects\u001b[39m=\u001b[39;49mcustom_objects)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\serialization.py:249\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \n\u001b[0;32m    214\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m populate_deserializable_objects()\n\u001b[1;32m--> 249\u001b[0m \u001b[39mreturn\u001b[39;00m generic_utils\u001b[39m.\u001b[39;49mdeserialize_keras_object(\n\u001b[0;32m    250\u001b[0m     config,\n\u001b[0;32m    251\u001b[0m     module_objects\u001b[39m=\u001b[39;49mLOCAL\u001b[39m.\u001b[39;49mALL_OBJECTS,\n\u001b[0;32m    252\u001b[0m     custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[0;32m    253\u001b[0m     printable_module_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlayer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    254\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\generic_utils.py:734\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    731\u001b[0m custom_objects \u001b[39m=\u001b[39m custom_objects \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m    733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcustom_objects\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m arg_spec\u001b[39m.\u001b[39margs:\n\u001b[1;32m--> 734\u001b[0m     deserialized_obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(\n\u001b[0;32m    735\u001b[0m         cls_config,\n\u001b[0;32m    736\u001b[0m         custom_objects\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[0;32m    737\u001b[0m             \u001b[39mlist\u001b[39;49m(_GLOBAL_CUSTOM_OBJECTS\u001b[39m.\u001b[39;49mitems())\n\u001b[0;32m    738\u001b[0m             \u001b[39m+\u001b[39;49m \u001b[39mlist\u001b[39;49m(_THREAD_LOCAL_CUSTOM_OBJECTS\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m\u001b[39m.\u001b[39;49mitems())\n\u001b[0;32m    739\u001b[0m             \u001b[39m+\u001b[39;49m \u001b[39mlist\u001b[39;49m(custom_objects\u001b[39m.\u001b[39;49mitems())\n\u001b[0;32m    740\u001b[0m         ),\n\u001b[0;32m    741\u001b[0m     )\n\u001b[0;32m    742\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    743\u001b[0m     \u001b[39mwith\u001b[39;00m CustomObjectScope(custom_objects):\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:3034\u001b[0m, in \u001b[0;36mModel.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m   3027\u001b[0m functional_model_keys \u001b[39m=\u001b[39m [\n\u001b[0;32m   3028\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3029\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlayers\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3030\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_layers\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3031\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_layers\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3032\u001b[0m ]\n\u001b[0;32m   3033\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(key \u001b[39min\u001b[39;00m config \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m functional_model_keys):\n\u001b[1;32m-> 3034\u001b[0m     inputs, outputs, layers \u001b[39m=\u001b[39m functional\u001b[39m.\u001b[39;49mreconstruct_from_config(\n\u001b[0;32m   3035\u001b[0m         config, custom_objects\n\u001b[0;32m   3036\u001b[0m     )\n\u001b[0;32m   3037\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[0;32m   3038\u001b[0m         inputs\u001b[39m=\u001b[39minputs, outputs\u001b[39m=\u001b[39moutputs, name\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3039\u001b[0m     )\n\u001b[0;32m   3040\u001b[0m     functional\u001b[39m.\u001b[39mconnect_ancillary_layers(model, layers)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py:1481\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[1;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[0;32m   1479\u001b[0m \u001b[39mwhile\u001b[39;00m layer_nodes:\n\u001b[0;32m   1480\u001b[0m     node_data \u001b[39m=\u001b[39m layer_nodes[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1481\u001b[0m     \u001b[39mif\u001b[39;00m process_node(layer, node_data):\n\u001b[0;32m   1482\u001b[0m         layer_nodes\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m)\n\u001b[0;32m   1483\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1484\u001b[0m         \u001b[39m# If a node can't be processed, stop processing the\u001b[39;00m\n\u001b[0;32m   1485\u001b[0m         \u001b[39m# nodes of the current layer to maintain node ordering.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py:1421\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[1;34m(layer, node_data)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m layer\u001b[39m.\u001b[39m_preserve_input_structure_in_config:\n\u001b[0;32m   1418\u001b[0m     input_tensors \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39munnest_if_single_tensor(\n\u001b[0;32m   1419\u001b[0m         input_tensors\n\u001b[0;32m   1420\u001b[0m     )\n\u001b[1;32m-> 1421\u001b[0m output_tensors \u001b[39m=\u001b[39m layer(input_tensors, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1423\u001b[0m \u001b[39m# Update node index map.\u001b[39;00m\n\u001b[0;32m   1424\u001b[0m output_index \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(output_tensors)[\n\u001b[0;32m   1425\u001b[0m     \u001b[39m0\u001b[39m\n\u001b[0;32m   1426\u001b[0m ]\u001b[39m.\u001b[39m_keras_history\u001b[39m.\u001b[39mnode_index\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py:1011\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[39m# on symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\n\u001b[0;32m   1009\u001b[0m     \u001b[39mself\u001b[39m, inputs, args, kwargs, input_list\n\u001b[0;32m   1010\u001b[0m ):\n\u001b[1;32m-> 1011\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(\n\u001b[0;32m   1012\u001b[0m         inputs, args, kwargs, input_list\n\u001b[0;32m   1013\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py:2498\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   2491\u001b[0m         training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   2494\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value\n\u001b[0;32m   2495\u001b[0m ):\n\u001b[0;32m   2496\u001b[0m     \u001b[39m# Check input assumptions set after layer building, e.g. input\u001b[39;00m\n\u001b[0;32m   2497\u001b[0m     \u001b[39m# shape.\u001b[39;00m\n\u001b[1;32m-> 2498\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[0;32m   2499\u001b[0m         inputs, input_masks, args, kwargs\n\u001b[0;32m   2500\u001b[0m     )\n\u001b[0;32m   2502\u001b[0m     \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2503\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2504\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2505\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2506\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2507\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py:2345\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m   2341\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   2342\u001b[0m         keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature\n\u001b[0;32m   2343\u001b[0m     )\n\u001b[0;32m   2344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(\n\u001b[0;32m   2346\u001b[0m         inputs, args, kwargs, input_masks\n\u001b[0;32m   2347\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py:2404\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m   2402\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m   2403\u001b[0m         inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m-> 2404\u001b[0m         outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m   2407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(\n\u001b[0;32m   2408\u001b[0m     inputs, outputs, input_masks, build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\merging\\base_merge.py:196\u001b[0m, in \u001b[0;36m_Merge.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[39mreturn\u001b[39;00m y\n\u001b[0;32m    195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_function(inputs)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\merging\\multiply.py:50\u001b[0m, in \u001b[0;36mMultiply._merge_function\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     48\u001b[0m output \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(inputs)):\n\u001b[1;32m---> 50\u001b[0m     output \u001b[39m=\u001b[39m output \u001b[39m*\u001b[39;49m inputs[i]\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1407\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1403\u001b[0m   \u001b[39m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m   \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m   \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m   x, y \u001b[39m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[1;32m-> 1407\u001b[0m   \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1408\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1409\u001b[0m   \u001b[39m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m   \u001b[39m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1413\u001b[0m   \u001b[39m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m   \u001b[39m# informative.\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mtype\u001b[39m(y), \u001b[39m\"\u001b[39m\u001b[39m__r\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m op_name):\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1767\u001b[0m, in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1765\u001b[0m   \u001b[39mreturn\u001b[39;00m sparse_tensor\u001b[39m.\u001b[39mSparseTensor(y\u001b[39m.\u001b[39mindices, new_vals, y\u001b[39m.\u001b[39mdense_shape)\n\u001b[0;32m   1766\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1767\u001b[0m   \u001b[39mreturn\u001b[39;00m multiply(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:529\u001b[0m, in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.multiply\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultiply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    481\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39mregister_binary_elementwise_api\n\u001b[0;32m    482\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmultiply\u001b[39m(x, y, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    484\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns an element-wise x * y.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[39m  For example:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[39m   * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 529\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmul(x, y, name)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6588\u001b[0m, in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6586\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   6587\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 6588\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   6589\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mMul\u001b[39;49m\u001b[39m\"\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   6590\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   6591\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3801\u001b[0m       node_def,\n\u001b[0;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2105\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   2107\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2108\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[0;32m   2111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aydin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1966\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1962\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1963\u001b[0m                                          serialized)\n\u001b[0;32m   1965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1966\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1967\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1968\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from scipy.stats import binom\n",
    "import gc\n",
    "\n",
    "# Garbage Collection (memory)\n",
    "gc.collect()\n",
    "\n",
    "Extra_EXT = \"_T\"  # _T or _T_BL\n",
    "prob_L = 0.9995\n",
    "tick_spacing = 5\n",
    "Train_data_test = False\n",
    "if SAVE_TYPE == \"TF\":\n",
    "    # Load the pre-trained model\n",
    "    model = load_model(f\"PAI_model{Extra_EXT}\")\n",
    "else:\n",
    "    # Load the pre-trained model\n",
    "    model = load_model(f\"PAI_model{Extra_EXT}.h5\")\n",
    "\n",
    "# Ensure the model's input_shape matches your data\n",
    "assert model.input_shape[1:] == (img_res[0], img_res[1], img_res[2]), \"Models input shape doesnt match data.\"\n",
    "\n",
    "# Make predictions on validation data\n",
    "val_predictions = model.predict(x_val)\n",
    "val_predictions = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# Make predictions on Train data\n",
    "if Train_data_test:\n",
    "    Train_predictions = model.predict(x_train)\n",
    "    Train_predictions = np.argmax(Train_predictions, axis=1)\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = model.predict(x_test)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Convert y_val and y_test from one-hot encoder to their original form\n",
    "y_val_original = np.argmax(y_val, axis=1)\n",
    "y_test_original = np.argmax(y_test, axis=1)\n",
    "if Train_data_test:\n",
    "    y_train_original = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Calculate accuracy on validation data\n",
    "val_accuracy = accuracy_score(y_val_original, val_predictions)\n",
    "\n",
    "# Calculate accuracy on Train data\n",
    "if Train_data_test:\n",
    "    Train_accuracy = accuracy_score(y_val_original, Train_predictions)\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_accuracy = accuracy_score(y_test_original, test_predictions)\n",
    "\n",
    "# Print acc\n",
    "if Train_data_test:\n",
    "    print(f\"The accuracy of the model on Train data is {Train_accuracy:.2%}\")\n",
    "print(f\"The accuracy of the model on validation data is {val_accuracy:.2%}\")\n",
    "print(f\"The accuracy of the model on test data is {test_accuracy:.2%}\")\n",
    "\n",
    "# Visualize the predictions on validation data as a grid of squares\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_val[i])\n",
    "    plt.title(f\"True: {y_val_original[i]}\\nPredicted: {val_predictions[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    img = x_val[i]\n",
    "    heatmap = make_gradcam_heatmap(img[np.newaxis, ...], model, \"top_conv\", sensitivity_map=2)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    # Apply Adaptive Histogram Equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(8, 8))  # Create CLAHE object\n",
    "    heatmap = clahe.apply(heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    if RANGE_NOM:\n",
    "        superimposed_img = (heatmap / 255) * 0.5 + img\n",
    "    else:\n",
    "        superimposed_img = (heatmap / 255) * 0.5 + (img / 255)\n",
    "    # clip\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 1)  # ensure the values are in the range [0, 1]\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.title(f\"True: {y_val_original[i]}\\nPredicted: {val_predictions[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define the list of labels\n",
    "labels = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "\n",
    "# Create a confusion matrix for validation data\n",
    "val_cm = confusion_matrix(y_val_original, val_predictions)\n",
    "\n",
    "# Create a confusion matrix for test data\n",
    "test_cm = confusion_matrix(y_test_original, test_predictions)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap for validation data\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(val_cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion Matrix - Validation Data\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the confusion matrix as a heatmap for test data\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(test_cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion Matrix - Test Data\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Define the range of test data sizes to use\n",
    "data_sizes = range(1, len(x_test), 4)\n",
    "# Calculate the probability of a wrong prediction based on test accuracy\n",
    "prob_wrong = 1 - test_accuracy\n",
    "\n",
    "# Create a list to store the number of incorrect predictions for each test data size\n",
    "incorrect_predictions = []\n",
    "\n",
    "# Generate predictions and track incorrect predictions for each data size\n",
    "for size in tqdm(data_sizes, desc=\"Predicting\", unit=\"dpb\"):\n",
    "    # Garbage Collection (memory)\n",
    "    gc.collect()\n",
    "    # Randomly select a subset of test data\n",
    "    indices = np.random.choice(len(x_test), size, replace=False)\n",
    "    x_test_subset = x_test[indices]\n",
    "    y_test_subset = y_test[indices]\n",
    "\n",
    "    # Make predictions on the subset of test data\n",
    "    test_predictions = model.predict(x_test_subset, batch_size=1, verbose=0, max_queue_size=120, workers=1, use_multiprocessing=False)\n",
    "    test_predictions = np.argmax(test_predictions, axis=1)\n",
    "    y_test_original_subset = np.argmax(y_test_subset, axis=1)\n",
    "\n",
    "    # Calculate the number of incorrect predictions\n",
    "    incorrect_preds = np.sum(test_predictions != y_test_original_subset)\n",
    "    incorrect_predictions.append(incorrect_preds)\n",
    "\n",
    "# Plot the number of incorrect predictions vs. the number of data points\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_sizes, incorrect_predictions)\n",
    "plt.xlabel(\"Number of Data Points\")\n",
    "plt.ylabel(\"Number of Incorrect Predictions\")\n",
    "# Add gridlines for the x and y axes\n",
    "plt.grid(True)\n",
    "\n",
    "# Change the tick spacing for the x and y axes\n",
    "plt.xticks(np.arange(min(data_sizes), max(data_sizes) + 1, 50))\n",
    "plt.yticks(np.arange(0, max(incorrect_predictions) + 5, 3))\n",
    "\n",
    "plt.title(\"Number of Incorrect Predictions vs. Number of Data Points\")\n",
    "plt.show()\n",
    "\n",
    "# Define the range of test data sizes to use\n",
    "data_sizes = range(1, len(x_test), 1)\n",
    "\n",
    "# Calculate the probability of a wrong prediction based on test accuracy\n",
    "prob_wrong = 1 - test_accuracy\n",
    "\n",
    "# Create a list to store the probability of getting at least one wrong answer for each test data size\n",
    "probabilities = []\n",
    "\n",
    "# Calculate the probability of getting at least one wrong answer for each data size\n",
    "for size in data_sizes:\n",
    "    # Calculate the cumulative distribution function (CDF) of the binomial distribution at 0\n",
    "    cdf = binom.cdf(0, size, prob_wrong)\n",
    "    # Subtract the CDF from 1 to get the probability of getting at least one wrong answer\n",
    "    prob = 1 - cdf\n",
    "    probabilities.append(prob)\n",
    "\n",
    "# Find the index of the first data point that has a probability greater than prob_L%\n",
    "index = next((i for i, p in enumerate(probabilities) if p > prob_L), len(probabilities))\n",
    "\n",
    "# Limit the x-axis to the first data point that has a probability greater than prob_L%\n",
    "data_sizes = data_sizes[: index + 1]\n",
    "probabilities = probabilities[: index + 1]\n",
    "\n",
    "# Plot the probability vs. the number of data points\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_sizes, probabilities)\n",
    "plt.xlabel(\"Number of Data Points\")\n",
    "plt.ylabel(\"Probability\")\n",
    "\n",
    "# Add gridlines for the x and y axes\n",
    "plt.grid(True)\n",
    "\n",
    "# Change the tick spacing for the x and y axes\n",
    "plt.xticks(np.arange(min(data_sizes), max(data_sizes) + 1, tick_spacing + 2))\n",
    "plt.yticks(np.arange(0, max(probabilities) + 0.1, tick_spacing / 100))\n",
    "\n",
    "plt.ylim(top=1.01)\n",
    "\n",
    "plt.title(\"Probability of Getting at Least One Wrong Answer vs. Number of Data Points\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
